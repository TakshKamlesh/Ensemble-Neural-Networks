{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "airplane severity",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQYjJ3ZtZsqZ",
        "colab_type": "code",
        "outputId": "3dab6558-5501-432b-e964-7469e1ae0c1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QETYptFJZzeC",
        "colab_type": "code",
        "outputId": "c3fead49-f106-4eb1-dcec-04816b92bc48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd gdrive/My Drive/airplane"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/airplane\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufZJI5gQaHEQ",
        "colab_type": "code",
        "outputId": "d694ed3b-bc0e-4cf6-c9d8-50a7b42f343c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8DH-1yimKQx",
        "colab_type": "code",
        "outputId": "b8587a3b-27fe-49c5-8f56-3a4ccb1b34a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        }
      },
      "source": [
        "!pip3 install --upgrade tensorflow"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: tensorflow in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.2.0,>=2.1.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.1.0)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.1.8)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.17.5)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.34.2)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<2.2.0,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.1.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.2)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow) (45.1.0)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (1.11.0)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.16.1)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.0)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2019.11.28)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsS75NG3aWAZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = pd.read_csv('train.csv')\n",
        "test_data = pd.read_csv('test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ArnvjCkaab4",
        "colab_type": "code",
        "outputId": "4ce9335d-5db5-4499-f779-7fd03ad9337e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Severity</th>\n",
              "      <th>Safety_Score</th>\n",
              "      <th>Days_Since_Inspection</th>\n",
              "      <th>Total_Safety_Complaints</th>\n",
              "      <th>Control_Metric</th>\n",
              "      <th>Turbulence_In_gforces</th>\n",
              "      <th>Cabin_Temperature</th>\n",
              "      <th>Accident_Type_Code</th>\n",
              "      <th>Max_Elevation</th>\n",
              "      <th>Violations</th>\n",
              "      <th>Adverse_Weather_Metric</th>\n",
              "      <th>Accident_ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Minor_Damage_And_Injuries</td>\n",
              "      <td>49.223744</td>\n",
              "      <td>14</td>\n",
              "      <td>22</td>\n",
              "      <td>71.285324</td>\n",
              "      <td>0.272118</td>\n",
              "      <td>78.04</td>\n",
              "      <td>2</td>\n",
              "      <td>31335.476824</td>\n",
              "      <td>3</td>\n",
              "      <td>0.424352</td>\n",
              "      <td>7570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Minor_Damage_And_Injuries</td>\n",
              "      <td>62.465753</td>\n",
              "      <td>10</td>\n",
              "      <td>27</td>\n",
              "      <td>72.288058</td>\n",
              "      <td>0.423939</td>\n",
              "      <td>84.54</td>\n",
              "      <td>2</td>\n",
              "      <td>26024.711057</td>\n",
              "      <td>2</td>\n",
              "      <td>0.352350</td>\n",
              "      <td>12128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Significant_Damage_And_Fatalities</td>\n",
              "      <td>63.059361</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "      <td>66.362808</td>\n",
              "      <td>0.322604</td>\n",
              "      <td>78.86</td>\n",
              "      <td>7</td>\n",
              "      <td>39269.053927</td>\n",
              "      <td>3</td>\n",
              "      <td>0.003364</td>\n",
              "      <td>2181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Significant_Damage_And_Serious_Injuries</td>\n",
              "      <td>48.082192</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>74.703737</td>\n",
              "      <td>0.337029</td>\n",
              "      <td>81.79</td>\n",
              "      <td>3</td>\n",
              "      <td>42771.499200</td>\n",
              "      <td>1</td>\n",
              "      <td>0.211728</td>\n",
              "      <td>5946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Significant_Damage_And_Fatalities</td>\n",
              "      <td>26.484018</td>\n",
              "      <td>13</td>\n",
              "      <td>25</td>\n",
              "      <td>47.948952</td>\n",
              "      <td>0.541140</td>\n",
              "      <td>77.16</td>\n",
              "      <td>3</td>\n",
              "      <td>35509.228515</td>\n",
              "      <td>2</td>\n",
              "      <td>0.176883</td>\n",
              "      <td>9054</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  Severity  ...  Accident_ID\n",
              "0                Minor_Damage_And_Injuries  ...         7570\n",
              "1                Minor_Damage_And_Injuries  ...        12128\n",
              "2        Significant_Damage_And_Fatalities  ...         2181\n",
              "3  Significant_Damage_And_Serious_Injuries  ...         5946\n",
              "4        Significant_Damage_And_Fatalities  ...         9054\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4EXx6aRah1v",
        "colab_type": "code",
        "outputId": "cd59eb2d-e257-4ed1-d4be-1ac30bdd10ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "test_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Safety_Score</th>\n",
              "      <th>Days_Since_Inspection</th>\n",
              "      <th>Total_Safety_Complaints</th>\n",
              "      <th>Control_Metric</th>\n",
              "      <th>Turbulence_In_gforces</th>\n",
              "      <th>Cabin_Temperature</th>\n",
              "      <th>Accident_Type_Code</th>\n",
              "      <th>Max_Elevation</th>\n",
              "      <th>Violations</th>\n",
              "      <th>Adverse_Weather_Metric</th>\n",
              "      <th>Accident_ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19.497717</td>\n",
              "      <td>16</td>\n",
              "      <td>6</td>\n",
              "      <td>72.151322</td>\n",
              "      <td>0.388959</td>\n",
              "      <td>78.32</td>\n",
              "      <td>4</td>\n",
              "      <td>37949.724386</td>\n",
              "      <td>2</td>\n",
              "      <td>0.069692</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>58.173516</td>\n",
              "      <td>15</td>\n",
              "      <td>3</td>\n",
              "      <td>64.585232</td>\n",
              "      <td>0.250841</td>\n",
              "      <td>78.60</td>\n",
              "      <td>7</td>\n",
              "      <td>30194.805567</td>\n",
              "      <td>2</td>\n",
              "      <td>0.002777</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>33.287671</td>\n",
              "      <td>15</td>\n",
              "      <td>3</td>\n",
              "      <td>64.721969</td>\n",
              "      <td>0.336669</td>\n",
              "      <td>86.96</td>\n",
              "      <td>6</td>\n",
              "      <td>17572.925484</td>\n",
              "      <td>1</td>\n",
              "      <td>0.004316</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.287671</td>\n",
              "      <td>21</td>\n",
              "      <td>5</td>\n",
              "      <td>66.362808</td>\n",
              "      <td>0.421775</td>\n",
              "      <td>80.86</td>\n",
              "      <td>3</td>\n",
              "      <td>40209.186341</td>\n",
              "      <td>2</td>\n",
              "      <td>0.199990</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10.867580</td>\n",
              "      <td>18</td>\n",
              "      <td>2</td>\n",
              "      <td>56.107566</td>\n",
              "      <td>0.313228</td>\n",
              "      <td>79.22</td>\n",
              "      <td>2</td>\n",
              "      <td>35495.525408</td>\n",
              "      <td>2</td>\n",
              "      <td>0.483696</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Safety_Score  Days_Since_Inspection  ...  Adverse_Weather_Metric  Accident_ID\n",
              "0     19.497717                     16  ...                0.069692            1\n",
              "1     58.173516                     15  ...                0.002777           10\n",
              "2     33.287671                     15  ...                0.004316           14\n",
              "3      3.287671                     21  ...                0.199990           17\n",
              "4     10.867580                     18  ...                0.483696           21\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOMIK29Aajdt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = train_data.drop(columns = ['Accident_ID'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ci-_4gqr2B_r",
        "colab_type": "code",
        "outputId": "00fbbdcc-c51b-4520-dfe5-915b67c01d75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Severity</th>\n",
              "      <th>Safety_Score</th>\n",
              "      <th>Days_Since_Inspection</th>\n",
              "      <th>Total_Safety_Complaints</th>\n",
              "      <th>Control_Metric</th>\n",
              "      <th>Turbulence_In_gforces</th>\n",
              "      <th>Cabin_Temperature</th>\n",
              "      <th>Accident_Type_Code</th>\n",
              "      <th>Max_Elevation</th>\n",
              "      <th>Violations</th>\n",
              "      <th>Adverse_Weather_Metric</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Minor_Damage_And_Injuries</td>\n",
              "      <td>49.223744</td>\n",
              "      <td>14</td>\n",
              "      <td>22</td>\n",
              "      <td>71.285324</td>\n",
              "      <td>0.272118</td>\n",
              "      <td>78.04</td>\n",
              "      <td>2</td>\n",
              "      <td>31335.476824</td>\n",
              "      <td>3</td>\n",
              "      <td>0.424352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Minor_Damage_And_Injuries</td>\n",
              "      <td>62.465753</td>\n",
              "      <td>10</td>\n",
              "      <td>27</td>\n",
              "      <td>72.288058</td>\n",
              "      <td>0.423939</td>\n",
              "      <td>84.54</td>\n",
              "      <td>2</td>\n",
              "      <td>26024.711057</td>\n",
              "      <td>2</td>\n",
              "      <td>0.352350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Significant_Damage_And_Fatalities</td>\n",
              "      <td>63.059361</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "      <td>66.362808</td>\n",
              "      <td>0.322604</td>\n",
              "      <td>78.86</td>\n",
              "      <td>7</td>\n",
              "      <td>39269.053927</td>\n",
              "      <td>3</td>\n",
              "      <td>0.003364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Significant_Damage_And_Serious_Injuries</td>\n",
              "      <td>48.082192</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>74.703737</td>\n",
              "      <td>0.337029</td>\n",
              "      <td>81.79</td>\n",
              "      <td>3</td>\n",
              "      <td>42771.499200</td>\n",
              "      <td>1</td>\n",
              "      <td>0.211728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Significant_Damage_And_Fatalities</td>\n",
              "      <td>26.484018</td>\n",
              "      <td>13</td>\n",
              "      <td>25</td>\n",
              "      <td>47.948952</td>\n",
              "      <td>0.541140</td>\n",
              "      <td>77.16</td>\n",
              "      <td>3</td>\n",
              "      <td>35509.228515</td>\n",
              "      <td>2</td>\n",
              "      <td>0.176883</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  Severity  ...  Adverse_Weather_Metric\n",
              "0                Minor_Damage_And_Injuries  ...                0.424352\n",
              "1                Minor_Damage_And_Injuries  ...                0.352350\n",
              "2        Significant_Damage_And_Fatalities  ...                0.003364\n",
              "3  Significant_Damage_And_Serious_Injuries  ...                0.211728\n",
              "4        Significant_Damage_And_Fatalities  ...                0.176883\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPVRhhCv8EpU",
        "colab_type": "code",
        "outputId": "d9e4ba87-b813-4224-af5e-6e1210f3195a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "atc = train_data.values[:,7]\n",
        "atc = atc -  1\n",
        "atcu = np.unique(atc)\n",
        "atcu"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tjzin6UstUAR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "atctc = np_utils.to_categorical(atc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bhC8WX9wnw4",
        "colab_type": "code",
        "outputId": "9697fb06-cc86-4aea-dc3a-b30c80fe4751",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "atctc[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NV-YnCkbCLa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y = train_data.values[:,0]\n",
        "classes = np.unique(Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXkB-0rkbC19",
        "colab_type": "code",
        "outputId": "dbf87cd9-2bad-43d6-cbe4-ce3da146f504",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "classes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Highly_Fatal_And_Damaging', 'Minor_Damage_And_Injuries',\n",
              "       'Significant_Damage_And_Fatalities',\n",
              "       'Significant_Damage_And_Serious_Injuries'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZwwJdSrbLti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_dict = {'Highly_Fatal_And_Damaging':0, 'Minor_Damage_And_Injuries':1,\n",
        "       'Significant_Damage_And_Fatalities':2,\n",
        "       'Significant_Damage_And_Serious_Injuries':3}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKlw1RbAO1hW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index_dict = {0:'Highly_Fatal_And_Damaging',1:'Minor_Damage_And_Injuries',2:'Significant_Damage_And_Fatalities',3:'Significant_Damage_And_Serious_Injuries'}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsHiTGdNbZ1E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = np.array([class_dict[i] for i in Y])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQWoBscvbjpH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = np_utils.to_categorical(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOLZPVX2bmSS",
        "colab_type": "code",
        "outputId": "a191f7e6-048d-4b55-ee69-958ccf06baa4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "y[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., 0.],\n",
              "       [0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0.],\n",
              "       [0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0.],\n",
              "       [0., 1., 0., 0.],\n",
              "       [1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0.],\n",
              "       [1., 0., 0., 0.],\n",
              "       [0., 0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aupNWMhUmVVX",
        "colab_type": "code",
        "outputId": "39187a65-0eac-47e8-9e50-5181a588c5ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2yw8B1-mcEF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = train_data.drop(columns = ['Accident_Type_Code'])\n",
        "X = train_data.values[:,1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvVTOVuTuVpf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rj4lnMbpIxKt",
        "colab_type": "code",
        "outputId": "30a7f64c-decd-48ea-88ea-dcdc5d9c936e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vADwGUV5uFXB",
        "colab_type": "code",
        "outputId": "244bbb27-b46d-492d-f782-0215e99e0d5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Xt = np.hstack((X, atctc))\n",
        "Xt.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 16)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "birhWirvv6eo",
        "colab_type": "code",
        "outputId": "b5990411-9de6-4e02-9b51-6e930112fa84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "Xt[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([49.2237442922374, 14, 22, 71.285323609845, 0.272117562206996,\n",
              "       78.04, 31335.4768243775, 3, 0.42435208330785296, 0.0, 1.0, 0.0,\n",
              "       0.0, 0.0, 0.0, 0.0], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAs1bDfCzLSC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "actT = test_data.values[:,6]\n",
        "actTu = np.unique(actT)\n",
        "actTu = actTu - 1\n",
        "actTct = np_utils.to_categorical(actT-1)\n",
        "XT = test_data.drop(columns = ['Accident_Type_Code']).values[:,:-1]\n",
        "XTT = np.hstack((XT , actTct))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b66D3f02yT_k",
        "colab_type": "code",
        "outputId": "ebc611b6-b4d4-4317-f1d2-475047e1c4de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "XTT[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.94977169e+01, 1.60000000e+01, 6.00000000e+00, 7.21513218e+01,\n",
              "       3.88958529e-01, 7.83200000e+01, 3.79497244e+04, 2.00000000e+00,\n",
              "       6.96924473e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
              "       1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bmu1aQeEo24-",
        "colab_type": "code",
        "outputId": "862b55ca-c51f-45af-97d2-a46700613340",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "acc_ids[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCfY2c1d0n1k",
        "colab_type": "code",
        "outputId": "fa97acb0-3ba0-48d7-f646-0f1b5caa1cf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "XTT.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2500, 16)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4TL6p8KzWbR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X2 = Xt\n",
        "XT2 = XTT"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0EmR7jIzB-R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(9):\n",
        "\n",
        "  t_mean = X[:,i].mean(axis = 0)\n",
        "  t_std = X[:,i].std(axis = 0)\n",
        "  X2[:, i] = (X[:,i] - t_mean)/t_std\n",
        "  XT2[:,i] = (XT[: , i] - t_mean)/t_std "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekrNlRNPcQ8l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X2, y ,test_size = 0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OI0CrNYvq7op",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = np.array(X_train , dtype= 'float16')\n",
        "X_test = np.asarray(X_test , dtype = 'float16')\n",
        "y_train = np.asarray(y_train , dtype = 'int')\n",
        "y_test = np.asarray(y_test , dtype = 'int')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYzUF18_rzb1",
        "colab_type": "code",
        "outputId": "90b9bb9a-ac56-4451-b761-b9e99a101358",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "X_train[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.2664, -0.828 ,  0.78  ,  0.4016, -0.616 , -0.2498,  1.1045,\n",
              "        0.9497, -0.4688,  0.    ,  0.    ,  0.    ,  1.    ,  0.    ,\n",
              "        0.    ,  0.    ], dtype=float16)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPXzzYNuMOwe",
        "colab_type": "code",
        "outputId": "ba912aa1-365f-4166-cd23-6cb89fef30fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnc51rdxqB89",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "es = tf.keras.callbacks.EarlyStopping(monitor = 'accuracy')\n",
        "optimizer = tf.keras.optimizers.Adadelta()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tN22u1m9XsU1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_layer = tf.keras.layers.Input((11,))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FL6RzGbXeAxc",
        "colab_type": "code",
        "outputId": "3675c3e8-4e3f-4868-ecdd-ae75a0a7e30a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "model1 = tf.keras.models.Sequential()\n",
        "model1.add(tf.keras.layers.Dense(6 , input_shape = (16,)))\n",
        "model1.add(tf.keras.layers.Dense(10,activation = 'relu'))\n",
        "model1.add(tf.keras.layers.Dropout(0.3))\n",
        "model1.add(tf.keras.layers.Dense(4 , activation = 'softmax'))\n",
        "model1.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
        "model1.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 6)                 102       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                70        \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 4)                 44        \n",
            "=================================================================\n",
            "Total params: 216\n",
            "Trainable params: 216\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBy5-XVynxP5",
        "colab_type": "code",
        "outputId": "2192b3a4-797e-4f8c-8c3e-110480e0169e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history1 = model1.fit(X_train, y_train, batch_size  = 200, epochs = 500 ,  validation_data = [X_test, y_test] , shuffle= True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8000 samples, validate on 2000 samples\n",
            "Epoch 1/500\n",
            "8000/8000 [==============================] - 2s 247us/sample - loss: 1.4711 - accuracy: 0.2841 - val_loss: 1.3934 - val_accuracy: 0.3365\n",
            "Epoch 2/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 1.3911 - accuracy: 0.3429 - val_loss: 1.3356 - val_accuracy: 0.3780\n",
            "Epoch 3/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 1.3303 - accuracy: 0.3689 - val_loss: 1.2881 - val_accuracy: 0.4135\n",
            "Epoch 4/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 1.2859 - accuracy: 0.4053 - val_loss: 1.2442 - val_accuracy: 0.4550\n",
            "Epoch 5/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 1.2506 - accuracy: 0.4252 - val_loss: 1.2008 - val_accuracy: 0.4905\n",
            "Epoch 6/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 1.2130 - accuracy: 0.4505 - val_loss: 1.1555 - val_accuracy: 0.5260\n",
            "Epoch 7/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 1.1673 - accuracy: 0.4915 - val_loss: 1.1065 - val_accuracy: 0.5690\n",
            "Epoch 8/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 1.1300 - accuracy: 0.5048 - val_loss: 1.0568 - val_accuracy: 0.5930\n",
            "Epoch 9/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 1.0854 - accuracy: 0.5274 - val_loss: 1.0049 - val_accuracy: 0.6075\n",
            "Epoch 10/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 1.0425 - accuracy: 0.5436 - val_loss: 0.9543 - val_accuracy: 0.6115\n",
            "Epoch 11/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.9987 - accuracy: 0.5610 - val_loss: 0.9057 - val_accuracy: 0.6240\n",
            "Epoch 12/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.9615 - accuracy: 0.5847 - val_loss: 0.8599 - val_accuracy: 0.6480\n",
            "Epoch 13/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.9209 - accuracy: 0.6135 - val_loss: 0.8229 - val_accuracy: 0.6760\n",
            "Epoch 14/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.9012 - accuracy: 0.6225 - val_loss: 0.7893 - val_accuracy: 0.6935\n",
            "Epoch 15/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.8709 - accuracy: 0.6378 - val_loss: 0.7593 - val_accuracy: 0.7055\n",
            "Epoch 16/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.8464 - accuracy: 0.6441 - val_loss: 0.7325 - val_accuracy: 0.7250\n",
            "Epoch 17/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.8255 - accuracy: 0.6550 - val_loss: 0.7090 - val_accuracy: 0.7330\n",
            "Epoch 18/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.8149 - accuracy: 0.6568 - val_loss: 0.6882 - val_accuracy: 0.7460\n",
            "Epoch 19/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.7944 - accuracy: 0.6701 - val_loss: 0.6694 - val_accuracy: 0.7565\n",
            "Epoch 20/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.7776 - accuracy: 0.6820 - val_loss: 0.6514 - val_accuracy: 0.7655\n",
            "Epoch 21/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.7627 - accuracy: 0.6856 - val_loss: 0.6341 - val_accuracy: 0.7720\n",
            "Epoch 22/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.7417 - accuracy: 0.6977 - val_loss: 0.6175 - val_accuracy: 0.7805\n",
            "Epoch 23/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.7363 - accuracy: 0.7015 - val_loss: 0.6043 - val_accuracy: 0.7850\n",
            "Epoch 24/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.7222 - accuracy: 0.6996 - val_loss: 0.5911 - val_accuracy: 0.7910\n",
            "Epoch 25/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.7216 - accuracy: 0.7079 - val_loss: 0.5816 - val_accuracy: 0.7925\n",
            "Epoch 26/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.7014 - accuracy: 0.7120 - val_loss: 0.5710 - val_accuracy: 0.7975\n",
            "Epoch 27/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.7021 - accuracy: 0.7125 - val_loss: 0.5617 - val_accuracy: 0.7965\n",
            "Epoch 28/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.6917 - accuracy: 0.7147 - val_loss: 0.5536 - val_accuracy: 0.7960\n",
            "Epoch 29/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.6894 - accuracy: 0.7149 - val_loss: 0.5477 - val_accuracy: 0.7990\n",
            "Epoch 30/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.6809 - accuracy: 0.7226 - val_loss: 0.5411 - val_accuracy: 0.8035\n",
            "Epoch 31/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.6768 - accuracy: 0.7200 - val_loss: 0.5335 - val_accuracy: 0.8070\n",
            "Epoch 32/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.6774 - accuracy: 0.7150 - val_loss: 0.5295 - val_accuracy: 0.8085\n",
            "Epoch 33/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.6826 - accuracy: 0.7214 - val_loss: 0.5257 - val_accuracy: 0.8075\n",
            "Epoch 34/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.6687 - accuracy: 0.7260 - val_loss: 0.5205 - val_accuracy: 0.8055\n",
            "Epoch 35/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.6582 - accuracy: 0.7304 - val_loss: 0.5172 - val_accuracy: 0.8060\n",
            "Epoch 36/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.6643 - accuracy: 0.7260 - val_loss: 0.5126 - val_accuracy: 0.8080\n",
            "Epoch 37/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.6610 - accuracy: 0.7260 - val_loss: 0.5101 - val_accuracy: 0.8080\n",
            "Epoch 38/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.6501 - accuracy: 0.7335 - val_loss: 0.5046 - val_accuracy: 0.8095\n",
            "Epoch 39/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.6495 - accuracy: 0.7293 - val_loss: 0.5010 - val_accuracy: 0.8110\n",
            "Epoch 40/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.6605 - accuracy: 0.7240 - val_loss: 0.4992 - val_accuracy: 0.8130\n",
            "Epoch 41/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.6613 - accuracy: 0.7251 - val_loss: 0.4963 - val_accuracy: 0.8135\n",
            "Epoch 42/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.6413 - accuracy: 0.7370 - val_loss: 0.4929 - val_accuracy: 0.8155\n",
            "Epoch 43/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.6333 - accuracy: 0.7401 - val_loss: 0.4906 - val_accuracy: 0.8145\n",
            "Epoch 44/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.6442 - accuracy: 0.7325 - val_loss: 0.4901 - val_accuracy: 0.8140\n",
            "Epoch 45/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.6459 - accuracy: 0.7326 - val_loss: 0.4896 - val_accuracy: 0.8150\n",
            "Epoch 46/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.6416 - accuracy: 0.7355 - val_loss: 0.4845 - val_accuracy: 0.8155\n",
            "Epoch 47/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.6461 - accuracy: 0.7345 - val_loss: 0.4841 - val_accuracy: 0.8185\n",
            "Epoch 48/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.6371 - accuracy: 0.7380 - val_loss: 0.4815 - val_accuracy: 0.8165\n",
            "Epoch 49/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.6382 - accuracy: 0.7364 - val_loss: 0.4801 - val_accuracy: 0.8180\n",
            "Epoch 50/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.6413 - accuracy: 0.7330 - val_loss: 0.4806 - val_accuracy: 0.8170\n",
            "Epoch 51/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.6307 - accuracy: 0.7383 - val_loss: 0.4763 - val_accuracy: 0.8175\n",
            "Epoch 52/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.6333 - accuracy: 0.7390 - val_loss: 0.4756 - val_accuracy: 0.8180\n",
            "Epoch 53/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.6269 - accuracy: 0.7410 - val_loss: 0.4737 - val_accuracy: 0.8195\n",
            "Epoch 54/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.6459 - accuracy: 0.7325 - val_loss: 0.4729 - val_accuracy: 0.8205\n",
            "Epoch 55/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.6286 - accuracy: 0.7384 - val_loss: 0.4732 - val_accuracy: 0.8200\n",
            "Epoch 56/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.6246 - accuracy: 0.7456 - val_loss: 0.4721 - val_accuracy: 0.8185\n",
            "Epoch 57/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.6393 - accuracy: 0.7375 - val_loss: 0.4729 - val_accuracy: 0.8200\n",
            "Epoch 58/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.6300 - accuracy: 0.7421 - val_loss: 0.4712 - val_accuracy: 0.8200\n",
            "Epoch 59/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.6223 - accuracy: 0.7435 - val_loss: 0.4702 - val_accuracy: 0.8190\n",
            "Epoch 60/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.6160 - accuracy: 0.7479 - val_loss: 0.4654 - val_accuracy: 0.8200\n",
            "Epoch 61/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.6314 - accuracy: 0.7430 - val_loss: 0.4669 - val_accuracy: 0.8200\n",
            "Epoch 62/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.6265 - accuracy: 0.7444 - val_loss: 0.4651 - val_accuracy: 0.8215\n",
            "Epoch 63/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.6219 - accuracy: 0.7464 - val_loss: 0.4647 - val_accuracy: 0.8225\n",
            "Epoch 64/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.6294 - accuracy: 0.7487 - val_loss: 0.4654 - val_accuracy: 0.8195\n",
            "Epoch 65/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.6167 - accuracy: 0.7446 - val_loss: 0.4625 - val_accuracy: 0.8205\n",
            "Epoch 66/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.6246 - accuracy: 0.7427 - val_loss: 0.4624 - val_accuracy: 0.8215\n",
            "Epoch 67/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.6326 - accuracy: 0.7415 - val_loss: 0.4617 - val_accuracy: 0.8200\n",
            "Epoch 68/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.6169 - accuracy: 0.7445 - val_loss: 0.4613 - val_accuracy: 0.8215\n",
            "Epoch 69/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.6244 - accuracy: 0.7499 - val_loss: 0.4639 - val_accuracy: 0.8205\n",
            "Epoch 70/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.6299 - accuracy: 0.7418 - val_loss: 0.4606 - val_accuracy: 0.8215\n",
            "Epoch 71/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.6259 - accuracy: 0.7399 - val_loss: 0.4618 - val_accuracy: 0.8225\n",
            "Epoch 72/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.6204 - accuracy: 0.7462 - val_loss: 0.4607 - val_accuracy: 0.8245\n",
            "Epoch 73/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.6232 - accuracy: 0.7489 - val_loss: 0.4613 - val_accuracy: 0.8230\n",
            "Epoch 74/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.6123 - accuracy: 0.7496 - val_loss: 0.4587 - val_accuracy: 0.8225\n",
            "Epoch 75/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.6150 - accuracy: 0.7514 - val_loss: 0.4562 - val_accuracy: 0.8210\n",
            "Epoch 76/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.6242 - accuracy: 0.7456 - val_loss: 0.4539 - val_accuracy: 0.8225\n",
            "Epoch 77/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.6151 - accuracy: 0.7455 - val_loss: 0.4551 - val_accuracy: 0.8255\n",
            "Epoch 78/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.6083 - accuracy: 0.7517 - val_loss: 0.4553 - val_accuracy: 0.8235\n",
            "Epoch 79/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.6105 - accuracy: 0.7476 - val_loss: 0.4537 - val_accuracy: 0.8235\n",
            "Epoch 80/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.6114 - accuracy: 0.7513 - val_loss: 0.4525 - val_accuracy: 0.8260\n",
            "Epoch 81/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.6113 - accuracy: 0.7467 - val_loss: 0.4529 - val_accuracy: 0.8250\n",
            "Epoch 82/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.6163 - accuracy: 0.7466 - val_loss: 0.4531 - val_accuracy: 0.8290\n",
            "Epoch 83/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.6126 - accuracy: 0.7516 - val_loss: 0.4518 - val_accuracy: 0.8275\n",
            "Epoch 84/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.6105 - accuracy: 0.7542 - val_loss: 0.4509 - val_accuracy: 0.8285\n",
            "Epoch 85/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.6183 - accuracy: 0.7466 - val_loss: 0.4529 - val_accuracy: 0.8255\n",
            "Epoch 86/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.6191 - accuracy: 0.7467 - val_loss: 0.4531 - val_accuracy: 0.8270\n",
            "Epoch 87/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.6176 - accuracy: 0.7502 - val_loss: 0.4545 - val_accuracy: 0.8285\n",
            "Epoch 88/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.6203 - accuracy: 0.7489 - val_loss: 0.4544 - val_accuracy: 0.8250\n",
            "Epoch 89/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.6113 - accuracy: 0.7511 - val_loss: 0.4514 - val_accuracy: 0.8290\n",
            "Epoch 90/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.6035 - accuracy: 0.7540 - val_loss: 0.4496 - val_accuracy: 0.8285\n",
            "Epoch 91/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.6084 - accuracy: 0.7567 - val_loss: 0.4510 - val_accuracy: 0.8260\n",
            "Epoch 92/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.6156 - accuracy: 0.7517 - val_loss: 0.4506 - val_accuracy: 0.8265\n",
            "Epoch 93/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5992 - accuracy: 0.7564 - val_loss: 0.4496 - val_accuracy: 0.8275\n",
            "Epoch 94/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.6123 - accuracy: 0.7514 - val_loss: 0.4472 - val_accuracy: 0.8295\n",
            "Epoch 95/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.6026 - accuracy: 0.7534 - val_loss: 0.4460 - val_accuracy: 0.8295\n",
            "Epoch 96/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.6130 - accuracy: 0.7508 - val_loss: 0.4478 - val_accuracy: 0.8275\n",
            "Epoch 97/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5969 - accuracy: 0.7560 - val_loss: 0.4483 - val_accuracy: 0.8275\n",
            "Epoch 98/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.6160 - accuracy: 0.7500 - val_loss: 0.4461 - val_accuracy: 0.8280\n",
            "Epoch 99/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.6057 - accuracy: 0.7508 - val_loss: 0.4471 - val_accuracy: 0.8285\n",
            "Epoch 100/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.6156 - accuracy: 0.7495 - val_loss: 0.4482 - val_accuracy: 0.8295\n",
            "Epoch 101/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.6067 - accuracy: 0.7538 - val_loss: 0.4484 - val_accuracy: 0.8275\n",
            "Epoch 102/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5964 - accuracy: 0.7565 - val_loss: 0.4469 - val_accuracy: 0.8290\n",
            "Epoch 103/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5965 - accuracy: 0.7609 - val_loss: 0.4474 - val_accuracy: 0.8275\n",
            "Epoch 104/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.6060 - accuracy: 0.7580 - val_loss: 0.4450 - val_accuracy: 0.8270\n",
            "Epoch 105/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.6069 - accuracy: 0.7520 - val_loss: 0.4428 - val_accuracy: 0.8300\n",
            "Epoch 106/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.6109 - accuracy: 0.7476 - val_loss: 0.4446 - val_accuracy: 0.8285\n",
            "Epoch 107/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.6032 - accuracy: 0.7540 - val_loss: 0.4451 - val_accuracy: 0.8310\n",
            "Epoch 108/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.6110 - accuracy: 0.7624 - val_loss: 0.4465 - val_accuracy: 0.8310\n",
            "Epoch 109/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.6003 - accuracy: 0.7596 - val_loss: 0.4438 - val_accuracy: 0.8320\n",
            "Epoch 110/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.6067 - accuracy: 0.7540 - val_loss: 0.4426 - val_accuracy: 0.8335\n",
            "Epoch 111/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5979 - accuracy: 0.7614 - val_loss: 0.4414 - val_accuracy: 0.8315\n",
            "Epoch 112/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5928 - accuracy: 0.7589 - val_loss: 0.4406 - val_accuracy: 0.8310\n",
            "Epoch 113/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5890 - accuracy: 0.7624 - val_loss: 0.4376 - val_accuracy: 0.8330\n",
            "Epoch 114/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.6059 - accuracy: 0.7589 - val_loss: 0.4400 - val_accuracy: 0.8320\n",
            "Epoch 115/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5829 - accuracy: 0.7661 - val_loss: 0.4394 - val_accuracy: 0.8345\n",
            "Epoch 116/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.6019 - accuracy: 0.7663 - val_loss: 0.4396 - val_accuracy: 0.8325\n",
            "Epoch 117/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5923 - accuracy: 0.7694 - val_loss: 0.4345 - val_accuracy: 0.8335\n",
            "Epoch 118/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.6030 - accuracy: 0.7669 - val_loss: 0.4378 - val_accuracy: 0.8335\n",
            "Epoch 119/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5901 - accuracy: 0.7661 - val_loss: 0.4372 - val_accuracy: 0.8370\n",
            "Epoch 120/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5870 - accuracy: 0.7646 - val_loss: 0.4374 - val_accuracy: 0.8345\n",
            "Epoch 121/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5744 - accuracy: 0.7667 - val_loss: 0.4323 - val_accuracy: 0.8365\n",
            "Epoch 122/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5802 - accuracy: 0.7653 - val_loss: 0.4331 - val_accuracy: 0.8360\n",
            "Epoch 123/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5797 - accuracy: 0.7682 - val_loss: 0.4306 - val_accuracy: 0.8360\n",
            "Epoch 124/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5756 - accuracy: 0.7697 - val_loss: 0.4275 - val_accuracy: 0.8385\n",
            "Epoch 125/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5826 - accuracy: 0.7678 - val_loss: 0.4285 - val_accuracy: 0.8380\n",
            "Epoch 126/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5667 - accuracy: 0.7734 - val_loss: 0.4268 - val_accuracy: 0.8375\n",
            "Epoch 127/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5692 - accuracy: 0.7722 - val_loss: 0.4260 - val_accuracy: 0.8390\n",
            "Epoch 128/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5671 - accuracy: 0.7746 - val_loss: 0.4234 - val_accuracy: 0.8400\n",
            "Epoch 129/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5722 - accuracy: 0.7779 - val_loss: 0.4224 - val_accuracy: 0.8405\n",
            "Epoch 130/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5677 - accuracy: 0.7796 - val_loss: 0.4236 - val_accuracy: 0.8390\n",
            "Epoch 131/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.5589 - accuracy: 0.7857 - val_loss: 0.4212 - val_accuracy: 0.8375\n",
            "Epoch 132/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5496 - accuracy: 0.7844 - val_loss: 0.4196 - val_accuracy: 0.8405\n",
            "Epoch 133/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5553 - accuracy: 0.7894 - val_loss: 0.4169 - val_accuracy: 0.8405\n",
            "Epoch 134/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5616 - accuracy: 0.7880 - val_loss: 0.4185 - val_accuracy: 0.8415\n",
            "Epoch 135/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5659 - accuracy: 0.7857 - val_loss: 0.4207 - val_accuracy: 0.8410\n",
            "Epoch 136/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5661 - accuracy: 0.7824 - val_loss: 0.4216 - val_accuracy: 0.8390\n",
            "Epoch 137/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.5611 - accuracy: 0.7825 - val_loss: 0.4187 - val_accuracy: 0.8410\n",
            "Epoch 138/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5583 - accuracy: 0.7871 - val_loss: 0.4180 - val_accuracy: 0.8390\n",
            "Epoch 139/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5687 - accuracy: 0.7825 - val_loss: 0.4194 - val_accuracy: 0.8375\n",
            "Epoch 140/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5564 - accuracy: 0.7883 - val_loss: 0.4182 - val_accuracy: 0.8390\n",
            "Epoch 141/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5639 - accuracy: 0.7814 - val_loss: 0.4165 - val_accuracy: 0.8410\n",
            "Epoch 142/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.5486 - accuracy: 0.7875 - val_loss: 0.4153 - val_accuracy: 0.8415\n",
            "Epoch 143/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5484 - accuracy: 0.7884 - val_loss: 0.4163 - val_accuracy: 0.8395\n",
            "Epoch 144/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5596 - accuracy: 0.7871 - val_loss: 0.4152 - val_accuracy: 0.8415\n",
            "Epoch 145/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5629 - accuracy: 0.7846 - val_loss: 0.4160 - val_accuracy: 0.8425\n",
            "Epoch 146/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5548 - accuracy: 0.7884 - val_loss: 0.4153 - val_accuracy: 0.8410\n",
            "Epoch 147/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5508 - accuracy: 0.7884 - val_loss: 0.4139 - val_accuracy: 0.8385\n",
            "Epoch 148/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5602 - accuracy: 0.7836 - val_loss: 0.4139 - val_accuracy: 0.8370\n",
            "Epoch 149/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5600 - accuracy: 0.7779 - val_loss: 0.4149 - val_accuracy: 0.8405\n",
            "Epoch 150/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5639 - accuracy: 0.7860 - val_loss: 0.4123 - val_accuracy: 0.8430\n",
            "Epoch 151/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5612 - accuracy: 0.7850 - val_loss: 0.4114 - val_accuracy: 0.8400\n",
            "Epoch 152/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5639 - accuracy: 0.7822 - val_loss: 0.4113 - val_accuracy: 0.8380\n",
            "Epoch 153/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5609 - accuracy: 0.7837 - val_loss: 0.4125 - val_accuracy: 0.8400\n",
            "Epoch 154/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5699 - accuracy: 0.7857 - val_loss: 0.4166 - val_accuracy: 0.8355\n",
            "Epoch 155/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5644 - accuracy: 0.7819 - val_loss: 0.4146 - val_accuracy: 0.8405\n",
            "Epoch 156/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5502 - accuracy: 0.7905 - val_loss: 0.4129 - val_accuracy: 0.8405\n",
            "Epoch 157/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5487 - accuracy: 0.7870 - val_loss: 0.4122 - val_accuracy: 0.8385\n",
            "Epoch 158/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.5481 - accuracy: 0.7925 - val_loss: 0.4103 - val_accuracy: 0.8415\n",
            "Epoch 159/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5590 - accuracy: 0.7820 - val_loss: 0.4114 - val_accuracy: 0.8390\n",
            "Epoch 160/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5702 - accuracy: 0.7814 - val_loss: 0.4117 - val_accuracy: 0.8385\n",
            "Epoch 161/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5553 - accuracy: 0.7839 - val_loss: 0.4131 - val_accuracy: 0.8365\n",
            "Epoch 162/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5612 - accuracy: 0.7840 - val_loss: 0.4101 - val_accuracy: 0.8405\n",
            "Epoch 163/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5549 - accuracy: 0.7846 - val_loss: 0.4115 - val_accuracy: 0.8385\n",
            "Epoch 164/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5494 - accuracy: 0.7862 - val_loss: 0.4101 - val_accuracy: 0.8390\n",
            "Epoch 165/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5403 - accuracy: 0.7894 - val_loss: 0.4086 - val_accuracy: 0.8390\n",
            "Epoch 166/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5494 - accuracy: 0.7857 - val_loss: 0.4090 - val_accuracy: 0.8400\n",
            "Epoch 167/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5556 - accuracy: 0.7851 - val_loss: 0.4080 - val_accuracy: 0.8410\n",
            "Epoch 168/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5467 - accuracy: 0.7875 - val_loss: 0.4072 - val_accuracy: 0.8425\n",
            "Epoch 169/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5583 - accuracy: 0.7865 - val_loss: 0.4078 - val_accuracy: 0.8450\n",
            "Epoch 170/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.5454 - accuracy: 0.7861 - val_loss: 0.4093 - val_accuracy: 0.8390\n",
            "Epoch 171/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5511 - accuracy: 0.7896 - val_loss: 0.4096 - val_accuracy: 0.8425\n",
            "Epoch 172/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5544 - accuracy: 0.7837 - val_loss: 0.4087 - val_accuracy: 0.8380\n",
            "Epoch 173/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5499 - accuracy: 0.7896 - val_loss: 0.4071 - val_accuracy: 0.8430\n",
            "Epoch 174/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5672 - accuracy: 0.7883 - val_loss: 0.4074 - val_accuracy: 0.8430\n",
            "Epoch 175/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5674 - accuracy: 0.7816 - val_loss: 0.4104 - val_accuracy: 0.8445\n",
            "Epoch 176/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5555 - accuracy: 0.7879 - val_loss: 0.4110 - val_accuracy: 0.8415\n",
            "Epoch 177/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.5474 - accuracy: 0.7901 - val_loss: 0.4086 - val_accuracy: 0.8435\n",
            "Epoch 178/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5585 - accuracy: 0.7876 - val_loss: 0.4098 - val_accuracy: 0.8420\n",
            "Epoch 179/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5594 - accuracy: 0.7824 - val_loss: 0.4093 - val_accuracy: 0.8385\n",
            "Epoch 180/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5552 - accuracy: 0.7869 - val_loss: 0.4087 - val_accuracy: 0.8390\n",
            "Epoch 181/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5488 - accuracy: 0.7875 - val_loss: 0.4084 - val_accuracy: 0.8415\n",
            "Epoch 182/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5566 - accuracy: 0.7804 - val_loss: 0.4087 - val_accuracy: 0.8420\n",
            "Epoch 183/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5458 - accuracy: 0.7931 - val_loss: 0.4063 - val_accuracy: 0.8430\n",
            "Epoch 184/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5465 - accuracy: 0.7879 - val_loss: 0.4076 - val_accuracy: 0.8405\n",
            "Epoch 185/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5406 - accuracy: 0.7925 - val_loss: 0.4050 - val_accuracy: 0.8420\n",
            "Epoch 186/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5610 - accuracy: 0.7847 - val_loss: 0.4069 - val_accuracy: 0.8400\n",
            "Epoch 187/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5599 - accuracy: 0.7845 - val_loss: 0.4089 - val_accuracy: 0.8395\n",
            "Epoch 188/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5641 - accuracy: 0.7836 - val_loss: 0.4086 - val_accuracy: 0.8440\n",
            "Epoch 189/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.5527 - accuracy: 0.7894 - val_loss: 0.4070 - val_accuracy: 0.8440\n",
            "Epoch 190/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5507 - accuracy: 0.7859 - val_loss: 0.4068 - val_accuracy: 0.8440\n",
            "Epoch 191/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5544 - accuracy: 0.7846 - val_loss: 0.4080 - val_accuracy: 0.8430\n",
            "Epoch 192/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5537 - accuracy: 0.7870 - val_loss: 0.4082 - val_accuracy: 0.8410\n",
            "Epoch 193/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5505 - accuracy: 0.7906 - val_loss: 0.4064 - val_accuracy: 0.8400\n",
            "Epoch 194/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5527 - accuracy: 0.7894 - val_loss: 0.4074 - val_accuracy: 0.8410\n",
            "Epoch 195/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5704 - accuracy: 0.7789 - val_loss: 0.4094 - val_accuracy: 0.8390\n",
            "Epoch 196/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5521 - accuracy: 0.7847 - val_loss: 0.4081 - val_accuracy: 0.8415\n",
            "Epoch 197/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5467 - accuracy: 0.7885 - val_loss: 0.4064 - val_accuracy: 0.8430\n",
            "Epoch 198/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5489 - accuracy: 0.7859 - val_loss: 0.4074 - val_accuracy: 0.8400\n",
            "Epoch 199/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5632 - accuracy: 0.7855 - val_loss: 0.4076 - val_accuracy: 0.8435\n",
            "Epoch 200/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5546 - accuracy: 0.7819 - val_loss: 0.4079 - val_accuracy: 0.8395\n",
            "Epoch 201/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5456 - accuracy: 0.7849 - val_loss: 0.4072 - val_accuracy: 0.8380\n",
            "Epoch 202/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5523 - accuracy: 0.7905 - val_loss: 0.4070 - val_accuracy: 0.8375\n",
            "Epoch 203/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5581 - accuracy: 0.7822 - val_loss: 0.4065 - val_accuracy: 0.8400\n",
            "Epoch 204/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5554 - accuracy: 0.7850 - val_loss: 0.4072 - val_accuracy: 0.8420\n",
            "Epoch 205/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5627 - accuracy: 0.7861 - val_loss: 0.4069 - val_accuracy: 0.8390\n",
            "Epoch 206/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5389 - accuracy: 0.7914 - val_loss: 0.4073 - val_accuracy: 0.8395\n",
            "Epoch 207/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5540 - accuracy: 0.7856 - val_loss: 0.4064 - val_accuracy: 0.8410\n",
            "Epoch 208/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.5570 - accuracy: 0.7851 - val_loss: 0.4078 - val_accuracy: 0.8425\n",
            "Epoch 209/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5548 - accuracy: 0.7874 - val_loss: 0.4077 - val_accuracy: 0.8405\n",
            "Epoch 210/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5466 - accuracy: 0.7908 - val_loss: 0.4063 - val_accuracy: 0.8415\n",
            "Epoch 211/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5573 - accuracy: 0.7851 - val_loss: 0.4089 - val_accuracy: 0.8395\n",
            "Epoch 212/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5463 - accuracy: 0.7893 - val_loss: 0.4061 - val_accuracy: 0.8415\n",
            "Epoch 213/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5659 - accuracy: 0.7862 - val_loss: 0.4074 - val_accuracy: 0.8400\n",
            "Epoch 214/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5589 - accuracy: 0.7830 - val_loss: 0.4065 - val_accuracy: 0.8430\n",
            "Epoch 215/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5464 - accuracy: 0.7904 - val_loss: 0.4049 - val_accuracy: 0.8410\n",
            "Epoch 216/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5406 - accuracy: 0.7935 - val_loss: 0.4032 - val_accuracy: 0.8430\n",
            "Epoch 217/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5491 - accuracy: 0.7887 - val_loss: 0.4048 - val_accuracy: 0.8425\n",
            "Epoch 218/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5611 - accuracy: 0.7851 - val_loss: 0.4069 - val_accuracy: 0.8400\n",
            "Epoch 219/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5613 - accuracy: 0.7864 - val_loss: 0.4069 - val_accuracy: 0.8370\n",
            "Epoch 220/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5459 - accuracy: 0.7879 - val_loss: 0.4064 - val_accuracy: 0.8425\n",
            "Epoch 221/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5489 - accuracy: 0.7859 - val_loss: 0.4072 - val_accuracy: 0.8425\n",
            "Epoch 222/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.5602 - accuracy: 0.7864 - val_loss: 0.4079 - val_accuracy: 0.8415\n",
            "Epoch 223/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5533 - accuracy: 0.7868 - val_loss: 0.4062 - val_accuracy: 0.8400\n",
            "Epoch 224/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5600 - accuracy: 0.7896 - val_loss: 0.4072 - val_accuracy: 0.8410\n",
            "Epoch 225/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5443 - accuracy: 0.7895 - val_loss: 0.4061 - val_accuracy: 0.8405\n",
            "Epoch 226/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5568 - accuracy: 0.7853 - val_loss: 0.4083 - val_accuracy: 0.8420\n",
            "Epoch 227/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5500 - accuracy: 0.7931 - val_loss: 0.4077 - val_accuracy: 0.8410\n",
            "Epoch 228/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5533 - accuracy: 0.7901 - val_loss: 0.4053 - val_accuracy: 0.8420\n",
            "Epoch 229/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5517 - accuracy: 0.7900 - val_loss: 0.4059 - val_accuracy: 0.8435\n",
            "Epoch 230/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5648 - accuracy: 0.7812 - val_loss: 0.4060 - val_accuracy: 0.8435\n",
            "Epoch 231/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5569 - accuracy: 0.7847 - val_loss: 0.4066 - val_accuracy: 0.8435\n",
            "Epoch 232/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5552 - accuracy: 0.7835 - val_loss: 0.4090 - val_accuracy: 0.8400\n",
            "Epoch 233/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.5434 - accuracy: 0.7883 - val_loss: 0.4070 - val_accuracy: 0.8430\n",
            "Epoch 234/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5484 - accuracy: 0.7918 - val_loss: 0.4053 - val_accuracy: 0.8415\n",
            "Epoch 235/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5446 - accuracy: 0.7885 - val_loss: 0.4045 - val_accuracy: 0.8425\n",
            "Epoch 236/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5464 - accuracy: 0.7901 - val_loss: 0.4057 - val_accuracy: 0.8415\n",
            "Epoch 237/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5451 - accuracy: 0.7868 - val_loss: 0.4027 - val_accuracy: 0.8415\n",
            "Epoch 238/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5540 - accuracy: 0.7857 - val_loss: 0.4042 - val_accuracy: 0.8420\n",
            "Epoch 239/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5671 - accuracy: 0.7825 - val_loss: 0.4068 - val_accuracy: 0.8420\n",
            "Epoch 240/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5575 - accuracy: 0.7870 - val_loss: 0.4074 - val_accuracy: 0.8410\n",
            "Epoch 241/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5544 - accuracy: 0.7844 - val_loss: 0.4078 - val_accuracy: 0.8415\n",
            "Epoch 242/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5364 - accuracy: 0.7905 - val_loss: 0.4064 - val_accuracy: 0.8440\n",
            "Epoch 243/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5475 - accuracy: 0.7891 - val_loss: 0.4039 - val_accuracy: 0.8435\n",
            "Epoch 244/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5580 - accuracy: 0.7865 - val_loss: 0.4038 - val_accuracy: 0.8430\n",
            "Epoch 245/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5579 - accuracy: 0.7868 - val_loss: 0.4061 - val_accuracy: 0.8440\n",
            "Epoch 246/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5443 - accuracy: 0.7906 - val_loss: 0.4049 - val_accuracy: 0.8435\n",
            "Epoch 247/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5646 - accuracy: 0.7876 - val_loss: 0.4087 - val_accuracy: 0.8415\n",
            "Epoch 248/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5516 - accuracy: 0.7890 - val_loss: 0.4067 - val_accuracy: 0.8440\n",
            "Epoch 249/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5490 - accuracy: 0.7916 - val_loss: 0.4041 - val_accuracy: 0.8410\n",
            "Epoch 250/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5511 - accuracy: 0.7915 - val_loss: 0.4047 - val_accuracy: 0.8435\n",
            "Epoch 251/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5560 - accuracy: 0.7862 - val_loss: 0.4053 - val_accuracy: 0.8430\n",
            "Epoch 252/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5489 - accuracy: 0.7885 - val_loss: 0.4046 - val_accuracy: 0.8430\n",
            "Epoch 253/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5547 - accuracy: 0.7866 - val_loss: 0.4055 - val_accuracy: 0.8415\n",
            "Epoch 254/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5565 - accuracy: 0.7884 - val_loss: 0.4050 - val_accuracy: 0.8430\n",
            "Epoch 255/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5617 - accuracy: 0.7864 - val_loss: 0.4053 - val_accuracy: 0.8430\n",
            "Epoch 256/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5535 - accuracy: 0.7894 - val_loss: 0.4064 - val_accuracy: 0.8430\n",
            "Epoch 257/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5500 - accuracy: 0.7904 - val_loss: 0.4073 - val_accuracy: 0.8435\n",
            "Epoch 258/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5480 - accuracy: 0.7901 - val_loss: 0.4043 - val_accuracy: 0.8400\n",
            "Epoch 259/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5549 - accuracy: 0.7886 - val_loss: 0.4054 - val_accuracy: 0.8435\n",
            "Epoch 260/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5601 - accuracy: 0.7818 - val_loss: 0.4042 - val_accuracy: 0.8430\n",
            "Epoch 261/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5431 - accuracy: 0.7901 - val_loss: 0.4043 - val_accuracy: 0.8445\n",
            "Epoch 262/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5585 - accuracy: 0.7797 - val_loss: 0.4059 - val_accuracy: 0.8415\n",
            "Epoch 263/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5510 - accuracy: 0.7872 - val_loss: 0.4041 - val_accuracy: 0.8430\n",
            "Epoch 264/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5440 - accuracy: 0.7909 - val_loss: 0.4034 - val_accuracy: 0.8420\n",
            "Epoch 265/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5493 - accuracy: 0.7890 - val_loss: 0.4043 - val_accuracy: 0.8420\n",
            "Epoch 266/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5572 - accuracy: 0.7910 - val_loss: 0.4052 - val_accuracy: 0.8420\n",
            "Epoch 267/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5534 - accuracy: 0.7844 - val_loss: 0.4066 - val_accuracy: 0.8420\n",
            "Epoch 268/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5459 - accuracy: 0.7887 - val_loss: 0.4053 - val_accuracy: 0.8405\n",
            "Epoch 269/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5533 - accuracy: 0.7886 - val_loss: 0.4039 - val_accuracy: 0.8430\n",
            "Epoch 270/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5533 - accuracy: 0.7870 - val_loss: 0.4057 - val_accuracy: 0.8430\n",
            "Epoch 271/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5361 - accuracy: 0.7929 - val_loss: 0.4042 - val_accuracy: 0.8420\n",
            "Epoch 272/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5474 - accuracy: 0.7869 - val_loss: 0.4027 - val_accuracy: 0.8420\n",
            "Epoch 273/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5364 - accuracy: 0.7900 - val_loss: 0.4016 - val_accuracy: 0.8415\n",
            "Epoch 274/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5520 - accuracy: 0.7859 - val_loss: 0.4014 - val_accuracy: 0.8420\n",
            "Epoch 275/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5572 - accuracy: 0.7796 - val_loss: 0.4014 - val_accuracy: 0.8435\n",
            "Epoch 276/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.5639 - accuracy: 0.7879 - val_loss: 0.4030 - val_accuracy: 0.8450\n",
            "Epoch 277/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5480 - accuracy: 0.7909 - val_loss: 0.4048 - val_accuracy: 0.8420\n",
            "Epoch 278/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5530 - accuracy: 0.7837 - val_loss: 0.4039 - val_accuracy: 0.8445\n",
            "Epoch 279/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5508 - accuracy: 0.7885 - val_loss: 0.4047 - val_accuracy: 0.8440\n",
            "Epoch 280/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5526 - accuracy: 0.7875 - val_loss: 0.4048 - val_accuracy: 0.8415\n",
            "Epoch 281/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5510 - accuracy: 0.7933 - val_loss: 0.4020 - val_accuracy: 0.8445\n",
            "Epoch 282/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5458 - accuracy: 0.7931 - val_loss: 0.4014 - val_accuracy: 0.8430\n",
            "Epoch 283/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5440 - accuracy: 0.7896 - val_loss: 0.4016 - val_accuracy: 0.8440\n",
            "Epoch 284/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5496 - accuracy: 0.7868 - val_loss: 0.4037 - val_accuracy: 0.8420\n",
            "Epoch 285/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5499 - accuracy: 0.7866 - val_loss: 0.4026 - val_accuracy: 0.8435\n",
            "Epoch 286/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5457 - accuracy: 0.7911 - val_loss: 0.4049 - val_accuracy: 0.8425\n",
            "Epoch 287/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5598 - accuracy: 0.7894 - val_loss: 0.4040 - val_accuracy: 0.8420\n",
            "Epoch 288/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5557 - accuracy: 0.7844 - val_loss: 0.4031 - val_accuracy: 0.8420\n",
            "Epoch 289/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5461 - accuracy: 0.7896 - val_loss: 0.4038 - val_accuracy: 0.8430\n",
            "Epoch 290/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5543 - accuracy: 0.7824 - val_loss: 0.4049 - val_accuracy: 0.8435\n",
            "Epoch 291/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5558 - accuracy: 0.7895 - val_loss: 0.4042 - val_accuracy: 0.8430\n",
            "Epoch 292/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5572 - accuracy: 0.7919 - val_loss: 0.4041 - val_accuracy: 0.8425\n",
            "Epoch 293/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5460 - accuracy: 0.7869 - val_loss: 0.4035 - val_accuracy: 0.8430\n",
            "Epoch 294/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5472 - accuracy: 0.7872 - val_loss: 0.4049 - val_accuracy: 0.8425\n",
            "Epoch 295/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5434 - accuracy: 0.7881 - val_loss: 0.4002 - val_accuracy: 0.8445\n",
            "Epoch 296/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.5426 - accuracy: 0.7883 - val_loss: 0.3992 - val_accuracy: 0.8435\n",
            "Epoch 297/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5470 - accuracy: 0.7909 - val_loss: 0.4001 - val_accuracy: 0.8440\n",
            "Epoch 298/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5432 - accuracy: 0.7925 - val_loss: 0.4004 - val_accuracy: 0.8435\n",
            "Epoch 299/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5483 - accuracy: 0.7921 - val_loss: 0.4016 - val_accuracy: 0.8440\n",
            "Epoch 300/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5530 - accuracy: 0.7940 - val_loss: 0.4026 - val_accuracy: 0.8430\n",
            "Epoch 301/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5559 - accuracy: 0.7839 - val_loss: 0.4016 - val_accuracy: 0.8425\n",
            "Epoch 302/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5479 - accuracy: 0.7895 - val_loss: 0.4015 - val_accuracy: 0.8425\n",
            "Epoch 303/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5482 - accuracy: 0.7939 - val_loss: 0.4012 - val_accuracy: 0.8440\n",
            "Epoch 304/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.5539 - accuracy: 0.7918 - val_loss: 0.4016 - val_accuracy: 0.8440\n",
            "Epoch 305/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5544 - accuracy: 0.7870 - val_loss: 0.4024 - val_accuracy: 0.8455\n",
            "Epoch 306/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5448 - accuracy: 0.7912 - val_loss: 0.4006 - val_accuracy: 0.8430\n",
            "Epoch 307/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5471 - accuracy: 0.7943 - val_loss: 0.3999 - val_accuracy: 0.8435\n",
            "Epoch 308/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5432 - accuracy: 0.7896 - val_loss: 0.4006 - val_accuracy: 0.8440\n",
            "Epoch 309/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5555 - accuracy: 0.7874 - val_loss: 0.3993 - val_accuracy: 0.8430\n",
            "Epoch 310/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5508 - accuracy: 0.7886 - val_loss: 0.4002 - val_accuracy: 0.8440\n",
            "Epoch 311/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5618 - accuracy: 0.7890 - val_loss: 0.4029 - val_accuracy: 0.8450\n",
            "Epoch 312/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5574 - accuracy: 0.7889 - val_loss: 0.3995 - val_accuracy: 0.8465\n",
            "Epoch 313/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5519 - accuracy: 0.7861 - val_loss: 0.4007 - val_accuracy: 0.8435\n",
            "Epoch 314/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.5435 - accuracy: 0.7914 - val_loss: 0.3996 - val_accuracy: 0.8465\n",
            "Epoch 315/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5466 - accuracy: 0.7879 - val_loss: 0.4020 - val_accuracy: 0.8450\n",
            "Epoch 316/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5407 - accuracy: 0.7897 - val_loss: 0.4017 - val_accuracy: 0.8460\n",
            "Epoch 317/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5454 - accuracy: 0.7844 - val_loss: 0.4006 - val_accuracy: 0.8430\n",
            "Epoch 318/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5559 - accuracy: 0.7893 - val_loss: 0.4008 - val_accuracy: 0.8425\n",
            "Epoch 319/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5507 - accuracy: 0.7861 - val_loss: 0.4018 - val_accuracy: 0.8425\n",
            "Epoch 320/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.5492 - accuracy: 0.7831 - val_loss: 0.4013 - val_accuracy: 0.8435\n",
            "Epoch 321/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5440 - accuracy: 0.7844 - val_loss: 0.3994 - val_accuracy: 0.8425\n",
            "Epoch 322/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5565 - accuracy: 0.7865 - val_loss: 0.4007 - val_accuracy: 0.8415\n",
            "Epoch 323/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5444 - accuracy: 0.7856 - val_loss: 0.3994 - val_accuracy: 0.8445\n",
            "Epoch 324/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5499 - accuracy: 0.7878 - val_loss: 0.4012 - val_accuracy: 0.8430\n",
            "Epoch 325/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5346 - accuracy: 0.7940 - val_loss: 0.3983 - val_accuracy: 0.8445\n",
            "Epoch 326/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5512 - accuracy: 0.7866 - val_loss: 0.3993 - val_accuracy: 0.8430\n",
            "Epoch 327/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5367 - accuracy: 0.7954 - val_loss: 0.3996 - val_accuracy: 0.8440\n",
            "Epoch 328/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5550 - accuracy: 0.7851 - val_loss: 0.3987 - val_accuracy: 0.8425\n",
            "Epoch 329/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5561 - accuracy: 0.7862 - val_loss: 0.4013 - val_accuracy: 0.8440\n",
            "Epoch 330/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5458 - accuracy: 0.7879 - val_loss: 0.4012 - val_accuracy: 0.8445\n",
            "Epoch 331/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5448 - accuracy: 0.7908 - val_loss: 0.4019 - val_accuracy: 0.8440\n",
            "Epoch 332/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5436 - accuracy: 0.7937 - val_loss: 0.4011 - val_accuracy: 0.8440\n",
            "Epoch 333/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5506 - accuracy: 0.7910 - val_loss: 0.4016 - val_accuracy: 0.8445\n",
            "Epoch 334/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5583 - accuracy: 0.7880 - val_loss: 0.4023 - val_accuracy: 0.8440\n",
            "Epoch 335/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5501 - accuracy: 0.7886 - val_loss: 0.4010 - val_accuracy: 0.8430\n",
            "Epoch 336/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5465 - accuracy: 0.7909 - val_loss: 0.4015 - val_accuracy: 0.8440\n",
            "Epoch 337/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5540 - accuracy: 0.7910 - val_loss: 0.4023 - val_accuracy: 0.8430\n",
            "Epoch 338/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5619 - accuracy: 0.7886 - val_loss: 0.4023 - val_accuracy: 0.8430\n",
            "Epoch 339/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5384 - accuracy: 0.7936 - val_loss: 0.4013 - val_accuracy: 0.8435\n",
            "Epoch 340/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5589 - accuracy: 0.7883 - val_loss: 0.4004 - val_accuracy: 0.8450\n",
            "Epoch 341/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5523 - accuracy: 0.7885 - val_loss: 0.4009 - val_accuracy: 0.8445\n",
            "Epoch 342/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5455 - accuracy: 0.7918 - val_loss: 0.4009 - val_accuracy: 0.8430\n",
            "Epoch 343/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5467 - accuracy: 0.7890 - val_loss: 0.3987 - val_accuracy: 0.8465\n",
            "Epoch 344/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5507 - accuracy: 0.7908 - val_loss: 0.4000 - val_accuracy: 0.8430\n",
            "Epoch 345/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5451 - accuracy: 0.7929 - val_loss: 0.3997 - val_accuracy: 0.8440\n",
            "Epoch 346/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5379 - accuracy: 0.7894 - val_loss: 0.3980 - val_accuracy: 0.8430\n",
            "Epoch 347/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5541 - accuracy: 0.7897 - val_loss: 0.4006 - val_accuracy: 0.8445\n",
            "Epoch 348/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5526 - accuracy: 0.7861 - val_loss: 0.3971 - val_accuracy: 0.8450\n",
            "Epoch 349/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5466 - accuracy: 0.7909 - val_loss: 0.3990 - val_accuracy: 0.8445\n",
            "Epoch 350/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5404 - accuracy: 0.7926 - val_loss: 0.4000 - val_accuracy: 0.8445\n",
            "Epoch 351/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5503 - accuracy: 0.7885 - val_loss: 0.3971 - val_accuracy: 0.8435\n",
            "Epoch 352/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5501 - accuracy: 0.7901 - val_loss: 0.3983 - val_accuracy: 0.8435\n",
            "Epoch 353/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5491 - accuracy: 0.7880 - val_loss: 0.4010 - val_accuracy: 0.8420\n",
            "Epoch 354/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5523 - accuracy: 0.7859 - val_loss: 0.4010 - val_accuracy: 0.8430\n",
            "Epoch 355/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5467 - accuracy: 0.7922 - val_loss: 0.4004 - val_accuracy: 0.8435\n",
            "Epoch 356/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5490 - accuracy: 0.7844 - val_loss: 0.3993 - val_accuracy: 0.8450\n",
            "Epoch 357/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5539 - accuracy: 0.7818 - val_loss: 0.4006 - val_accuracy: 0.8440\n",
            "Epoch 358/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5534 - accuracy: 0.7889 - val_loss: 0.3988 - val_accuracy: 0.8470\n",
            "Epoch 359/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5303 - accuracy: 0.8005 - val_loss: 0.3979 - val_accuracy: 0.8430\n",
            "Epoch 360/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5558 - accuracy: 0.7844 - val_loss: 0.3980 - val_accuracy: 0.8435\n",
            "Epoch 361/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5548 - accuracy: 0.7891 - val_loss: 0.3996 - val_accuracy: 0.8445\n",
            "Epoch 362/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5502 - accuracy: 0.7870 - val_loss: 0.4008 - val_accuracy: 0.8435\n",
            "Epoch 363/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5377 - accuracy: 0.7904 - val_loss: 0.3980 - val_accuracy: 0.8445\n",
            "Epoch 364/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5529 - accuracy: 0.7851 - val_loss: 0.3986 - val_accuracy: 0.8450\n",
            "Epoch 365/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5412 - accuracy: 0.7937 - val_loss: 0.3968 - val_accuracy: 0.8435\n",
            "Epoch 366/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5559 - accuracy: 0.7878 - val_loss: 0.3991 - val_accuracy: 0.8455\n",
            "Epoch 367/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5446 - accuracy: 0.7897 - val_loss: 0.3970 - val_accuracy: 0.8470\n",
            "Epoch 368/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5676 - accuracy: 0.7831 - val_loss: 0.4007 - val_accuracy: 0.8450\n",
            "Epoch 369/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5389 - accuracy: 0.7905 - val_loss: 0.3978 - val_accuracy: 0.8460\n",
            "Epoch 370/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5474 - accuracy: 0.7885 - val_loss: 0.3973 - val_accuracy: 0.8455\n",
            "Epoch 371/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5519 - accuracy: 0.7920 - val_loss: 0.3980 - val_accuracy: 0.8490\n",
            "Epoch 372/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5476 - accuracy: 0.7901 - val_loss: 0.3977 - val_accuracy: 0.8475\n",
            "Epoch 373/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5467 - accuracy: 0.7891 - val_loss: 0.3974 - val_accuracy: 0.8465\n",
            "Epoch 374/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5503 - accuracy: 0.7943 - val_loss: 0.3960 - val_accuracy: 0.8475\n",
            "Epoch 375/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5363 - accuracy: 0.7937 - val_loss: 0.3958 - val_accuracy: 0.8480\n",
            "Epoch 376/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5462 - accuracy: 0.7901 - val_loss: 0.3963 - val_accuracy: 0.8485\n",
            "Epoch 377/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5420 - accuracy: 0.7899 - val_loss: 0.3955 - val_accuracy: 0.8485\n",
            "Epoch 378/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5390 - accuracy: 0.7958 - val_loss: 0.3940 - val_accuracy: 0.8505\n",
            "Epoch 379/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5367 - accuracy: 0.7883 - val_loss: 0.3955 - val_accuracy: 0.8490\n",
            "Epoch 380/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5363 - accuracy: 0.7928 - val_loss: 0.3944 - val_accuracy: 0.8470\n",
            "Epoch 381/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5370 - accuracy: 0.7937 - val_loss: 0.3922 - val_accuracy: 0.8485\n",
            "Epoch 382/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5495 - accuracy: 0.7883 - val_loss: 0.3943 - val_accuracy: 0.8495\n",
            "Epoch 383/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5460 - accuracy: 0.7890 - val_loss: 0.3959 - val_accuracy: 0.8475\n",
            "Epoch 384/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5531 - accuracy: 0.7904 - val_loss: 0.3939 - val_accuracy: 0.8495\n",
            "Epoch 385/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5375 - accuracy: 0.7937 - val_loss: 0.3906 - val_accuracy: 0.8510\n",
            "Epoch 386/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5527 - accuracy: 0.7891 - val_loss: 0.3922 - val_accuracy: 0.8500\n",
            "Epoch 387/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5387 - accuracy: 0.7910 - val_loss: 0.3911 - val_accuracy: 0.8505\n",
            "Epoch 388/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5385 - accuracy: 0.7908 - val_loss: 0.3907 - val_accuracy: 0.8500\n",
            "Epoch 389/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5423 - accuracy: 0.7851 - val_loss: 0.3907 - val_accuracy: 0.8485\n",
            "Epoch 390/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5456 - accuracy: 0.7904 - val_loss: 0.3914 - val_accuracy: 0.8490\n",
            "Epoch 391/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5479 - accuracy: 0.7878 - val_loss: 0.3919 - val_accuracy: 0.8500\n",
            "Epoch 392/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5427 - accuracy: 0.7941 - val_loss: 0.3894 - val_accuracy: 0.8535\n",
            "Epoch 393/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5430 - accuracy: 0.7937 - val_loss: 0.3891 - val_accuracy: 0.8515\n",
            "Epoch 394/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5463 - accuracy: 0.7914 - val_loss: 0.3884 - val_accuracy: 0.8515\n",
            "Epoch 395/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5353 - accuracy: 0.7962 - val_loss: 0.3871 - val_accuracy: 0.8530\n",
            "Epoch 396/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5374 - accuracy: 0.7904 - val_loss: 0.3871 - val_accuracy: 0.8525\n",
            "Epoch 397/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5370 - accuracy: 0.7946 - val_loss: 0.3857 - val_accuracy: 0.8525\n",
            "Epoch 398/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5370 - accuracy: 0.7896 - val_loss: 0.3856 - val_accuracy: 0.8525\n",
            "Epoch 399/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5367 - accuracy: 0.7933 - val_loss: 0.3858 - val_accuracy: 0.8495\n",
            "Epoch 400/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5442 - accuracy: 0.7897 - val_loss: 0.3841 - val_accuracy: 0.8520\n",
            "Epoch 401/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5424 - accuracy: 0.7889 - val_loss: 0.3817 - val_accuracy: 0.8520\n",
            "Epoch 402/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5323 - accuracy: 0.7940 - val_loss: 0.3809 - val_accuracy: 0.8525\n",
            "Epoch 403/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5397 - accuracy: 0.7947 - val_loss: 0.3800 - val_accuracy: 0.8545\n",
            "Epoch 404/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5263 - accuracy: 0.7985 - val_loss: 0.3786 - val_accuracy: 0.8520\n",
            "Epoch 405/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5240 - accuracy: 0.7976 - val_loss: 0.3752 - val_accuracy: 0.8535\n",
            "Epoch 406/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.5478 - accuracy: 0.7893 - val_loss: 0.3779 - val_accuracy: 0.8540\n",
            "Epoch 407/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5389 - accuracy: 0.7905 - val_loss: 0.3781 - val_accuracy: 0.8535\n",
            "Epoch 408/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.5374 - accuracy: 0.7936 - val_loss: 0.3749 - val_accuracy: 0.8545\n",
            "Epoch 409/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5447 - accuracy: 0.7922 - val_loss: 0.3749 - val_accuracy: 0.8545\n",
            "Epoch 410/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5454 - accuracy: 0.7919 - val_loss: 0.3756 - val_accuracy: 0.8550\n",
            "Epoch 411/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5410 - accuracy: 0.7934 - val_loss: 0.3731 - val_accuracy: 0.8560\n",
            "Epoch 412/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5387 - accuracy: 0.7944 - val_loss: 0.3732 - val_accuracy: 0.8550\n",
            "Epoch 413/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5262 - accuracy: 0.7995 - val_loss: 0.3714 - val_accuracy: 0.8540\n",
            "Epoch 414/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5299 - accuracy: 0.7959 - val_loss: 0.3715 - val_accuracy: 0.8545\n",
            "Epoch 415/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5279 - accuracy: 0.8133 - val_loss: 0.3716 - val_accuracy: 0.8745\n",
            "Epoch 416/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5306 - accuracy: 0.8102 - val_loss: 0.3713 - val_accuracy: 0.8735\n",
            "Epoch 417/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5406 - accuracy: 0.7991 - val_loss: 0.3719 - val_accuracy: 0.8730\n",
            "Epoch 418/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5380 - accuracy: 0.8091 - val_loss: 0.3714 - val_accuracy: 0.8745\n",
            "Epoch 419/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5281 - accuracy: 0.8111 - val_loss: 0.3702 - val_accuracy: 0.8760\n",
            "Epoch 420/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5305 - accuracy: 0.8106 - val_loss: 0.3679 - val_accuracy: 0.8740\n",
            "Epoch 421/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5215 - accuracy: 0.8167 - val_loss: 0.3663 - val_accuracy: 0.8765\n",
            "Epoch 422/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5299 - accuracy: 0.8115 - val_loss: 0.3684 - val_accuracy: 0.8745\n",
            "Epoch 423/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5292 - accuracy: 0.8104 - val_loss: 0.3671 - val_accuracy: 0.8735\n",
            "Epoch 424/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5148 - accuracy: 0.8154 - val_loss: 0.3642 - val_accuracy: 0.8740\n",
            "Epoch 425/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5295 - accuracy: 0.8089 - val_loss: 0.3632 - val_accuracy: 0.8765\n",
            "Epoch 426/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5388 - accuracy: 0.8074 - val_loss: 0.3647 - val_accuracy: 0.8755\n",
            "Epoch 427/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5332 - accuracy: 0.8135 - val_loss: 0.3652 - val_accuracy: 0.8745\n",
            "Epoch 428/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.5278 - accuracy: 0.8145 - val_loss: 0.3643 - val_accuracy: 0.8750\n",
            "Epoch 429/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5339 - accuracy: 0.8064 - val_loss: 0.3648 - val_accuracy: 0.8745\n",
            "Epoch 430/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5307 - accuracy: 0.8091 - val_loss: 0.3626 - val_accuracy: 0.8750\n",
            "Epoch 431/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5283 - accuracy: 0.8135 - val_loss: 0.3626 - val_accuracy: 0.8755\n",
            "Epoch 432/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5360 - accuracy: 0.8037 - val_loss: 0.3637 - val_accuracy: 0.8745\n",
            "Epoch 433/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5395 - accuracy: 0.8064 - val_loss: 0.3658 - val_accuracy: 0.8755\n",
            "Epoch 434/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5408 - accuracy: 0.8035 - val_loss: 0.3668 - val_accuracy: 0.8755\n",
            "Epoch 435/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5279 - accuracy: 0.8120 - val_loss: 0.3637 - val_accuracy: 0.8765\n",
            "Epoch 436/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.5151 - accuracy: 0.8105 - val_loss: 0.3630 - val_accuracy: 0.8750\n",
            "Epoch 437/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5314 - accuracy: 0.8077 - val_loss: 0.3622 - val_accuracy: 0.8760\n",
            "Epoch 438/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5290 - accuracy: 0.8087 - val_loss: 0.3608 - val_accuracy: 0.8760\n",
            "Epoch 439/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5337 - accuracy: 0.8080 - val_loss: 0.3630 - val_accuracy: 0.8765\n",
            "Epoch 440/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5362 - accuracy: 0.8060 - val_loss: 0.3630 - val_accuracy: 0.8760\n",
            "Epoch 441/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5335 - accuracy: 0.8099 - val_loss: 0.3600 - val_accuracy: 0.8775\n",
            "Epoch 442/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5355 - accuracy: 0.8073 - val_loss: 0.3609 - val_accuracy: 0.8770\n",
            "Epoch 443/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5248 - accuracy: 0.8046 - val_loss: 0.3609 - val_accuracy: 0.8760\n",
            "Epoch 444/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5210 - accuracy: 0.8089 - val_loss: 0.3588 - val_accuracy: 0.8760\n",
            "Epoch 445/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5361 - accuracy: 0.8074 - val_loss: 0.3597 - val_accuracy: 0.8765\n",
            "Epoch 446/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5255 - accuracy: 0.8074 - val_loss: 0.3612 - val_accuracy: 0.8765\n",
            "Epoch 447/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5290 - accuracy: 0.8089 - val_loss: 0.3611 - val_accuracy: 0.8770\n",
            "Epoch 448/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5384 - accuracy: 0.8062 - val_loss: 0.3602 - val_accuracy: 0.8770\n",
            "Epoch 449/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5172 - accuracy: 0.8141 - val_loss: 0.3599 - val_accuracy: 0.8775\n",
            "Epoch 450/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5293 - accuracy: 0.8059 - val_loss: 0.3603 - val_accuracy: 0.8765\n",
            "Epoch 451/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.5194 - accuracy: 0.8138 - val_loss: 0.3573 - val_accuracy: 0.8765\n",
            "Epoch 452/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5321 - accuracy: 0.8094 - val_loss: 0.3596 - val_accuracy: 0.8765\n",
            "Epoch 453/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5293 - accuracy: 0.8100 - val_loss: 0.3614 - val_accuracy: 0.8770\n",
            "Epoch 454/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5347 - accuracy: 0.8056 - val_loss: 0.3610 - val_accuracy: 0.8760\n",
            "Epoch 455/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5242 - accuracy: 0.8058 - val_loss: 0.3598 - val_accuracy: 0.8750\n",
            "Epoch 456/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5222 - accuracy: 0.8090 - val_loss: 0.3597 - val_accuracy: 0.8760\n",
            "Epoch 457/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5325 - accuracy: 0.8075 - val_loss: 0.3589 - val_accuracy: 0.8755\n",
            "Epoch 458/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5328 - accuracy: 0.8058 - val_loss: 0.3602 - val_accuracy: 0.8755\n",
            "Epoch 459/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.5203 - accuracy: 0.8126 - val_loss: 0.3602 - val_accuracy: 0.8760\n",
            "Epoch 460/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5345 - accuracy: 0.8048 - val_loss: 0.3602 - val_accuracy: 0.8760\n",
            "Epoch 461/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5299 - accuracy: 0.8129 - val_loss: 0.3607 - val_accuracy: 0.8770\n",
            "Epoch 462/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5333 - accuracy: 0.8048 - val_loss: 0.3609 - val_accuracy: 0.8750\n",
            "Epoch 463/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5236 - accuracy: 0.8060 - val_loss: 0.3595 - val_accuracy: 0.8755\n",
            "Epoch 464/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5113 - accuracy: 0.8146 - val_loss: 0.3594 - val_accuracy: 0.8755\n",
            "Epoch 465/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5213 - accuracy: 0.8084 - val_loss: 0.3576 - val_accuracy: 0.8760\n",
            "Epoch 466/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5224 - accuracy: 0.8121 - val_loss: 0.3598 - val_accuracy: 0.8765\n",
            "Epoch 467/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5354 - accuracy: 0.8089 - val_loss: 0.3588 - val_accuracy: 0.8750\n",
            "Epoch 468/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5223 - accuracy: 0.8079 - val_loss: 0.3601 - val_accuracy: 0.8745\n",
            "Epoch 469/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5183 - accuracy: 0.8091 - val_loss: 0.3575 - val_accuracy: 0.8745\n",
            "Epoch 470/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5290 - accuracy: 0.8090 - val_loss: 0.3571 - val_accuracy: 0.8760\n",
            "Epoch 471/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5157 - accuracy: 0.8117 - val_loss: 0.3575 - val_accuracy: 0.8750\n",
            "Epoch 472/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5417 - accuracy: 0.8041 - val_loss: 0.3596 - val_accuracy: 0.8740\n",
            "Epoch 473/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5203 - accuracy: 0.8104 - val_loss: 0.3583 - val_accuracy: 0.8750\n",
            "Epoch 474/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5266 - accuracy: 0.8090 - val_loss: 0.3589 - val_accuracy: 0.8750\n",
            "Epoch 475/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5286 - accuracy: 0.8051 - val_loss: 0.3559 - val_accuracy: 0.8750\n",
            "Epoch 476/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.5365 - accuracy: 0.8046 - val_loss: 0.3583 - val_accuracy: 0.8740\n",
            "Epoch 477/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5389 - accuracy: 0.8036 - val_loss: 0.3595 - val_accuracy: 0.8730\n",
            "Epoch 478/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5237 - accuracy: 0.8099 - val_loss: 0.3580 - val_accuracy: 0.8740\n",
            "Epoch 479/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5444 - accuracy: 0.8061 - val_loss: 0.3594 - val_accuracy: 0.8735\n",
            "Epoch 480/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5265 - accuracy: 0.8049 - val_loss: 0.3614 - val_accuracy: 0.8735\n",
            "Epoch 481/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5353 - accuracy: 0.8065 - val_loss: 0.3613 - val_accuracy: 0.8755\n",
            "Epoch 482/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5316 - accuracy: 0.8086 - val_loss: 0.3602 - val_accuracy: 0.8750\n",
            "Epoch 483/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5346 - accuracy: 0.8071 - val_loss: 0.3580 - val_accuracy: 0.8760\n",
            "Epoch 484/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5280 - accuracy: 0.8087 - val_loss: 0.3572 - val_accuracy: 0.8740\n",
            "Epoch 485/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5211 - accuracy: 0.8104 - val_loss: 0.3561 - val_accuracy: 0.8750\n",
            "Epoch 486/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5296 - accuracy: 0.8092 - val_loss: 0.3566 - val_accuracy: 0.8745\n",
            "Epoch 487/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5292 - accuracy: 0.8077 - val_loss: 0.3591 - val_accuracy: 0.8735\n",
            "Epoch 488/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5381 - accuracy: 0.8067 - val_loss: 0.3594 - val_accuracy: 0.8745\n",
            "Epoch 489/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5218 - accuracy: 0.8098 - val_loss: 0.3562 - val_accuracy: 0.8745\n",
            "Epoch 490/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5279 - accuracy: 0.8091 - val_loss: 0.3556 - val_accuracy: 0.8750\n",
            "Epoch 491/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5209 - accuracy: 0.8070 - val_loss: 0.3566 - val_accuracy: 0.8745\n",
            "Epoch 492/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5345 - accuracy: 0.8091 - val_loss: 0.3564 - val_accuracy: 0.8750\n",
            "Epoch 493/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5293 - accuracy: 0.8083 - val_loss: 0.3594 - val_accuracy: 0.8745\n",
            "Epoch 494/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5378 - accuracy: 0.8041 - val_loss: 0.3578 - val_accuracy: 0.8745\n",
            "Epoch 495/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5235 - accuracy: 0.8098 - val_loss: 0.3583 - val_accuracy: 0.8750\n",
            "Epoch 496/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5321 - accuracy: 0.8099 - val_loss: 0.3584 - val_accuracy: 0.8755\n",
            "Epoch 497/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5227 - accuracy: 0.8096 - val_loss: 0.3588 - val_accuracy: 0.8735\n",
            "Epoch 498/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.5152 - accuracy: 0.8135 - val_loss: 0.3565 - val_accuracy: 0.8750\n",
            "Epoch 499/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5330 - accuracy: 0.8086 - val_loss: 0.3564 - val_accuracy: 0.8745\n",
            "Epoch 500/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5330 - accuracy: 0.8062 - val_loss: 0.3574 - val_accuracy: 0.8740\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mcv4uRT3qPFj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ss = pd.read_csv('sample_submission.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bX68fq62NO7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_predictions1 = model1.predict(XT2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdzUA1tONgUr",
        "colab_type": "code",
        "outputId": "4f6a5cc0-7250-40ff-ae1c-51292dba2606",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "test_predictions1[:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.99972105e-01, 3.54412277e-10, 4.16944310e-08, 2.78898769e-05],\n",
              "       [1.16517951e-08, 4.04071179e-04, 9.98762488e-01, 8.33429105e-04],\n",
              "       [1.06888376e-01, 8.32626969e-02, 1.11065898e-03, 8.08738291e-01],\n",
              "       [9.99857187e-01, 1.43277816e-08, 1.15651819e-05, 1.31185690e-04],\n",
              "       [4.62458223e-01, 5.23232757e-06, 5.37534118e-01, 2.40763848e-06]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dG2Rl_F7PKjM",
        "colab_type": "code",
        "outputId": "3085e486-6bb6-4cf3-c1e5-6e5a9047391d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "ss.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accident_ID</th>\n",
              "      <th>Severity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Minor_Damage_And_Injuries</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>Highly_Fatal_And_Damaging</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>14</td>\n",
              "      <td>Highly_Fatal_And_Damaging</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>17</td>\n",
              "      <td>Significant_Damage_And_Serious_Injuries</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>21</td>\n",
              "      <td>Minor_Damage_And_Injuries</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Accident_ID                                 Severity\n",
              "0            1                Minor_Damage_And_Injuries\n",
              "1           10                Highly_Fatal_And_Damaging\n",
              "2           14                Highly_Fatal_And_Damaging\n",
              "3           17  Significant_Damage_And_Serious_Injuries\n",
              "4           21                Minor_Damage_And_Injuries"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8NSMoQ6QOHz",
        "colab_type": "code",
        "outputId": "15c0a24d-faef-4bae-9f71-5394e2496860",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "model2 = tf.keras.models.Sequential()\n",
        "model2.add(tf.keras.layers.Dense(12 , input_shape = (16,)))\n",
        "model2.add(tf.keras.layers.Dense(16 , activation = 'relu'))\n",
        "model2.add(tf.keras.layers.Dropout(0.3))\n",
        "model2.add(tf.keras.layers.Dense(8 , activation = 'relu'))\n",
        "model2.add(tf.keras.layers.Dense(4, activation = 'softmax'))\n",
        "model2.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
        "model2.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_7 (Dense)              (None, 12)                204       \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 16)                208       \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 8)                 136       \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 4)                 36        \n",
            "=================================================================\n",
            "Total params: 584\n",
            "Trainable params: 584\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DekpiZ4jS0xu",
        "colab_type": "code",
        "outputId": "aef6c549-0fbc-4605-aeae-19052c6a906a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history2 = model2.fit(X_train, y_train, batch_size  = 300, epochs = 6000 ,  validation_data = [X_test, y_test] ,shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8000 samples, validate on 2000 samples\n",
            "Epoch 1/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2620 - accuracy: 0.9103 - val_loss: 0.1872 - val_accuracy: 0.9450\n",
            "Epoch 2/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2570 - accuracy: 0.9143 - val_loss: 0.1862 - val_accuracy: 0.9460\n",
            "Epoch 3/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2667 - accuracy: 0.9154 - val_loss: 0.1906 - val_accuracy: 0.9425\n",
            "Epoch 4/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2571 - accuracy: 0.9168 - val_loss: 0.1860 - val_accuracy: 0.9455\n",
            "Epoch 5/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2582 - accuracy: 0.9151 - val_loss: 0.1886 - val_accuracy: 0.9460\n",
            "Epoch 6/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2530 - accuracy: 0.9161 - val_loss: 0.1888 - val_accuracy: 0.9450\n",
            "Epoch 7/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2590 - accuracy: 0.9143 - val_loss: 0.1871 - val_accuracy: 0.9450\n",
            "Epoch 8/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2658 - accuracy: 0.9141 - val_loss: 0.1874 - val_accuracy: 0.9470\n",
            "Epoch 9/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2653 - accuracy: 0.9131 - val_loss: 0.1901 - val_accuracy: 0.9455\n",
            "Epoch 10/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2565 - accuracy: 0.9137 - val_loss: 0.1883 - val_accuracy: 0.9435\n",
            "Epoch 11/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2624 - accuracy: 0.9134 - val_loss: 0.1881 - val_accuracy: 0.9465\n",
            "Epoch 12/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2640 - accuracy: 0.9115 - val_loss: 0.1868 - val_accuracy: 0.9440\n",
            "Epoch 13/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2683 - accuracy: 0.9100 - val_loss: 0.1870 - val_accuracy: 0.9460\n",
            "Epoch 14/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2604 - accuracy: 0.9116 - val_loss: 0.1845 - val_accuracy: 0.9450\n",
            "Epoch 15/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2687 - accuracy: 0.9116 - val_loss: 0.1873 - val_accuracy: 0.9440\n",
            "Epoch 16/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2546 - accuracy: 0.9172 - val_loss: 0.1874 - val_accuracy: 0.9455\n",
            "Epoch 17/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2573 - accuracy: 0.9144 - val_loss: 0.1876 - val_accuracy: 0.9455\n",
            "Epoch 18/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2635 - accuracy: 0.9153 - val_loss: 0.1858 - val_accuracy: 0.9455\n",
            "Epoch 19/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2619 - accuracy: 0.9137 - val_loss: 0.1860 - val_accuracy: 0.9445\n",
            "Epoch 20/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2605 - accuracy: 0.9184 - val_loss: 0.1866 - val_accuracy: 0.9460\n",
            "Epoch 21/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2513 - accuracy: 0.9179 - val_loss: 0.1887 - val_accuracy: 0.9425\n",
            "Epoch 22/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2602 - accuracy: 0.9146 - val_loss: 0.1877 - val_accuracy: 0.9435\n",
            "Epoch 23/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2612 - accuracy: 0.9129 - val_loss: 0.1866 - val_accuracy: 0.9445\n",
            "Epoch 24/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2635 - accuracy: 0.9112 - val_loss: 0.1868 - val_accuracy: 0.9425\n",
            "Epoch 25/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2557 - accuracy: 0.9147 - val_loss: 0.1842 - val_accuracy: 0.9455\n",
            "Epoch 26/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2612 - accuracy: 0.9151 - val_loss: 0.1864 - val_accuracy: 0.9465\n",
            "Epoch 27/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2558 - accuracy: 0.9159 - val_loss: 0.1872 - val_accuracy: 0.9470\n",
            "Epoch 28/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2612 - accuracy: 0.9121 - val_loss: 0.1846 - val_accuracy: 0.9440\n",
            "Epoch 29/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2651 - accuracy: 0.9162 - val_loss: 0.1856 - val_accuracy: 0.9475\n",
            "Epoch 30/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2626 - accuracy: 0.9121 - val_loss: 0.1864 - val_accuracy: 0.9455\n",
            "Epoch 31/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2577 - accuracy: 0.9112 - val_loss: 0.1861 - val_accuracy: 0.9435\n",
            "Epoch 32/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2601 - accuracy: 0.9129 - val_loss: 0.1868 - val_accuracy: 0.9450\n",
            "Epoch 33/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2563 - accuracy: 0.9154 - val_loss: 0.1903 - val_accuracy: 0.9440\n",
            "Epoch 34/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2684 - accuracy: 0.9145 - val_loss: 0.1861 - val_accuracy: 0.9465\n",
            "Epoch 35/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2625 - accuracy: 0.9144 - val_loss: 0.1872 - val_accuracy: 0.9435\n",
            "Epoch 36/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2621 - accuracy: 0.9109 - val_loss: 0.1896 - val_accuracy: 0.9445\n",
            "Epoch 37/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2551 - accuracy: 0.9174 - val_loss: 0.1889 - val_accuracy: 0.9480\n",
            "Epoch 38/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2651 - accuracy: 0.9129 - val_loss: 0.1869 - val_accuracy: 0.9455\n",
            "Epoch 39/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2654 - accuracy: 0.9118 - val_loss: 0.1874 - val_accuracy: 0.9455\n",
            "Epoch 40/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2617 - accuracy: 0.9122 - val_loss: 0.1872 - val_accuracy: 0.9440\n",
            "Epoch 41/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2572 - accuracy: 0.9111 - val_loss: 0.1870 - val_accuracy: 0.9455\n",
            "Epoch 42/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2663 - accuracy: 0.9097 - val_loss: 0.1875 - val_accuracy: 0.9455\n",
            "Epoch 43/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2617 - accuracy: 0.9150 - val_loss: 0.1872 - val_accuracy: 0.9450\n",
            "Epoch 44/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2601 - accuracy: 0.9130 - val_loss: 0.1855 - val_accuracy: 0.9455\n",
            "Epoch 45/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2638 - accuracy: 0.9133 - val_loss: 0.1885 - val_accuracy: 0.9450\n",
            "Epoch 46/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2547 - accuracy: 0.9170 - val_loss: 0.1855 - val_accuracy: 0.9460\n",
            "Epoch 47/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2554 - accuracy: 0.9159 - val_loss: 0.1869 - val_accuracy: 0.9440\n",
            "Epoch 48/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2660 - accuracy: 0.9103 - val_loss: 0.1857 - val_accuracy: 0.9440\n",
            "Epoch 49/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2658 - accuracy: 0.9084 - val_loss: 0.1881 - val_accuracy: 0.9450\n",
            "Epoch 50/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2621 - accuracy: 0.9134 - val_loss: 0.1868 - val_accuracy: 0.9450\n",
            "Epoch 51/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2699 - accuracy: 0.9095 - val_loss: 0.1857 - val_accuracy: 0.9460\n",
            "Epoch 52/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2744 - accuracy: 0.9106 - val_loss: 0.1854 - val_accuracy: 0.9475\n",
            "Epoch 53/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2560 - accuracy: 0.9150 - val_loss: 0.1853 - val_accuracy: 0.9465\n",
            "Epoch 54/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2628 - accuracy: 0.9139 - val_loss: 0.1904 - val_accuracy: 0.9440\n",
            "Epoch 55/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2641 - accuracy: 0.9135 - val_loss: 0.1862 - val_accuracy: 0.9430\n",
            "Epoch 56/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2540 - accuracy: 0.9128 - val_loss: 0.1863 - val_accuracy: 0.9430\n",
            "Epoch 57/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2558 - accuracy: 0.9137 - val_loss: 0.1891 - val_accuracy: 0.9460\n",
            "Epoch 58/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2569 - accuracy: 0.9164 - val_loss: 0.1847 - val_accuracy: 0.9475\n",
            "Epoch 59/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2649 - accuracy: 0.9120 - val_loss: 0.1830 - val_accuracy: 0.9450\n",
            "Epoch 60/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2505 - accuracy: 0.9119 - val_loss: 0.1853 - val_accuracy: 0.9440\n",
            "Epoch 61/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2599 - accuracy: 0.9168 - val_loss: 0.1854 - val_accuracy: 0.9445\n",
            "Epoch 62/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2618 - accuracy: 0.9112 - val_loss: 0.1880 - val_accuracy: 0.9450\n",
            "Epoch 63/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2597 - accuracy: 0.9122 - val_loss: 0.1892 - val_accuracy: 0.9445\n",
            "Epoch 64/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2590 - accuracy: 0.9128 - val_loss: 0.1870 - val_accuracy: 0.9475\n",
            "Epoch 65/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2602 - accuracy: 0.9130 - val_loss: 0.1886 - val_accuracy: 0.9455\n",
            "Epoch 66/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2647 - accuracy: 0.9149 - val_loss: 0.1858 - val_accuracy: 0.9460\n",
            "Epoch 67/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2562 - accuracy: 0.9130 - val_loss: 0.1860 - val_accuracy: 0.9435\n",
            "Epoch 68/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2540 - accuracy: 0.9159 - val_loss: 0.1852 - val_accuracy: 0.9455\n",
            "Epoch 69/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2600 - accuracy: 0.9153 - val_loss: 0.1837 - val_accuracy: 0.9460\n",
            "Epoch 70/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2574 - accuracy: 0.9170 - val_loss: 0.1849 - val_accuracy: 0.9440\n",
            "Epoch 71/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2582 - accuracy: 0.9119 - val_loss: 0.1908 - val_accuracy: 0.9420\n",
            "Epoch 72/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2668 - accuracy: 0.9112 - val_loss: 0.1848 - val_accuracy: 0.9460\n",
            "Epoch 73/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2701 - accuracy: 0.9085 - val_loss: 0.1898 - val_accuracy: 0.9435\n",
            "Epoch 74/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2562 - accuracy: 0.9143 - val_loss: 0.1872 - val_accuracy: 0.9460\n",
            "Epoch 75/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2669 - accuracy: 0.9085 - val_loss: 0.1887 - val_accuracy: 0.9440\n",
            "Epoch 76/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2594 - accuracy: 0.9150 - val_loss: 0.1840 - val_accuracy: 0.9460\n",
            "Epoch 77/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2592 - accuracy: 0.9106 - val_loss: 0.1872 - val_accuracy: 0.9445\n",
            "Epoch 78/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2641 - accuracy: 0.9107 - val_loss: 0.1864 - val_accuracy: 0.9450\n",
            "Epoch 79/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2548 - accuracy: 0.9133 - val_loss: 0.1910 - val_accuracy: 0.9460\n",
            "Epoch 80/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2600 - accuracy: 0.9139 - val_loss: 0.1862 - val_accuracy: 0.9445\n",
            "Epoch 81/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2565 - accuracy: 0.9128 - val_loss: 0.1860 - val_accuracy: 0.9455\n",
            "Epoch 82/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2610 - accuracy: 0.9107 - val_loss: 0.1851 - val_accuracy: 0.9465\n",
            "Epoch 83/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2541 - accuracy: 0.9186 - val_loss: 0.1874 - val_accuracy: 0.9455\n",
            "Epoch 84/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2638 - accuracy: 0.9131 - val_loss: 0.1845 - val_accuracy: 0.9470\n",
            "Epoch 85/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2587 - accuracy: 0.9144 - val_loss: 0.1872 - val_accuracy: 0.9465\n",
            "Epoch 86/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2540 - accuracy: 0.9172 - val_loss: 0.1875 - val_accuracy: 0.9445\n",
            "Epoch 87/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2559 - accuracy: 0.9131 - val_loss: 0.1872 - val_accuracy: 0.9450\n",
            "Epoch 88/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2680 - accuracy: 0.9150 - val_loss: 0.1878 - val_accuracy: 0.9450\n",
            "Epoch 89/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2578 - accuracy: 0.9161 - val_loss: 0.1868 - val_accuracy: 0.9450\n",
            "Epoch 90/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2617 - accuracy: 0.9140 - val_loss: 0.1891 - val_accuracy: 0.9445\n",
            "Epoch 91/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2543 - accuracy: 0.9149 - val_loss: 0.1868 - val_accuracy: 0.9445\n",
            "Epoch 92/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2657 - accuracy: 0.9133 - val_loss: 0.1902 - val_accuracy: 0.9440\n",
            "Epoch 93/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2629 - accuracy: 0.9129 - val_loss: 0.1893 - val_accuracy: 0.9460\n",
            "Epoch 94/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2615 - accuracy: 0.9134 - val_loss: 0.1886 - val_accuracy: 0.9415\n",
            "Epoch 95/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2606 - accuracy: 0.9160 - val_loss: 0.1884 - val_accuracy: 0.9445\n",
            "Epoch 96/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2648 - accuracy: 0.9106 - val_loss: 0.1863 - val_accuracy: 0.9430\n",
            "Epoch 97/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2615 - accuracy: 0.9141 - val_loss: 0.1854 - val_accuracy: 0.9445\n",
            "Epoch 98/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2624 - accuracy: 0.9150 - val_loss: 0.1887 - val_accuracy: 0.9450\n",
            "Epoch 99/6000\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2548 - accuracy: 0.9159 - val_loss: 0.1867 - val_accuracy: 0.9470\n",
            "Epoch 100/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2587 - accuracy: 0.9137 - val_loss: 0.1886 - val_accuracy: 0.9445\n",
            "Epoch 101/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2569 - accuracy: 0.9136 - val_loss: 0.1898 - val_accuracy: 0.9425\n",
            "Epoch 102/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2570 - accuracy: 0.9160 - val_loss: 0.1865 - val_accuracy: 0.9445\n",
            "Epoch 103/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2575 - accuracy: 0.9146 - val_loss: 0.1865 - val_accuracy: 0.9460\n",
            "Epoch 104/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2596 - accuracy: 0.9166 - val_loss: 0.1863 - val_accuracy: 0.9435\n",
            "Epoch 105/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2720 - accuracy: 0.9111 - val_loss: 0.1869 - val_accuracy: 0.9450\n",
            "Epoch 106/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2633 - accuracy: 0.9133 - val_loss: 0.1900 - val_accuracy: 0.9445\n",
            "Epoch 107/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2638 - accuracy: 0.9134 - val_loss: 0.1881 - val_accuracy: 0.9465\n",
            "Epoch 108/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2575 - accuracy: 0.9147 - val_loss: 0.1862 - val_accuracy: 0.9440\n",
            "Epoch 109/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2539 - accuracy: 0.9158 - val_loss: 0.1916 - val_accuracy: 0.9460\n",
            "Epoch 110/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2624 - accuracy: 0.9143 - val_loss: 0.1841 - val_accuracy: 0.9470\n",
            "Epoch 111/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2595 - accuracy: 0.9128 - val_loss: 0.1848 - val_accuracy: 0.9450\n",
            "Epoch 112/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2540 - accuracy: 0.9150 - val_loss: 0.1859 - val_accuracy: 0.9465\n",
            "Epoch 113/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2617 - accuracy: 0.9146 - val_loss: 0.1875 - val_accuracy: 0.9450\n",
            "Epoch 114/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2552 - accuracy: 0.9120 - val_loss: 0.1839 - val_accuracy: 0.9465\n",
            "Epoch 115/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2601 - accuracy: 0.9154 - val_loss: 0.1886 - val_accuracy: 0.9450\n",
            "Epoch 116/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2641 - accuracy: 0.9143 - val_loss: 0.1854 - val_accuracy: 0.9440\n",
            "Epoch 117/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2673 - accuracy: 0.9110 - val_loss: 0.1867 - val_accuracy: 0.9460\n",
            "Epoch 118/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2710 - accuracy: 0.9149 - val_loss: 0.1891 - val_accuracy: 0.9445\n",
            "Epoch 119/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2605 - accuracy: 0.9137 - val_loss: 0.1861 - val_accuracy: 0.9450\n",
            "Epoch 120/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2569 - accuracy: 0.9137 - val_loss: 0.1865 - val_accuracy: 0.9440\n",
            "Epoch 121/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2608 - accuracy: 0.9179 - val_loss: 0.1853 - val_accuracy: 0.9460\n",
            "Epoch 122/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2646 - accuracy: 0.9162 - val_loss: 0.1873 - val_accuracy: 0.9480\n",
            "Epoch 123/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2682 - accuracy: 0.9106 - val_loss: 0.1861 - val_accuracy: 0.9465\n",
            "Epoch 124/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2560 - accuracy: 0.9187 - val_loss: 0.1856 - val_accuracy: 0.9465\n",
            "Epoch 125/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2686 - accuracy: 0.9134 - val_loss: 0.1867 - val_accuracy: 0.9440\n",
            "Epoch 126/6000\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2689 - accuracy: 0.9118 - val_loss: 0.1869 - val_accuracy: 0.9445\n",
            "Epoch 127/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2533 - accuracy: 0.9150 - val_loss: 0.1879 - val_accuracy: 0.9445\n",
            "Epoch 128/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2644 - accuracy: 0.9140 - val_loss: 0.1882 - val_accuracy: 0.9455\n",
            "Epoch 129/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2570 - accuracy: 0.9140 - val_loss: 0.1853 - val_accuracy: 0.9455\n",
            "Epoch 130/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2604 - accuracy: 0.9170 - val_loss: 0.1846 - val_accuracy: 0.9465\n",
            "Epoch 131/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2591 - accuracy: 0.9139 - val_loss: 0.1886 - val_accuracy: 0.9455\n",
            "Epoch 132/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2680 - accuracy: 0.9116 - val_loss: 0.1873 - val_accuracy: 0.9490\n",
            "Epoch 133/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2628 - accuracy: 0.9118 - val_loss: 0.1876 - val_accuracy: 0.9480\n",
            "Epoch 134/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2516 - accuracy: 0.9169 - val_loss: 0.1896 - val_accuracy: 0.9450\n",
            "Epoch 135/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2552 - accuracy: 0.9199 - val_loss: 0.1870 - val_accuracy: 0.9415\n",
            "Epoch 136/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2518 - accuracy: 0.9168 - val_loss: 0.1884 - val_accuracy: 0.9455\n",
            "Epoch 137/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2538 - accuracy: 0.9178 - val_loss: 0.1846 - val_accuracy: 0.9485\n",
            "Epoch 138/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2608 - accuracy: 0.9130 - val_loss: 0.1848 - val_accuracy: 0.9465\n",
            "Epoch 139/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2665 - accuracy: 0.9110 - val_loss: 0.1892 - val_accuracy: 0.9460\n",
            "Epoch 140/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2628 - accuracy: 0.9135 - val_loss: 0.1867 - val_accuracy: 0.9455\n",
            "Epoch 141/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2581 - accuracy: 0.9156 - val_loss: 0.1829 - val_accuracy: 0.9460\n",
            "Epoch 142/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2569 - accuracy: 0.9135 - val_loss: 0.1862 - val_accuracy: 0.9450\n",
            "Epoch 143/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2635 - accuracy: 0.9128 - val_loss: 0.1851 - val_accuracy: 0.9465\n",
            "Epoch 144/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2614 - accuracy: 0.9158 - val_loss: 0.1834 - val_accuracy: 0.9480\n",
            "Epoch 145/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2623 - accuracy: 0.9153 - val_loss: 0.1846 - val_accuracy: 0.9460\n",
            "Epoch 146/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2577 - accuracy: 0.9126 - val_loss: 0.1868 - val_accuracy: 0.9460\n",
            "Epoch 147/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2607 - accuracy: 0.9144 - val_loss: 0.1857 - val_accuracy: 0.9480\n",
            "Epoch 148/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2638 - accuracy: 0.9100 - val_loss: 0.1852 - val_accuracy: 0.9460\n",
            "Epoch 149/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2644 - accuracy: 0.9150 - val_loss: 0.1881 - val_accuracy: 0.9450\n",
            "Epoch 150/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2610 - accuracy: 0.9147 - val_loss: 0.1849 - val_accuracy: 0.9460\n",
            "Epoch 151/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2608 - accuracy: 0.9116 - val_loss: 0.1872 - val_accuracy: 0.9460\n",
            "Epoch 152/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2654 - accuracy: 0.9122 - val_loss: 0.1846 - val_accuracy: 0.9465\n",
            "Epoch 153/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2647 - accuracy: 0.9139 - val_loss: 0.1869 - val_accuracy: 0.9450\n",
            "Epoch 154/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2625 - accuracy: 0.9146 - val_loss: 0.1860 - val_accuracy: 0.9460\n",
            "Epoch 155/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2535 - accuracy: 0.9156 - val_loss: 0.1878 - val_accuracy: 0.9440\n",
            "Epoch 156/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2589 - accuracy: 0.9155 - val_loss: 0.1868 - val_accuracy: 0.9430\n",
            "Epoch 157/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2534 - accuracy: 0.9160 - val_loss: 0.1898 - val_accuracy: 0.9450\n",
            "Epoch 158/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2633 - accuracy: 0.9094 - val_loss: 0.1862 - val_accuracy: 0.9435\n",
            "Epoch 159/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2600 - accuracy: 0.9134 - val_loss: 0.1885 - val_accuracy: 0.9455\n",
            "Epoch 160/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2586 - accuracy: 0.9114 - val_loss: 0.1885 - val_accuracy: 0.9440\n",
            "Epoch 161/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2591 - accuracy: 0.9144 - val_loss: 0.1906 - val_accuracy: 0.9445\n",
            "Epoch 162/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2623 - accuracy: 0.9096 - val_loss: 0.1877 - val_accuracy: 0.9455\n",
            "Epoch 163/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2636 - accuracy: 0.9125 - val_loss: 0.1858 - val_accuracy: 0.9475\n",
            "Epoch 164/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2634 - accuracy: 0.9153 - val_loss: 0.1878 - val_accuracy: 0.9425\n",
            "Epoch 165/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2579 - accuracy: 0.9125 - val_loss: 0.1842 - val_accuracy: 0.9475\n",
            "Epoch 166/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2642 - accuracy: 0.9141 - val_loss: 0.1907 - val_accuracy: 0.9455\n",
            "Epoch 167/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2659 - accuracy: 0.9130 - val_loss: 0.1858 - val_accuracy: 0.9480\n",
            "Epoch 168/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2632 - accuracy: 0.9154 - val_loss: 0.1883 - val_accuracy: 0.9445\n",
            "Epoch 169/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2578 - accuracy: 0.9146 - val_loss: 0.1866 - val_accuracy: 0.9450\n",
            "Epoch 170/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2697 - accuracy: 0.9122 - val_loss: 0.1872 - val_accuracy: 0.9465\n",
            "Epoch 171/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2683 - accuracy: 0.9114 - val_loss: 0.1883 - val_accuracy: 0.9450\n",
            "Epoch 172/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2556 - accuracy: 0.9178 - val_loss: 0.1851 - val_accuracy: 0.9475\n",
            "Epoch 173/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2599 - accuracy: 0.9097 - val_loss: 0.1888 - val_accuracy: 0.9480\n",
            "Epoch 174/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2667 - accuracy: 0.9111 - val_loss: 0.1877 - val_accuracy: 0.9460\n",
            "Epoch 175/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2583 - accuracy: 0.9159 - val_loss: 0.1870 - val_accuracy: 0.9460\n",
            "Epoch 176/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2491 - accuracy: 0.9184 - val_loss: 0.1886 - val_accuracy: 0.9455\n",
            "Epoch 177/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2570 - accuracy: 0.9156 - val_loss: 0.1861 - val_accuracy: 0.9455\n",
            "Epoch 178/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2588 - accuracy: 0.9166 - val_loss: 0.1861 - val_accuracy: 0.9470\n",
            "Epoch 179/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2503 - accuracy: 0.9184 - val_loss: 0.1848 - val_accuracy: 0.9455\n",
            "Epoch 180/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2535 - accuracy: 0.9193 - val_loss: 0.1839 - val_accuracy: 0.9480\n",
            "Epoch 181/6000\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2564 - accuracy: 0.9145 - val_loss: 0.1836 - val_accuracy: 0.9445\n",
            "Epoch 182/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2658 - accuracy: 0.9159 - val_loss: 0.1836 - val_accuracy: 0.9465\n",
            "Epoch 183/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2577 - accuracy: 0.9170 - val_loss: 0.1844 - val_accuracy: 0.9475\n",
            "Epoch 184/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2562 - accuracy: 0.9158 - val_loss: 0.1845 - val_accuracy: 0.9470\n",
            "Epoch 185/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2560 - accuracy: 0.9144 - val_loss: 0.1827 - val_accuracy: 0.9480\n",
            "Epoch 186/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2612 - accuracy: 0.9161 - val_loss: 0.1890 - val_accuracy: 0.9465\n",
            "Epoch 187/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2631 - accuracy: 0.9124 - val_loss: 0.1829 - val_accuracy: 0.9485\n",
            "Epoch 188/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2541 - accuracy: 0.9145 - val_loss: 0.1855 - val_accuracy: 0.9480\n",
            "Epoch 189/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2639 - accuracy: 0.9160 - val_loss: 0.1891 - val_accuracy: 0.9460\n",
            "Epoch 190/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2560 - accuracy: 0.9115 - val_loss: 0.1864 - val_accuracy: 0.9460\n",
            "Epoch 191/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2571 - accuracy: 0.9155 - val_loss: 0.1845 - val_accuracy: 0.9470\n",
            "Epoch 192/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2562 - accuracy: 0.9179 - val_loss: 0.1889 - val_accuracy: 0.9465\n",
            "Epoch 193/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2565 - accuracy: 0.9130 - val_loss: 0.1871 - val_accuracy: 0.9460\n",
            "Epoch 194/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2563 - accuracy: 0.9149 - val_loss: 0.1900 - val_accuracy: 0.9435\n",
            "Epoch 195/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2696 - accuracy: 0.9134 - val_loss: 0.1876 - val_accuracy: 0.9455\n",
            "Epoch 196/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2573 - accuracy: 0.9139 - val_loss: 0.1825 - val_accuracy: 0.9480\n",
            "Epoch 197/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2545 - accuracy: 0.9115 - val_loss: 0.1857 - val_accuracy: 0.9460\n",
            "Epoch 198/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2601 - accuracy: 0.9119 - val_loss: 0.1840 - val_accuracy: 0.9470\n",
            "Epoch 199/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2664 - accuracy: 0.9145 - val_loss: 0.1843 - val_accuracy: 0.9460\n",
            "Epoch 200/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2547 - accuracy: 0.9169 - val_loss: 0.1892 - val_accuracy: 0.9450\n",
            "Epoch 201/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2631 - accuracy: 0.9122 - val_loss: 0.1854 - val_accuracy: 0.9460\n",
            "Epoch 202/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2511 - accuracy: 0.9144 - val_loss: 0.1854 - val_accuracy: 0.9455\n",
            "Epoch 203/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2675 - accuracy: 0.9149 - val_loss: 0.1859 - val_accuracy: 0.9480\n",
            "Epoch 204/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2503 - accuracy: 0.9174 - val_loss: 0.1845 - val_accuracy: 0.9470\n",
            "Epoch 205/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2551 - accuracy: 0.9162 - val_loss: 0.1858 - val_accuracy: 0.9460\n",
            "Epoch 206/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2572 - accuracy: 0.9143 - val_loss: 0.1881 - val_accuracy: 0.9445\n",
            "Epoch 207/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2591 - accuracy: 0.9141 - val_loss: 0.1898 - val_accuracy: 0.9450\n",
            "Epoch 208/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2675 - accuracy: 0.9129 - val_loss: 0.1887 - val_accuracy: 0.9450\n",
            "Epoch 209/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2575 - accuracy: 0.9147 - val_loss: 0.1923 - val_accuracy: 0.9410\n",
            "Epoch 210/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2624 - accuracy: 0.9119 - val_loss: 0.1890 - val_accuracy: 0.9445\n",
            "Epoch 211/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2566 - accuracy: 0.9162 - val_loss: 0.1884 - val_accuracy: 0.9445\n",
            "Epoch 212/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2596 - accuracy: 0.9146 - val_loss: 0.1854 - val_accuracy: 0.9460\n",
            "Epoch 213/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2665 - accuracy: 0.9145 - val_loss: 0.1872 - val_accuracy: 0.9445\n",
            "Epoch 214/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2598 - accuracy: 0.9110 - val_loss: 0.1866 - val_accuracy: 0.9445\n",
            "Epoch 215/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2623 - accuracy: 0.9139 - val_loss: 0.1868 - val_accuracy: 0.9455\n",
            "Epoch 216/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2625 - accuracy: 0.9133 - val_loss: 0.1861 - val_accuracy: 0.9460\n",
            "Epoch 217/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2518 - accuracy: 0.9168 - val_loss: 0.1844 - val_accuracy: 0.9470\n",
            "Epoch 218/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2604 - accuracy: 0.9145 - val_loss: 0.1877 - val_accuracy: 0.9440\n",
            "Epoch 219/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2563 - accuracy: 0.9156 - val_loss: 0.1870 - val_accuracy: 0.9430\n",
            "Epoch 220/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2715 - accuracy: 0.9136 - val_loss: 0.1912 - val_accuracy: 0.9420\n",
            "Epoch 221/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2660 - accuracy: 0.9135 - val_loss: 0.1885 - val_accuracy: 0.9450\n",
            "Epoch 222/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2594 - accuracy: 0.9151 - val_loss: 0.1868 - val_accuracy: 0.9440\n",
            "Epoch 223/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2581 - accuracy: 0.9143 - val_loss: 0.1879 - val_accuracy: 0.9455\n",
            "Epoch 224/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2588 - accuracy: 0.9154 - val_loss: 0.1849 - val_accuracy: 0.9450\n",
            "Epoch 225/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2593 - accuracy: 0.9141 - val_loss: 0.1848 - val_accuracy: 0.9475\n",
            "Epoch 226/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2527 - accuracy: 0.9185 - val_loss: 0.1884 - val_accuracy: 0.9435\n",
            "Epoch 227/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2546 - accuracy: 0.9166 - val_loss: 0.1844 - val_accuracy: 0.9460\n",
            "Epoch 228/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2643 - accuracy: 0.9179 - val_loss: 0.1869 - val_accuracy: 0.9465\n",
            "Epoch 229/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2703 - accuracy: 0.9120 - val_loss: 0.1820 - val_accuracy: 0.9455\n",
            "Epoch 230/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2534 - accuracy: 0.9180 - val_loss: 0.1815 - val_accuracy: 0.9455\n",
            "Epoch 231/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2596 - accuracy: 0.9129 - val_loss: 0.1843 - val_accuracy: 0.9460\n",
            "Epoch 232/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2581 - accuracy: 0.9172 - val_loss: 0.1816 - val_accuracy: 0.9440\n",
            "Epoch 233/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2650 - accuracy: 0.9170 - val_loss: 0.1859 - val_accuracy: 0.9455\n",
            "Epoch 234/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2492 - accuracy: 0.9175 - val_loss: 0.1874 - val_accuracy: 0.9450\n",
            "Epoch 235/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2582 - accuracy: 0.9162 - val_loss: 0.1872 - val_accuracy: 0.9455\n",
            "Epoch 236/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2627 - accuracy: 0.9143 - val_loss: 0.1851 - val_accuracy: 0.9445\n",
            "Epoch 237/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2526 - accuracy: 0.9165 - val_loss: 0.1849 - val_accuracy: 0.9455\n",
            "Epoch 238/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2614 - accuracy: 0.9168 - val_loss: 0.1823 - val_accuracy: 0.9470\n",
            "Epoch 239/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2601 - accuracy: 0.9161 - val_loss: 0.1837 - val_accuracy: 0.9440\n",
            "Epoch 240/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2610 - accuracy: 0.9119 - val_loss: 0.1844 - val_accuracy: 0.9475\n",
            "Epoch 241/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2626 - accuracy: 0.9143 - val_loss: 0.1859 - val_accuracy: 0.9445\n",
            "Epoch 242/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2554 - accuracy: 0.9129 - val_loss: 0.1824 - val_accuracy: 0.9440\n",
            "Epoch 243/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2596 - accuracy: 0.9136 - val_loss: 0.1850 - val_accuracy: 0.9475\n",
            "Epoch 244/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2526 - accuracy: 0.9172 - val_loss: 0.1841 - val_accuracy: 0.9460\n",
            "Epoch 245/6000\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2609 - accuracy: 0.9118 - val_loss: 0.1854 - val_accuracy: 0.9450\n",
            "Epoch 246/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2604 - accuracy: 0.9166 - val_loss: 0.1885 - val_accuracy: 0.9455\n",
            "Epoch 247/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2524 - accuracy: 0.9164 - val_loss: 0.1853 - val_accuracy: 0.9460\n",
            "Epoch 248/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2638 - accuracy: 0.9115 - val_loss: 0.1867 - val_accuracy: 0.9430\n",
            "Epoch 249/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2660 - accuracy: 0.9154 - val_loss: 0.1834 - val_accuracy: 0.9460\n",
            "Epoch 250/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2427 - accuracy: 0.9211 - val_loss: 0.1837 - val_accuracy: 0.9475\n",
            "Epoch 251/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2576 - accuracy: 0.9139 - val_loss: 0.1836 - val_accuracy: 0.9465\n",
            "Epoch 252/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2640 - accuracy: 0.9136 - val_loss: 0.1860 - val_accuracy: 0.9465\n",
            "Epoch 253/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2504 - accuracy: 0.9169 - val_loss: 0.1846 - val_accuracy: 0.9470\n",
            "Epoch 254/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2566 - accuracy: 0.9156 - val_loss: 0.1874 - val_accuracy: 0.9440\n",
            "Epoch 255/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2511 - accuracy: 0.9186 - val_loss: 0.1856 - val_accuracy: 0.9450\n",
            "Epoch 256/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2659 - accuracy: 0.9135 - val_loss: 0.1874 - val_accuracy: 0.9455\n",
            "Epoch 257/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2604 - accuracy: 0.9180 - val_loss: 0.1862 - val_accuracy: 0.9450\n",
            "Epoch 258/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2614 - accuracy: 0.9134 - val_loss: 0.1857 - val_accuracy: 0.9460\n",
            "Epoch 259/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2675 - accuracy: 0.9171 - val_loss: 0.1882 - val_accuracy: 0.9460\n",
            "Epoch 260/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2556 - accuracy: 0.9178 - val_loss: 0.1881 - val_accuracy: 0.9460\n",
            "Epoch 261/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2512 - accuracy: 0.9184 - val_loss: 0.1875 - val_accuracy: 0.9460\n",
            "Epoch 262/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2633 - accuracy: 0.9129 - val_loss: 0.1867 - val_accuracy: 0.9470\n",
            "Epoch 263/6000\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2573 - accuracy: 0.9162 - val_loss: 0.1874 - val_accuracy: 0.9440\n",
            "Epoch 264/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2576 - accuracy: 0.9128 - val_loss: 0.1873 - val_accuracy: 0.9465\n",
            "Epoch 265/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2575 - accuracy: 0.9136 - val_loss: 0.1856 - val_accuracy: 0.9455\n",
            "Epoch 266/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2554 - accuracy: 0.9162 - val_loss: 0.1847 - val_accuracy: 0.9465\n",
            "Epoch 267/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2536 - accuracy: 0.9158 - val_loss: 0.1842 - val_accuracy: 0.9460\n",
            "Epoch 268/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2577 - accuracy: 0.9184 - val_loss: 0.1853 - val_accuracy: 0.9460\n",
            "Epoch 269/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2653 - accuracy: 0.9155 - val_loss: 0.1871 - val_accuracy: 0.9465\n",
            "Epoch 270/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2516 - accuracy: 0.9183 - val_loss: 0.1844 - val_accuracy: 0.9460\n",
            "Epoch 271/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2655 - accuracy: 0.9107 - val_loss: 0.1877 - val_accuracy: 0.9435\n",
            "Epoch 272/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2655 - accuracy: 0.9165 - val_loss: 0.1852 - val_accuracy: 0.9460\n",
            "Epoch 273/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2506 - accuracy: 0.9189 - val_loss: 0.1869 - val_accuracy: 0.9435\n",
            "Epoch 274/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2563 - accuracy: 0.9186 - val_loss: 0.1887 - val_accuracy: 0.9430\n",
            "Epoch 275/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2599 - accuracy: 0.9169 - val_loss: 0.1862 - val_accuracy: 0.9475\n",
            "Epoch 276/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2637 - accuracy: 0.9103 - val_loss: 0.1868 - val_accuracy: 0.9475\n",
            "Epoch 277/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2593 - accuracy: 0.9180 - val_loss: 0.1877 - val_accuracy: 0.9450\n",
            "Epoch 278/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2595 - accuracy: 0.9175 - val_loss: 0.1868 - val_accuracy: 0.9450\n",
            "Epoch 279/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2524 - accuracy: 0.9175 - val_loss: 0.1851 - val_accuracy: 0.9470\n",
            "Epoch 280/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2618 - accuracy: 0.9151 - val_loss: 0.1855 - val_accuracy: 0.9455\n",
            "Epoch 281/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2617 - accuracy: 0.9131 - val_loss: 0.1872 - val_accuracy: 0.9465\n",
            "Epoch 282/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2454 - accuracy: 0.9171 - val_loss: 0.1844 - val_accuracy: 0.9440\n",
            "Epoch 283/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2631 - accuracy: 0.9118 - val_loss: 0.1859 - val_accuracy: 0.9430\n",
            "Epoch 284/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2563 - accuracy: 0.9156 - val_loss: 0.1878 - val_accuracy: 0.9465\n",
            "Epoch 285/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2584 - accuracy: 0.9147 - val_loss: 0.1837 - val_accuracy: 0.9450\n",
            "Epoch 286/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2575 - accuracy: 0.9149 - val_loss: 0.1824 - val_accuracy: 0.9465\n",
            "Epoch 287/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2529 - accuracy: 0.9172 - val_loss: 0.1904 - val_accuracy: 0.9420\n",
            "Epoch 288/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2605 - accuracy: 0.9166 - val_loss: 0.1867 - val_accuracy: 0.9465\n",
            "Epoch 289/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2581 - accuracy: 0.9165 - val_loss: 0.1868 - val_accuracy: 0.9440\n",
            "Epoch 290/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2561 - accuracy: 0.9178 - val_loss: 0.1889 - val_accuracy: 0.9465\n",
            "Epoch 291/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2528 - accuracy: 0.9184 - val_loss: 0.1875 - val_accuracy: 0.9450\n",
            "Epoch 292/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2558 - accuracy: 0.9170 - val_loss: 0.1849 - val_accuracy: 0.9445\n",
            "Epoch 293/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2584 - accuracy: 0.9164 - val_loss: 0.1892 - val_accuracy: 0.9460\n",
            "Epoch 294/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2568 - accuracy: 0.9147 - val_loss: 0.1881 - val_accuracy: 0.9460\n",
            "Epoch 295/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2500 - accuracy: 0.9178 - val_loss: 0.1865 - val_accuracy: 0.9460\n",
            "Epoch 296/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2547 - accuracy: 0.9156 - val_loss: 0.1908 - val_accuracy: 0.9440\n",
            "Epoch 297/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2541 - accuracy: 0.9180 - val_loss: 0.1881 - val_accuracy: 0.9455\n",
            "Epoch 298/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2579 - accuracy: 0.9171 - val_loss: 0.1882 - val_accuracy: 0.9445\n",
            "Epoch 299/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2588 - accuracy: 0.9181 - val_loss: 0.1896 - val_accuracy: 0.9440\n",
            "Epoch 300/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2600 - accuracy: 0.9154 - val_loss: 0.1877 - val_accuracy: 0.9445\n",
            "Epoch 301/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2635 - accuracy: 0.9119 - val_loss: 0.1928 - val_accuracy: 0.9425\n",
            "Epoch 302/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2648 - accuracy: 0.9134 - val_loss: 0.1930 - val_accuracy: 0.9430\n",
            "Epoch 303/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2539 - accuracy: 0.9170 - val_loss: 0.1890 - val_accuracy: 0.9465\n",
            "Epoch 304/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2597 - accuracy: 0.9165 - val_loss: 0.1843 - val_accuracy: 0.9465\n",
            "Epoch 305/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2580 - accuracy: 0.9143 - val_loss: 0.1911 - val_accuracy: 0.9435\n",
            "Epoch 306/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2543 - accuracy: 0.9161 - val_loss: 0.1894 - val_accuracy: 0.9435\n",
            "Epoch 307/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2530 - accuracy: 0.9145 - val_loss: 0.1872 - val_accuracy: 0.9455\n",
            "Epoch 308/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2518 - accuracy: 0.9162 - val_loss: 0.1848 - val_accuracy: 0.9450\n",
            "Epoch 309/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2555 - accuracy: 0.9149 - val_loss: 0.1879 - val_accuracy: 0.9440\n",
            "Epoch 310/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2545 - accuracy: 0.9197 - val_loss: 0.1886 - val_accuracy: 0.9465\n",
            "Epoch 311/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2556 - accuracy: 0.9125 - val_loss: 0.1873 - val_accuracy: 0.9445\n",
            "Epoch 312/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2532 - accuracy: 0.9191 - val_loss: 0.1897 - val_accuracy: 0.9455\n",
            "Epoch 313/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2549 - accuracy: 0.9161 - val_loss: 0.1854 - val_accuracy: 0.9455\n",
            "Epoch 314/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2583 - accuracy: 0.9162 - val_loss: 0.1902 - val_accuracy: 0.9450\n",
            "Epoch 315/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2636 - accuracy: 0.9118 - val_loss: 0.1878 - val_accuracy: 0.9435\n",
            "Epoch 316/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2564 - accuracy: 0.9153 - val_loss: 0.1872 - val_accuracy: 0.9455\n",
            "Epoch 317/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2655 - accuracy: 0.9131 - val_loss: 0.1867 - val_accuracy: 0.9455\n",
            "Epoch 318/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2579 - accuracy: 0.9129 - val_loss: 0.1859 - val_accuracy: 0.9455\n",
            "Epoch 319/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2501 - accuracy: 0.9175 - val_loss: 0.1898 - val_accuracy: 0.9435\n",
            "Epoch 320/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2607 - accuracy: 0.9141 - val_loss: 0.1869 - val_accuracy: 0.9455\n",
            "Epoch 321/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2558 - accuracy: 0.9144 - val_loss: 0.1856 - val_accuracy: 0.9460\n",
            "Epoch 322/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2588 - accuracy: 0.9162 - val_loss: 0.1847 - val_accuracy: 0.9470\n",
            "Epoch 323/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2562 - accuracy: 0.9149 - val_loss: 0.1890 - val_accuracy: 0.9465\n",
            "Epoch 324/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2626 - accuracy: 0.9115 - val_loss: 0.1847 - val_accuracy: 0.9440\n",
            "Epoch 325/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2576 - accuracy: 0.9150 - val_loss: 0.1842 - val_accuracy: 0.9455\n",
            "Epoch 326/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2590 - accuracy: 0.9129 - val_loss: 0.1889 - val_accuracy: 0.9455\n",
            "Epoch 327/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2516 - accuracy: 0.9159 - val_loss: 0.1886 - val_accuracy: 0.9455\n",
            "Epoch 328/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2522 - accuracy: 0.9161 - val_loss: 0.1858 - val_accuracy: 0.9445\n",
            "Epoch 329/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2519 - accuracy: 0.9141 - val_loss: 0.1869 - val_accuracy: 0.9460\n",
            "Epoch 330/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2601 - accuracy: 0.9133 - val_loss: 0.1837 - val_accuracy: 0.9460\n",
            "Epoch 331/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2573 - accuracy: 0.9179 - val_loss: 0.1871 - val_accuracy: 0.9465\n",
            "Epoch 332/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2588 - accuracy: 0.9144 - val_loss: 0.1877 - val_accuracy: 0.9455\n",
            "Epoch 333/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2584 - accuracy: 0.9143 - val_loss: 0.1900 - val_accuracy: 0.9455\n",
            "Epoch 334/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2616 - accuracy: 0.9135 - val_loss: 0.1837 - val_accuracy: 0.9465\n",
            "Epoch 335/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2589 - accuracy: 0.9154 - val_loss: 0.1848 - val_accuracy: 0.9450\n",
            "Epoch 336/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2480 - accuracy: 0.9187 - val_loss: 0.1874 - val_accuracy: 0.9455\n",
            "Epoch 337/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2567 - accuracy: 0.9143 - val_loss: 0.1871 - val_accuracy: 0.9460\n",
            "Epoch 338/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2527 - accuracy: 0.9190 - val_loss: 0.1855 - val_accuracy: 0.9435\n",
            "Epoch 339/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2553 - accuracy: 0.9190 - val_loss: 0.1856 - val_accuracy: 0.9455\n",
            "Epoch 340/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2608 - accuracy: 0.9165 - val_loss: 0.1872 - val_accuracy: 0.9465\n",
            "Epoch 341/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2538 - accuracy: 0.9174 - val_loss: 0.1856 - val_accuracy: 0.9470\n",
            "Epoch 342/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2585 - accuracy: 0.9171 - val_loss: 0.1869 - val_accuracy: 0.9460\n",
            "Epoch 343/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2553 - accuracy: 0.9141 - val_loss: 0.1875 - val_accuracy: 0.9440\n",
            "Epoch 344/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2571 - accuracy: 0.9160 - val_loss: 0.1871 - val_accuracy: 0.9450\n",
            "Epoch 345/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2600 - accuracy: 0.9162 - val_loss: 0.1887 - val_accuracy: 0.9430\n",
            "Epoch 346/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2518 - accuracy: 0.9187 - val_loss: 0.1868 - val_accuracy: 0.9440\n",
            "Epoch 347/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2523 - accuracy: 0.9210 - val_loss: 0.1867 - val_accuracy: 0.9470\n",
            "Epoch 348/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2583 - accuracy: 0.9164 - val_loss: 0.1884 - val_accuracy: 0.9440\n",
            "Epoch 349/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2753 - accuracy: 0.9159 - val_loss: 0.1889 - val_accuracy: 0.9455\n",
            "Epoch 350/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2642 - accuracy: 0.9151 - val_loss: 0.1880 - val_accuracy: 0.9430\n",
            "Epoch 351/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2529 - accuracy: 0.9183 - val_loss: 0.1879 - val_accuracy: 0.9450\n",
            "Epoch 352/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2516 - accuracy: 0.9179 - val_loss: 0.1890 - val_accuracy: 0.9455\n",
            "Epoch 353/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2536 - accuracy: 0.9178 - val_loss: 0.1879 - val_accuracy: 0.9435\n",
            "Epoch 354/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2607 - accuracy: 0.9136 - val_loss: 0.1897 - val_accuracy: 0.9445\n",
            "Epoch 355/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2510 - accuracy: 0.9172 - val_loss: 0.1888 - val_accuracy: 0.9435\n",
            "Epoch 356/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2637 - accuracy: 0.9129 - val_loss: 0.1914 - val_accuracy: 0.9445\n",
            "Epoch 357/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2516 - accuracy: 0.9180 - val_loss: 0.1877 - val_accuracy: 0.9455\n",
            "Epoch 358/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2610 - accuracy: 0.9169 - val_loss: 0.1898 - val_accuracy: 0.9450\n",
            "Epoch 359/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2590 - accuracy: 0.9158 - val_loss: 0.1899 - val_accuracy: 0.9440\n",
            "Epoch 360/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2596 - accuracy: 0.9190 - val_loss: 0.1851 - val_accuracy: 0.9460\n",
            "Epoch 361/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2540 - accuracy: 0.9197 - val_loss: 0.1882 - val_accuracy: 0.9450\n",
            "Epoch 362/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2573 - accuracy: 0.9144 - val_loss: 0.1909 - val_accuracy: 0.9420\n",
            "Epoch 363/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2520 - accuracy: 0.9197 - val_loss: 0.1888 - val_accuracy: 0.9445\n",
            "Epoch 364/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2528 - accuracy: 0.9181 - val_loss: 0.1867 - val_accuracy: 0.9445\n",
            "Epoch 365/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2477 - accuracy: 0.9166 - val_loss: 0.1877 - val_accuracy: 0.9460\n",
            "Epoch 366/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2527 - accuracy: 0.9196 - val_loss: 0.1856 - val_accuracy: 0.9455\n",
            "Epoch 367/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2601 - accuracy: 0.9143 - val_loss: 0.1864 - val_accuracy: 0.9465\n",
            "Epoch 368/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2545 - accuracy: 0.9185 - val_loss: 0.1890 - val_accuracy: 0.9430\n",
            "Epoch 369/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2559 - accuracy: 0.9164 - val_loss: 0.1897 - val_accuracy: 0.9460\n",
            "Epoch 370/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2582 - accuracy: 0.9169 - val_loss: 0.1868 - val_accuracy: 0.9455\n",
            "Epoch 371/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2536 - accuracy: 0.9196 - val_loss: 0.1840 - val_accuracy: 0.9460\n",
            "Epoch 372/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2482 - accuracy: 0.9218 - val_loss: 0.1852 - val_accuracy: 0.9445\n",
            "Epoch 373/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2484 - accuracy: 0.9191 - val_loss: 0.1859 - val_accuracy: 0.9460\n",
            "Epoch 374/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2552 - accuracy: 0.9154 - val_loss: 0.1865 - val_accuracy: 0.9445\n",
            "Epoch 375/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2567 - accuracy: 0.9170 - val_loss: 0.1854 - val_accuracy: 0.9455\n",
            "Epoch 376/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2607 - accuracy: 0.9154 - val_loss: 0.1914 - val_accuracy: 0.9435\n",
            "Epoch 377/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2540 - accuracy: 0.9174 - val_loss: 0.1899 - val_accuracy: 0.9460\n",
            "Epoch 378/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2570 - accuracy: 0.9141 - val_loss: 0.1880 - val_accuracy: 0.9455\n",
            "Epoch 379/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2587 - accuracy: 0.9174 - val_loss: 0.1864 - val_accuracy: 0.9455\n",
            "Epoch 380/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2578 - accuracy: 0.9165 - val_loss: 0.1878 - val_accuracy: 0.9450\n",
            "Epoch 381/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2612 - accuracy: 0.9154 - val_loss: 0.1903 - val_accuracy: 0.9445\n",
            "Epoch 382/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2638 - accuracy: 0.9155 - val_loss: 0.1884 - val_accuracy: 0.9440\n",
            "Epoch 383/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2565 - accuracy: 0.9170 - val_loss: 0.1862 - val_accuracy: 0.9435\n",
            "Epoch 384/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2563 - accuracy: 0.9200 - val_loss: 0.1845 - val_accuracy: 0.9455\n",
            "Epoch 385/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2578 - accuracy: 0.9155 - val_loss: 0.1881 - val_accuracy: 0.9475\n",
            "Epoch 386/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2548 - accuracy: 0.9176 - val_loss: 0.1859 - val_accuracy: 0.9450\n",
            "Epoch 387/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2542 - accuracy: 0.9160 - val_loss: 0.1853 - val_accuracy: 0.9440\n",
            "Epoch 388/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2597 - accuracy: 0.9084 - val_loss: 0.1875 - val_accuracy: 0.9445\n",
            "Epoch 389/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2485 - accuracy: 0.9202 - val_loss: 0.1887 - val_accuracy: 0.9430\n",
            "Epoch 390/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2605 - accuracy: 0.9128 - val_loss: 0.1893 - val_accuracy: 0.9450\n",
            "Epoch 391/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2486 - accuracy: 0.9172 - val_loss: 0.1851 - val_accuracy: 0.9445\n",
            "Epoch 392/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2632 - accuracy: 0.9189 - val_loss: 0.1879 - val_accuracy: 0.9450\n",
            "Epoch 393/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2569 - accuracy: 0.9137 - val_loss: 0.1870 - val_accuracy: 0.9455\n",
            "Epoch 394/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2533 - accuracy: 0.9175 - val_loss: 0.1886 - val_accuracy: 0.9465\n",
            "Epoch 395/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2693 - accuracy: 0.9134 - val_loss: 0.1885 - val_accuracy: 0.9445\n",
            "Epoch 396/6000\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2559 - accuracy: 0.9161 - val_loss: 0.1890 - val_accuracy: 0.9460\n",
            "Epoch 397/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2569 - accuracy: 0.9145 - val_loss: 0.1870 - val_accuracy: 0.9450\n",
            "Epoch 398/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2567 - accuracy: 0.9153 - val_loss: 0.1863 - val_accuracy: 0.9450\n",
            "Epoch 399/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2604 - accuracy: 0.9190 - val_loss: 0.1904 - val_accuracy: 0.9430\n",
            "Epoch 400/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2564 - accuracy: 0.9158 - val_loss: 0.1894 - val_accuracy: 0.9455\n",
            "Epoch 401/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2561 - accuracy: 0.9145 - val_loss: 0.1889 - val_accuracy: 0.9450\n",
            "Epoch 402/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2586 - accuracy: 0.9171 - val_loss: 0.1857 - val_accuracy: 0.9455\n",
            "Epoch 403/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2594 - accuracy: 0.9171 - val_loss: 0.1868 - val_accuracy: 0.9455\n",
            "Epoch 404/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2572 - accuracy: 0.9162 - val_loss: 0.1843 - val_accuracy: 0.9460\n",
            "Epoch 405/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2662 - accuracy: 0.9154 - val_loss: 0.1848 - val_accuracy: 0.9465\n",
            "Epoch 406/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2558 - accuracy: 0.9155 - val_loss: 0.1848 - val_accuracy: 0.9460\n",
            "Epoch 407/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2539 - accuracy: 0.9191 - val_loss: 0.1842 - val_accuracy: 0.9445\n",
            "Epoch 408/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2530 - accuracy: 0.9172 - val_loss: 0.1848 - val_accuracy: 0.9455\n",
            "Epoch 409/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2583 - accuracy: 0.9196 - val_loss: 0.1878 - val_accuracy: 0.9445\n",
            "Epoch 410/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2573 - accuracy: 0.9183 - val_loss: 0.1885 - val_accuracy: 0.9435\n",
            "Epoch 411/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2505 - accuracy: 0.9169 - val_loss: 0.1910 - val_accuracy: 0.9450\n",
            "Epoch 412/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2576 - accuracy: 0.9166 - val_loss: 0.1902 - val_accuracy: 0.9445\n",
            "Epoch 413/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2522 - accuracy: 0.9179 - val_loss: 0.1902 - val_accuracy: 0.9425\n",
            "Epoch 414/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2627 - accuracy: 0.9155 - val_loss: 0.1879 - val_accuracy: 0.9450\n",
            "Epoch 415/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2521 - accuracy: 0.9181 - val_loss: 0.1881 - val_accuracy: 0.9420\n",
            "Epoch 416/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2609 - accuracy: 0.9159 - val_loss: 0.1894 - val_accuracy: 0.9460\n",
            "Epoch 417/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2494 - accuracy: 0.9206 - val_loss: 0.1901 - val_accuracy: 0.9420\n",
            "Epoch 418/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2489 - accuracy: 0.9200 - val_loss: 0.1845 - val_accuracy: 0.9455\n",
            "Epoch 419/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2433 - accuracy: 0.9196 - val_loss: 0.1884 - val_accuracy: 0.9445\n",
            "Epoch 420/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2573 - accuracy: 0.9181 - val_loss: 0.1830 - val_accuracy: 0.9450\n",
            "Epoch 421/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2605 - accuracy: 0.9126 - val_loss: 0.1824 - val_accuracy: 0.9455\n",
            "Epoch 422/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2514 - accuracy: 0.9190 - val_loss: 0.1865 - val_accuracy: 0.9450\n",
            "Epoch 423/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2536 - accuracy: 0.9162 - val_loss: 0.1861 - val_accuracy: 0.9450\n",
            "Epoch 424/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2528 - accuracy: 0.9185 - val_loss: 0.1866 - val_accuracy: 0.9435\n",
            "Epoch 425/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2473 - accuracy: 0.9214 - val_loss: 0.1843 - val_accuracy: 0.9470\n",
            "Epoch 426/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2479 - accuracy: 0.9179 - val_loss: 0.1862 - val_accuracy: 0.9470\n",
            "Epoch 427/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2504 - accuracy: 0.9180 - val_loss: 0.1893 - val_accuracy: 0.9435\n",
            "Epoch 428/6000\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2572 - accuracy: 0.9137 - val_loss: 0.1888 - val_accuracy: 0.9440\n",
            "Epoch 429/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2484 - accuracy: 0.9194 - val_loss: 0.1908 - val_accuracy: 0.9460\n",
            "Epoch 430/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2583 - accuracy: 0.9176 - val_loss: 0.1912 - val_accuracy: 0.9450\n",
            "Epoch 431/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2584 - accuracy: 0.9196 - val_loss: 0.1883 - val_accuracy: 0.9465\n",
            "Epoch 432/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2478 - accuracy: 0.9193 - val_loss: 0.1886 - val_accuracy: 0.9465\n",
            "Epoch 433/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2568 - accuracy: 0.9165 - val_loss: 0.1878 - val_accuracy: 0.9455\n",
            "Epoch 434/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2562 - accuracy: 0.9179 - val_loss: 0.1865 - val_accuracy: 0.9455\n",
            "Epoch 435/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2530 - accuracy: 0.9169 - val_loss: 0.1863 - val_accuracy: 0.9450\n",
            "Epoch 436/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2492 - accuracy: 0.9200 - val_loss: 0.1881 - val_accuracy: 0.9440\n",
            "Epoch 437/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2506 - accuracy: 0.9202 - val_loss: 0.1890 - val_accuracy: 0.9440\n",
            "Epoch 438/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2569 - accuracy: 0.9193 - val_loss: 0.1859 - val_accuracy: 0.9445\n",
            "Epoch 439/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2551 - accuracy: 0.9178 - val_loss: 0.1924 - val_accuracy: 0.9455\n",
            "Epoch 440/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2592 - accuracy: 0.9191 - val_loss: 0.1908 - val_accuracy: 0.9450\n",
            "Epoch 441/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2579 - accuracy: 0.9181 - val_loss: 0.1929 - val_accuracy: 0.9430\n",
            "Epoch 442/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2557 - accuracy: 0.9185 - val_loss: 0.1869 - val_accuracy: 0.9455\n",
            "Epoch 443/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2584 - accuracy: 0.9171 - val_loss: 0.1851 - val_accuracy: 0.9460\n",
            "Epoch 444/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2578 - accuracy: 0.9155 - val_loss: 0.1890 - val_accuracy: 0.9445\n",
            "Epoch 445/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2575 - accuracy: 0.9158 - val_loss: 0.1901 - val_accuracy: 0.9440\n",
            "Epoch 446/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2557 - accuracy: 0.9172 - val_loss: 0.1861 - val_accuracy: 0.9450\n",
            "Epoch 447/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2531 - accuracy: 0.9168 - val_loss: 0.1860 - val_accuracy: 0.9455\n",
            "Epoch 448/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2615 - accuracy: 0.9175 - val_loss: 0.1845 - val_accuracy: 0.9465\n",
            "Epoch 449/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2511 - accuracy: 0.9178 - val_loss: 0.1914 - val_accuracy: 0.9430\n",
            "Epoch 450/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2585 - accuracy: 0.9156 - val_loss: 0.1898 - val_accuracy: 0.9440\n",
            "Epoch 451/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2553 - accuracy: 0.9184 - val_loss: 0.1926 - val_accuracy: 0.9425\n",
            "Epoch 452/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2523 - accuracy: 0.9180 - val_loss: 0.1887 - val_accuracy: 0.9445\n",
            "Epoch 453/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2584 - accuracy: 0.9179 - val_loss: 0.1861 - val_accuracy: 0.9455\n",
            "Epoch 454/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2519 - accuracy: 0.9169 - val_loss: 0.1871 - val_accuracy: 0.9450\n",
            "Epoch 455/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2559 - accuracy: 0.9139 - val_loss: 0.1921 - val_accuracy: 0.9435\n",
            "Epoch 456/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2600 - accuracy: 0.9179 - val_loss: 0.1916 - val_accuracy: 0.9445\n",
            "Epoch 457/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2636 - accuracy: 0.9140 - val_loss: 0.1878 - val_accuracy: 0.9430\n",
            "Epoch 458/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2520 - accuracy: 0.9196 - val_loss: 0.1864 - val_accuracy: 0.9455\n",
            "Epoch 459/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2527 - accuracy: 0.9153 - val_loss: 0.1860 - val_accuracy: 0.9450\n",
            "Epoch 460/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2616 - accuracy: 0.9131 - val_loss: 0.1830 - val_accuracy: 0.9465\n",
            "Epoch 461/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2520 - accuracy: 0.9194 - val_loss: 0.1851 - val_accuracy: 0.9450\n",
            "Epoch 462/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2595 - accuracy: 0.9151 - val_loss: 0.1837 - val_accuracy: 0.9465\n",
            "Epoch 463/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2463 - accuracy: 0.9199 - val_loss: 0.1861 - val_accuracy: 0.9465\n",
            "Epoch 464/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2498 - accuracy: 0.9205 - val_loss: 0.1840 - val_accuracy: 0.9475\n",
            "Epoch 465/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2460 - accuracy: 0.9184 - val_loss: 0.1874 - val_accuracy: 0.9465\n",
            "Epoch 466/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2615 - accuracy: 0.9161 - val_loss: 0.1880 - val_accuracy: 0.9445\n",
            "Epoch 467/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2530 - accuracy: 0.9165 - val_loss: 0.1851 - val_accuracy: 0.9450\n",
            "Epoch 468/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2583 - accuracy: 0.9145 - val_loss: 0.1864 - val_accuracy: 0.9455\n",
            "Epoch 469/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2543 - accuracy: 0.9165 - val_loss: 0.1925 - val_accuracy: 0.9435\n",
            "Epoch 470/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2581 - accuracy: 0.9155 - val_loss: 0.1871 - val_accuracy: 0.9435\n",
            "Epoch 471/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2444 - accuracy: 0.9204 - val_loss: 0.1891 - val_accuracy: 0.9445\n",
            "Epoch 472/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2556 - accuracy: 0.9172 - val_loss: 0.1870 - val_accuracy: 0.9445\n",
            "Epoch 473/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2469 - accuracy: 0.9184 - val_loss: 0.1868 - val_accuracy: 0.9455\n",
            "Epoch 474/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2545 - accuracy: 0.9124 - val_loss: 0.1913 - val_accuracy: 0.9420\n",
            "Epoch 475/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2639 - accuracy: 0.9164 - val_loss: 0.1900 - val_accuracy: 0.9440\n",
            "Epoch 476/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2565 - accuracy: 0.9162 - val_loss: 0.1896 - val_accuracy: 0.9430\n",
            "Epoch 477/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2601 - accuracy: 0.9165 - val_loss: 0.1878 - val_accuracy: 0.9445\n",
            "Epoch 478/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2531 - accuracy: 0.9200 - val_loss: 0.1881 - val_accuracy: 0.9445\n",
            "Epoch 479/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2634 - accuracy: 0.9165 - val_loss: 0.1890 - val_accuracy: 0.9430\n",
            "Epoch 480/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2528 - accuracy: 0.9184 - val_loss: 0.1873 - val_accuracy: 0.9445\n",
            "Epoch 481/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2479 - accuracy: 0.9204 - val_loss: 0.1924 - val_accuracy: 0.9435\n",
            "Epoch 482/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2542 - accuracy: 0.9164 - val_loss: 0.1881 - val_accuracy: 0.9440\n",
            "Epoch 483/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2512 - accuracy: 0.9194 - val_loss: 0.1861 - val_accuracy: 0.9450\n",
            "Epoch 484/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2543 - accuracy: 0.9145 - val_loss: 0.1875 - val_accuracy: 0.9445\n",
            "Epoch 485/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2607 - accuracy: 0.9181 - val_loss: 0.1878 - val_accuracy: 0.9425\n",
            "Epoch 486/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2562 - accuracy: 0.9151 - val_loss: 0.1889 - val_accuracy: 0.9450\n",
            "Epoch 487/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2572 - accuracy: 0.9175 - val_loss: 0.1902 - val_accuracy: 0.9430\n",
            "Epoch 488/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2551 - accuracy: 0.9164 - val_loss: 0.1864 - val_accuracy: 0.9465\n",
            "Epoch 489/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2605 - accuracy: 0.9162 - val_loss: 0.1855 - val_accuracy: 0.9450\n",
            "Epoch 490/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2537 - accuracy: 0.9178 - val_loss: 0.1881 - val_accuracy: 0.9455\n",
            "Epoch 491/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2505 - accuracy: 0.9151 - val_loss: 0.1910 - val_accuracy: 0.9420\n",
            "Epoch 492/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2666 - accuracy: 0.9150 - val_loss: 0.1922 - val_accuracy: 0.9430\n",
            "Epoch 493/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2541 - accuracy: 0.9168 - val_loss: 0.1886 - val_accuracy: 0.9450\n",
            "Epoch 494/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2603 - accuracy: 0.9190 - val_loss: 0.1895 - val_accuracy: 0.9440\n",
            "Epoch 495/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2621 - accuracy: 0.9171 - val_loss: 0.1889 - val_accuracy: 0.9455\n",
            "Epoch 496/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2762 - accuracy: 0.9143 - val_loss: 0.1864 - val_accuracy: 0.9445\n",
            "Epoch 497/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2458 - accuracy: 0.9194 - val_loss: 0.1880 - val_accuracy: 0.9430\n",
            "Epoch 498/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2521 - accuracy: 0.9181 - val_loss: 0.1857 - val_accuracy: 0.9455\n",
            "Epoch 499/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2593 - accuracy: 0.9161 - val_loss: 0.1872 - val_accuracy: 0.9440\n",
            "Epoch 500/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2511 - accuracy: 0.9176 - val_loss: 0.1871 - val_accuracy: 0.9435\n",
            "Epoch 501/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2527 - accuracy: 0.9153 - val_loss: 0.1876 - val_accuracy: 0.9455\n",
            "Epoch 502/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2526 - accuracy: 0.9161 - val_loss: 0.1883 - val_accuracy: 0.9435\n",
            "Epoch 503/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2496 - accuracy: 0.9164 - val_loss: 0.1911 - val_accuracy: 0.9415\n",
            "Epoch 504/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2586 - accuracy: 0.9149 - val_loss: 0.1878 - val_accuracy: 0.9450\n",
            "Epoch 505/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2495 - accuracy: 0.9181 - val_loss: 0.1851 - val_accuracy: 0.9445\n",
            "Epoch 506/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2637 - accuracy: 0.9154 - val_loss: 0.1861 - val_accuracy: 0.9460\n",
            "Epoch 507/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2500 - accuracy: 0.9183 - val_loss: 0.1878 - val_accuracy: 0.9450\n",
            "Epoch 508/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2562 - accuracy: 0.9151 - val_loss: 0.1897 - val_accuracy: 0.9450\n",
            "Epoch 509/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2499 - accuracy: 0.9183 - val_loss: 0.1861 - val_accuracy: 0.9450\n",
            "Epoch 510/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2611 - accuracy: 0.9155 - val_loss: 0.1882 - val_accuracy: 0.9455\n",
            "Epoch 511/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2504 - accuracy: 0.9176 - val_loss: 0.1892 - val_accuracy: 0.9455\n",
            "Epoch 512/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2598 - accuracy: 0.9106 - val_loss: 0.1869 - val_accuracy: 0.9470\n",
            "Epoch 513/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2509 - accuracy: 0.9199 - val_loss: 0.1876 - val_accuracy: 0.9465\n",
            "Epoch 514/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2524 - accuracy: 0.9187 - val_loss: 0.1873 - val_accuracy: 0.9450\n",
            "Epoch 515/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2552 - accuracy: 0.9160 - val_loss: 0.1886 - val_accuracy: 0.9440\n",
            "Epoch 516/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2568 - accuracy: 0.9190 - val_loss: 0.1850 - val_accuracy: 0.9460\n",
            "Epoch 517/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2546 - accuracy: 0.9170 - val_loss: 0.1925 - val_accuracy: 0.9435\n",
            "Epoch 518/6000\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2578 - accuracy: 0.9168 - val_loss: 0.1882 - val_accuracy: 0.9465\n",
            "Epoch 519/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2533 - accuracy: 0.9170 - val_loss: 0.1873 - val_accuracy: 0.9460\n",
            "Epoch 520/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2553 - accuracy: 0.9174 - val_loss: 0.1875 - val_accuracy: 0.9455\n",
            "Epoch 521/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2556 - accuracy: 0.9162 - val_loss: 0.1863 - val_accuracy: 0.9465\n",
            "Epoch 522/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2563 - accuracy: 0.9195 - val_loss: 0.1891 - val_accuracy: 0.9440\n",
            "Epoch 523/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2613 - accuracy: 0.9140 - val_loss: 0.1882 - val_accuracy: 0.9455\n",
            "Epoch 524/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2566 - accuracy: 0.9181 - val_loss: 0.1860 - val_accuracy: 0.9460\n",
            "Epoch 525/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2509 - accuracy: 0.9162 - val_loss: 0.1870 - val_accuracy: 0.9460\n",
            "Epoch 526/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2446 - accuracy: 0.9209 - val_loss: 0.1846 - val_accuracy: 0.9475\n",
            "Epoch 527/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2600 - accuracy: 0.9144 - val_loss: 0.1869 - val_accuracy: 0.9450\n",
            "Epoch 528/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2499 - accuracy: 0.9211 - val_loss: 0.1855 - val_accuracy: 0.9455\n",
            "Epoch 529/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2422 - accuracy: 0.9183 - val_loss: 0.1881 - val_accuracy: 0.9455\n",
            "Epoch 530/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2525 - accuracy: 0.9218 - val_loss: 0.1886 - val_accuracy: 0.9435\n",
            "Epoch 531/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2634 - accuracy: 0.9162 - val_loss: 0.1897 - val_accuracy: 0.9440\n",
            "Epoch 532/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2559 - accuracy: 0.9181 - val_loss: 0.1866 - val_accuracy: 0.9450\n",
            "Epoch 533/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2506 - accuracy: 0.9155 - val_loss: 0.1926 - val_accuracy: 0.9435\n",
            "Epoch 534/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2508 - accuracy: 0.9180 - val_loss: 0.1876 - val_accuracy: 0.9455\n",
            "Epoch 535/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2641 - accuracy: 0.9186 - val_loss: 0.1876 - val_accuracy: 0.9450\n",
            "Epoch 536/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2488 - accuracy: 0.9202 - val_loss: 0.1879 - val_accuracy: 0.9435\n",
            "Epoch 537/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2559 - accuracy: 0.9186 - val_loss: 0.1918 - val_accuracy: 0.9435\n",
            "Epoch 538/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2499 - accuracy: 0.9164 - val_loss: 0.1877 - val_accuracy: 0.9455\n",
            "Epoch 539/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2606 - accuracy: 0.9165 - val_loss: 0.1885 - val_accuracy: 0.9440\n",
            "Epoch 540/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2502 - accuracy: 0.9190 - val_loss: 0.1887 - val_accuracy: 0.9450\n",
            "Epoch 541/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2555 - accuracy: 0.9171 - val_loss: 0.1862 - val_accuracy: 0.9445\n",
            "Epoch 542/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2599 - accuracy: 0.9151 - val_loss: 0.1898 - val_accuracy: 0.9445\n",
            "Epoch 543/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2596 - accuracy: 0.9156 - val_loss: 0.1903 - val_accuracy: 0.9450\n",
            "Epoch 544/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2571 - accuracy: 0.9166 - val_loss: 0.1905 - val_accuracy: 0.9440\n",
            "Epoch 545/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2546 - accuracy: 0.9187 - val_loss: 0.1885 - val_accuracy: 0.9460\n",
            "Epoch 546/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2533 - accuracy: 0.9189 - val_loss: 0.1903 - val_accuracy: 0.9465\n",
            "Epoch 547/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2537 - accuracy: 0.9161 - val_loss: 0.1864 - val_accuracy: 0.9440\n",
            "Epoch 548/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2592 - accuracy: 0.9154 - val_loss: 0.1879 - val_accuracy: 0.9455\n",
            "Epoch 549/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2472 - accuracy: 0.9176 - val_loss: 0.1895 - val_accuracy: 0.9445\n",
            "Epoch 550/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2532 - accuracy: 0.9181 - val_loss: 0.1901 - val_accuracy: 0.9450\n",
            "Epoch 551/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2469 - accuracy: 0.9185 - val_loss: 0.1880 - val_accuracy: 0.9455\n",
            "Epoch 552/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2522 - accuracy: 0.9185 - val_loss: 0.1906 - val_accuracy: 0.9450\n",
            "Epoch 553/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2577 - accuracy: 0.9161 - val_loss: 0.1892 - val_accuracy: 0.9460\n",
            "Epoch 554/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2534 - accuracy: 0.9162 - val_loss: 0.1884 - val_accuracy: 0.9445\n",
            "Epoch 555/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2527 - accuracy: 0.9189 - val_loss: 0.1913 - val_accuracy: 0.9425\n",
            "Epoch 556/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2601 - accuracy: 0.9158 - val_loss: 0.1946 - val_accuracy: 0.9425\n",
            "Epoch 557/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2467 - accuracy: 0.9212 - val_loss: 0.1894 - val_accuracy: 0.9425\n",
            "Epoch 558/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2569 - accuracy: 0.9170 - val_loss: 0.1909 - val_accuracy: 0.9430\n",
            "Epoch 559/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2498 - accuracy: 0.9222 - val_loss: 0.1874 - val_accuracy: 0.9450\n",
            "Epoch 560/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2591 - accuracy: 0.9212 - val_loss: 0.1924 - val_accuracy: 0.9435\n",
            "Epoch 561/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2477 - accuracy: 0.9186 - val_loss: 0.1869 - val_accuracy: 0.9430\n",
            "Epoch 562/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2533 - accuracy: 0.9187 - val_loss: 0.1886 - val_accuracy: 0.9460\n",
            "Epoch 563/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2624 - accuracy: 0.9184 - val_loss: 0.1933 - val_accuracy: 0.9445\n",
            "Epoch 564/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2538 - accuracy: 0.9139 - val_loss: 0.1915 - val_accuracy: 0.9440\n",
            "Epoch 565/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2686 - accuracy: 0.9129 - val_loss: 0.1905 - val_accuracy: 0.9465\n",
            "Epoch 566/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2567 - accuracy: 0.9159 - val_loss: 0.1918 - val_accuracy: 0.9440\n",
            "Epoch 567/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2566 - accuracy: 0.9154 - val_loss: 0.1967 - val_accuracy: 0.9415\n",
            "Epoch 568/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2575 - accuracy: 0.9171 - val_loss: 0.1908 - val_accuracy: 0.9430\n",
            "Epoch 569/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2479 - accuracy: 0.9135 - val_loss: 0.1922 - val_accuracy: 0.9445\n",
            "Epoch 570/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2590 - accuracy: 0.9147 - val_loss: 0.1925 - val_accuracy: 0.9420\n",
            "Epoch 571/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2578 - accuracy: 0.9211 - val_loss: 0.1917 - val_accuracy: 0.9445\n",
            "Epoch 572/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2512 - accuracy: 0.9183 - val_loss: 0.1892 - val_accuracy: 0.9425\n",
            "Epoch 573/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2518 - accuracy: 0.9168 - val_loss: 0.1876 - val_accuracy: 0.9455\n",
            "Epoch 574/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2572 - accuracy: 0.9190 - val_loss: 0.1901 - val_accuracy: 0.9440\n",
            "Epoch 575/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2520 - accuracy: 0.9187 - val_loss: 0.1974 - val_accuracy: 0.9420\n",
            "Epoch 576/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2542 - accuracy: 0.9174 - val_loss: 0.1921 - val_accuracy: 0.9430\n",
            "Epoch 577/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2478 - accuracy: 0.9211 - val_loss: 0.1864 - val_accuracy: 0.9445\n",
            "Epoch 578/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2503 - accuracy: 0.9200 - val_loss: 0.1901 - val_accuracy: 0.9450\n",
            "Epoch 579/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2431 - accuracy: 0.9250 - val_loss: 0.1914 - val_accuracy: 0.9440\n",
            "Epoch 580/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2567 - accuracy: 0.9156 - val_loss: 0.1972 - val_accuracy: 0.9405\n",
            "Epoch 581/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2502 - accuracy: 0.9194 - val_loss: 0.1915 - val_accuracy: 0.9435\n",
            "Epoch 582/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2544 - accuracy: 0.9184 - val_loss: 0.1924 - val_accuracy: 0.9445\n",
            "Epoch 583/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2459 - accuracy: 0.9185 - val_loss: 0.1912 - val_accuracy: 0.9455\n",
            "Epoch 584/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2500 - accuracy: 0.9154 - val_loss: 0.1921 - val_accuracy: 0.9430\n",
            "Epoch 585/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2510 - accuracy: 0.9189 - val_loss: 0.1948 - val_accuracy: 0.9430\n",
            "Epoch 586/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2629 - accuracy: 0.9162 - val_loss: 0.1893 - val_accuracy: 0.9455\n",
            "Epoch 587/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2457 - accuracy: 0.9181 - val_loss: 0.1921 - val_accuracy: 0.9425\n",
            "Epoch 588/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2559 - accuracy: 0.9174 - val_loss: 0.1927 - val_accuracy: 0.9440\n",
            "Epoch 589/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2494 - accuracy: 0.9175 - val_loss: 0.1920 - val_accuracy: 0.9430\n",
            "Epoch 590/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2538 - accuracy: 0.9147 - val_loss: 0.1909 - val_accuracy: 0.9450\n",
            "Epoch 591/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2505 - accuracy: 0.9212 - val_loss: 0.1907 - val_accuracy: 0.9435\n",
            "Epoch 592/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2584 - accuracy: 0.9161 - val_loss: 0.1914 - val_accuracy: 0.9445\n",
            "Epoch 593/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2519 - accuracy: 0.9180 - val_loss: 0.1901 - val_accuracy: 0.9450\n",
            "Epoch 594/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2466 - accuracy: 0.9200 - val_loss: 0.1926 - val_accuracy: 0.9435\n",
            "Epoch 595/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2536 - accuracy: 0.9134 - val_loss: 0.1916 - val_accuracy: 0.9460\n",
            "Epoch 596/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2500 - accuracy: 0.9197 - val_loss: 0.1897 - val_accuracy: 0.9455\n",
            "Epoch 597/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2521 - accuracy: 0.9187 - val_loss: 0.1891 - val_accuracy: 0.9445\n",
            "Epoch 598/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2583 - accuracy: 0.9179 - val_loss: 0.1924 - val_accuracy: 0.9430\n",
            "Epoch 599/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2481 - accuracy: 0.9194 - val_loss: 0.1866 - val_accuracy: 0.9465\n",
            "Epoch 600/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2592 - accuracy: 0.9145 - val_loss: 0.1944 - val_accuracy: 0.9420\n",
            "Epoch 601/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2561 - accuracy: 0.9159 - val_loss: 0.1916 - val_accuracy: 0.9450\n",
            "Epoch 602/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2590 - accuracy: 0.9183 - val_loss: 0.1898 - val_accuracy: 0.9455\n",
            "Epoch 603/6000\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2521 - accuracy: 0.9184 - val_loss: 0.1910 - val_accuracy: 0.9435\n",
            "Epoch 604/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2486 - accuracy: 0.9199 - val_loss: 0.1886 - val_accuracy: 0.9445\n",
            "Epoch 605/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2561 - accuracy: 0.9190 - val_loss: 0.1888 - val_accuracy: 0.9435\n",
            "Epoch 606/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2402 - accuracy: 0.9237 - val_loss: 0.1883 - val_accuracy: 0.9455\n",
            "Epoch 607/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2538 - accuracy: 0.9181 - val_loss: 0.1919 - val_accuracy: 0.9445\n",
            "Epoch 608/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2579 - accuracy: 0.9146 - val_loss: 0.1863 - val_accuracy: 0.9450\n",
            "Epoch 609/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2597 - accuracy: 0.9168 - val_loss: 0.1886 - val_accuracy: 0.9450\n",
            "Epoch 610/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2524 - accuracy: 0.9172 - val_loss: 0.1896 - val_accuracy: 0.9460\n",
            "Epoch 611/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2506 - accuracy: 0.9181 - val_loss: 0.1888 - val_accuracy: 0.9440\n",
            "Epoch 612/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2478 - accuracy: 0.9172 - val_loss: 0.1897 - val_accuracy: 0.9440\n",
            "Epoch 613/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2549 - accuracy: 0.9159 - val_loss: 0.1958 - val_accuracy: 0.9415\n",
            "Epoch 614/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2560 - accuracy: 0.9183 - val_loss: 0.1942 - val_accuracy: 0.9410\n",
            "Epoch 615/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2622 - accuracy: 0.9162 - val_loss: 0.1896 - val_accuracy: 0.9455\n",
            "Epoch 616/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2462 - accuracy: 0.9179 - val_loss: 0.1925 - val_accuracy: 0.9435\n",
            "Epoch 617/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2490 - accuracy: 0.9218 - val_loss: 0.1887 - val_accuracy: 0.9465\n",
            "Epoch 618/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2612 - accuracy: 0.9181 - val_loss: 0.1906 - val_accuracy: 0.9465\n",
            "Epoch 619/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2616 - accuracy: 0.9169 - val_loss: 0.1867 - val_accuracy: 0.9455\n",
            "Epoch 620/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2559 - accuracy: 0.9184 - val_loss: 0.1883 - val_accuracy: 0.9450\n",
            "Epoch 621/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2504 - accuracy: 0.9193 - val_loss: 0.1904 - val_accuracy: 0.9455\n",
            "Epoch 622/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2518 - accuracy: 0.9180 - val_loss: 0.1867 - val_accuracy: 0.9460\n",
            "Epoch 623/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2521 - accuracy: 0.9185 - val_loss: 0.1878 - val_accuracy: 0.9455\n",
            "Epoch 624/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2452 - accuracy: 0.9186 - val_loss: 0.1902 - val_accuracy: 0.9440\n",
            "Epoch 625/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2641 - accuracy: 0.9165 - val_loss: 0.1912 - val_accuracy: 0.9445\n",
            "Epoch 626/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2524 - accuracy: 0.9184 - val_loss: 0.1908 - val_accuracy: 0.9445\n",
            "Epoch 627/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2678 - accuracy: 0.9141 - val_loss: 0.1927 - val_accuracy: 0.9430\n",
            "Epoch 628/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2457 - accuracy: 0.9156 - val_loss: 0.1904 - val_accuracy: 0.9455\n",
            "Epoch 629/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2639 - accuracy: 0.9165 - val_loss: 0.1907 - val_accuracy: 0.9445\n",
            "Epoch 630/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2532 - accuracy: 0.9195 - val_loss: 0.1921 - val_accuracy: 0.9430\n",
            "Epoch 631/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2589 - accuracy: 0.9162 - val_loss: 0.1928 - val_accuracy: 0.9430\n",
            "Epoch 632/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2485 - accuracy: 0.9175 - val_loss: 0.1941 - val_accuracy: 0.9445\n",
            "Epoch 633/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2545 - accuracy: 0.9174 - val_loss: 0.1908 - val_accuracy: 0.9440\n",
            "Epoch 634/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2541 - accuracy: 0.9166 - val_loss: 0.1907 - val_accuracy: 0.9435\n",
            "Epoch 635/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2540 - accuracy: 0.9179 - val_loss: 0.1916 - val_accuracy: 0.9430\n",
            "Epoch 636/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2569 - accuracy: 0.9164 - val_loss: 0.1968 - val_accuracy: 0.9415\n",
            "Epoch 637/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2467 - accuracy: 0.9221 - val_loss: 0.1936 - val_accuracy: 0.9415\n",
            "Epoch 638/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2586 - accuracy: 0.9149 - val_loss: 0.1899 - val_accuracy: 0.9455\n",
            "Epoch 639/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2600 - accuracy: 0.9168 - val_loss: 0.1919 - val_accuracy: 0.9440\n",
            "Epoch 640/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2532 - accuracy: 0.9172 - val_loss: 0.1968 - val_accuracy: 0.9415\n",
            "Epoch 641/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2569 - accuracy: 0.9176 - val_loss: 0.1891 - val_accuracy: 0.9430\n",
            "Epoch 642/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2474 - accuracy: 0.9186 - val_loss: 0.1928 - val_accuracy: 0.9435\n",
            "Epoch 643/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2521 - accuracy: 0.9176 - val_loss: 0.1895 - val_accuracy: 0.9450\n",
            "Epoch 644/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2490 - accuracy: 0.9193 - val_loss: 0.1896 - val_accuracy: 0.9450\n",
            "Epoch 645/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2580 - accuracy: 0.9185 - val_loss: 0.1900 - val_accuracy: 0.9455\n",
            "Epoch 646/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2525 - accuracy: 0.9158 - val_loss: 0.1906 - val_accuracy: 0.9435\n",
            "Epoch 647/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2546 - accuracy: 0.9139 - val_loss: 0.1907 - val_accuracy: 0.9445\n",
            "Epoch 648/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2545 - accuracy: 0.9155 - val_loss: 0.1926 - val_accuracy: 0.9425\n",
            "Epoch 649/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2500 - accuracy: 0.9178 - val_loss: 0.1907 - val_accuracy: 0.9430\n",
            "Epoch 650/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2515 - accuracy: 0.9169 - val_loss: 0.1886 - val_accuracy: 0.9450\n",
            "Epoch 651/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2512 - accuracy: 0.9172 - val_loss: 0.1897 - val_accuracy: 0.9455\n",
            "Epoch 652/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2597 - accuracy: 0.9179 - val_loss: 0.1876 - val_accuracy: 0.9455\n",
            "Epoch 653/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2578 - accuracy: 0.9146 - val_loss: 0.1865 - val_accuracy: 0.9460\n",
            "Epoch 654/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2541 - accuracy: 0.9169 - val_loss: 0.1893 - val_accuracy: 0.9445\n",
            "Epoch 655/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2552 - accuracy: 0.9168 - val_loss: 0.1916 - val_accuracy: 0.9435\n",
            "Epoch 656/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2563 - accuracy: 0.9164 - val_loss: 0.1864 - val_accuracy: 0.9460\n",
            "Epoch 657/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2477 - accuracy: 0.9196 - val_loss: 0.1911 - val_accuracy: 0.9420\n",
            "Epoch 658/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2479 - accuracy: 0.9225 - val_loss: 0.1887 - val_accuracy: 0.9465\n",
            "Epoch 659/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2522 - accuracy: 0.9169 - val_loss: 0.1876 - val_accuracy: 0.9470\n",
            "Epoch 660/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2557 - accuracy: 0.9158 - val_loss: 0.1900 - val_accuracy: 0.9460\n",
            "Epoch 661/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2542 - accuracy: 0.9154 - val_loss: 0.1912 - val_accuracy: 0.9420\n",
            "Epoch 662/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2501 - accuracy: 0.9171 - val_loss: 0.1926 - val_accuracy: 0.9430\n",
            "Epoch 663/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2570 - accuracy: 0.9153 - val_loss: 0.1898 - val_accuracy: 0.9445\n",
            "Epoch 664/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2470 - accuracy: 0.9195 - val_loss: 0.1890 - val_accuracy: 0.9445\n",
            "Epoch 665/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2475 - accuracy: 0.9186 - val_loss: 0.1887 - val_accuracy: 0.9450\n",
            "Epoch 666/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2537 - accuracy: 0.9154 - val_loss: 0.1903 - val_accuracy: 0.9445\n",
            "Epoch 667/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2503 - accuracy: 0.9190 - val_loss: 0.1962 - val_accuracy: 0.9410\n",
            "Epoch 668/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2505 - accuracy: 0.9189 - val_loss: 0.1954 - val_accuracy: 0.9410\n",
            "Epoch 669/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2475 - accuracy: 0.9190 - val_loss: 0.1907 - val_accuracy: 0.9440\n",
            "Epoch 670/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2426 - accuracy: 0.9224 - val_loss: 0.1916 - val_accuracy: 0.9440\n",
            "Epoch 671/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2434 - accuracy: 0.9205 - val_loss: 0.1881 - val_accuracy: 0.9450\n",
            "Epoch 672/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2528 - accuracy: 0.9169 - val_loss: 0.1953 - val_accuracy: 0.9405\n",
            "Epoch 673/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2462 - accuracy: 0.9216 - val_loss: 0.1880 - val_accuracy: 0.9445\n",
            "Epoch 674/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2557 - accuracy: 0.9155 - val_loss: 0.1879 - val_accuracy: 0.9445\n",
            "Epoch 675/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2561 - accuracy: 0.9171 - val_loss: 0.1901 - val_accuracy: 0.9455\n",
            "Epoch 676/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2519 - accuracy: 0.9202 - val_loss: 0.1925 - val_accuracy: 0.9450\n",
            "Epoch 677/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2648 - accuracy: 0.9129 - val_loss: 0.1927 - val_accuracy: 0.9420\n",
            "Epoch 678/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2533 - accuracy: 0.9165 - val_loss: 0.1929 - val_accuracy: 0.9435\n",
            "Epoch 679/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2504 - accuracy: 0.9178 - val_loss: 0.1906 - val_accuracy: 0.9450\n",
            "Epoch 680/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2499 - accuracy: 0.9187 - val_loss: 0.1888 - val_accuracy: 0.9460\n",
            "Epoch 681/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2487 - accuracy: 0.9204 - val_loss: 0.1887 - val_accuracy: 0.9450\n",
            "Epoch 682/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2489 - accuracy: 0.9212 - val_loss: 0.1900 - val_accuracy: 0.9445\n",
            "Epoch 683/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2457 - accuracy: 0.9197 - val_loss: 0.1929 - val_accuracy: 0.9450\n",
            "Epoch 684/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2470 - accuracy: 0.9196 - val_loss: 0.1863 - val_accuracy: 0.9465\n",
            "Epoch 685/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2535 - accuracy: 0.9159 - val_loss: 0.1891 - val_accuracy: 0.9475\n",
            "Epoch 686/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2580 - accuracy: 0.9155 - val_loss: 0.1912 - val_accuracy: 0.9450\n",
            "Epoch 687/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2518 - accuracy: 0.9174 - val_loss: 0.1857 - val_accuracy: 0.9455\n",
            "Epoch 688/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2496 - accuracy: 0.9185 - val_loss: 0.1893 - val_accuracy: 0.9440\n",
            "Epoch 689/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2615 - accuracy: 0.9200 - val_loss: 0.1873 - val_accuracy: 0.9460\n",
            "Epoch 690/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2510 - accuracy: 0.9189 - val_loss: 0.1862 - val_accuracy: 0.9445\n",
            "Epoch 691/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2563 - accuracy: 0.9183 - val_loss: 0.1888 - val_accuracy: 0.9465\n",
            "Epoch 692/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2425 - accuracy: 0.9212 - val_loss: 0.1872 - val_accuracy: 0.9455\n",
            "Epoch 693/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2504 - accuracy: 0.9162 - val_loss: 0.1940 - val_accuracy: 0.9430\n",
            "Epoch 694/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2606 - accuracy: 0.9190 - val_loss: 0.1903 - val_accuracy: 0.9460\n",
            "Epoch 695/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2479 - accuracy: 0.9193 - val_loss: 0.1890 - val_accuracy: 0.9455\n",
            "Epoch 696/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2566 - accuracy: 0.9135 - val_loss: 0.1855 - val_accuracy: 0.9455\n",
            "Epoch 697/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2506 - accuracy: 0.9176 - val_loss: 0.1910 - val_accuracy: 0.9445\n",
            "Epoch 698/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2551 - accuracy: 0.9185 - val_loss: 0.1872 - val_accuracy: 0.9440\n",
            "Epoch 699/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2434 - accuracy: 0.9215 - val_loss: 0.1902 - val_accuracy: 0.9455\n",
            "Epoch 700/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2521 - accuracy: 0.9179 - val_loss: 0.1913 - val_accuracy: 0.9440\n",
            "Epoch 701/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2481 - accuracy: 0.9197 - val_loss: 0.1883 - val_accuracy: 0.9445\n",
            "Epoch 702/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2474 - accuracy: 0.9216 - val_loss: 0.1880 - val_accuracy: 0.9450\n",
            "Epoch 703/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2509 - accuracy: 0.9222 - val_loss: 0.1907 - val_accuracy: 0.9445\n",
            "Epoch 704/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2451 - accuracy: 0.9210 - val_loss: 0.1891 - val_accuracy: 0.9445\n",
            "Epoch 705/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2546 - accuracy: 0.9187 - val_loss: 0.1872 - val_accuracy: 0.9450\n",
            "Epoch 706/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2516 - accuracy: 0.9180 - val_loss: 0.1914 - val_accuracy: 0.9445\n",
            "Epoch 707/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2500 - accuracy: 0.9169 - val_loss: 0.1877 - val_accuracy: 0.9455\n",
            "Epoch 708/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2606 - accuracy: 0.9121 - val_loss: 0.1930 - val_accuracy: 0.9430\n",
            "Epoch 709/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2465 - accuracy: 0.9233 - val_loss: 0.1898 - val_accuracy: 0.9440\n",
            "Epoch 710/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2461 - accuracy: 0.9165 - val_loss: 0.1919 - val_accuracy: 0.9455\n",
            "Epoch 711/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2556 - accuracy: 0.9183 - val_loss: 0.1861 - val_accuracy: 0.9445\n",
            "Epoch 712/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2589 - accuracy: 0.9155 - val_loss: 0.1935 - val_accuracy: 0.9425\n",
            "Epoch 713/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2468 - accuracy: 0.9211 - val_loss: 0.1863 - val_accuracy: 0.9470\n",
            "Epoch 714/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2524 - accuracy: 0.9172 - val_loss: 0.1902 - val_accuracy: 0.9455\n",
            "Epoch 715/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2467 - accuracy: 0.9197 - val_loss: 0.1890 - val_accuracy: 0.9460\n",
            "Epoch 716/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2610 - accuracy: 0.9180 - val_loss: 0.1925 - val_accuracy: 0.9420\n",
            "Epoch 717/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2483 - accuracy: 0.9179 - val_loss: 0.1893 - val_accuracy: 0.9440\n",
            "Epoch 718/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2514 - accuracy: 0.9178 - val_loss: 0.1938 - val_accuracy: 0.9420\n",
            "Epoch 719/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2493 - accuracy: 0.9219 - val_loss: 0.1942 - val_accuracy: 0.9430\n",
            "Epoch 720/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2569 - accuracy: 0.9179 - val_loss: 0.1918 - val_accuracy: 0.9445\n",
            "Epoch 721/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2572 - accuracy: 0.9175 - val_loss: 0.1906 - val_accuracy: 0.9435\n",
            "Epoch 722/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2563 - accuracy: 0.9155 - val_loss: 0.1888 - val_accuracy: 0.9460\n",
            "Epoch 723/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2479 - accuracy: 0.9189 - val_loss: 0.1910 - val_accuracy: 0.9445\n",
            "Epoch 724/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2515 - accuracy: 0.9196 - val_loss: 0.1898 - val_accuracy: 0.9440\n",
            "Epoch 725/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2491 - accuracy: 0.9185 - val_loss: 0.1890 - val_accuracy: 0.9460\n",
            "Epoch 726/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2570 - accuracy: 0.9160 - val_loss: 0.1900 - val_accuracy: 0.9455\n",
            "Epoch 727/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2532 - accuracy: 0.9191 - val_loss: 0.1863 - val_accuracy: 0.9460\n",
            "Epoch 728/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2634 - accuracy: 0.9186 - val_loss: 0.1983 - val_accuracy: 0.9410\n",
            "Epoch 729/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2506 - accuracy: 0.9190 - val_loss: 0.1892 - val_accuracy: 0.9435\n",
            "Epoch 730/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2438 - accuracy: 0.9197 - val_loss: 0.1896 - val_accuracy: 0.9445\n",
            "Epoch 731/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2437 - accuracy: 0.9208 - val_loss: 0.1932 - val_accuracy: 0.9430\n",
            "Epoch 732/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2526 - accuracy: 0.9170 - val_loss: 0.1932 - val_accuracy: 0.9430\n",
            "Epoch 733/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2537 - accuracy: 0.9184 - val_loss: 0.1936 - val_accuracy: 0.9455\n",
            "Epoch 734/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2483 - accuracy: 0.9160 - val_loss: 0.1907 - val_accuracy: 0.9445\n",
            "Epoch 735/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2560 - accuracy: 0.9193 - val_loss: 0.1867 - val_accuracy: 0.9450\n",
            "Epoch 736/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2563 - accuracy: 0.9150 - val_loss: 0.1897 - val_accuracy: 0.9440\n",
            "Epoch 737/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2449 - accuracy: 0.9208 - val_loss: 0.1897 - val_accuracy: 0.9460\n",
            "Epoch 738/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2472 - accuracy: 0.9185 - val_loss: 0.1911 - val_accuracy: 0.9435\n",
            "Epoch 739/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2532 - accuracy: 0.9165 - val_loss: 0.1872 - val_accuracy: 0.9440\n",
            "Epoch 740/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2468 - accuracy: 0.9190 - val_loss: 0.1918 - val_accuracy: 0.9435\n",
            "Epoch 741/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2536 - accuracy: 0.9189 - val_loss: 0.1873 - val_accuracy: 0.9445\n",
            "Epoch 742/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2572 - accuracy: 0.9126 - val_loss: 0.1908 - val_accuracy: 0.9440\n",
            "Epoch 743/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2558 - accuracy: 0.9164 - val_loss: 0.1874 - val_accuracy: 0.9460\n",
            "Epoch 744/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2557 - accuracy: 0.9176 - val_loss: 0.1884 - val_accuracy: 0.9445\n",
            "Epoch 745/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2531 - accuracy: 0.9181 - val_loss: 0.1878 - val_accuracy: 0.9470\n",
            "Epoch 746/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2536 - accuracy: 0.9161 - val_loss: 0.1885 - val_accuracy: 0.9455\n",
            "Epoch 747/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2521 - accuracy: 0.9194 - val_loss: 0.1946 - val_accuracy: 0.9460\n",
            "Epoch 748/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2614 - accuracy: 0.9159 - val_loss: 0.1910 - val_accuracy: 0.9440\n",
            "Epoch 749/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2493 - accuracy: 0.9176 - val_loss: 0.1892 - val_accuracy: 0.9445\n",
            "Epoch 750/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2517 - accuracy: 0.9193 - val_loss: 0.1904 - val_accuracy: 0.9430\n",
            "Epoch 751/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2482 - accuracy: 0.9184 - val_loss: 0.1911 - val_accuracy: 0.9440\n",
            "Epoch 752/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2584 - accuracy: 0.9159 - val_loss: 0.1916 - val_accuracy: 0.9450\n",
            "Epoch 753/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2470 - accuracy: 0.9186 - val_loss: 0.1956 - val_accuracy: 0.9425\n",
            "Epoch 754/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2596 - accuracy: 0.9175 - val_loss: 0.1900 - val_accuracy: 0.9450\n",
            "Epoch 755/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2493 - accuracy: 0.9164 - val_loss: 0.1898 - val_accuracy: 0.9445\n",
            "Epoch 756/6000\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2594 - accuracy: 0.9153 - val_loss: 0.1941 - val_accuracy: 0.9435\n",
            "Epoch 757/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2557 - accuracy: 0.9197 - val_loss: 0.1954 - val_accuracy: 0.9435\n",
            "Epoch 758/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2627 - accuracy: 0.9143 - val_loss: 0.1913 - val_accuracy: 0.9465\n",
            "Epoch 759/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2493 - accuracy: 0.9201 - val_loss: 0.1873 - val_accuracy: 0.9455\n",
            "Epoch 760/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2502 - accuracy: 0.9208 - val_loss: 0.1900 - val_accuracy: 0.9450\n",
            "Epoch 761/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2486 - accuracy: 0.9164 - val_loss: 0.1922 - val_accuracy: 0.9440\n",
            "Epoch 762/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2461 - accuracy: 0.9191 - val_loss: 0.1906 - val_accuracy: 0.9450\n",
            "Epoch 763/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2543 - accuracy: 0.9149 - val_loss: 0.1878 - val_accuracy: 0.9460\n",
            "Epoch 764/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2501 - accuracy: 0.9190 - val_loss: 0.1896 - val_accuracy: 0.9440\n",
            "Epoch 765/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2570 - accuracy: 0.9195 - val_loss: 0.1901 - val_accuracy: 0.9445\n",
            "Epoch 766/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2484 - accuracy: 0.9205 - val_loss: 0.1922 - val_accuracy: 0.9425\n",
            "Epoch 767/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2490 - accuracy: 0.9209 - val_loss: 0.1957 - val_accuracy: 0.9415\n",
            "Epoch 768/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2428 - accuracy: 0.9206 - val_loss: 0.1909 - val_accuracy: 0.9440\n",
            "Epoch 769/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2423 - accuracy: 0.9211 - val_loss: 0.1907 - val_accuracy: 0.9450\n",
            "Epoch 770/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2533 - accuracy: 0.9197 - val_loss: 0.1925 - val_accuracy: 0.9440\n",
            "Epoch 771/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2545 - accuracy: 0.9175 - val_loss: 0.1932 - val_accuracy: 0.9435\n",
            "Epoch 772/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2462 - accuracy: 0.9206 - val_loss: 0.1865 - val_accuracy: 0.9455\n",
            "Epoch 773/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2625 - accuracy: 0.9156 - val_loss: 0.1933 - val_accuracy: 0.9420\n",
            "Epoch 774/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2455 - accuracy: 0.9185 - val_loss: 0.1905 - val_accuracy: 0.9450\n",
            "Epoch 775/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2496 - accuracy: 0.9190 - val_loss: 0.1881 - val_accuracy: 0.9465\n",
            "Epoch 776/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2588 - accuracy: 0.9184 - val_loss: 0.1867 - val_accuracy: 0.9460\n",
            "Epoch 777/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2550 - accuracy: 0.9155 - val_loss: 0.1886 - val_accuracy: 0.9460\n",
            "Epoch 778/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2515 - accuracy: 0.9179 - val_loss: 0.1957 - val_accuracy: 0.9420\n",
            "Epoch 779/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2589 - accuracy: 0.9166 - val_loss: 0.1882 - val_accuracy: 0.9455\n",
            "Epoch 780/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2419 - accuracy: 0.9233 - val_loss: 0.1968 - val_accuracy: 0.9420\n",
            "Epoch 781/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2491 - accuracy: 0.9170 - val_loss: 0.1908 - val_accuracy: 0.9440\n",
            "Epoch 782/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2516 - accuracy: 0.9144 - val_loss: 0.1879 - val_accuracy: 0.9445\n",
            "Epoch 783/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2657 - accuracy: 0.9156 - val_loss: 0.1941 - val_accuracy: 0.9435\n",
            "Epoch 784/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2581 - accuracy: 0.9191 - val_loss: 0.1920 - val_accuracy: 0.9440\n",
            "Epoch 785/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2454 - accuracy: 0.9215 - val_loss: 0.1933 - val_accuracy: 0.9435\n",
            "Epoch 786/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2488 - accuracy: 0.9170 - val_loss: 0.1880 - val_accuracy: 0.9455\n",
            "Epoch 787/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2675 - accuracy: 0.9131 - val_loss: 0.1928 - val_accuracy: 0.9440\n",
            "Epoch 788/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2570 - accuracy: 0.9149 - val_loss: 0.1930 - val_accuracy: 0.9440\n",
            "Epoch 789/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2584 - accuracy: 0.9156 - val_loss: 0.1907 - val_accuracy: 0.9435\n",
            "Epoch 790/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2488 - accuracy: 0.9172 - val_loss: 0.1925 - val_accuracy: 0.9435\n",
            "Epoch 791/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2528 - accuracy: 0.9199 - val_loss: 0.1922 - val_accuracy: 0.9435\n",
            "Epoch 792/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2599 - accuracy: 0.9184 - val_loss: 0.1910 - val_accuracy: 0.9440\n",
            "Epoch 793/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2534 - accuracy: 0.9169 - val_loss: 0.1932 - val_accuracy: 0.9430\n",
            "Epoch 794/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2530 - accuracy: 0.9195 - val_loss: 0.1929 - val_accuracy: 0.9425\n",
            "Epoch 795/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2458 - accuracy: 0.9170 - val_loss: 0.1928 - val_accuracy: 0.9460\n",
            "Epoch 796/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2478 - accuracy: 0.9147 - val_loss: 0.1939 - val_accuracy: 0.9405\n",
            "Epoch 797/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2566 - accuracy: 0.9151 - val_loss: 0.1923 - val_accuracy: 0.9430\n",
            "Epoch 798/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2644 - accuracy: 0.9144 - val_loss: 0.1967 - val_accuracy: 0.9385\n",
            "Epoch 799/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2550 - accuracy: 0.9172 - val_loss: 0.1923 - val_accuracy: 0.9455\n",
            "Epoch 800/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2648 - accuracy: 0.9153 - val_loss: 0.1943 - val_accuracy: 0.9435\n",
            "Epoch 801/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2500 - accuracy: 0.9168 - val_loss: 0.1916 - val_accuracy: 0.9435\n",
            "Epoch 802/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2575 - accuracy: 0.9191 - val_loss: 0.1955 - val_accuracy: 0.9440\n",
            "Epoch 803/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2511 - accuracy: 0.9216 - val_loss: 0.1920 - val_accuracy: 0.9445\n",
            "Epoch 804/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2532 - accuracy: 0.9187 - val_loss: 0.1947 - val_accuracy: 0.9420\n",
            "Epoch 805/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2654 - accuracy: 0.9181 - val_loss: 0.1948 - val_accuracy: 0.9440\n",
            "Epoch 806/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2496 - accuracy: 0.9186 - val_loss: 0.1946 - val_accuracy: 0.9430\n",
            "Epoch 807/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2511 - accuracy: 0.9196 - val_loss: 0.1949 - val_accuracy: 0.9420\n",
            "Epoch 808/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2564 - accuracy: 0.9164 - val_loss: 0.1982 - val_accuracy: 0.9395\n",
            "Epoch 809/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2456 - accuracy: 0.9181 - val_loss: 0.1906 - val_accuracy: 0.9465\n",
            "Epoch 810/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2462 - accuracy: 0.9204 - val_loss: 0.1958 - val_accuracy: 0.9430\n",
            "Epoch 811/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2441 - accuracy: 0.9197 - val_loss: 0.1913 - val_accuracy: 0.9440\n",
            "Epoch 812/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2574 - accuracy: 0.9193 - val_loss: 0.1924 - val_accuracy: 0.9460\n",
            "Epoch 813/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2578 - accuracy: 0.9172 - val_loss: 0.1922 - val_accuracy: 0.9430\n",
            "Epoch 814/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2574 - accuracy: 0.9186 - val_loss: 0.1934 - val_accuracy: 0.9445\n",
            "Epoch 815/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2550 - accuracy: 0.9183 - val_loss: 0.1954 - val_accuracy: 0.9410\n",
            "Epoch 816/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2587 - accuracy: 0.9130 - val_loss: 0.1985 - val_accuracy: 0.9435\n",
            "Epoch 817/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2535 - accuracy: 0.9164 - val_loss: 0.2019 - val_accuracy: 0.9385\n",
            "Epoch 818/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2488 - accuracy: 0.9214 - val_loss: 0.1942 - val_accuracy: 0.9440\n",
            "Epoch 819/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2568 - accuracy: 0.9174 - val_loss: 0.1930 - val_accuracy: 0.9440\n",
            "Epoch 820/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2593 - accuracy: 0.9135 - val_loss: 0.1944 - val_accuracy: 0.9450\n",
            "Epoch 821/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2461 - accuracy: 0.9175 - val_loss: 0.1952 - val_accuracy: 0.9430\n",
            "Epoch 822/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2554 - accuracy: 0.9155 - val_loss: 0.1951 - val_accuracy: 0.9440\n",
            "Epoch 823/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2492 - accuracy: 0.9193 - val_loss: 0.1968 - val_accuracy: 0.9420\n",
            "Epoch 824/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2473 - accuracy: 0.9214 - val_loss: 0.1943 - val_accuracy: 0.9435\n",
            "Epoch 825/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2485 - accuracy: 0.9209 - val_loss: 0.1949 - val_accuracy: 0.9425\n",
            "Epoch 826/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2435 - accuracy: 0.9193 - val_loss: 0.1946 - val_accuracy: 0.9435\n",
            "Epoch 827/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2516 - accuracy: 0.9174 - val_loss: 0.1916 - val_accuracy: 0.9435\n",
            "Epoch 828/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2585 - accuracy: 0.9165 - val_loss: 0.1918 - val_accuracy: 0.9450\n",
            "Epoch 829/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2487 - accuracy: 0.9215 - val_loss: 0.1946 - val_accuracy: 0.9435\n",
            "Epoch 830/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2506 - accuracy: 0.9206 - val_loss: 0.1920 - val_accuracy: 0.9445\n",
            "Epoch 831/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2556 - accuracy: 0.9166 - val_loss: 0.1899 - val_accuracy: 0.9450\n",
            "Epoch 832/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2514 - accuracy: 0.9193 - val_loss: 0.1936 - val_accuracy: 0.9440\n",
            "Epoch 833/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2505 - accuracy: 0.9171 - val_loss: 0.1923 - val_accuracy: 0.9435\n",
            "Epoch 834/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2594 - accuracy: 0.9143 - val_loss: 0.1932 - val_accuracy: 0.9455\n",
            "Epoch 835/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2523 - accuracy: 0.9168 - val_loss: 0.1934 - val_accuracy: 0.9440\n",
            "Epoch 836/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2527 - accuracy: 0.9181 - val_loss: 0.1932 - val_accuracy: 0.9455\n",
            "Epoch 837/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2499 - accuracy: 0.9168 - val_loss: 0.1876 - val_accuracy: 0.9450\n",
            "Epoch 838/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2505 - accuracy: 0.9208 - val_loss: 0.2002 - val_accuracy: 0.9410\n",
            "Epoch 839/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2575 - accuracy: 0.9176 - val_loss: 0.1916 - val_accuracy: 0.9450\n",
            "Epoch 840/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2606 - accuracy: 0.9178 - val_loss: 0.1932 - val_accuracy: 0.9445\n",
            "Epoch 841/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2563 - accuracy: 0.9165 - val_loss: 0.1924 - val_accuracy: 0.9430\n",
            "Epoch 842/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2490 - accuracy: 0.9190 - val_loss: 0.1904 - val_accuracy: 0.9440\n",
            "Epoch 843/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2525 - accuracy: 0.9158 - val_loss: 0.1926 - val_accuracy: 0.9440\n",
            "Epoch 844/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2565 - accuracy: 0.9187 - val_loss: 0.1913 - val_accuracy: 0.9450\n",
            "Epoch 845/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2489 - accuracy: 0.9200 - val_loss: 0.1877 - val_accuracy: 0.9465\n",
            "Epoch 846/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2483 - accuracy: 0.9211 - val_loss: 0.1865 - val_accuracy: 0.9465\n",
            "Epoch 847/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2489 - accuracy: 0.9185 - val_loss: 0.1910 - val_accuracy: 0.9440\n",
            "Epoch 848/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2513 - accuracy: 0.9162 - val_loss: 0.1956 - val_accuracy: 0.9440\n",
            "Epoch 849/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2473 - accuracy: 0.9166 - val_loss: 0.1937 - val_accuracy: 0.9440\n",
            "Epoch 850/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2485 - accuracy: 0.9175 - val_loss: 0.1907 - val_accuracy: 0.9440\n",
            "Epoch 851/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2518 - accuracy: 0.9172 - val_loss: 0.1906 - val_accuracy: 0.9425\n",
            "Epoch 852/6000\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2539 - accuracy: 0.9159 - val_loss: 0.1875 - val_accuracy: 0.9430\n",
            "Epoch 853/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2469 - accuracy: 0.9184 - val_loss: 0.1945 - val_accuracy: 0.9430\n",
            "Epoch 854/6000\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2445 - accuracy: 0.9189 - val_loss: 0.1877 - val_accuracy: 0.9445\n",
            "Epoch 855/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2577 - accuracy: 0.9176 - val_loss: 0.1938 - val_accuracy: 0.9460\n",
            "Epoch 856/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2519 - accuracy: 0.9210 - val_loss: 0.1955 - val_accuracy: 0.9440\n",
            "Epoch 857/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2576 - accuracy: 0.9169 - val_loss: 0.1894 - val_accuracy: 0.9435\n",
            "Epoch 858/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2510 - accuracy: 0.9146 - val_loss: 0.1956 - val_accuracy: 0.9435\n",
            "Epoch 859/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2517 - accuracy: 0.9186 - val_loss: 0.1925 - val_accuracy: 0.9450\n",
            "Epoch 860/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2693 - accuracy: 0.9155 - val_loss: 0.1932 - val_accuracy: 0.9435\n",
            "Epoch 861/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2504 - accuracy: 0.9202 - val_loss: 0.1946 - val_accuracy: 0.9440\n",
            "Epoch 862/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2451 - accuracy: 0.9211 - val_loss: 0.1910 - val_accuracy: 0.9430\n",
            "Epoch 863/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2499 - accuracy: 0.9211 - val_loss: 0.1928 - val_accuracy: 0.9420\n",
            "Epoch 864/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2554 - accuracy: 0.9137 - val_loss: 0.1911 - val_accuracy: 0.9465\n",
            "Epoch 865/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2456 - accuracy: 0.9191 - val_loss: 0.1935 - val_accuracy: 0.9440\n",
            "Epoch 866/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2472 - accuracy: 0.9201 - val_loss: 0.1961 - val_accuracy: 0.9420\n",
            "Epoch 867/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2501 - accuracy: 0.9193 - val_loss: 0.1990 - val_accuracy: 0.9430\n",
            "Epoch 868/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2468 - accuracy: 0.9161 - val_loss: 0.1919 - val_accuracy: 0.9440\n",
            "Epoch 869/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2502 - accuracy: 0.9187 - val_loss: 0.1934 - val_accuracy: 0.9445\n",
            "Epoch 870/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2403 - accuracy: 0.9214 - val_loss: 0.1933 - val_accuracy: 0.9445\n",
            "Epoch 871/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2455 - accuracy: 0.9196 - val_loss: 0.1959 - val_accuracy: 0.9420\n",
            "Epoch 872/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2518 - accuracy: 0.9197 - val_loss: 0.1967 - val_accuracy: 0.9415\n",
            "Epoch 873/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2516 - accuracy: 0.9164 - val_loss: 0.1949 - val_accuracy: 0.9435\n",
            "Epoch 874/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2521 - accuracy: 0.9158 - val_loss: 0.1932 - val_accuracy: 0.9425\n",
            "Epoch 875/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2470 - accuracy: 0.9191 - val_loss: 0.1962 - val_accuracy: 0.9435\n",
            "Epoch 876/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2549 - accuracy: 0.9159 - val_loss: 0.1932 - val_accuracy: 0.9415\n",
            "Epoch 877/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2596 - accuracy: 0.9151 - val_loss: 0.1945 - val_accuracy: 0.9430\n",
            "Epoch 878/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2391 - accuracy: 0.9231 - val_loss: 0.1978 - val_accuracy: 0.9410\n",
            "Epoch 879/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2472 - accuracy: 0.9179 - val_loss: 0.1915 - val_accuracy: 0.9435\n",
            "Epoch 880/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2554 - accuracy: 0.9172 - val_loss: 0.1949 - val_accuracy: 0.9440\n",
            "Epoch 881/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2520 - accuracy: 0.9194 - val_loss: 0.1918 - val_accuracy: 0.9450\n",
            "Epoch 882/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2410 - accuracy: 0.9218 - val_loss: 0.1938 - val_accuracy: 0.9435\n",
            "Epoch 883/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2445 - accuracy: 0.9216 - val_loss: 0.1954 - val_accuracy: 0.9440\n",
            "Epoch 884/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2472 - accuracy: 0.9195 - val_loss: 0.1949 - val_accuracy: 0.9430\n",
            "Epoch 885/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2566 - accuracy: 0.9180 - val_loss: 0.1925 - val_accuracy: 0.9410\n",
            "Epoch 886/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2506 - accuracy: 0.9147 - val_loss: 0.1971 - val_accuracy: 0.9430\n",
            "Epoch 887/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2513 - accuracy: 0.9206 - val_loss: 0.1943 - val_accuracy: 0.9410\n",
            "Epoch 888/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2527 - accuracy: 0.9151 - val_loss: 0.1901 - val_accuracy: 0.9455\n",
            "Epoch 889/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2611 - accuracy: 0.9141 - val_loss: 0.1970 - val_accuracy: 0.9420\n",
            "Epoch 890/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2532 - accuracy: 0.9159 - val_loss: 0.1956 - val_accuracy: 0.9425\n",
            "Epoch 891/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2516 - accuracy: 0.9162 - val_loss: 0.1927 - val_accuracy: 0.9435\n",
            "Epoch 892/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2509 - accuracy: 0.9191 - val_loss: 0.1942 - val_accuracy: 0.9450\n",
            "Epoch 893/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2504 - accuracy: 0.9175 - val_loss: 0.1963 - val_accuracy: 0.9425\n",
            "Epoch 894/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2559 - accuracy: 0.9178 - val_loss: 0.1973 - val_accuracy: 0.9425\n",
            "Epoch 895/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2592 - accuracy: 0.9161 - val_loss: 0.1917 - val_accuracy: 0.9455\n",
            "Epoch 896/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2484 - accuracy: 0.9183 - val_loss: 0.1909 - val_accuracy: 0.9440\n",
            "Epoch 897/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2517 - accuracy: 0.9161 - val_loss: 0.1947 - val_accuracy: 0.9435\n",
            "Epoch 898/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2451 - accuracy: 0.9175 - val_loss: 0.1927 - val_accuracy: 0.9410\n",
            "Epoch 899/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2456 - accuracy: 0.9186 - val_loss: 0.1934 - val_accuracy: 0.9435\n",
            "Epoch 900/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2583 - accuracy: 0.9184 - val_loss: 0.1943 - val_accuracy: 0.9440\n",
            "Epoch 901/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2513 - accuracy: 0.9174 - val_loss: 0.1937 - val_accuracy: 0.9430\n",
            "Epoch 902/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2494 - accuracy: 0.9164 - val_loss: 0.1955 - val_accuracy: 0.9430\n",
            "Epoch 903/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2457 - accuracy: 0.9196 - val_loss: 0.1919 - val_accuracy: 0.9450\n",
            "Epoch 904/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2525 - accuracy: 0.9171 - val_loss: 0.1960 - val_accuracy: 0.9435\n",
            "Epoch 905/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2499 - accuracy: 0.9171 - val_loss: 0.1991 - val_accuracy: 0.9415\n",
            "Epoch 906/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2498 - accuracy: 0.9195 - val_loss: 0.1933 - val_accuracy: 0.9430\n",
            "Epoch 907/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2623 - accuracy: 0.9184 - val_loss: 0.1941 - val_accuracy: 0.9430\n",
            "Epoch 908/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2643 - accuracy: 0.9171 - val_loss: 0.1915 - val_accuracy: 0.9445\n",
            "Epoch 909/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2483 - accuracy: 0.9222 - val_loss: 0.1947 - val_accuracy: 0.9420\n",
            "Epoch 910/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2420 - accuracy: 0.9200 - val_loss: 0.1904 - val_accuracy: 0.9435\n",
            "Epoch 911/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2524 - accuracy: 0.9164 - val_loss: 0.1941 - val_accuracy: 0.9425\n",
            "Epoch 912/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2574 - accuracy: 0.9158 - val_loss: 0.1975 - val_accuracy: 0.9435\n",
            "Epoch 913/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2475 - accuracy: 0.9194 - val_loss: 0.1949 - val_accuracy: 0.9430\n",
            "Epoch 914/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2605 - accuracy: 0.9169 - val_loss: 0.1943 - val_accuracy: 0.9400\n",
            "Epoch 915/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2388 - accuracy: 0.9218 - val_loss: 0.1953 - val_accuracy: 0.9425\n",
            "Epoch 916/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2480 - accuracy: 0.9184 - val_loss: 0.1943 - val_accuracy: 0.9435\n",
            "Epoch 917/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2397 - accuracy: 0.9194 - val_loss: 0.1917 - val_accuracy: 0.9410\n",
            "Epoch 918/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2433 - accuracy: 0.9222 - val_loss: 0.1922 - val_accuracy: 0.9415\n",
            "Epoch 919/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2498 - accuracy: 0.9189 - val_loss: 0.1975 - val_accuracy: 0.9420\n",
            "Epoch 920/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2545 - accuracy: 0.9218 - val_loss: 0.1913 - val_accuracy: 0.9450\n",
            "Epoch 921/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2507 - accuracy: 0.9194 - val_loss: 0.1904 - val_accuracy: 0.9420\n",
            "Epoch 922/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2541 - accuracy: 0.9197 - val_loss: 0.1940 - val_accuracy: 0.9405\n",
            "Epoch 923/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2551 - accuracy: 0.9169 - val_loss: 0.1968 - val_accuracy: 0.9410\n",
            "Epoch 924/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2438 - accuracy: 0.9195 - val_loss: 0.1937 - val_accuracy: 0.9425\n",
            "Epoch 925/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2485 - accuracy: 0.9190 - val_loss: 0.1956 - val_accuracy: 0.9410\n",
            "Epoch 926/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2371 - accuracy: 0.9195 - val_loss: 0.1949 - val_accuracy: 0.9420\n",
            "Epoch 927/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2509 - accuracy: 0.9191 - val_loss: 0.1918 - val_accuracy: 0.9430\n",
            "Epoch 928/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2474 - accuracy: 0.9185 - val_loss: 0.1963 - val_accuracy: 0.9415\n",
            "Epoch 929/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2498 - accuracy: 0.9169 - val_loss: 0.1937 - val_accuracy: 0.9435\n",
            "Epoch 930/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2560 - accuracy: 0.9156 - val_loss: 0.1931 - val_accuracy: 0.9425\n",
            "Epoch 931/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2517 - accuracy: 0.9147 - val_loss: 0.2015 - val_accuracy: 0.9400\n",
            "Epoch 932/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2492 - accuracy: 0.9218 - val_loss: 0.1975 - val_accuracy: 0.9425\n",
            "Epoch 933/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2437 - accuracy: 0.9215 - val_loss: 0.1935 - val_accuracy: 0.9440\n",
            "Epoch 934/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2435 - accuracy: 0.9187 - val_loss: 0.1958 - val_accuracy: 0.9420\n",
            "Epoch 935/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2493 - accuracy: 0.9184 - val_loss: 0.1914 - val_accuracy: 0.9435\n",
            "Epoch 936/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2444 - accuracy: 0.9210 - val_loss: 0.1901 - val_accuracy: 0.9440\n",
            "Epoch 937/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2422 - accuracy: 0.9204 - val_loss: 0.1910 - val_accuracy: 0.9430\n",
            "Epoch 938/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2571 - accuracy: 0.9172 - val_loss: 0.1936 - val_accuracy: 0.9430\n",
            "Epoch 939/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2511 - accuracy: 0.9184 - val_loss: 0.1889 - val_accuracy: 0.9445\n",
            "Epoch 940/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2413 - accuracy: 0.9196 - val_loss: 0.1918 - val_accuracy: 0.9425\n",
            "Epoch 941/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2518 - accuracy: 0.9185 - val_loss: 0.2017 - val_accuracy: 0.9405\n",
            "Epoch 942/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2494 - accuracy: 0.9196 - val_loss: 0.1934 - val_accuracy: 0.9425\n",
            "Epoch 943/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2582 - accuracy: 0.9160 - val_loss: 0.1958 - val_accuracy: 0.9405\n",
            "Epoch 944/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2500 - accuracy: 0.9165 - val_loss: 0.1914 - val_accuracy: 0.9445\n",
            "Epoch 945/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2474 - accuracy: 0.9212 - val_loss: 0.1890 - val_accuracy: 0.9440\n",
            "Epoch 946/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2544 - accuracy: 0.9191 - val_loss: 0.1940 - val_accuracy: 0.9410\n",
            "Epoch 947/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2393 - accuracy: 0.9183 - val_loss: 0.1923 - val_accuracy: 0.9425\n",
            "Epoch 948/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2506 - accuracy: 0.9204 - val_loss: 0.1925 - val_accuracy: 0.9430\n",
            "Epoch 949/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2520 - accuracy: 0.9166 - val_loss: 0.1935 - val_accuracy: 0.9420\n",
            "Epoch 950/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2458 - accuracy: 0.9194 - val_loss: 0.1950 - val_accuracy: 0.9435\n",
            "Epoch 951/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2516 - accuracy: 0.9181 - val_loss: 0.1907 - val_accuracy: 0.9450\n",
            "Epoch 952/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2505 - accuracy: 0.9185 - val_loss: 0.1978 - val_accuracy: 0.9420\n",
            "Epoch 953/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2467 - accuracy: 0.9214 - val_loss: 0.1974 - val_accuracy: 0.9425\n",
            "Epoch 954/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2434 - accuracy: 0.9193 - val_loss: 0.1916 - val_accuracy: 0.9445\n",
            "Epoch 955/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2465 - accuracy: 0.9195 - val_loss: 0.1957 - val_accuracy: 0.9435\n",
            "Epoch 956/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2584 - accuracy: 0.9183 - val_loss: 0.1949 - val_accuracy: 0.9430\n",
            "Epoch 957/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2511 - accuracy: 0.9185 - val_loss: 0.1990 - val_accuracy: 0.9435\n",
            "Epoch 958/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2530 - accuracy: 0.9186 - val_loss: 0.1928 - val_accuracy: 0.9430\n",
            "Epoch 959/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2524 - accuracy: 0.9190 - val_loss: 0.1958 - val_accuracy: 0.9420\n",
            "Epoch 960/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2543 - accuracy: 0.9199 - val_loss: 0.1961 - val_accuracy: 0.9430\n",
            "Epoch 961/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2508 - accuracy: 0.9204 - val_loss: 0.1940 - val_accuracy: 0.9415\n",
            "Epoch 962/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2480 - accuracy: 0.9183 - val_loss: 0.1976 - val_accuracy: 0.9415\n",
            "Epoch 963/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2442 - accuracy: 0.9200 - val_loss: 0.1966 - val_accuracy: 0.9435\n",
            "Epoch 964/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2472 - accuracy: 0.9195 - val_loss: 0.1955 - val_accuracy: 0.9415\n",
            "Epoch 965/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2464 - accuracy: 0.9194 - val_loss: 0.1923 - val_accuracy: 0.9435\n",
            "Epoch 966/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2572 - accuracy: 0.9162 - val_loss: 0.1941 - val_accuracy: 0.9440\n",
            "Epoch 967/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2489 - accuracy: 0.9209 - val_loss: 0.1958 - val_accuracy: 0.9430\n",
            "Epoch 968/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2415 - accuracy: 0.9216 - val_loss: 0.1957 - val_accuracy: 0.9420\n",
            "Epoch 969/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2504 - accuracy: 0.9156 - val_loss: 0.1923 - val_accuracy: 0.9440\n",
            "Epoch 970/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2646 - accuracy: 0.9191 - val_loss: 0.1945 - val_accuracy: 0.9440\n",
            "Epoch 971/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2497 - accuracy: 0.9184 - val_loss: 0.1980 - val_accuracy: 0.9420\n",
            "Epoch 972/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2509 - accuracy: 0.9199 - val_loss: 0.1941 - val_accuracy: 0.9440\n",
            "Epoch 973/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2458 - accuracy: 0.9176 - val_loss: 0.1928 - val_accuracy: 0.9440\n",
            "Epoch 974/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2476 - accuracy: 0.9199 - val_loss: 0.1909 - val_accuracy: 0.9445\n",
            "Epoch 975/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2526 - accuracy: 0.9199 - val_loss: 0.1931 - val_accuracy: 0.9430\n",
            "Epoch 976/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2542 - accuracy: 0.9159 - val_loss: 0.1964 - val_accuracy: 0.9425\n",
            "Epoch 977/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2440 - accuracy: 0.9204 - val_loss: 0.1979 - val_accuracy: 0.9405\n",
            "Epoch 978/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2471 - accuracy: 0.9186 - val_loss: 0.1985 - val_accuracy: 0.9410\n",
            "Epoch 979/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2583 - accuracy: 0.9183 - val_loss: 0.1941 - val_accuracy: 0.9425\n",
            "Epoch 980/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2419 - accuracy: 0.9200 - val_loss: 0.1961 - val_accuracy: 0.9415\n",
            "Epoch 981/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2531 - accuracy: 0.9176 - val_loss: 0.1931 - val_accuracy: 0.9425\n",
            "Epoch 982/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2538 - accuracy: 0.9181 - val_loss: 0.2005 - val_accuracy: 0.9420\n",
            "Epoch 983/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2507 - accuracy: 0.9185 - val_loss: 0.1969 - val_accuracy: 0.9430\n",
            "Epoch 984/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2516 - accuracy: 0.9210 - val_loss: 0.1982 - val_accuracy: 0.9420\n",
            "Epoch 985/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2447 - accuracy: 0.9196 - val_loss: 0.1982 - val_accuracy: 0.9405\n",
            "Epoch 986/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2476 - accuracy: 0.9202 - val_loss: 0.1957 - val_accuracy: 0.9440\n",
            "Epoch 987/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2416 - accuracy: 0.9209 - val_loss: 0.1974 - val_accuracy: 0.9425\n",
            "Epoch 988/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2454 - accuracy: 0.9208 - val_loss: 0.1971 - val_accuracy: 0.9425\n",
            "Epoch 989/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2491 - accuracy: 0.9219 - val_loss: 0.1930 - val_accuracy: 0.9435\n",
            "Epoch 990/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2476 - accuracy: 0.9184 - val_loss: 0.1952 - val_accuracy: 0.9440\n",
            "Epoch 991/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2479 - accuracy: 0.9204 - val_loss: 0.1930 - val_accuracy: 0.9430\n",
            "Epoch 992/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2474 - accuracy: 0.9265 - val_loss: 0.1983 - val_accuracy: 0.9430\n",
            "Epoch 993/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2478 - accuracy: 0.9209 - val_loss: 0.1945 - val_accuracy: 0.9425\n",
            "Epoch 994/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2454 - accuracy: 0.9225 - val_loss: 0.2005 - val_accuracy: 0.9420\n",
            "Epoch 995/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2451 - accuracy: 0.9185 - val_loss: 0.1970 - val_accuracy: 0.9405\n",
            "Epoch 996/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2462 - accuracy: 0.9210 - val_loss: 0.1950 - val_accuracy: 0.9420\n",
            "Epoch 997/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2551 - accuracy: 0.9204 - val_loss: 0.1991 - val_accuracy: 0.9420\n",
            "Epoch 998/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2461 - accuracy: 0.9204 - val_loss: 0.1984 - val_accuracy: 0.9410\n",
            "Epoch 999/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2571 - accuracy: 0.9176 - val_loss: 0.1985 - val_accuracy: 0.9420\n",
            "Epoch 1000/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2491 - accuracy: 0.9200 - val_loss: 0.1943 - val_accuracy: 0.9435\n",
            "Epoch 1001/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2537 - accuracy: 0.9189 - val_loss: 0.1985 - val_accuracy: 0.9420\n",
            "Epoch 1002/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2404 - accuracy: 0.9221 - val_loss: 0.1951 - val_accuracy: 0.9410\n",
            "Epoch 1003/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2529 - accuracy: 0.9186 - val_loss: 0.1911 - val_accuracy: 0.9425\n",
            "Epoch 1004/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2543 - accuracy: 0.9172 - val_loss: 0.1944 - val_accuracy: 0.9445\n",
            "Epoch 1005/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2412 - accuracy: 0.9201 - val_loss: 0.1907 - val_accuracy: 0.9445\n",
            "Epoch 1006/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2604 - accuracy: 0.9181 - val_loss: 0.1979 - val_accuracy: 0.9420\n",
            "Epoch 1007/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2444 - accuracy: 0.9195 - val_loss: 0.1938 - val_accuracy: 0.9420\n",
            "Epoch 1008/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2423 - accuracy: 0.9202 - val_loss: 0.1971 - val_accuracy: 0.9440\n",
            "Epoch 1009/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2418 - accuracy: 0.9241 - val_loss: 0.1905 - val_accuracy: 0.9440\n",
            "Epoch 1010/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2413 - accuracy: 0.9231 - val_loss: 0.1929 - val_accuracy: 0.9440\n",
            "Epoch 1011/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2509 - accuracy: 0.9219 - val_loss: 0.1903 - val_accuracy: 0.9440\n",
            "Epoch 1012/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2523 - accuracy: 0.9156 - val_loss: 0.1970 - val_accuracy: 0.9410\n",
            "Epoch 1013/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2444 - accuracy: 0.9222 - val_loss: 0.1943 - val_accuracy: 0.9440\n",
            "Epoch 1014/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2537 - accuracy: 0.9183 - val_loss: 0.1946 - val_accuracy: 0.9430\n",
            "Epoch 1015/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2404 - accuracy: 0.9206 - val_loss: 0.1946 - val_accuracy: 0.9430\n",
            "Epoch 1016/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2485 - accuracy: 0.9186 - val_loss: 0.2016 - val_accuracy: 0.9425\n",
            "Epoch 1017/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2423 - accuracy: 0.9226 - val_loss: 0.1961 - val_accuracy: 0.9435\n",
            "Epoch 1018/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2418 - accuracy: 0.9209 - val_loss: 0.1933 - val_accuracy: 0.9425\n",
            "Epoch 1019/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2449 - accuracy: 0.9225 - val_loss: 0.1930 - val_accuracy: 0.9450\n",
            "Epoch 1020/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2464 - accuracy: 0.9200 - val_loss: 0.1940 - val_accuracy: 0.9410\n",
            "Epoch 1021/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2598 - accuracy: 0.9186 - val_loss: 0.1937 - val_accuracy: 0.9425\n",
            "Epoch 1022/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2464 - accuracy: 0.9193 - val_loss: 0.1954 - val_accuracy: 0.9420\n",
            "Epoch 1023/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2532 - accuracy: 0.9194 - val_loss: 0.1924 - val_accuracy: 0.9455\n",
            "Epoch 1024/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2486 - accuracy: 0.9185 - val_loss: 0.1943 - val_accuracy: 0.9435\n",
            "Epoch 1025/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2519 - accuracy: 0.9184 - val_loss: 0.1965 - val_accuracy: 0.9420\n",
            "Epoch 1026/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2475 - accuracy: 0.9212 - val_loss: 0.1981 - val_accuracy: 0.9405\n",
            "Epoch 1027/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2477 - accuracy: 0.9195 - val_loss: 0.1982 - val_accuracy: 0.9430\n",
            "Epoch 1028/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2507 - accuracy: 0.9227 - val_loss: 0.1980 - val_accuracy: 0.9420\n",
            "Epoch 1029/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2572 - accuracy: 0.9179 - val_loss: 0.1958 - val_accuracy: 0.9430\n",
            "Epoch 1030/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2386 - accuracy: 0.9212 - val_loss: 0.1916 - val_accuracy: 0.9450\n",
            "Epoch 1031/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2530 - accuracy: 0.9191 - val_loss: 0.1986 - val_accuracy: 0.9415\n",
            "Epoch 1032/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2529 - accuracy: 0.9190 - val_loss: 0.1918 - val_accuracy: 0.9435\n",
            "Epoch 1033/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2415 - accuracy: 0.9209 - val_loss: 0.1966 - val_accuracy: 0.9430\n",
            "Epoch 1034/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2452 - accuracy: 0.9205 - val_loss: 0.1968 - val_accuracy: 0.9420\n",
            "Epoch 1035/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2434 - accuracy: 0.9225 - val_loss: 0.1925 - val_accuracy: 0.9425\n",
            "Epoch 1036/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2457 - accuracy: 0.9193 - val_loss: 0.1955 - val_accuracy: 0.9410\n",
            "Epoch 1037/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2465 - accuracy: 0.9194 - val_loss: 0.1926 - val_accuracy: 0.9425\n",
            "Epoch 1038/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2474 - accuracy: 0.9210 - val_loss: 0.1949 - val_accuracy: 0.9420\n",
            "Epoch 1039/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2468 - accuracy: 0.9227 - val_loss: 0.1921 - val_accuracy: 0.9420\n",
            "Epoch 1040/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2440 - accuracy: 0.9200 - val_loss: 0.1904 - val_accuracy: 0.9440\n",
            "Epoch 1041/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2556 - accuracy: 0.9165 - val_loss: 0.1983 - val_accuracy: 0.9410\n",
            "Epoch 1042/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2310 - accuracy: 0.9255 - val_loss: 0.1957 - val_accuracy: 0.9430\n",
            "Epoch 1043/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2439 - accuracy: 0.9200 - val_loss: 0.1941 - val_accuracy: 0.9425\n",
            "Epoch 1044/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2422 - accuracy: 0.9235 - val_loss: 0.1951 - val_accuracy: 0.9425\n",
            "Epoch 1045/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2410 - accuracy: 0.9249 - val_loss: 0.1884 - val_accuracy: 0.9445\n",
            "Epoch 1046/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2472 - accuracy: 0.9206 - val_loss: 0.1947 - val_accuracy: 0.9435\n",
            "Epoch 1047/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2448 - accuracy: 0.9209 - val_loss: 0.1977 - val_accuracy: 0.9420\n",
            "Epoch 1048/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2591 - accuracy: 0.9186 - val_loss: 0.1917 - val_accuracy: 0.9440\n",
            "Epoch 1049/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2416 - accuracy: 0.9233 - val_loss: 0.1944 - val_accuracy: 0.9430\n",
            "Epoch 1050/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2447 - accuracy: 0.9186 - val_loss: 0.1985 - val_accuracy: 0.9400\n",
            "Epoch 1051/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2466 - accuracy: 0.9216 - val_loss: 0.1945 - val_accuracy: 0.9435\n",
            "Epoch 1052/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2447 - accuracy: 0.9201 - val_loss: 0.1947 - val_accuracy: 0.9440\n",
            "Epoch 1053/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2454 - accuracy: 0.9212 - val_loss: 0.1911 - val_accuracy: 0.9445\n",
            "Epoch 1054/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2526 - accuracy: 0.9184 - val_loss: 0.1933 - val_accuracy: 0.9425\n",
            "Epoch 1055/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2408 - accuracy: 0.9220 - val_loss: 0.1931 - val_accuracy: 0.9435\n",
            "Epoch 1056/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2562 - accuracy: 0.9193 - val_loss: 0.1885 - val_accuracy: 0.9455\n",
            "Epoch 1057/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2382 - accuracy: 0.9241 - val_loss: 0.1902 - val_accuracy: 0.9445\n",
            "Epoch 1058/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2410 - accuracy: 0.9218 - val_loss: 0.1911 - val_accuracy: 0.9415\n",
            "Epoch 1059/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2478 - accuracy: 0.9211 - val_loss: 0.1933 - val_accuracy: 0.9395\n",
            "Epoch 1060/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2439 - accuracy: 0.9208 - val_loss: 0.1887 - val_accuracy: 0.9440\n",
            "Epoch 1061/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2401 - accuracy: 0.9251 - val_loss: 0.1875 - val_accuracy: 0.9440\n",
            "Epoch 1062/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2434 - accuracy: 0.9202 - val_loss: 0.1906 - val_accuracy: 0.9425\n",
            "Epoch 1063/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2433 - accuracy: 0.9193 - val_loss: 0.1904 - val_accuracy: 0.9415\n",
            "Epoch 1064/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2470 - accuracy: 0.9205 - val_loss: 0.1925 - val_accuracy: 0.9435\n",
            "Epoch 1065/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2447 - accuracy: 0.9197 - val_loss: 0.1964 - val_accuracy: 0.9420\n",
            "Epoch 1066/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2480 - accuracy: 0.9224 - val_loss: 0.1907 - val_accuracy: 0.9430\n",
            "Epoch 1067/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2464 - accuracy: 0.9204 - val_loss: 0.1923 - val_accuracy: 0.9440\n",
            "Epoch 1068/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2473 - accuracy: 0.9200 - val_loss: 0.1916 - val_accuracy: 0.9440\n",
            "Epoch 1069/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2391 - accuracy: 0.9237 - val_loss: 0.1921 - val_accuracy: 0.9435\n",
            "Epoch 1070/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2460 - accuracy: 0.9219 - val_loss: 0.1895 - val_accuracy: 0.9425\n",
            "Epoch 1071/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2416 - accuracy: 0.9244 - val_loss: 0.1892 - val_accuracy: 0.9445\n",
            "Epoch 1072/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2480 - accuracy: 0.9199 - val_loss: 0.1910 - val_accuracy: 0.9455\n",
            "Epoch 1073/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2380 - accuracy: 0.9225 - val_loss: 0.1896 - val_accuracy: 0.9450\n",
            "Epoch 1074/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2412 - accuracy: 0.9201 - val_loss: 0.1928 - val_accuracy: 0.9425\n",
            "Epoch 1075/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2500 - accuracy: 0.9194 - val_loss: 0.1898 - val_accuracy: 0.9430\n",
            "Epoch 1076/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2523 - accuracy: 0.9219 - val_loss: 0.1894 - val_accuracy: 0.9435\n",
            "Epoch 1077/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2542 - accuracy: 0.9200 - val_loss: 0.1903 - val_accuracy: 0.9450\n",
            "Epoch 1078/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2449 - accuracy: 0.9224 - val_loss: 0.1933 - val_accuracy: 0.9435\n",
            "Epoch 1079/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2372 - accuracy: 0.9221 - val_loss: 0.1930 - val_accuracy: 0.9430\n",
            "Epoch 1080/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2423 - accuracy: 0.9224 - val_loss: 0.1892 - val_accuracy: 0.9455\n",
            "Epoch 1081/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2468 - accuracy: 0.9214 - val_loss: 0.1954 - val_accuracy: 0.9430\n",
            "Epoch 1082/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2471 - accuracy: 0.9216 - val_loss: 0.1886 - val_accuracy: 0.9450\n",
            "Epoch 1083/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2447 - accuracy: 0.9220 - val_loss: 0.1943 - val_accuracy: 0.9405\n",
            "Epoch 1084/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2566 - accuracy: 0.9195 - val_loss: 0.1958 - val_accuracy: 0.9420\n",
            "Epoch 1085/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2425 - accuracy: 0.9210 - val_loss: 0.1930 - val_accuracy: 0.9420\n",
            "Epoch 1086/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2447 - accuracy: 0.9233 - val_loss: 0.1899 - val_accuracy: 0.9430\n",
            "Epoch 1087/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2453 - accuracy: 0.9208 - val_loss: 0.1922 - val_accuracy: 0.9420\n",
            "Epoch 1088/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2466 - accuracy: 0.9204 - val_loss: 0.1919 - val_accuracy: 0.9430\n",
            "Epoch 1089/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2441 - accuracy: 0.9221 - val_loss: 0.1954 - val_accuracy: 0.9445\n",
            "Epoch 1090/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2433 - accuracy: 0.9230 - val_loss: 0.1913 - val_accuracy: 0.9435\n",
            "Epoch 1091/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2386 - accuracy: 0.9234 - val_loss: 0.1962 - val_accuracy: 0.9415\n",
            "Epoch 1092/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2416 - accuracy: 0.9227 - val_loss: 0.1918 - val_accuracy: 0.9440\n",
            "Epoch 1093/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2422 - accuracy: 0.9211 - val_loss: 0.1945 - val_accuracy: 0.9440\n",
            "Epoch 1094/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2460 - accuracy: 0.9244 - val_loss: 0.1944 - val_accuracy: 0.9435\n",
            "Epoch 1095/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2435 - accuracy: 0.9208 - val_loss: 0.1988 - val_accuracy: 0.9420\n",
            "Epoch 1096/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2417 - accuracy: 0.9199 - val_loss: 0.1917 - val_accuracy: 0.9430\n",
            "Epoch 1097/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2456 - accuracy: 0.9216 - val_loss: 0.1962 - val_accuracy: 0.9415\n",
            "Epoch 1098/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2327 - accuracy: 0.9265 - val_loss: 0.1909 - val_accuracy: 0.9450\n",
            "Epoch 1099/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2549 - accuracy: 0.9201 - val_loss: 0.1929 - val_accuracy: 0.9425\n",
            "Epoch 1100/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2384 - accuracy: 0.9227 - val_loss: 0.1900 - val_accuracy: 0.9445\n",
            "Epoch 1101/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2508 - accuracy: 0.9184 - val_loss: 0.1923 - val_accuracy: 0.9415\n",
            "Epoch 1102/6000\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2536 - accuracy: 0.9221 - val_loss: 0.1939 - val_accuracy: 0.9435\n",
            "Epoch 1103/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2462 - accuracy: 0.9214 - val_loss: 0.1949 - val_accuracy: 0.9435\n",
            "Epoch 1104/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2368 - accuracy: 0.9225 - val_loss: 0.1907 - val_accuracy: 0.9435\n",
            "Epoch 1105/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2509 - accuracy: 0.9187 - val_loss: 0.1880 - val_accuracy: 0.9445\n",
            "Epoch 1106/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2459 - accuracy: 0.9216 - val_loss: 0.1901 - val_accuracy: 0.9420\n",
            "Epoch 1107/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2347 - accuracy: 0.9209 - val_loss: 0.1902 - val_accuracy: 0.9435\n",
            "Epoch 1108/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2484 - accuracy: 0.9211 - val_loss: 0.1900 - val_accuracy: 0.9450\n",
            "Epoch 1109/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2563 - accuracy: 0.9201 - val_loss: 0.1966 - val_accuracy: 0.9425\n",
            "Epoch 1110/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2475 - accuracy: 0.9180 - val_loss: 0.1946 - val_accuracy: 0.9435\n",
            "Epoch 1111/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2537 - accuracy: 0.9185 - val_loss: 0.1949 - val_accuracy: 0.9420\n",
            "Epoch 1112/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2534 - accuracy: 0.9210 - val_loss: 0.1933 - val_accuracy: 0.9430\n",
            "Epoch 1113/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2540 - accuracy: 0.9193 - val_loss: 0.1962 - val_accuracy: 0.9420\n",
            "Epoch 1114/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2382 - accuracy: 0.9222 - val_loss: 0.1957 - val_accuracy: 0.9405\n",
            "Epoch 1115/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2388 - accuracy: 0.9222 - val_loss: 0.1954 - val_accuracy: 0.9440\n",
            "Epoch 1116/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2452 - accuracy: 0.9220 - val_loss: 0.1931 - val_accuracy: 0.9435\n",
            "Epoch 1117/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2491 - accuracy: 0.9201 - val_loss: 0.1964 - val_accuracy: 0.9405\n",
            "Epoch 1118/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2440 - accuracy: 0.9225 - val_loss: 0.1913 - val_accuracy: 0.9425\n",
            "Epoch 1119/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2504 - accuracy: 0.9195 - val_loss: 0.1951 - val_accuracy: 0.9430\n",
            "Epoch 1120/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2513 - accuracy: 0.9218 - val_loss: 0.1945 - val_accuracy: 0.9430\n",
            "Epoch 1121/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2517 - accuracy: 0.9222 - val_loss: 0.1947 - val_accuracy: 0.9425\n",
            "Epoch 1122/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2433 - accuracy: 0.9234 - val_loss: 0.1940 - val_accuracy: 0.9410\n",
            "Epoch 1123/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2521 - accuracy: 0.9212 - val_loss: 0.1954 - val_accuracy: 0.9440\n",
            "Epoch 1124/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2481 - accuracy: 0.9219 - val_loss: 0.1935 - val_accuracy: 0.9430\n",
            "Epoch 1125/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2345 - accuracy: 0.9218 - val_loss: 0.1922 - val_accuracy: 0.9430\n",
            "Epoch 1126/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2461 - accuracy: 0.9218 - val_loss: 0.1949 - val_accuracy: 0.9410\n",
            "Epoch 1127/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2379 - accuracy: 0.9211 - val_loss: 0.1995 - val_accuracy: 0.9415\n",
            "Epoch 1128/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2376 - accuracy: 0.9237 - val_loss: 0.1940 - val_accuracy: 0.9435\n",
            "Epoch 1129/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2331 - accuracy: 0.9222 - val_loss: 0.1925 - val_accuracy: 0.9445\n",
            "Epoch 1130/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2413 - accuracy: 0.9234 - val_loss: 0.1961 - val_accuracy: 0.9425\n",
            "Epoch 1131/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2409 - accuracy: 0.9205 - val_loss: 0.1940 - val_accuracy: 0.9410\n",
            "Epoch 1132/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2460 - accuracy: 0.9214 - val_loss: 0.1906 - val_accuracy: 0.9440\n",
            "Epoch 1133/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2430 - accuracy: 0.9239 - val_loss: 0.1935 - val_accuracy: 0.9420\n",
            "Epoch 1134/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2600 - accuracy: 0.9199 - val_loss: 0.1955 - val_accuracy: 0.9430\n",
            "Epoch 1135/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2409 - accuracy: 0.9205 - val_loss: 0.1935 - val_accuracy: 0.9420\n",
            "Epoch 1136/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2313 - accuracy: 0.9269 - val_loss: 0.1950 - val_accuracy: 0.9420\n",
            "Epoch 1137/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2519 - accuracy: 0.9210 - val_loss: 0.1991 - val_accuracy: 0.9405\n",
            "Epoch 1138/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2431 - accuracy: 0.9226 - val_loss: 0.1957 - val_accuracy: 0.9415\n",
            "Epoch 1139/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2472 - accuracy: 0.9208 - val_loss: 0.1949 - val_accuracy: 0.9405\n",
            "Epoch 1140/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2491 - accuracy: 0.9225 - val_loss: 0.2006 - val_accuracy: 0.9420\n",
            "Epoch 1141/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2525 - accuracy: 0.9204 - val_loss: 0.1912 - val_accuracy: 0.9455\n",
            "Epoch 1142/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2417 - accuracy: 0.9233 - val_loss: 0.1935 - val_accuracy: 0.9445\n",
            "Epoch 1143/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2465 - accuracy: 0.9206 - val_loss: 0.1900 - val_accuracy: 0.9440\n",
            "Epoch 1144/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2436 - accuracy: 0.9212 - val_loss: 0.1945 - val_accuracy: 0.9425\n",
            "Epoch 1145/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2469 - accuracy: 0.9199 - val_loss: 0.1967 - val_accuracy: 0.9410\n",
            "Epoch 1146/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2507 - accuracy: 0.9194 - val_loss: 0.1923 - val_accuracy: 0.9435\n",
            "Epoch 1147/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2487 - accuracy: 0.9212 - val_loss: 0.1945 - val_accuracy: 0.9440\n",
            "Epoch 1148/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2393 - accuracy: 0.9197 - val_loss: 0.1968 - val_accuracy: 0.9405\n",
            "Epoch 1149/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2418 - accuracy: 0.9240 - val_loss: 0.1947 - val_accuracy: 0.9410\n",
            "Epoch 1150/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2537 - accuracy: 0.9159 - val_loss: 0.1957 - val_accuracy: 0.9435\n",
            "Epoch 1151/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2435 - accuracy: 0.9231 - val_loss: 0.1997 - val_accuracy: 0.9420\n",
            "Epoch 1152/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2488 - accuracy: 0.9209 - val_loss: 0.1923 - val_accuracy: 0.9435\n",
            "Epoch 1153/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2430 - accuracy: 0.9245 - val_loss: 0.1943 - val_accuracy: 0.9410\n",
            "Epoch 1154/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2444 - accuracy: 0.9220 - val_loss: 0.1932 - val_accuracy: 0.9435\n",
            "Epoch 1155/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2440 - accuracy: 0.9221 - val_loss: 0.1889 - val_accuracy: 0.9450\n",
            "Epoch 1156/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2469 - accuracy: 0.9193 - val_loss: 0.1916 - val_accuracy: 0.9450\n",
            "Epoch 1157/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2450 - accuracy: 0.9241 - val_loss: 0.1913 - val_accuracy: 0.9445\n",
            "Epoch 1158/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2422 - accuracy: 0.9249 - val_loss: 0.1928 - val_accuracy: 0.9435\n",
            "Epoch 1159/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2479 - accuracy: 0.9205 - val_loss: 0.1956 - val_accuracy: 0.9440\n",
            "Epoch 1160/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2425 - accuracy: 0.9227 - val_loss: 0.1978 - val_accuracy: 0.9410\n",
            "Epoch 1161/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2520 - accuracy: 0.9235 - val_loss: 0.1958 - val_accuracy: 0.9445\n",
            "Epoch 1162/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2479 - accuracy: 0.9191 - val_loss: 0.1979 - val_accuracy: 0.9440\n",
            "Epoch 1163/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2459 - accuracy: 0.9236 - val_loss: 0.2008 - val_accuracy: 0.9420\n",
            "Epoch 1164/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2486 - accuracy: 0.9206 - val_loss: 0.1961 - val_accuracy: 0.9425\n",
            "Epoch 1165/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2538 - accuracy: 0.9215 - val_loss: 0.1962 - val_accuracy: 0.9415\n",
            "Epoch 1166/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2478 - accuracy: 0.9212 - val_loss: 0.1959 - val_accuracy: 0.9440\n",
            "Epoch 1167/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2405 - accuracy: 0.9237 - val_loss: 0.1948 - val_accuracy: 0.9425\n",
            "Epoch 1168/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2527 - accuracy: 0.9212 - val_loss: 0.1951 - val_accuracy: 0.9450\n",
            "Epoch 1169/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2464 - accuracy: 0.9224 - val_loss: 0.1952 - val_accuracy: 0.9450\n",
            "Epoch 1170/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2367 - accuracy: 0.9204 - val_loss: 0.1965 - val_accuracy: 0.9445\n",
            "Epoch 1171/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2401 - accuracy: 0.9227 - val_loss: 0.1914 - val_accuracy: 0.9445\n",
            "Epoch 1172/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2474 - accuracy: 0.9220 - val_loss: 0.1922 - val_accuracy: 0.9430\n",
            "Epoch 1173/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2415 - accuracy: 0.9239 - val_loss: 0.1966 - val_accuracy: 0.9435\n",
            "Epoch 1174/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2379 - accuracy: 0.9222 - val_loss: 0.1928 - val_accuracy: 0.9435\n",
            "Epoch 1175/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2493 - accuracy: 0.9233 - val_loss: 0.1950 - val_accuracy: 0.9440\n",
            "Epoch 1176/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2446 - accuracy: 0.9220 - val_loss: 0.1959 - val_accuracy: 0.9450\n",
            "Epoch 1177/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2501 - accuracy: 0.9237 - val_loss: 0.1941 - val_accuracy: 0.9445\n",
            "Epoch 1178/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2472 - accuracy: 0.9186 - val_loss: 0.1935 - val_accuracy: 0.9445\n",
            "Epoch 1179/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2487 - accuracy: 0.9216 - val_loss: 0.1940 - val_accuracy: 0.9435\n",
            "Epoch 1180/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2416 - accuracy: 0.9216 - val_loss: 0.1971 - val_accuracy: 0.9430\n",
            "Epoch 1181/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2478 - accuracy: 0.9209 - val_loss: 0.1932 - val_accuracy: 0.9445\n",
            "Epoch 1182/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2454 - accuracy: 0.9166 - val_loss: 0.1937 - val_accuracy: 0.9435\n",
            "Epoch 1183/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2413 - accuracy: 0.9212 - val_loss: 0.1922 - val_accuracy: 0.9435\n",
            "Epoch 1184/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2401 - accuracy: 0.9231 - val_loss: 0.1932 - val_accuracy: 0.9430\n",
            "Epoch 1185/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2467 - accuracy: 0.9224 - val_loss: 0.1963 - val_accuracy: 0.9425\n",
            "Epoch 1186/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2397 - accuracy: 0.9233 - val_loss: 0.1947 - val_accuracy: 0.9440\n",
            "Epoch 1187/6000\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2454 - accuracy: 0.9200 - val_loss: 0.1975 - val_accuracy: 0.9425\n",
            "Epoch 1188/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2516 - accuracy: 0.9209 - val_loss: 0.1953 - val_accuracy: 0.9430\n",
            "Epoch 1189/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2432 - accuracy: 0.9196 - val_loss: 0.1968 - val_accuracy: 0.9420\n",
            "Epoch 1190/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2345 - accuracy: 0.9256 - val_loss: 0.1945 - val_accuracy: 0.9440\n",
            "Epoch 1191/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2377 - accuracy: 0.9224 - val_loss: 0.1912 - val_accuracy: 0.9440\n",
            "Epoch 1192/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2471 - accuracy: 0.9240 - val_loss: 0.1914 - val_accuracy: 0.9435\n",
            "Epoch 1193/6000\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2451 - accuracy: 0.9231 - val_loss: 0.1911 - val_accuracy: 0.9430\n",
            "Epoch 1194/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2447 - accuracy: 0.9196 - val_loss: 0.1918 - val_accuracy: 0.9420\n",
            "Epoch 1195/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2444 - accuracy: 0.9218 - val_loss: 0.1912 - val_accuracy: 0.9440\n",
            "Epoch 1196/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2447 - accuracy: 0.9221 - val_loss: 0.1916 - val_accuracy: 0.9420\n",
            "Epoch 1197/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2435 - accuracy: 0.9202 - val_loss: 0.1929 - val_accuracy: 0.9430\n",
            "Epoch 1198/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2521 - accuracy: 0.9215 - val_loss: 0.1916 - val_accuracy: 0.9435\n",
            "Epoch 1199/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2459 - accuracy: 0.9233 - val_loss: 0.1948 - val_accuracy: 0.9435\n",
            "Epoch 1200/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2428 - accuracy: 0.9215 - val_loss: 0.1941 - val_accuracy: 0.9430\n",
            "Epoch 1201/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2507 - accuracy: 0.9194 - val_loss: 0.1947 - val_accuracy: 0.9425\n",
            "Epoch 1202/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2460 - accuracy: 0.9196 - val_loss: 0.1936 - val_accuracy: 0.9430\n",
            "Epoch 1203/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2438 - accuracy: 0.9209 - val_loss: 0.1930 - val_accuracy: 0.9420\n",
            "Epoch 1204/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2442 - accuracy: 0.9226 - val_loss: 0.1918 - val_accuracy: 0.9435\n",
            "Epoch 1205/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2404 - accuracy: 0.9233 - val_loss: 0.1914 - val_accuracy: 0.9440\n",
            "Epoch 1206/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2386 - accuracy: 0.9218 - val_loss: 0.1945 - val_accuracy: 0.9430\n",
            "Epoch 1207/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2441 - accuracy: 0.9222 - val_loss: 0.1933 - val_accuracy: 0.9425\n",
            "Epoch 1208/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2373 - accuracy: 0.9249 - val_loss: 0.1916 - val_accuracy: 0.9435\n",
            "Epoch 1209/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2412 - accuracy: 0.9256 - val_loss: 0.1968 - val_accuracy: 0.9425\n",
            "Epoch 1210/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2411 - accuracy: 0.9239 - val_loss: 0.1965 - val_accuracy: 0.9440\n",
            "Epoch 1211/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2374 - accuracy: 0.9224 - val_loss: 0.1895 - val_accuracy: 0.9430\n",
            "Epoch 1212/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2482 - accuracy: 0.9230 - val_loss: 0.1991 - val_accuracy: 0.9420\n",
            "Epoch 1213/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2447 - accuracy: 0.9234 - val_loss: 0.1929 - val_accuracy: 0.9420\n",
            "Epoch 1214/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2461 - accuracy: 0.9221 - val_loss: 0.1934 - val_accuracy: 0.9420\n",
            "Epoch 1215/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2399 - accuracy: 0.9215 - val_loss: 0.1957 - val_accuracy: 0.9430\n",
            "Epoch 1216/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2350 - accuracy: 0.9269 - val_loss: 0.1923 - val_accuracy: 0.9420\n",
            "Epoch 1217/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2411 - accuracy: 0.9250 - val_loss: 0.1984 - val_accuracy: 0.9420\n",
            "Epoch 1218/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2460 - accuracy: 0.9206 - val_loss: 0.1979 - val_accuracy: 0.9435\n",
            "Epoch 1219/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2369 - accuracy: 0.9221 - val_loss: 0.1939 - val_accuracy: 0.9430\n",
            "Epoch 1220/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2486 - accuracy: 0.9233 - val_loss: 0.1930 - val_accuracy: 0.9430\n",
            "Epoch 1221/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2370 - accuracy: 0.9264 - val_loss: 0.1927 - val_accuracy: 0.9435\n",
            "Epoch 1222/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2394 - accuracy: 0.9233 - val_loss: 0.1923 - val_accuracy: 0.9435\n",
            "Epoch 1223/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2388 - accuracy: 0.9222 - val_loss: 0.1931 - val_accuracy: 0.9435\n",
            "Epoch 1224/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2412 - accuracy: 0.9250 - val_loss: 0.2000 - val_accuracy: 0.9435\n",
            "Epoch 1225/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2445 - accuracy: 0.9214 - val_loss: 0.1945 - val_accuracy: 0.9420\n",
            "Epoch 1226/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2389 - accuracy: 0.9246 - val_loss: 0.1915 - val_accuracy: 0.9430\n",
            "Epoch 1227/6000\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2508 - accuracy: 0.9222 - val_loss: 0.1986 - val_accuracy: 0.9425\n",
            "Epoch 1228/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2380 - accuracy: 0.9237 - val_loss: 0.1937 - val_accuracy: 0.9435\n",
            "Epoch 1229/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2363 - accuracy: 0.9235 - val_loss: 0.1932 - val_accuracy: 0.9425\n",
            "Epoch 1230/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2428 - accuracy: 0.9216 - val_loss: 0.1958 - val_accuracy: 0.9450\n",
            "Epoch 1231/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2528 - accuracy: 0.9191 - val_loss: 0.1929 - val_accuracy: 0.9430\n",
            "Epoch 1232/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2414 - accuracy: 0.9240 - val_loss: 0.1983 - val_accuracy: 0.9415\n",
            "Epoch 1233/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2468 - accuracy: 0.9219 - val_loss: 0.1931 - val_accuracy: 0.9445\n",
            "Epoch 1234/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2460 - accuracy: 0.9224 - val_loss: 0.1922 - val_accuracy: 0.9430\n",
            "Epoch 1235/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2406 - accuracy: 0.9205 - val_loss: 0.1921 - val_accuracy: 0.9425\n",
            "Epoch 1236/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2465 - accuracy: 0.9190 - val_loss: 0.1899 - val_accuracy: 0.9450\n",
            "Epoch 1237/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2558 - accuracy: 0.9210 - val_loss: 0.1969 - val_accuracy: 0.9410\n",
            "Epoch 1238/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2407 - accuracy: 0.9243 - val_loss: 0.1945 - val_accuracy: 0.9425\n",
            "Epoch 1239/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2446 - accuracy: 0.9219 - val_loss: 0.1910 - val_accuracy: 0.9455\n",
            "Epoch 1240/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2388 - accuracy: 0.9214 - val_loss: 0.1916 - val_accuracy: 0.9430\n",
            "Epoch 1241/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2369 - accuracy: 0.9270 - val_loss: 0.1917 - val_accuracy: 0.9440\n",
            "Epoch 1242/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2404 - accuracy: 0.9212 - val_loss: 0.1943 - val_accuracy: 0.9435\n",
            "Epoch 1243/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2378 - accuracy: 0.9259 - val_loss: 0.1906 - val_accuracy: 0.9445\n",
            "Epoch 1244/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2379 - accuracy: 0.9215 - val_loss: 0.1960 - val_accuracy: 0.9435\n",
            "Epoch 1245/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2372 - accuracy: 0.9240 - val_loss: 0.1921 - val_accuracy: 0.9415\n",
            "Epoch 1246/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2397 - accuracy: 0.9233 - val_loss: 0.1884 - val_accuracy: 0.9450\n",
            "Epoch 1247/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2367 - accuracy: 0.9222 - val_loss: 0.1921 - val_accuracy: 0.9415\n",
            "Epoch 1248/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2404 - accuracy: 0.9222 - val_loss: 0.1900 - val_accuracy: 0.9450\n",
            "Epoch 1249/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2406 - accuracy: 0.9222 - val_loss: 0.1901 - val_accuracy: 0.9435\n",
            "Epoch 1250/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2519 - accuracy: 0.9226 - val_loss: 0.1914 - val_accuracy: 0.9435\n",
            "Epoch 1251/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2424 - accuracy: 0.9236 - val_loss: 0.1908 - val_accuracy: 0.9435\n",
            "Epoch 1252/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2405 - accuracy: 0.9218 - val_loss: 0.1893 - val_accuracy: 0.9435\n",
            "Epoch 1253/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2294 - accuracy: 0.9239 - val_loss: 0.1922 - val_accuracy: 0.9430\n",
            "Epoch 1254/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2408 - accuracy: 0.9220 - val_loss: 0.1915 - val_accuracy: 0.9430\n",
            "Epoch 1255/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2545 - accuracy: 0.9221 - val_loss: 0.1884 - val_accuracy: 0.9450\n",
            "Epoch 1256/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2429 - accuracy: 0.9186 - val_loss: 0.1882 - val_accuracy: 0.9435\n",
            "Epoch 1257/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2430 - accuracy: 0.9230 - val_loss: 0.1874 - val_accuracy: 0.9445\n",
            "Epoch 1258/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2330 - accuracy: 0.9225 - val_loss: 0.1889 - val_accuracy: 0.9435\n",
            "Epoch 1259/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2457 - accuracy: 0.9226 - val_loss: 0.1885 - val_accuracy: 0.9425\n",
            "Epoch 1260/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2409 - accuracy: 0.9224 - val_loss: 0.1892 - val_accuracy: 0.9445\n",
            "Epoch 1261/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2408 - accuracy: 0.9224 - val_loss: 0.1921 - val_accuracy: 0.9420\n",
            "Epoch 1262/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2391 - accuracy: 0.9246 - val_loss: 0.1916 - val_accuracy: 0.9430\n",
            "Epoch 1263/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2395 - accuracy: 0.9233 - val_loss: 0.1935 - val_accuracy: 0.9415\n",
            "Epoch 1264/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2412 - accuracy: 0.9226 - val_loss: 0.1915 - val_accuracy: 0.9435\n",
            "Epoch 1265/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2359 - accuracy: 0.9239 - val_loss: 0.1878 - val_accuracy: 0.9445\n",
            "Epoch 1266/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2434 - accuracy: 0.9219 - val_loss: 0.1923 - val_accuracy: 0.9435\n",
            "Epoch 1267/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2429 - accuracy: 0.9235 - val_loss: 0.1903 - val_accuracy: 0.9445\n",
            "Epoch 1268/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2422 - accuracy: 0.9237 - val_loss: 0.1966 - val_accuracy: 0.9430\n",
            "Epoch 1269/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2440 - accuracy: 0.9209 - val_loss: 0.1954 - val_accuracy: 0.9440\n",
            "Epoch 1270/6000\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2420 - accuracy: 0.9210 - val_loss: 0.1980 - val_accuracy: 0.9435\n",
            "Epoch 1271/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2375 - accuracy: 0.9224 - val_loss: 0.1885 - val_accuracy: 0.9445\n",
            "Epoch 1272/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2382 - accuracy: 0.9233 - val_loss: 0.1916 - val_accuracy: 0.9435\n",
            "Epoch 1273/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2473 - accuracy: 0.9254 - val_loss: 0.1971 - val_accuracy: 0.9420\n",
            "Epoch 1274/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2405 - accuracy: 0.9221 - val_loss: 0.1952 - val_accuracy: 0.9415\n",
            "Epoch 1275/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2496 - accuracy: 0.9218 - val_loss: 0.1908 - val_accuracy: 0.9440\n",
            "Epoch 1276/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2419 - accuracy: 0.9215 - val_loss: 0.1949 - val_accuracy: 0.9425\n",
            "Epoch 1277/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2390 - accuracy: 0.9230 - val_loss: 0.1952 - val_accuracy: 0.9420\n",
            "Epoch 1278/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2502 - accuracy: 0.9233 - val_loss: 0.1906 - val_accuracy: 0.9425\n",
            "Epoch 1279/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2417 - accuracy: 0.9200 - val_loss: 0.1914 - val_accuracy: 0.9430\n",
            "Epoch 1280/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2451 - accuracy: 0.9191 - val_loss: 0.1944 - val_accuracy: 0.9415\n",
            "Epoch 1281/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2458 - accuracy: 0.9237 - val_loss: 0.1897 - val_accuracy: 0.9430\n",
            "Epoch 1282/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2454 - accuracy: 0.9208 - val_loss: 0.1928 - val_accuracy: 0.9430\n",
            "Epoch 1283/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2333 - accuracy: 0.9225 - val_loss: 0.1900 - val_accuracy: 0.9445\n",
            "Epoch 1284/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2337 - accuracy: 0.9249 - val_loss: 0.1900 - val_accuracy: 0.9420\n",
            "Epoch 1285/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2372 - accuracy: 0.9234 - val_loss: 0.1908 - val_accuracy: 0.9455\n",
            "Epoch 1286/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2407 - accuracy: 0.9211 - val_loss: 0.1907 - val_accuracy: 0.9430\n",
            "Epoch 1287/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2417 - accuracy: 0.9226 - val_loss: 0.1929 - val_accuracy: 0.9430\n",
            "Epoch 1288/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2446 - accuracy: 0.9236 - val_loss: 0.1926 - val_accuracy: 0.9425\n",
            "Epoch 1289/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2417 - accuracy: 0.9187 - val_loss: 0.1920 - val_accuracy: 0.9435\n",
            "Epoch 1290/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2391 - accuracy: 0.9236 - val_loss: 0.1909 - val_accuracy: 0.9445\n",
            "Epoch 1291/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2364 - accuracy: 0.9224 - val_loss: 0.1885 - val_accuracy: 0.9445\n",
            "Epoch 1292/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2368 - accuracy: 0.9237 - val_loss: 0.1897 - val_accuracy: 0.9435\n",
            "Epoch 1293/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2412 - accuracy: 0.9243 - val_loss: 0.1957 - val_accuracy: 0.9440\n",
            "Epoch 1294/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2375 - accuracy: 0.9241 - val_loss: 0.1899 - val_accuracy: 0.9435\n",
            "Epoch 1295/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2317 - accuracy: 0.9259 - val_loss: 0.1937 - val_accuracy: 0.9440\n",
            "Epoch 1296/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2483 - accuracy: 0.9244 - val_loss: 0.1927 - val_accuracy: 0.9435\n",
            "Epoch 1297/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2365 - accuracy: 0.9258 - val_loss: 0.1919 - val_accuracy: 0.9430\n",
            "Epoch 1298/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2390 - accuracy: 0.9261 - val_loss: 0.1944 - val_accuracy: 0.9435\n",
            "Epoch 1299/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2357 - accuracy: 0.9236 - val_loss: 0.1890 - val_accuracy: 0.9455\n",
            "Epoch 1300/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2380 - accuracy: 0.9251 - val_loss: 0.1921 - val_accuracy: 0.9430\n",
            "Epoch 1301/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2395 - accuracy: 0.9233 - val_loss: 0.1903 - val_accuracy: 0.9430\n",
            "Epoch 1302/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2383 - accuracy: 0.9231 - val_loss: 0.1938 - val_accuracy: 0.9425\n",
            "Epoch 1303/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2433 - accuracy: 0.9240 - val_loss: 0.1927 - val_accuracy: 0.9435\n",
            "Epoch 1304/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2375 - accuracy: 0.9219 - val_loss: 0.1959 - val_accuracy: 0.9440\n",
            "Epoch 1305/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2373 - accuracy: 0.9249 - val_loss: 0.1899 - val_accuracy: 0.9435\n",
            "Epoch 1306/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2316 - accuracy: 0.9245 - val_loss: 0.1883 - val_accuracy: 0.9435\n",
            "Epoch 1307/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2373 - accuracy: 0.9254 - val_loss: 0.1951 - val_accuracy: 0.9420\n",
            "Epoch 1308/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2402 - accuracy: 0.9201 - val_loss: 0.1912 - val_accuracy: 0.9440\n",
            "Epoch 1309/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2429 - accuracy: 0.9230 - val_loss: 0.1917 - val_accuracy: 0.9425\n",
            "Epoch 1310/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2337 - accuracy: 0.9258 - val_loss: 0.1939 - val_accuracy: 0.9430\n",
            "Epoch 1311/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2360 - accuracy: 0.9227 - val_loss: 0.1922 - val_accuracy: 0.9445\n",
            "Epoch 1312/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2356 - accuracy: 0.9271 - val_loss: 0.1930 - val_accuracy: 0.9425\n",
            "Epoch 1313/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2368 - accuracy: 0.9215 - val_loss: 0.1970 - val_accuracy: 0.9440\n",
            "Epoch 1314/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2314 - accuracy: 0.9239 - val_loss: 0.1909 - val_accuracy: 0.9435\n",
            "Epoch 1315/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2351 - accuracy: 0.9235 - val_loss: 0.1902 - val_accuracy: 0.9440\n",
            "Epoch 1316/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2404 - accuracy: 0.9246 - val_loss: 0.1956 - val_accuracy: 0.9430\n",
            "Epoch 1317/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2405 - accuracy: 0.9219 - val_loss: 0.1937 - val_accuracy: 0.9430\n",
            "Epoch 1318/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2369 - accuracy: 0.9260 - val_loss: 0.1943 - val_accuracy: 0.9420\n",
            "Epoch 1319/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2301 - accuracy: 0.9260 - val_loss: 0.1928 - val_accuracy: 0.9430\n",
            "Epoch 1320/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2443 - accuracy: 0.9211 - val_loss: 0.1920 - val_accuracy: 0.9450\n",
            "Epoch 1321/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2478 - accuracy: 0.9209 - val_loss: 0.1945 - val_accuracy: 0.9435\n",
            "Epoch 1322/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2357 - accuracy: 0.9260 - val_loss: 0.1865 - val_accuracy: 0.9430\n",
            "Epoch 1323/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2414 - accuracy: 0.9243 - val_loss: 0.1865 - val_accuracy: 0.9440\n",
            "Epoch 1324/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2397 - accuracy: 0.9241 - val_loss: 0.1909 - val_accuracy: 0.9455\n",
            "Epoch 1325/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2514 - accuracy: 0.9221 - val_loss: 0.1958 - val_accuracy: 0.9445\n",
            "Epoch 1326/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2396 - accuracy: 0.9229 - val_loss: 0.1880 - val_accuracy: 0.9445\n",
            "Epoch 1327/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2379 - accuracy: 0.9231 - val_loss: 0.1898 - val_accuracy: 0.9455\n",
            "Epoch 1328/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2338 - accuracy: 0.9255 - val_loss: 0.1910 - val_accuracy: 0.9450\n",
            "Epoch 1329/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2486 - accuracy: 0.9214 - val_loss: 0.1905 - val_accuracy: 0.9450\n",
            "Epoch 1330/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2469 - accuracy: 0.9208 - val_loss: 0.1965 - val_accuracy: 0.9425\n",
            "Epoch 1331/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2399 - accuracy: 0.9212 - val_loss: 0.1954 - val_accuracy: 0.9435\n",
            "Epoch 1332/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2404 - accuracy: 0.9218 - val_loss: 0.1914 - val_accuracy: 0.9435\n",
            "Epoch 1333/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2505 - accuracy: 0.9218 - val_loss: 0.1987 - val_accuracy: 0.9435\n",
            "Epoch 1334/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2380 - accuracy: 0.9240 - val_loss: 0.1964 - val_accuracy: 0.9435\n",
            "Epoch 1335/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2660 - accuracy: 0.9200 - val_loss: 0.1915 - val_accuracy: 0.9435\n",
            "Epoch 1336/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2400 - accuracy: 0.9211 - val_loss: 0.1972 - val_accuracy: 0.9435\n",
            "Epoch 1337/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2363 - accuracy: 0.9231 - val_loss: 0.1935 - val_accuracy: 0.9440\n",
            "Epoch 1338/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2474 - accuracy: 0.9222 - val_loss: 0.1927 - val_accuracy: 0.9440\n",
            "Epoch 1339/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2405 - accuracy: 0.9224 - val_loss: 0.1930 - val_accuracy: 0.9435\n",
            "Epoch 1340/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2336 - accuracy: 0.9277 - val_loss: 0.1909 - val_accuracy: 0.9440\n",
            "Epoch 1341/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2329 - accuracy: 0.9229 - val_loss: 0.1892 - val_accuracy: 0.9430\n",
            "Epoch 1342/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2383 - accuracy: 0.9214 - val_loss: 0.1939 - val_accuracy: 0.9455\n",
            "Epoch 1343/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2382 - accuracy: 0.9241 - val_loss: 0.1933 - val_accuracy: 0.9430\n",
            "Epoch 1344/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2405 - accuracy: 0.9244 - val_loss: 0.1898 - val_accuracy: 0.9435\n",
            "Epoch 1345/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2436 - accuracy: 0.9200 - val_loss: 0.1922 - val_accuracy: 0.9425\n",
            "Epoch 1346/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2483 - accuracy: 0.9212 - val_loss: 0.1910 - val_accuracy: 0.9440\n",
            "Epoch 1347/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2380 - accuracy: 0.9236 - val_loss: 0.1929 - val_accuracy: 0.9425\n",
            "Epoch 1348/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2400 - accuracy: 0.9239 - val_loss: 0.1952 - val_accuracy: 0.9430\n",
            "Epoch 1349/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2411 - accuracy: 0.9220 - val_loss: 0.1920 - val_accuracy: 0.9440\n",
            "Epoch 1350/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2488 - accuracy: 0.9231 - val_loss: 0.1876 - val_accuracy: 0.9440\n",
            "Epoch 1351/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2437 - accuracy: 0.9210 - val_loss: 0.1971 - val_accuracy: 0.9425\n",
            "Epoch 1352/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2429 - accuracy: 0.9235 - val_loss: 0.1916 - val_accuracy: 0.9450\n",
            "Epoch 1353/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2339 - accuracy: 0.9236 - val_loss: 0.1901 - val_accuracy: 0.9455\n",
            "Epoch 1354/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2368 - accuracy: 0.9244 - val_loss: 0.1929 - val_accuracy: 0.9440\n",
            "Epoch 1355/6000\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2440 - accuracy: 0.9225 - val_loss: 0.1955 - val_accuracy: 0.9450\n",
            "Epoch 1356/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2414 - accuracy: 0.9216 - val_loss: 0.1916 - val_accuracy: 0.9440\n",
            "Epoch 1357/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2468 - accuracy: 0.9236 - val_loss: 0.1932 - val_accuracy: 0.9430\n",
            "Epoch 1358/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2394 - accuracy: 0.9243 - val_loss: 0.1922 - val_accuracy: 0.9430\n",
            "Epoch 1359/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2528 - accuracy: 0.9206 - val_loss: 0.1913 - val_accuracy: 0.9455\n",
            "Epoch 1360/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2382 - accuracy: 0.9233 - val_loss: 0.1981 - val_accuracy: 0.9435\n",
            "Epoch 1361/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2397 - accuracy: 0.9222 - val_loss: 0.1962 - val_accuracy: 0.9445\n",
            "Epoch 1362/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2473 - accuracy: 0.9229 - val_loss: 0.1953 - val_accuracy: 0.9440\n",
            "Epoch 1363/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2339 - accuracy: 0.9252 - val_loss: 0.1908 - val_accuracy: 0.9450\n",
            "Epoch 1364/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2362 - accuracy: 0.9240 - val_loss: 0.1950 - val_accuracy: 0.9435\n",
            "Epoch 1365/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2494 - accuracy: 0.9250 - val_loss: 0.1929 - val_accuracy: 0.9430\n",
            "Epoch 1366/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2368 - accuracy: 0.9239 - val_loss: 0.1936 - val_accuracy: 0.9430\n",
            "Epoch 1367/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2466 - accuracy: 0.9231 - val_loss: 0.1940 - val_accuracy: 0.9435\n",
            "Epoch 1368/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2471 - accuracy: 0.9246 - val_loss: 0.1991 - val_accuracy: 0.9425\n",
            "Epoch 1369/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2489 - accuracy: 0.9210 - val_loss: 0.1954 - val_accuracy: 0.9440\n",
            "Epoch 1370/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2389 - accuracy: 0.9211 - val_loss: 0.1948 - val_accuracy: 0.9450\n",
            "Epoch 1371/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2609 - accuracy: 0.9239 - val_loss: 0.1931 - val_accuracy: 0.9425\n",
            "Epoch 1372/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2408 - accuracy: 0.9254 - val_loss: 0.1947 - val_accuracy: 0.9440\n",
            "Epoch 1373/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2423 - accuracy: 0.9212 - val_loss: 0.1948 - val_accuracy: 0.9445\n",
            "Epoch 1374/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2366 - accuracy: 0.9240 - val_loss: 0.1893 - val_accuracy: 0.9445\n",
            "Epoch 1375/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2359 - accuracy: 0.9229 - val_loss: 0.1928 - val_accuracy: 0.9445\n",
            "Epoch 1376/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2358 - accuracy: 0.9250 - val_loss: 0.1921 - val_accuracy: 0.9440\n",
            "Epoch 1377/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2400 - accuracy: 0.9251 - val_loss: 0.1889 - val_accuracy: 0.9430\n",
            "Epoch 1378/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2359 - accuracy: 0.9234 - val_loss: 0.1894 - val_accuracy: 0.9440\n",
            "Epoch 1379/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2359 - accuracy: 0.9240 - val_loss: 0.1937 - val_accuracy: 0.9445\n",
            "Epoch 1380/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2406 - accuracy: 0.9255 - val_loss: 0.1925 - val_accuracy: 0.9435\n",
            "Epoch 1381/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2397 - accuracy: 0.9211 - val_loss: 0.1926 - val_accuracy: 0.9440\n",
            "Epoch 1382/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2398 - accuracy: 0.9225 - val_loss: 0.1950 - val_accuracy: 0.9430\n",
            "Epoch 1383/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2359 - accuracy: 0.9243 - val_loss: 0.1956 - val_accuracy: 0.9450\n",
            "Epoch 1384/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2326 - accuracy: 0.9264 - val_loss: 0.1930 - val_accuracy: 0.9440\n",
            "Epoch 1385/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2371 - accuracy: 0.9260 - val_loss: 0.1930 - val_accuracy: 0.9420\n",
            "Epoch 1386/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2397 - accuracy: 0.9237 - val_loss: 0.1913 - val_accuracy: 0.9450\n",
            "Epoch 1387/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2457 - accuracy: 0.9240 - val_loss: 0.1913 - val_accuracy: 0.9435\n",
            "Epoch 1388/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2348 - accuracy: 0.9234 - val_loss: 0.1925 - val_accuracy: 0.9440\n",
            "Epoch 1389/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2450 - accuracy: 0.9237 - val_loss: 0.1899 - val_accuracy: 0.9435\n",
            "Epoch 1390/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2351 - accuracy: 0.9234 - val_loss: 0.1903 - val_accuracy: 0.9440\n",
            "Epoch 1391/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2335 - accuracy: 0.9227 - val_loss: 0.1964 - val_accuracy: 0.9430\n",
            "Epoch 1392/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2444 - accuracy: 0.9252 - val_loss: 0.1934 - val_accuracy: 0.9435\n",
            "Epoch 1393/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2424 - accuracy: 0.9206 - val_loss: 0.1939 - val_accuracy: 0.9435\n",
            "Epoch 1394/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2305 - accuracy: 0.9251 - val_loss: 0.1917 - val_accuracy: 0.9435\n",
            "Epoch 1395/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2437 - accuracy: 0.9208 - val_loss: 0.1910 - val_accuracy: 0.9435\n",
            "Epoch 1396/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2428 - accuracy: 0.9230 - val_loss: 0.1950 - val_accuracy: 0.9435\n",
            "Epoch 1397/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2356 - accuracy: 0.9231 - val_loss: 0.1916 - val_accuracy: 0.9450\n",
            "Epoch 1398/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2291 - accuracy: 0.9269 - val_loss: 0.1975 - val_accuracy: 0.9430\n",
            "Epoch 1399/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2368 - accuracy: 0.9245 - val_loss: 0.1979 - val_accuracy: 0.9430\n",
            "Epoch 1400/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2348 - accuracy: 0.9260 - val_loss: 0.1853 - val_accuracy: 0.9455\n",
            "Epoch 1401/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2336 - accuracy: 0.9219 - val_loss: 0.1905 - val_accuracy: 0.9440\n",
            "Epoch 1402/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2395 - accuracy: 0.9236 - val_loss: 0.1944 - val_accuracy: 0.9425\n",
            "Epoch 1403/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2432 - accuracy: 0.9244 - val_loss: 0.1948 - val_accuracy: 0.9445\n",
            "Epoch 1404/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2439 - accuracy: 0.9201 - val_loss: 0.1888 - val_accuracy: 0.9450\n",
            "Epoch 1405/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2426 - accuracy: 0.9211 - val_loss: 0.1930 - val_accuracy: 0.9425\n",
            "Epoch 1406/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2342 - accuracy: 0.9260 - val_loss: 0.1892 - val_accuracy: 0.9435\n",
            "Epoch 1407/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2344 - accuracy: 0.9256 - val_loss: 0.1918 - val_accuracy: 0.9440\n",
            "Epoch 1408/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2430 - accuracy: 0.9250 - val_loss: 0.1916 - val_accuracy: 0.9440\n",
            "Epoch 1409/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2450 - accuracy: 0.9214 - val_loss: 0.1910 - val_accuracy: 0.9445\n",
            "Epoch 1410/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2384 - accuracy: 0.9212 - val_loss: 0.1953 - val_accuracy: 0.9435\n",
            "Epoch 1411/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2398 - accuracy: 0.9255 - val_loss: 0.1921 - val_accuracy: 0.9445\n",
            "Epoch 1412/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2391 - accuracy: 0.9261 - val_loss: 0.1961 - val_accuracy: 0.9425\n",
            "Epoch 1413/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2366 - accuracy: 0.9233 - val_loss: 0.1929 - val_accuracy: 0.9425\n",
            "Epoch 1414/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2382 - accuracy: 0.9220 - val_loss: 0.1921 - val_accuracy: 0.9420\n",
            "Epoch 1415/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2389 - accuracy: 0.9229 - val_loss: 0.1955 - val_accuracy: 0.9415\n",
            "Epoch 1416/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2503 - accuracy: 0.9226 - val_loss: 0.1988 - val_accuracy: 0.9440\n",
            "Epoch 1417/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2478 - accuracy: 0.9218 - val_loss: 0.1980 - val_accuracy: 0.9430\n",
            "Epoch 1418/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2402 - accuracy: 0.9218 - val_loss: 0.1926 - val_accuracy: 0.9440\n",
            "Epoch 1419/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2381 - accuracy: 0.9227 - val_loss: 0.1949 - val_accuracy: 0.9440\n",
            "Epoch 1420/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2352 - accuracy: 0.9249 - val_loss: 0.1929 - val_accuracy: 0.9435\n",
            "Epoch 1421/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2395 - accuracy: 0.9220 - val_loss: 0.1985 - val_accuracy: 0.9445\n",
            "Epoch 1422/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2352 - accuracy: 0.9250 - val_loss: 0.1914 - val_accuracy: 0.9450\n",
            "Epoch 1423/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2321 - accuracy: 0.9237 - val_loss: 0.1946 - val_accuracy: 0.9440\n",
            "Epoch 1424/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2352 - accuracy: 0.9275 - val_loss: 0.1923 - val_accuracy: 0.9445\n",
            "Epoch 1425/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2416 - accuracy: 0.9225 - val_loss: 0.1952 - val_accuracy: 0.9425\n",
            "Epoch 1426/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2328 - accuracy: 0.9260 - val_loss: 0.1911 - val_accuracy: 0.9455\n",
            "Epoch 1427/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2364 - accuracy: 0.9268 - val_loss: 0.1950 - val_accuracy: 0.9440\n",
            "Epoch 1428/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2430 - accuracy: 0.9226 - val_loss: 0.1921 - val_accuracy: 0.9435\n",
            "Epoch 1429/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2437 - accuracy: 0.9224 - val_loss: 0.1916 - val_accuracy: 0.9435\n",
            "Epoch 1430/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2388 - accuracy: 0.9219 - val_loss: 0.1899 - val_accuracy: 0.9445\n",
            "Epoch 1431/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2371 - accuracy: 0.9221 - val_loss: 0.1946 - val_accuracy: 0.9455\n",
            "Epoch 1432/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2370 - accuracy: 0.9243 - val_loss: 0.1962 - val_accuracy: 0.9420\n",
            "Epoch 1433/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2412 - accuracy: 0.9227 - val_loss: 0.1937 - val_accuracy: 0.9455\n",
            "Epoch 1434/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2377 - accuracy: 0.9244 - val_loss: 0.1896 - val_accuracy: 0.9445\n",
            "Epoch 1435/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2352 - accuracy: 0.9258 - val_loss: 0.1912 - val_accuracy: 0.9435\n",
            "Epoch 1436/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2422 - accuracy: 0.9246 - val_loss: 0.1907 - val_accuracy: 0.9445\n",
            "Epoch 1437/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2325 - accuracy: 0.9259 - val_loss: 0.1908 - val_accuracy: 0.9430\n",
            "Epoch 1438/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2433 - accuracy: 0.9227 - val_loss: 0.1917 - val_accuracy: 0.9430\n",
            "Epoch 1439/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2446 - accuracy: 0.9211 - val_loss: 0.1924 - val_accuracy: 0.9450\n",
            "Epoch 1440/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2460 - accuracy: 0.9251 - val_loss: 0.1937 - val_accuracy: 0.9450\n",
            "Epoch 1441/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2385 - accuracy: 0.9247 - val_loss: 0.1918 - val_accuracy: 0.9440\n",
            "Epoch 1442/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2298 - accuracy: 0.9259 - val_loss: 0.1936 - val_accuracy: 0.9430\n",
            "Epoch 1443/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2385 - accuracy: 0.9241 - val_loss: 0.1910 - val_accuracy: 0.9430\n",
            "Epoch 1444/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2379 - accuracy: 0.9214 - val_loss: 0.1954 - val_accuracy: 0.9455\n",
            "Epoch 1445/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2403 - accuracy: 0.9218 - val_loss: 0.1948 - val_accuracy: 0.9435\n",
            "Epoch 1446/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2431 - accuracy: 0.9234 - val_loss: 0.1915 - val_accuracy: 0.9445\n",
            "Epoch 1447/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2361 - accuracy: 0.9219 - val_loss: 0.1898 - val_accuracy: 0.9440\n",
            "Epoch 1448/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2537 - accuracy: 0.9200 - val_loss: 0.1929 - val_accuracy: 0.9425\n",
            "Epoch 1449/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2434 - accuracy: 0.9237 - val_loss: 0.1980 - val_accuracy: 0.9435\n",
            "Epoch 1450/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2424 - accuracy: 0.9241 - val_loss: 0.1888 - val_accuracy: 0.9430\n",
            "Epoch 1451/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2359 - accuracy: 0.9221 - val_loss: 0.1970 - val_accuracy: 0.9430\n",
            "Epoch 1452/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2361 - accuracy: 0.9256 - val_loss: 0.1931 - val_accuracy: 0.9435\n",
            "Epoch 1453/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2395 - accuracy: 0.9234 - val_loss: 0.1918 - val_accuracy: 0.9440\n",
            "Epoch 1454/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2367 - accuracy: 0.9237 - val_loss: 0.1991 - val_accuracy: 0.9435\n",
            "Epoch 1455/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2466 - accuracy: 0.9206 - val_loss: 0.1917 - val_accuracy: 0.9435\n",
            "Epoch 1456/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2370 - accuracy: 0.9255 - val_loss: 0.1931 - val_accuracy: 0.9440\n",
            "Epoch 1457/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2392 - accuracy: 0.9256 - val_loss: 0.1928 - val_accuracy: 0.9460\n",
            "Epoch 1458/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2449 - accuracy: 0.9225 - val_loss: 0.1853 - val_accuracy: 0.9465\n",
            "Epoch 1459/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2372 - accuracy: 0.9265 - val_loss: 0.1931 - val_accuracy: 0.9420\n",
            "Epoch 1460/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2250 - accuracy: 0.9271 - val_loss: 0.1984 - val_accuracy: 0.9430\n",
            "Epoch 1461/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2475 - accuracy: 0.9224 - val_loss: 0.1953 - val_accuracy: 0.9440\n",
            "Epoch 1462/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2414 - accuracy: 0.9212 - val_loss: 0.1936 - val_accuracy: 0.9435\n",
            "Epoch 1463/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2367 - accuracy: 0.9229 - val_loss: 0.1911 - val_accuracy: 0.9445\n",
            "Epoch 1464/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2354 - accuracy: 0.9258 - val_loss: 0.1896 - val_accuracy: 0.9440\n",
            "Epoch 1465/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2380 - accuracy: 0.9241 - val_loss: 0.1973 - val_accuracy: 0.9430\n",
            "Epoch 1466/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2368 - accuracy: 0.9227 - val_loss: 0.1936 - val_accuracy: 0.9425\n",
            "Epoch 1467/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2374 - accuracy: 0.9245 - val_loss: 0.1965 - val_accuracy: 0.9435\n",
            "Epoch 1468/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2357 - accuracy: 0.9249 - val_loss: 0.1981 - val_accuracy: 0.9435\n",
            "Epoch 1469/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2337 - accuracy: 0.9260 - val_loss: 0.1953 - val_accuracy: 0.9440\n",
            "Epoch 1470/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2359 - accuracy: 0.9226 - val_loss: 0.1919 - val_accuracy: 0.9440\n",
            "Epoch 1471/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2394 - accuracy: 0.9236 - val_loss: 0.1887 - val_accuracy: 0.9455\n",
            "Epoch 1472/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2471 - accuracy: 0.9215 - val_loss: 0.1935 - val_accuracy: 0.9435\n",
            "Epoch 1473/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2393 - accuracy: 0.9226 - val_loss: 0.2000 - val_accuracy: 0.9440\n",
            "Epoch 1474/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2446 - accuracy: 0.9233 - val_loss: 0.1900 - val_accuracy: 0.9455\n",
            "Epoch 1475/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2331 - accuracy: 0.9252 - val_loss: 0.1929 - val_accuracy: 0.9445\n",
            "Epoch 1476/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2393 - accuracy: 0.9260 - val_loss: 0.1909 - val_accuracy: 0.9435\n",
            "Epoch 1477/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2277 - accuracy: 0.9266 - val_loss: 0.1908 - val_accuracy: 0.9460\n",
            "Epoch 1478/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2342 - accuracy: 0.9255 - val_loss: 0.1929 - val_accuracy: 0.9445\n",
            "Epoch 1479/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2369 - accuracy: 0.9230 - val_loss: 0.1935 - val_accuracy: 0.9440\n",
            "Epoch 1480/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2403 - accuracy: 0.9224 - val_loss: 0.1940 - val_accuracy: 0.9440\n",
            "Epoch 1481/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2405 - accuracy: 0.9221 - val_loss: 0.1927 - val_accuracy: 0.9450\n",
            "Epoch 1482/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2403 - accuracy: 0.9221 - val_loss: 0.1961 - val_accuracy: 0.9440\n",
            "Epoch 1483/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2414 - accuracy: 0.9224 - val_loss: 0.1987 - val_accuracy: 0.9440\n",
            "Epoch 1484/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2399 - accuracy: 0.9239 - val_loss: 0.1888 - val_accuracy: 0.9430\n",
            "Epoch 1485/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2435 - accuracy: 0.9201 - val_loss: 0.1919 - val_accuracy: 0.9440\n",
            "Epoch 1486/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2368 - accuracy: 0.9226 - val_loss: 0.1949 - val_accuracy: 0.9435\n",
            "Epoch 1487/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2393 - accuracy: 0.9221 - val_loss: 0.1937 - val_accuracy: 0.9445\n",
            "Epoch 1488/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2353 - accuracy: 0.9244 - val_loss: 0.1942 - val_accuracy: 0.9430\n",
            "Epoch 1489/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2355 - accuracy: 0.9260 - val_loss: 0.1917 - val_accuracy: 0.9450\n",
            "Epoch 1490/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2408 - accuracy: 0.9237 - val_loss: 0.1910 - val_accuracy: 0.9445\n",
            "Epoch 1491/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2443 - accuracy: 0.9237 - val_loss: 0.1888 - val_accuracy: 0.9445\n",
            "Epoch 1492/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2410 - accuracy: 0.9221 - val_loss: 0.1903 - val_accuracy: 0.9445\n",
            "Epoch 1493/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2243 - accuracy: 0.9276 - val_loss: 0.1906 - val_accuracy: 0.9440\n",
            "Epoch 1494/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2387 - accuracy: 0.9241 - val_loss: 0.1981 - val_accuracy: 0.9420\n",
            "Epoch 1495/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2321 - accuracy: 0.9265 - val_loss: 0.1910 - val_accuracy: 0.9435\n",
            "Epoch 1496/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2460 - accuracy: 0.9264 - val_loss: 0.1940 - val_accuracy: 0.9445\n",
            "Epoch 1497/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2421 - accuracy: 0.9229 - val_loss: 0.1915 - val_accuracy: 0.9435\n",
            "Epoch 1498/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2395 - accuracy: 0.9215 - val_loss: 0.1925 - val_accuracy: 0.9430\n",
            "Epoch 1499/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2313 - accuracy: 0.9259 - val_loss: 0.1882 - val_accuracy: 0.9445\n",
            "Epoch 1500/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2524 - accuracy: 0.9244 - val_loss: 0.1967 - val_accuracy: 0.9430\n",
            "Epoch 1501/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2275 - accuracy: 0.9285 - val_loss: 0.1964 - val_accuracy: 0.9430\n",
            "Epoch 1502/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2434 - accuracy: 0.9243 - val_loss: 0.1918 - val_accuracy: 0.9445\n",
            "Epoch 1503/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2330 - accuracy: 0.9218 - val_loss: 0.1919 - val_accuracy: 0.9455\n",
            "Epoch 1504/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2352 - accuracy: 0.9249 - val_loss: 0.1949 - val_accuracy: 0.9420\n",
            "Epoch 1505/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2385 - accuracy: 0.9256 - val_loss: 0.1929 - val_accuracy: 0.9455\n",
            "Epoch 1506/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2371 - accuracy: 0.9252 - val_loss: 0.1923 - val_accuracy: 0.9435\n",
            "Epoch 1507/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2439 - accuracy: 0.9252 - val_loss: 0.1970 - val_accuracy: 0.9435\n",
            "Epoch 1508/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2466 - accuracy: 0.9262 - val_loss: 0.1917 - val_accuracy: 0.9445\n",
            "Epoch 1509/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2391 - accuracy: 0.9221 - val_loss: 0.1902 - val_accuracy: 0.9455\n",
            "Epoch 1510/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2465 - accuracy: 0.9240 - val_loss: 0.1931 - val_accuracy: 0.9440\n",
            "Epoch 1511/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2448 - accuracy: 0.9230 - val_loss: 0.1950 - val_accuracy: 0.9430\n",
            "Epoch 1512/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2318 - accuracy: 0.9205 - val_loss: 0.1947 - val_accuracy: 0.9450\n",
            "Epoch 1513/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2473 - accuracy: 0.9218 - val_loss: 0.1942 - val_accuracy: 0.9425\n",
            "Epoch 1514/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2354 - accuracy: 0.9247 - val_loss: 0.1908 - val_accuracy: 0.9430\n",
            "Epoch 1515/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2353 - accuracy: 0.9277 - val_loss: 0.1940 - val_accuracy: 0.9450\n",
            "Epoch 1516/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2343 - accuracy: 0.9237 - val_loss: 0.1915 - val_accuracy: 0.9450\n",
            "Epoch 1517/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2370 - accuracy: 0.9237 - val_loss: 0.1960 - val_accuracy: 0.9440\n",
            "Epoch 1518/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2348 - accuracy: 0.9268 - val_loss: 0.1938 - val_accuracy: 0.9425\n",
            "Epoch 1519/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2330 - accuracy: 0.9227 - val_loss: 0.1928 - val_accuracy: 0.9445\n",
            "Epoch 1520/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2353 - accuracy: 0.9249 - val_loss: 0.1946 - val_accuracy: 0.9440\n",
            "Epoch 1521/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2342 - accuracy: 0.9204 - val_loss: 0.1943 - val_accuracy: 0.9435\n",
            "Epoch 1522/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2373 - accuracy: 0.9229 - val_loss: 0.1915 - val_accuracy: 0.9445\n",
            "Epoch 1523/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2441 - accuracy: 0.9231 - val_loss: 0.1918 - val_accuracy: 0.9440\n",
            "Epoch 1524/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2393 - accuracy: 0.9261 - val_loss: 0.1916 - val_accuracy: 0.9430\n",
            "Epoch 1525/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2359 - accuracy: 0.9237 - val_loss: 0.1962 - val_accuracy: 0.9435\n",
            "Epoch 1526/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2435 - accuracy: 0.9244 - val_loss: 0.1908 - val_accuracy: 0.9445\n",
            "Epoch 1527/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2333 - accuracy: 0.9251 - val_loss: 0.1919 - val_accuracy: 0.9425\n",
            "Epoch 1528/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2332 - accuracy: 0.9235 - val_loss: 0.1984 - val_accuracy: 0.9440\n",
            "Epoch 1529/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2459 - accuracy: 0.9193 - val_loss: 0.1911 - val_accuracy: 0.9440\n",
            "Epoch 1530/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2416 - accuracy: 0.9216 - val_loss: 0.1969 - val_accuracy: 0.9450\n",
            "Epoch 1531/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2425 - accuracy: 0.9226 - val_loss: 0.1920 - val_accuracy: 0.9425\n",
            "Epoch 1532/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2393 - accuracy: 0.9258 - val_loss: 0.1931 - val_accuracy: 0.9430\n",
            "Epoch 1533/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2380 - accuracy: 0.9236 - val_loss: 0.1962 - val_accuracy: 0.9440\n",
            "Epoch 1534/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2322 - accuracy: 0.9259 - val_loss: 0.1945 - val_accuracy: 0.9440\n",
            "Epoch 1535/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2337 - accuracy: 0.9245 - val_loss: 0.1937 - val_accuracy: 0.9435\n",
            "Epoch 1536/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2314 - accuracy: 0.9227 - val_loss: 0.1949 - val_accuracy: 0.9420\n",
            "Epoch 1537/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2340 - accuracy: 0.9247 - val_loss: 0.1933 - val_accuracy: 0.9430\n",
            "Epoch 1538/6000\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2433 - accuracy: 0.9201 - val_loss: 0.1910 - val_accuracy: 0.9430\n",
            "Epoch 1539/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2446 - accuracy: 0.9227 - val_loss: 0.1917 - val_accuracy: 0.9445\n",
            "Epoch 1540/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2329 - accuracy: 0.9240 - val_loss: 0.1915 - val_accuracy: 0.9440\n",
            "Epoch 1541/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2405 - accuracy: 0.9240 - val_loss: 0.1865 - val_accuracy: 0.9445\n",
            "Epoch 1542/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2474 - accuracy: 0.9215 - val_loss: 0.1906 - val_accuracy: 0.9430\n",
            "Epoch 1543/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2363 - accuracy: 0.9243 - val_loss: 0.1971 - val_accuracy: 0.9445\n",
            "Epoch 1544/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2286 - accuracy: 0.9234 - val_loss: 0.1922 - val_accuracy: 0.9430\n",
            "Epoch 1545/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2384 - accuracy: 0.9227 - val_loss: 0.1922 - val_accuracy: 0.9430\n",
            "Epoch 1546/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2495 - accuracy: 0.9222 - val_loss: 0.1909 - val_accuracy: 0.9430\n",
            "Epoch 1547/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2363 - accuracy: 0.9235 - val_loss: 0.1887 - val_accuracy: 0.9435\n",
            "Epoch 1548/6000\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2396 - accuracy: 0.9230 - val_loss: 0.1885 - val_accuracy: 0.9450\n",
            "Epoch 1549/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2374 - accuracy: 0.9231 - val_loss: 0.1948 - val_accuracy: 0.9445\n",
            "Epoch 1550/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2345 - accuracy: 0.9244 - val_loss: 0.1916 - val_accuracy: 0.9435\n",
            "Epoch 1551/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2498 - accuracy: 0.9237 - val_loss: 0.1928 - val_accuracy: 0.9435\n",
            "Epoch 1552/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2364 - accuracy: 0.9235 - val_loss: 0.1902 - val_accuracy: 0.9440\n",
            "Epoch 1553/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2387 - accuracy: 0.9246 - val_loss: 0.1926 - val_accuracy: 0.9445\n",
            "Epoch 1554/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2364 - accuracy: 0.9255 - val_loss: 0.1917 - val_accuracy: 0.9450\n",
            "Epoch 1555/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2332 - accuracy: 0.9258 - val_loss: 0.1958 - val_accuracy: 0.9420\n",
            "Epoch 1556/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2296 - accuracy: 0.9243 - val_loss: 0.1963 - val_accuracy: 0.9445\n",
            "Epoch 1557/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2489 - accuracy: 0.9212 - val_loss: 0.1930 - val_accuracy: 0.9440\n",
            "Epoch 1558/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2469 - accuracy: 0.9236 - val_loss: 0.1912 - val_accuracy: 0.9450\n",
            "Epoch 1559/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2347 - accuracy: 0.9231 - val_loss: 0.1906 - val_accuracy: 0.9455\n",
            "Epoch 1560/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2371 - accuracy: 0.9262 - val_loss: 0.1945 - val_accuracy: 0.9440\n",
            "Epoch 1561/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2321 - accuracy: 0.9245 - val_loss: 0.1980 - val_accuracy: 0.9445\n",
            "Epoch 1562/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2350 - accuracy: 0.9259 - val_loss: 0.1921 - val_accuracy: 0.9440\n",
            "Epoch 1563/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2370 - accuracy: 0.9233 - val_loss: 0.1915 - val_accuracy: 0.9440\n",
            "Epoch 1564/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2389 - accuracy: 0.9224 - val_loss: 0.1923 - val_accuracy: 0.9455\n",
            "Epoch 1565/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2320 - accuracy: 0.9255 - val_loss: 0.1949 - val_accuracy: 0.9420\n",
            "Epoch 1566/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2498 - accuracy: 0.9225 - val_loss: 0.1943 - val_accuracy: 0.9445\n",
            "Epoch 1567/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2399 - accuracy: 0.9226 - val_loss: 0.1872 - val_accuracy: 0.9440\n",
            "Epoch 1568/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2394 - accuracy: 0.9216 - val_loss: 0.1924 - val_accuracy: 0.9430\n",
            "Epoch 1569/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2486 - accuracy: 0.9252 - val_loss: 0.1975 - val_accuracy: 0.9445\n",
            "Epoch 1570/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2420 - accuracy: 0.9234 - val_loss: 0.1920 - val_accuracy: 0.9435\n",
            "Epoch 1571/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2354 - accuracy: 0.9247 - val_loss: 0.1914 - val_accuracy: 0.9445\n",
            "Epoch 1572/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2484 - accuracy: 0.9237 - val_loss: 0.1908 - val_accuracy: 0.9445\n",
            "Epoch 1573/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2466 - accuracy: 0.9226 - val_loss: 0.1929 - val_accuracy: 0.9445\n",
            "Epoch 1574/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2358 - accuracy: 0.9199 - val_loss: 0.1963 - val_accuracy: 0.9450\n",
            "Epoch 1575/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2366 - accuracy: 0.9271 - val_loss: 0.1990 - val_accuracy: 0.9430\n",
            "Epoch 1576/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2357 - accuracy: 0.9214 - val_loss: 0.1945 - val_accuracy: 0.9425\n",
            "Epoch 1577/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2414 - accuracy: 0.9225 - val_loss: 0.1918 - val_accuracy: 0.9450\n",
            "Epoch 1578/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2392 - accuracy: 0.9235 - val_loss: 0.1921 - val_accuracy: 0.9465\n",
            "Epoch 1579/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2356 - accuracy: 0.9196 - val_loss: 0.1931 - val_accuracy: 0.9440\n",
            "Epoch 1580/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2368 - accuracy: 0.9227 - val_loss: 0.1956 - val_accuracy: 0.9450\n",
            "Epoch 1581/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2396 - accuracy: 0.9256 - val_loss: 0.1920 - val_accuracy: 0.9450\n",
            "Epoch 1582/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2273 - accuracy: 0.9251 - val_loss: 0.1928 - val_accuracy: 0.9450\n",
            "Epoch 1583/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2377 - accuracy: 0.9215 - val_loss: 0.1947 - val_accuracy: 0.9445\n",
            "Epoch 1584/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2320 - accuracy: 0.9254 - val_loss: 0.2005 - val_accuracy: 0.9450\n",
            "Epoch 1585/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2330 - accuracy: 0.9231 - val_loss: 0.1957 - val_accuracy: 0.9440\n",
            "Epoch 1586/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2412 - accuracy: 0.9204 - val_loss: 0.1928 - val_accuracy: 0.9435\n",
            "Epoch 1587/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2468 - accuracy: 0.9244 - val_loss: 0.1924 - val_accuracy: 0.9430\n",
            "Epoch 1588/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2283 - accuracy: 0.9247 - val_loss: 0.1915 - val_accuracy: 0.9440\n",
            "Epoch 1589/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2444 - accuracy: 0.9243 - val_loss: 0.1870 - val_accuracy: 0.9460\n",
            "Epoch 1590/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2308 - accuracy: 0.9255 - val_loss: 0.1956 - val_accuracy: 0.9435\n",
            "Epoch 1591/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2349 - accuracy: 0.9235 - val_loss: 0.1949 - val_accuracy: 0.9440\n",
            "Epoch 1592/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2270 - accuracy: 0.9285 - val_loss: 0.1934 - val_accuracy: 0.9450\n",
            "Epoch 1593/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2385 - accuracy: 0.9230 - val_loss: 0.1902 - val_accuracy: 0.9440\n",
            "Epoch 1594/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2433 - accuracy: 0.9252 - val_loss: 0.1926 - val_accuracy: 0.9450\n",
            "Epoch 1595/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2378 - accuracy: 0.9264 - val_loss: 0.1927 - val_accuracy: 0.9430\n",
            "Epoch 1596/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2351 - accuracy: 0.9244 - val_loss: 0.1914 - val_accuracy: 0.9445\n",
            "Epoch 1597/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2417 - accuracy: 0.9260 - val_loss: 0.1912 - val_accuracy: 0.9430\n",
            "Epoch 1598/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2391 - accuracy: 0.9239 - val_loss: 0.1926 - val_accuracy: 0.9465\n",
            "Epoch 1599/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2350 - accuracy: 0.9244 - val_loss: 0.1961 - val_accuracy: 0.9445\n",
            "Epoch 1600/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2383 - accuracy: 0.9241 - val_loss: 0.1944 - val_accuracy: 0.9455\n",
            "Epoch 1601/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2359 - accuracy: 0.9247 - val_loss: 0.1930 - val_accuracy: 0.9450\n",
            "Epoch 1602/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2373 - accuracy: 0.9222 - val_loss: 0.1940 - val_accuracy: 0.9435\n",
            "Epoch 1603/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2510 - accuracy: 0.9212 - val_loss: 0.1924 - val_accuracy: 0.9445\n",
            "Epoch 1604/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2451 - accuracy: 0.9227 - val_loss: 0.1936 - val_accuracy: 0.9440\n",
            "Epoch 1605/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2264 - accuracy: 0.9279 - val_loss: 0.1904 - val_accuracy: 0.9435\n",
            "Epoch 1606/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2261 - accuracy: 0.9264 - val_loss: 0.1906 - val_accuracy: 0.9435\n",
            "Epoch 1607/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2399 - accuracy: 0.9240 - val_loss: 0.1921 - val_accuracy: 0.9430\n",
            "Epoch 1608/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2633 - accuracy: 0.9236 - val_loss: 0.1908 - val_accuracy: 0.9415\n",
            "Epoch 1609/6000\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2323 - accuracy: 0.9227 - val_loss: 0.1928 - val_accuracy: 0.9430\n",
            "Epoch 1610/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2385 - accuracy: 0.9237 - val_loss: 0.1925 - val_accuracy: 0.9445\n",
            "Epoch 1611/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2431 - accuracy: 0.9237 - val_loss: 0.1939 - val_accuracy: 0.9425\n",
            "Epoch 1612/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2374 - accuracy: 0.9249 - val_loss: 0.1953 - val_accuracy: 0.9440\n",
            "Epoch 1613/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2429 - accuracy: 0.9215 - val_loss: 0.1950 - val_accuracy: 0.9435\n",
            "Epoch 1614/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2305 - accuracy: 0.9230 - val_loss: 0.2014 - val_accuracy: 0.9420\n",
            "Epoch 1615/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2388 - accuracy: 0.9229 - val_loss: 0.1905 - val_accuracy: 0.9430\n",
            "Epoch 1616/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2323 - accuracy: 0.9255 - val_loss: 0.1922 - val_accuracy: 0.9445\n",
            "Epoch 1617/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2393 - accuracy: 0.9240 - val_loss: 0.1905 - val_accuracy: 0.9450\n",
            "Epoch 1618/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2358 - accuracy: 0.9266 - val_loss: 0.1930 - val_accuracy: 0.9450\n",
            "Epoch 1619/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2308 - accuracy: 0.9254 - val_loss: 0.1944 - val_accuracy: 0.9450\n",
            "Epoch 1620/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2411 - accuracy: 0.9251 - val_loss: 0.1935 - val_accuracy: 0.9445\n",
            "Epoch 1621/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2379 - accuracy: 0.9235 - val_loss: 0.1918 - val_accuracy: 0.9435\n",
            "Epoch 1622/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2352 - accuracy: 0.9226 - val_loss: 0.1958 - val_accuracy: 0.9435\n",
            "Epoch 1623/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2520 - accuracy: 0.9229 - val_loss: 0.1904 - val_accuracy: 0.9445\n",
            "Epoch 1624/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2379 - accuracy: 0.9256 - val_loss: 0.1952 - val_accuracy: 0.9430\n",
            "Epoch 1625/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2334 - accuracy: 0.9230 - val_loss: 0.1965 - val_accuracy: 0.9420\n",
            "Epoch 1626/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2376 - accuracy: 0.9243 - val_loss: 0.1945 - val_accuracy: 0.9450\n",
            "Epoch 1627/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2485 - accuracy: 0.9225 - val_loss: 0.1956 - val_accuracy: 0.9460\n",
            "Epoch 1628/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2390 - accuracy: 0.9243 - val_loss: 0.1973 - val_accuracy: 0.9445\n",
            "Epoch 1629/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2321 - accuracy: 0.9249 - val_loss: 0.1936 - val_accuracy: 0.9440\n",
            "Epoch 1630/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2327 - accuracy: 0.9249 - val_loss: 0.1929 - val_accuracy: 0.9430\n",
            "Epoch 1631/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2334 - accuracy: 0.9258 - val_loss: 0.1941 - val_accuracy: 0.9445\n",
            "Epoch 1632/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2380 - accuracy: 0.9222 - val_loss: 0.1922 - val_accuracy: 0.9445\n",
            "Epoch 1633/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2260 - accuracy: 0.9236 - val_loss: 0.1913 - val_accuracy: 0.9430\n",
            "Epoch 1634/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2340 - accuracy: 0.9229 - val_loss: 0.2049 - val_accuracy: 0.9420\n",
            "Epoch 1635/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2373 - accuracy: 0.9255 - val_loss: 0.1944 - val_accuracy: 0.9425\n",
            "Epoch 1636/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2421 - accuracy: 0.9240 - val_loss: 0.1950 - val_accuracy: 0.9440\n",
            "Epoch 1637/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2387 - accuracy: 0.9229 - val_loss: 0.1910 - val_accuracy: 0.9455\n",
            "Epoch 1638/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2415 - accuracy: 0.9221 - val_loss: 0.1921 - val_accuracy: 0.9435\n",
            "Epoch 1639/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2223 - accuracy: 0.9265 - val_loss: 0.1906 - val_accuracy: 0.9435\n",
            "Epoch 1640/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2298 - accuracy: 0.9256 - val_loss: 0.1919 - val_accuracy: 0.9445\n",
            "Epoch 1641/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2333 - accuracy: 0.9250 - val_loss: 0.1907 - val_accuracy: 0.9425\n",
            "Epoch 1642/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2405 - accuracy: 0.9236 - val_loss: 0.1956 - val_accuracy: 0.9440\n",
            "Epoch 1643/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2310 - accuracy: 0.9251 - val_loss: 0.1905 - val_accuracy: 0.9445\n",
            "Epoch 1644/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2372 - accuracy: 0.9226 - val_loss: 0.1972 - val_accuracy: 0.9435\n",
            "Epoch 1645/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2336 - accuracy: 0.9270 - val_loss: 0.1958 - val_accuracy: 0.9445\n",
            "Epoch 1646/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2459 - accuracy: 0.9230 - val_loss: 0.1883 - val_accuracy: 0.9420\n",
            "Epoch 1647/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2390 - accuracy: 0.9256 - val_loss: 0.1934 - val_accuracy: 0.9415\n",
            "Epoch 1648/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2381 - accuracy: 0.9233 - val_loss: 0.1927 - val_accuracy: 0.9445\n",
            "Epoch 1649/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2366 - accuracy: 0.9243 - val_loss: 0.1942 - val_accuracy: 0.9420\n",
            "Epoch 1650/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2279 - accuracy: 0.9277 - val_loss: 0.1897 - val_accuracy: 0.9450\n",
            "Epoch 1651/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2302 - accuracy: 0.9221 - val_loss: 0.1971 - val_accuracy: 0.9440\n",
            "Epoch 1652/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2404 - accuracy: 0.9241 - val_loss: 0.1969 - val_accuracy: 0.9435\n",
            "Epoch 1653/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2356 - accuracy: 0.9235 - val_loss: 0.1929 - val_accuracy: 0.9450\n",
            "Epoch 1654/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2474 - accuracy: 0.9227 - val_loss: 0.1925 - val_accuracy: 0.9440\n",
            "Epoch 1655/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2292 - accuracy: 0.9262 - val_loss: 0.1962 - val_accuracy: 0.9435\n",
            "Epoch 1656/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2346 - accuracy: 0.9260 - val_loss: 0.1899 - val_accuracy: 0.9440\n",
            "Epoch 1657/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2358 - accuracy: 0.9222 - val_loss: 0.1958 - val_accuracy: 0.9445\n",
            "Epoch 1658/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2375 - accuracy: 0.9239 - val_loss: 0.1944 - val_accuracy: 0.9405\n",
            "Epoch 1659/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2351 - accuracy: 0.9236 - val_loss: 0.1982 - val_accuracy: 0.9435\n",
            "Epoch 1660/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2386 - accuracy: 0.9235 - val_loss: 0.1910 - val_accuracy: 0.9435\n",
            "Epoch 1661/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2285 - accuracy: 0.9255 - val_loss: 0.1940 - val_accuracy: 0.9430\n",
            "Epoch 1662/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2337 - accuracy: 0.9212 - val_loss: 0.1947 - val_accuracy: 0.9440\n",
            "Epoch 1663/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2370 - accuracy: 0.9243 - val_loss: 0.1886 - val_accuracy: 0.9445\n",
            "Epoch 1664/6000\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2451 - accuracy: 0.9216 - val_loss: 0.1936 - val_accuracy: 0.9440\n",
            "Epoch 1665/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2527 - accuracy: 0.9214 - val_loss: 0.1893 - val_accuracy: 0.9450\n",
            "Epoch 1666/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2405 - accuracy: 0.9237 - val_loss: 0.1942 - val_accuracy: 0.9445\n",
            "Epoch 1667/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2389 - accuracy: 0.9222 - val_loss: 0.1947 - val_accuracy: 0.9455\n",
            "Epoch 1668/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2363 - accuracy: 0.9258 - val_loss: 0.1929 - val_accuracy: 0.9440\n",
            "Epoch 1669/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2362 - accuracy: 0.9239 - val_loss: 0.1960 - val_accuracy: 0.9450\n",
            "Epoch 1670/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2342 - accuracy: 0.9266 - val_loss: 0.1915 - val_accuracy: 0.9435\n",
            "Epoch 1671/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2330 - accuracy: 0.9225 - val_loss: 0.1930 - val_accuracy: 0.9450\n",
            "Epoch 1672/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2262 - accuracy: 0.9280 - val_loss: 0.1913 - val_accuracy: 0.9455\n",
            "Epoch 1673/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2385 - accuracy: 0.9225 - val_loss: 0.1909 - val_accuracy: 0.9455\n",
            "Epoch 1674/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2318 - accuracy: 0.9237 - val_loss: 0.1958 - val_accuracy: 0.9435\n",
            "Epoch 1675/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2355 - accuracy: 0.9215 - val_loss: 0.1907 - val_accuracy: 0.9445\n",
            "Epoch 1676/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2349 - accuracy: 0.9247 - val_loss: 0.1917 - val_accuracy: 0.9445\n",
            "Epoch 1677/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2330 - accuracy: 0.9246 - val_loss: 0.1916 - val_accuracy: 0.9445\n",
            "Epoch 1678/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2339 - accuracy: 0.9269 - val_loss: 0.1934 - val_accuracy: 0.9425\n",
            "Epoch 1679/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2271 - accuracy: 0.9245 - val_loss: 0.1937 - val_accuracy: 0.9425\n",
            "Epoch 1680/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2371 - accuracy: 0.9240 - val_loss: 0.1919 - val_accuracy: 0.9445\n",
            "Epoch 1681/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2346 - accuracy: 0.9251 - val_loss: 0.1892 - val_accuracy: 0.9445\n",
            "Epoch 1682/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2380 - accuracy: 0.9214 - val_loss: 0.1930 - val_accuracy: 0.9425\n",
            "Epoch 1683/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2382 - accuracy: 0.9241 - val_loss: 0.1998 - val_accuracy: 0.9435\n",
            "Epoch 1684/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2389 - accuracy: 0.9221 - val_loss: 0.1905 - val_accuracy: 0.9420\n",
            "Epoch 1685/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2413 - accuracy: 0.9196 - val_loss: 0.1915 - val_accuracy: 0.9445\n",
            "Epoch 1686/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2387 - accuracy: 0.9251 - val_loss: 0.1920 - val_accuracy: 0.9425\n",
            "Epoch 1687/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2294 - accuracy: 0.9258 - val_loss: 0.1911 - val_accuracy: 0.9445\n",
            "Epoch 1688/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2325 - accuracy: 0.9256 - val_loss: 0.1875 - val_accuracy: 0.9435\n",
            "Epoch 1689/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2325 - accuracy: 0.9255 - val_loss: 0.1910 - val_accuracy: 0.9435\n",
            "Epoch 1690/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2293 - accuracy: 0.9270 - val_loss: 0.1863 - val_accuracy: 0.9450\n",
            "Epoch 1691/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2485 - accuracy: 0.9233 - val_loss: 0.1915 - val_accuracy: 0.9455\n",
            "Epoch 1692/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2471 - accuracy: 0.9256 - val_loss: 0.1958 - val_accuracy: 0.9455\n",
            "Epoch 1693/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2351 - accuracy: 0.9229 - val_loss: 0.1887 - val_accuracy: 0.9440\n",
            "Epoch 1694/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2397 - accuracy: 0.9235 - val_loss: 0.1947 - val_accuracy: 0.9445\n",
            "Epoch 1695/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2363 - accuracy: 0.9226 - val_loss: 0.1934 - val_accuracy: 0.9455\n",
            "Epoch 1696/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2375 - accuracy: 0.9250 - val_loss: 0.1943 - val_accuracy: 0.9440\n",
            "Epoch 1697/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2426 - accuracy: 0.9210 - val_loss: 0.1933 - val_accuracy: 0.9435\n",
            "Epoch 1698/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2506 - accuracy: 0.9204 - val_loss: 0.1938 - val_accuracy: 0.9425\n",
            "Epoch 1699/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2302 - accuracy: 0.9245 - val_loss: 0.1893 - val_accuracy: 0.9425\n",
            "Epoch 1700/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2407 - accuracy: 0.9235 - val_loss: 0.1918 - val_accuracy: 0.9435\n",
            "Epoch 1701/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2287 - accuracy: 0.9275 - val_loss: 0.1936 - val_accuracy: 0.9425\n",
            "Epoch 1702/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2474 - accuracy: 0.9264 - val_loss: 0.1923 - val_accuracy: 0.9435\n",
            "Epoch 1703/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2379 - accuracy: 0.9245 - val_loss: 0.1925 - val_accuracy: 0.9445\n",
            "Epoch 1704/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2392 - accuracy: 0.9229 - val_loss: 0.1977 - val_accuracy: 0.9430\n",
            "Epoch 1705/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2298 - accuracy: 0.9269 - val_loss: 0.1955 - val_accuracy: 0.9440\n",
            "Epoch 1706/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2330 - accuracy: 0.9241 - val_loss: 0.1934 - val_accuracy: 0.9420\n",
            "Epoch 1707/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2333 - accuracy: 0.9251 - val_loss: 0.1890 - val_accuracy: 0.9445\n",
            "Epoch 1708/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2334 - accuracy: 0.9249 - val_loss: 0.1957 - val_accuracy: 0.9425\n",
            "Epoch 1709/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2314 - accuracy: 0.9255 - val_loss: 0.1920 - val_accuracy: 0.9440\n",
            "Epoch 1710/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2345 - accuracy: 0.9256 - val_loss: 0.1988 - val_accuracy: 0.9450\n",
            "Epoch 1711/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2494 - accuracy: 0.9214 - val_loss: 0.1926 - val_accuracy: 0.9440\n",
            "Epoch 1712/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2317 - accuracy: 0.9255 - val_loss: 0.1893 - val_accuracy: 0.9455\n",
            "Epoch 1713/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2239 - accuracy: 0.9262 - val_loss: 0.1909 - val_accuracy: 0.9440\n",
            "Epoch 1714/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2299 - accuracy: 0.9264 - val_loss: 0.1937 - val_accuracy: 0.9430\n",
            "Epoch 1715/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2365 - accuracy: 0.9236 - val_loss: 0.1906 - val_accuracy: 0.9445\n",
            "Epoch 1716/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2367 - accuracy: 0.9270 - val_loss: 0.1880 - val_accuracy: 0.9455\n",
            "Epoch 1717/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2390 - accuracy: 0.9214 - val_loss: 0.1942 - val_accuracy: 0.9440\n",
            "Epoch 1718/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2516 - accuracy: 0.9225 - val_loss: 0.1946 - val_accuracy: 0.9445\n",
            "Epoch 1719/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2361 - accuracy: 0.9221 - val_loss: 0.1896 - val_accuracy: 0.9445\n",
            "Epoch 1720/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2424 - accuracy: 0.9256 - val_loss: 0.1930 - val_accuracy: 0.9440\n",
            "Epoch 1721/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2379 - accuracy: 0.9249 - val_loss: 0.1920 - val_accuracy: 0.9435\n",
            "Epoch 1722/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2398 - accuracy: 0.9254 - val_loss: 0.1933 - val_accuracy: 0.9465\n",
            "Epoch 1723/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2329 - accuracy: 0.9265 - val_loss: 0.1936 - val_accuracy: 0.9425\n",
            "Epoch 1724/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2347 - accuracy: 0.9252 - val_loss: 0.1931 - val_accuracy: 0.9440\n",
            "Epoch 1725/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2422 - accuracy: 0.9240 - val_loss: 0.1952 - val_accuracy: 0.9445\n",
            "Epoch 1726/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2385 - accuracy: 0.9240 - val_loss: 0.1912 - val_accuracy: 0.9445\n",
            "Epoch 1727/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2350 - accuracy: 0.9246 - val_loss: 0.1943 - val_accuracy: 0.9425\n",
            "Epoch 1728/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2352 - accuracy: 0.9260 - val_loss: 0.1895 - val_accuracy: 0.9440\n",
            "Epoch 1729/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2318 - accuracy: 0.9255 - val_loss: 0.1887 - val_accuracy: 0.9450\n",
            "Epoch 1730/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2414 - accuracy: 0.9270 - val_loss: 0.1921 - val_accuracy: 0.9445\n",
            "Epoch 1731/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2359 - accuracy: 0.9245 - val_loss: 0.1961 - val_accuracy: 0.9460\n",
            "Epoch 1732/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2346 - accuracy: 0.9237 - val_loss: 0.1953 - val_accuracy: 0.9445\n",
            "Epoch 1733/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2411 - accuracy: 0.9266 - val_loss: 0.1955 - val_accuracy: 0.9440\n",
            "Epoch 1734/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2380 - accuracy: 0.9229 - val_loss: 0.1933 - val_accuracy: 0.9455\n",
            "Epoch 1735/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2427 - accuracy: 0.9237 - val_loss: 0.1928 - val_accuracy: 0.9435\n",
            "Epoch 1736/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2321 - accuracy: 0.9254 - val_loss: 0.1922 - val_accuracy: 0.9430\n",
            "Epoch 1737/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2388 - accuracy: 0.9240 - val_loss: 0.1936 - val_accuracy: 0.9425\n",
            "Epoch 1738/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2412 - accuracy: 0.9258 - val_loss: 0.1964 - val_accuracy: 0.9455\n",
            "Epoch 1739/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2409 - accuracy: 0.9240 - val_loss: 0.1917 - val_accuracy: 0.9450\n",
            "Epoch 1740/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2327 - accuracy: 0.9268 - val_loss: 0.1923 - val_accuracy: 0.9440\n",
            "Epoch 1741/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2345 - accuracy: 0.9261 - val_loss: 0.1946 - val_accuracy: 0.9440\n",
            "Epoch 1742/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2425 - accuracy: 0.9229 - val_loss: 0.1989 - val_accuracy: 0.9465\n",
            "Epoch 1743/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2359 - accuracy: 0.9251 - val_loss: 0.1964 - val_accuracy: 0.9435\n",
            "Epoch 1744/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2358 - accuracy: 0.9231 - val_loss: 0.1898 - val_accuracy: 0.9450\n",
            "Epoch 1745/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2360 - accuracy: 0.9252 - val_loss: 0.1939 - val_accuracy: 0.9425\n",
            "Epoch 1746/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2317 - accuracy: 0.9255 - val_loss: 0.1893 - val_accuracy: 0.9450\n",
            "Epoch 1747/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2345 - accuracy: 0.9249 - val_loss: 0.1939 - val_accuracy: 0.9445\n",
            "Epoch 1748/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2271 - accuracy: 0.9260 - val_loss: 0.1963 - val_accuracy: 0.9415\n",
            "Epoch 1749/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2439 - accuracy: 0.9227 - val_loss: 0.1920 - val_accuracy: 0.9455\n",
            "Epoch 1750/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2280 - accuracy: 0.9259 - val_loss: 0.1947 - val_accuracy: 0.9455\n",
            "Epoch 1751/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2327 - accuracy: 0.9262 - val_loss: 0.1943 - val_accuracy: 0.9445\n",
            "Epoch 1752/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2346 - accuracy: 0.9234 - val_loss: 0.2010 - val_accuracy: 0.9445\n",
            "Epoch 1753/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2409 - accuracy: 0.9243 - val_loss: 0.1916 - val_accuracy: 0.9435\n",
            "Epoch 1754/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2501 - accuracy: 0.9210 - val_loss: 0.1937 - val_accuracy: 0.9430\n",
            "Epoch 1755/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2438 - accuracy: 0.9239 - val_loss: 0.1916 - val_accuracy: 0.9440\n",
            "Epoch 1756/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2376 - accuracy: 0.9236 - val_loss: 0.1916 - val_accuracy: 0.9445\n",
            "Epoch 1757/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2361 - accuracy: 0.9254 - val_loss: 0.1938 - val_accuracy: 0.9455\n",
            "Epoch 1758/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2421 - accuracy: 0.9240 - val_loss: 0.1929 - val_accuracy: 0.9455\n",
            "Epoch 1759/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2300 - accuracy: 0.9254 - val_loss: 0.1893 - val_accuracy: 0.9450\n",
            "Epoch 1760/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2348 - accuracy: 0.9247 - val_loss: 0.1987 - val_accuracy: 0.9450\n",
            "Epoch 1761/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2343 - accuracy: 0.9259 - val_loss: 0.1938 - val_accuracy: 0.9445\n",
            "Epoch 1762/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2273 - accuracy: 0.9254 - val_loss: 0.1946 - val_accuracy: 0.9460\n",
            "Epoch 1763/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2363 - accuracy: 0.9264 - val_loss: 0.1946 - val_accuracy: 0.9435\n",
            "Epoch 1764/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2438 - accuracy: 0.9269 - val_loss: 0.1966 - val_accuracy: 0.9445\n",
            "Epoch 1765/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2341 - accuracy: 0.9264 - val_loss: 0.1964 - val_accuracy: 0.9450\n",
            "Epoch 1766/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2445 - accuracy: 0.9246 - val_loss: 0.1950 - val_accuracy: 0.9440\n",
            "Epoch 1767/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2390 - accuracy: 0.9229 - val_loss: 0.2001 - val_accuracy: 0.9455\n",
            "Epoch 1768/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2337 - accuracy: 0.9249 - val_loss: 0.1928 - val_accuracy: 0.9440\n",
            "Epoch 1769/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2307 - accuracy: 0.9261 - val_loss: 0.1947 - val_accuracy: 0.9450\n",
            "Epoch 1770/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2369 - accuracy: 0.9233 - val_loss: 0.1958 - val_accuracy: 0.9445\n",
            "Epoch 1771/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2335 - accuracy: 0.9255 - val_loss: 0.2002 - val_accuracy: 0.9435\n",
            "Epoch 1772/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2331 - accuracy: 0.9231 - val_loss: 0.1912 - val_accuracy: 0.9440\n",
            "Epoch 1773/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2489 - accuracy: 0.9245 - val_loss: 0.1929 - val_accuracy: 0.9445\n",
            "Epoch 1774/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2417 - accuracy: 0.9233 - val_loss: 0.1896 - val_accuracy: 0.9445\n",
            "Epoch 1775/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2419 - accuracy: 0.9239 - val_loss: 0.1944 - val_accuracy: 0.9450\n",
            "Epoch 1776/6000\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2344 - accuracy: 0.9221 - val_loss: 0.1903 - val_accuracy: 0.9460\n",
            "Epoch 1777/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2442 - accuracy: 0.9227 - val_loss: 0.1931 - val_accuracy: 0.9440\n",
            "Epoch 1778/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2436 - accuracy: 0.9229 - val_loss: 0.1943 - val_accuracy: 0.9420\n",
            "Epoch 1779/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2429 - accuracy: 0.9200 - val_loss: 0.1955 - val_accuracy: 0.9410\n",
            "Epoch 1780/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2408 - accuracy: 0.9277 - val_loss: 0.1946 - val_accuracy: 0.9435\n",
            "Epoch 1781/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2362 - accuracy: 0.9233 - val_loss: 0.1924 - val_accuracy: 0.9425\n",
            "Epoch 1782/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2349 - accuracy: 0.9261 - val_loss: 0.1912 - val_accuracy: 0.9435\n",
            "Epoch 1783/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2395 - accuracy: 0.9212 - val_loss: 0.1938 - val_accuracy: 0.9450\n",
            "Epoch 1784/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2345 - accuracy: 0.9222 - val_loss: 0.1989 - val_accuracy: 0.9435\n",
            "Epoch 1785/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2285 - accuracy: 0.9287 - val_loss: 0.1909 - val_accuracy: 0.9445\n",
            "Epoch 1786/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2386 - accuracy: 0.9243 - val_loss: 0.1940 - val_accuracy: 0.9430\n",
            "Epoch 1787/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2340 - accuracy: 0.9239 - val_loss: 0.1880 - val_accuracy: 0.9445\n",
            "Epoch 1788/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2303 - accuracy: 0.9264 - val_loss: 0.1929 - val_accuracy: 0.9440\n",
            "Epoch 1789/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2357 - accuracy: 0.9256 - val_loss: 0.1934 - val_accuracy: 0.9425\n",
            "Epoch 1790/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2369 - accuracy: 0.9251 - val_loss: 0.1902 - val_accuracy: 0.9440\n",
            "Epoch 1791/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2303 - accuracy: 0.9271 - val_loss: 0.1993 - val_accuracy: 0.9450\n",
            "Epoch 1792/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2372 - accuracy: 0.9250 - val_loss: 0.1925 - val_accuracy: 0.9440\n",
            "Epoch 1793/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2432 - accuracy: 0.9222 - val_loss: 0.1896 - val_accuracy: 0.9455\n",
            "Epoch 1794/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2318 - accuracy: 0.9234 - val_loss: 0.1945 - val_accuracy: 0.9440\n",
            "Epoch 1795/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2385 - accuracy: 0.9237 - val_loss: 0.1929 - val_accuracy: 0.9440\n",
            "Epoch 1796/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2330 - accuracy: 0.9251 - val_loss: 0.1962 - val_accuracy: 0.9435\n",
            "Epoch 1797/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2298 - accuracy: 0.9259 - val_loss: 0.1940 - val_accuracy: 0.9425\n",
            "Epoch 1798/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2376 - accuracy: 0.9262 - val_loss: 0.1944 - val_accuracy: 0.9425\n",
            "Epoch 1799/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2302 - accuracy: 0.9270 - val_loss: 0.1902 - val_accuracy: 0.9440\n",
            "Epoch 1800/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2344 - accuracy: 0.9239 - val_loss: 0.1915 - val_accuracy: 0.9435\n",
            "Epoch 1801/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2449 - accuracy: 0.9199 - val_loss: 0.1921 - val_accuracy: 0.9440\n",
            "Epoch 1802/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2361 - accuracy: 0.9249 - val_loss: 0.1924 - val_accuracy: 0.9430\n",
            "Epoch 1803/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2420 - accuracy: 0.9209 - val_loss: 0.1940 - val_accuracy: 0.9435\n",
            "Epoch 1804/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2494 - accuracy: 0.9252 - val_loss: 0.1941 - val_accuracy: 0.9450\n",
            "Epoch 1805/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2333 - accuracy: 0.9251 - val_loss: 0.1940 - val_accuracy: 0.9455\n",
            "Epoch 1806/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2364 - accuracy: 0.9224 - val_loss: 0.1964 - val_accuracy: 0.9450\n",
            "Epoch 1807/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2596 - accuracy: 0.9204 - val_loss: 0.1940 - val_accuracy: 0.9425\n",
            "Epoch 1808/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2368 - accuracy: 0.9250 - val_loss: 0.1916 - val_accuracy: 0.9445\n",
            "Epoch 1809/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2316 - accuracy: 0.9254 - val_loss: 0.1922 - val_accuracy: 0.9440\n",
            "Epoch 1810/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2534 - accuracy: 0.9204 - val_loss: 0.1910 - val_accuracy: 0.9445\n",
            "Epoch 1811/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2274 - accuracy: 0.9275 - val_loss: 0.1940 - val_accuracy: 0.9460\n",
            "Epoch 1812/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2318 - accuracy: 0.9212 - val_loss: 0.1958 - val_accuracy: 0.9445\n",
            "Epoch 1813/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2377 - accuracy: 0.9254 - val_loss: 0.1890 - val_accuracy: 0.9430\n",
            "Epoch 1814/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2434 - accuracy: 0.9221 - val_loss: 0.1947 - val_accuracy: 0.9460\n",
            "Epoch 1815/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2371 - accuracy: 0.9241 - val_loss: 0.1915 - val_accuracy: 0.9445\n",
            "Epoch 1816/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2416 - accuracy: 0.9255 - val_loss: 0.1934 - val_accuracy: 0.9465\n",
            "Epoch 1817/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2351 - accuracy: 0.9270 - val_loss: 0.1914 - val_accuracy: 0.9440\n",
            "Epoch 1818/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2329 - accuracy: 0.9252 - val_loss: 0.1916 - val_accuracy: 0.9435\n",
            "Epoch 1819/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2283 - accuracy: 0.9265 - val_loss: 0.1939 - val_accuracy: 0.9435\n",
            "Epoch 1820/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2422 - accuracy: 0.9250 - val_loss: 0.1943 - val_accuracy: 0.9450\n",
            "Epoch 1821/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2324 - accuracy: 0.9237 - val_loss: 0.1941 - val_accuracy: 0.9430\n",
            "Epoch 1822/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2322 - accuracy: 0.9236 - val_loss: 0.1926 - val_accuracy: 0.9455\n",
            "Epoch 1823/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2486 - accuracy: 0.9214 - val_loss: 0.1925 - val_accuracy: 0.9425\n",
            "Epoch 1824/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2376 - accuracy: 0.9243 - val_loss: 0.1927 - val_accuracy: 0.9450\n",
            "Epoch 1825/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2365 - accuracy: 0.9230 - val_loss: 0.1907 - val_accuracy: 0.9455\n",
            "Epoch 1826/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2412 - accuracy: 0.9227 - val_loss: 0.1948 - val_accuracy: 0.9445\n",
            "Epoch 1827/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2319 - accuracy: 0.9252 - val_loss: 0.1918 - val_accuracy: 0.9460\n",
            "Epoch 1828/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2282 - accuracy: 0.9320 - val_loss: 0.1887 - val_accuracy: 0.9455\n",
            "Epoch 1829/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2324 - accuracy: 0.9262 - val_loss: 0.1964 - val_accuracy: 0.9455\n",
            "Epoch 1830/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2433 - accuracy: 0.9236 - val_loss: 0.1987 - val_accuracy: 0.9445\n",
            "Epoch 1831/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2342 - accuracy: 0.9220 - val_loss: 0.1927 - val_accuracy: 0.9455\n",
            "Epoch 1832/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2273 - accuracy: 0.9266 - val_loss: 0.1926 - val_accuracy: 0.9450\n",
            "Epoch 1833/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2433 - accuracy: 0.9220 - val_loss: 0.1934 - val_accuracy: 0.9455\n",
            "Epoch 1834/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2390 - accuracy: 0.9246 - val_loss: 0.1955 - val_accuracy: 0.9460\n",
            "Epoch 1835/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2368 - accuracy: 0.9212 - val_loss: 0.1923 - val_accuracy: 0.9425\n",
            "Epoch 1836/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2292 - accuracy: 0.9269 - val_loss: 0.1930 - val_accuracy: 0.9440\n",
            "Epoch 1837/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2340 - accuracy: 0.9265 - val_loss: 0.1946 - val_accuracy: 0.9455\n",
            "Epoch 1838/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2406 - accuracy: 0.9271 - val_loss: 0.1918 - val_accuracy: 0.9440\n",
            "Epoch 1839/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2372 - accuracy: 0.9255 - val_loss: 0.1890 - val_accuracy: 0.9455\n",
            "Epoch 1840/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2396 - accuracy: 0.9255 - val_loss: 0.1956 - val_accuracy: 0.9460\n",
            "Epoch 1841/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2508 - accuracy: 0.9240 - val_loss: 0.1896 - val_accuracy: 0.9430\n",
            "Epoch 1842/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2371 - accuracy: 0.9243 - val_loss: 0.1938 - val_accuracy: 0.9455\n",
            "Epoch 1843/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2468 - accuracy: 0.9210 - val_loss: 0.1924 - val_accuracy: 0.9455\n",
            "Epoch 1844/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2435 - accuracy: 0.9259 - val_loss: 0.1873 - val_accuracy: 0.9450\n",
            "Epoch 1845/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2384 - accuracy: 0.9224 - val_loss: 0.1914 - val_accuracy: 0.9450\n",
            "Epoch 1846/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2364 - accuracy: 0.9249 - val_loss: 0.1933 - val_accuracy: 0.9460\n",
            "Epoch 1847/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2333 - accuracy: 0.9237 - val_loss: 0.1914 - val_accuracy: 0.9440\n",
            "Epoch 1848/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2391 - accuracy: 0.9233 - val_loss: 0.1937 - val_accuracy: 0.9450\n",
            "Epoch 1849/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2340 - accuracy: 0.9269 - val_loss: 0.1935 - val_accuracy: 0.9450\n",
            "Epoch 1850/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2487 - accuracy: 0.9243 - val_loss: 0.1936 - val_accuracy: 0.9450\n",
            "Epoch 1851/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2362 - accuracy: 0.9219 - val_loss: 0.1943 - val_accuracy: 0.9450\n",
            "Epoch 1852/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2357 - accuracy: 0.9247 - val_loss: 0.1970 - val_accuracy: 0.9435\n",
            "Epoch 1853/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2462 - accuracy: 0.9216 - val_loss: 0.1968 - val_accuracy: 0.9430\n",
            "Epoch 1854/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2507 - accuracy: 0.9240 - val_loss: 0.1942 - val_accuracy: 0.9460\n",
            "Epoch 1855/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2322 - accuracy: 0.9237 - val_loss: 0.1959 - val_accuracy: 0.9430\n",
            "Epoch 1856/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2321 - accuracy: 0.9237 - val_loss: 0.1939 - val_accuracy: 0.9420\n",
            "Epoch 1857/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2359 - accuracy: 0.9246 - val_loss: 0.1970 - val_accuracy: 0.9435\n",
            "Epoch 1858/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2308 - accuracy: 0.9241 - val_loss: 0.1912 - val_accuracy: 0.9445\n",
            "Epoch 1859/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2354 - accuracy: 0.9229 - val_loss: 0.1944 - val_accuracy: 0.9455\n",
            "Epoch 1860/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2310 - accuracy: 0.9276 - val_loss: 0.1958 - val_accuracy: 0.9435\n",
            "Epoch 1861/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2260 - accuracy: 0.9255 - val_loss: 0.1919 - val_accuracy: 0.9440\n",
            "Epoch 1862/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2388 - accuracy: 0.9229 - val_loss: 0.1950 - val_accuracy: 0.9450\n",
            "Epoch 1863/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2397 - accuracy: 0.9241 - val_loss: 0.1941 - val_accuracy: 0.9440\n",
            "Epoch 1864/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2267 - accuracy: 0.9254 - val_loss: 0.1902 - val_accuracy: 0.9430\n",
            "Epoch 1865/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2322 - accuracy: 0.9230 - val_loss: 0.1919 - val_accuracy: 0.9450\n",
            "Epoch 1866/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2338 - accuracy: 0.9245 - val_loss: 0.1931 - val_accuracy: 0.9445\n",
            "Epoch 1867/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2345 - accuracy: 0.9277 - val_loss: 0.1902 - val_accuracy: 0.9420\n",
            "Epoch 1868/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2366 - accuracy: 0.9229 - val_loss: 0.1922 - val_accuracy: 0.9440\n",
            "Epoch 1869/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2297 - accuracy: 0.9262 - val_loss: 0.1928 - val_accuracy: 0.9445\n",
            "Epoch 1870/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2423 - accuracy: 0.9264 - val_loss: 0.1921 - val_accuracy: 0.9435\n",
            "Epoch 1871/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2425 - accuracy: 0.9209 - val_loss: 0.1918 - val_accuracy: 0.9440\n",
            "Epoch 1872/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2390 - accuracy: 0.9235 - val_loss: 0.1891 - val_accuracy: 0.9440\n",
            "Epoch 1873/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2383 - accuracy: 0.9221 - val_loss: 0.1927 - val_accuracy: 0.9465\n",
            "Epoch 1874/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2391 - accuracy: 0.9241 - val_loss: 0.1936 - val_accuracy: 0.9440\n",
            "Epoch 1875/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2363 - accuracy: 0.9256 - val_loss: 0.1920 - val_accuracy: 0.9450\n",
            "Epoch 1876/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2432 - accuracy: 0.9225 - val_loss: 0.1897 - val_accuracy: 0.9445\n",
            "Epoch 1877/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2293 - accuracy: 0.9261 - val_loss: 0.1895 - val_accuracy: 0.9445\n",
            "Epoch 1878/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2321 - accuracy: 0.9265 - val_loss: 0.1910 - val_accuracy: 0.9425\n",
            "Epoch 1879/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2330 - accuracy: 0.9250 - val_loss: 0.1951 - val_accuracy: 0.9440\n",
            "Epoch 1880/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2339 - accuracy: 0.9290 - val_loss: 0.1900 - val_accuracy: 0.9420\n",
            "Epoch 1881/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2333 - accuracy: 0.9251 - val_loss: 0.1900 - val_accuracy: 0.9450\n",
            "Epoch 1882/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2237 - accuracy: 0.9280 - val_loss: 0.1927 - val_accuracy: 0.9460\n",
            "Epoch 1883/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2364 - accuracy: 0.9234 - val_loss: 0.1919 - val_accuracy: 0.9445\n",
            "Epoch 1884/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2342 - accuracy: 0.9221 - val_loss: 0.1915 - val_accuracy: 0.9430\n",
            "Epoch 1885/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2303 - accuracy: 0.9273 - val_loss: 0.1913 - val_accuracy: 0.9435\n",
            "Epoch 1886/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2373 - accuracy: 0.9235 - val_loss: 0.1954 - val_accuracy: 0.9455\n",
            "Epoch 1887/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2355 - accuracy: 0.9243 - val_loss: 0.1891 - val_accuracy: 0.9455\n",
            "Epoch 1888/6000\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2399 - accuracy: 0.9260 - val_loss: 0.1872 - val_accuracy: 0.9455\n",
            "Epoch 1889/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2360 - accuracy: 0.9240 - val_loss: 0.1959 - val_accuracy: 0.9420\n",
            "Epoch 1890/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2360 - accuracy: 0.9240 - val_loss: 0.1894 - val_accuracy: 0.9445\n",
            "Epoch 1891/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2359 - accuracy: 0.9250 - val_loss: 0.1972 - val_accuracy: 0.9445\n",
            "Epoch 1892/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2279 - accuracy: 0.9284 - val_loss: 0.1974 - val_accuracy: 0.9445\n",
            "Epoch 1893/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2383 - accuracy: 0.9218 - val_loss: 0.1977 - val_accuracy: 0.9445\n",
            "Epoch 1894/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2382 - accuracy: 0.9234 - val_loss: 0.1965 - val_accuracy: 0.9445\n",
            "Epoch 1895/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2392 - accuracy: 0.9245 - val_loss: 0.1915 - val_accuracy: 0.9435\n",
            "Epoch 1896/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2384 - accuracy: 0.9231 - val_loss: 0.1898 - val_accuracy: 0.9455\n",
            "Epoch 1897/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2396 - accuracy: 0.9221 - val_loss: 0.1934 - val_accuracy: 0.9445\n",
            "Epoch 1898/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2308 - accuracy: 0.9265 - val_loss: 0.1964 - val_accuracy: 0.9435\n",
            "Epoch 1899/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2385 - accuracy: 0.9231 - val_loss: 0.1908 - val_accuracy: 0.9435\n",
            "Epoch 1900/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2375 - accuracy: 0.9241 - val_loss: 0.1956 - val_accuracy: 0.9410\n",
            "Epoch 1901/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2528 - accuracy: 0.9184 - val_loss: 0.1923 - val_accuracy: 0.9455\n",
            "Epoch 1902/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2321 - accuracy: 0.9246 - val_loss: 0.1902 - val_accuracy: 0.9440\n",
            "Epoch 1903/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2429 - accuracy: 0.9240 - val_loss: 0.1976 - val_accuracy: 0.9430\n",
            "Epoch 1904/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2282 - accuracy: 0.9265 - val_loss: 0.1910 - val_accuracy: 0.9430\n",
            "Epoch 1905/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2326 - accuracy: 0.9235 - val_loss: 0.1917 - val_accuracy: 0.9440\n",
            "Epoch 1906/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2418 - accuracy: 0.9236 - val_loss: 0.1953 - val_accuracy: 0.9460\n",
            "Epoch 1907/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2329 - accuracy: 0.9239 - val_loss: 0.1938 - val_accuracy: 0.9430\n",
            "Epoch 1908/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2387 - accuracy: 0.9230 - val_loss: 0.1904 - val_accuracy: 0.9440\n",
            "Epoch 1909/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2389 - accuracy: 0.9254 - val_loss: 0.1913 - val_accuracy: 0.9450\n",
            "Epoch 1910/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2336 - accuracy: 0.9255 - val_loss: 0.1924 - val_accuracy: 0.9430\n",
            "Epoch 1911/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2360 - accuracy: 0.9239 - val_loss: 0.1919 - val_accuracy: 0.9420\n",
            "Epoch 1912/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2367 - accuracy: 0.9230 - val_loss: 0.1909 - val_accuracy: 0.9440\n",
            "Epoch 1913/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2521 - accuracy: 0.9225 - val_loss: 0.1928 - val_accuracy: 0.9455\n",
            "Epoch 1914/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2365 - accuracy: 0.9226 - val_loss: 0.1911 - val_accuracy: 0.9440\n",
            "Epoch 1915/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2340 - accuracy: 0.9247 - val_loss: 0.1943 - val_accuracy: 0.9435\n",
            "Epoch 1916/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2337 - accuracy: 0.9268 - val_loss: 0.1935 - val_accuracy: 0.9445\n",
            "Epoch 1917/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2319 - accuracy: 0.9273 - val_loss: 0.1915 - val_accuracy: 0.9430\n",
            "Epoch 1918/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2361 - accuracy: 0.9235 - val_loss: 0.1963 - val_accuracy: 0.9420\n",
            "Epoch 1919/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2331 - accuracy: 0.9236 - val_loss: 0.1901 - val_accuracy: 0.9430\n",
            "Epoch 1920/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2273 - accuracy: 0.9246 - val_loss: 0.1919 - val_accuracy: 0.9435\n",
            "Epoch 1921/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2373 - accuracy: 0.9249 - val_loss: 0.1946 - val_accuracy: 0.9430\n",
            "Epoch 1922/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2407 - accuracy: 0.9210 - val_loss: 0.1948 - val_accuracy: 0.9430\n",
            "Epoch 1923/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2320 - accuracy: 0.9274 - val_loss: 0.1942 - val_accuracy: 0.9445\n",
            "Epoch 1924/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2242 - accuracy: 0.9273 - val_loss: 0.1916 - val_accuracy: 0.9440\n",
            "Epoch 1925/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2360 - accuracy: 0.9246 - val_loss: 0.1933 - val_accuracy: 0.9430\n",
            "Epoch 1926/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2350 - accuracy: 0.9227 - val_loss: 0.1919 - val_accuracy: 0.9445\n",
            "Epoch 1927/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2330 - accuracy: 0.9256 - val_loss: 0.1947 - val_accuracy: 0.9435\n",
            "Epoch 1928/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2312 - accuracy: 0.9245 - val_loss: 0.1917 - val_accuracy: 0.9425\n",
            "Epoch 1929/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2380 - accuracy: 0.9227 - val_loss: 0.1942 - val_accuracy: 0.9425\n",
            "Epoch 1930/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2373 - accuracy: 0.9226 - val_loss: 0.1944 - val_accuracy: 0.9425\n",
            "Epoch 1931/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2468 - accuracy: 0.9241 - val_loss: 0.1939 - val_accuracy: 0.9470\n",
            "Epoch 1932/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2473 - accuracy: 0.9220 - val_loss: 0.1936 - val_accuracy: 0.9450\n",
            "Epoch 1933/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2273 - accuracy: 0.9246 - val_loss: 0.1903 - val_accuracy: 0.9445\n",
            "Epoch 1934/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2338 - accuracy: 0.9254 - val_loss: 0.1917 - val_accuracy: 0.9455\n",
            "Epoch 1935/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2315 - accuracy: 0.9251 - val_loss: 0.1913 - val_accuracy: 0.9420\n",
            "Epoch 1936/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2302 - accuracy: 0.9276 - val_loss: 0.1940 - val_accuracy: 0.9450\n",
            "Epoch 1937/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2302 - accuracy: 0.9276 - val_loss: 0.1895 - val_accuracy: 0.9450\n",
            "Epoch 1938/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2355 - accuracy: 0.9258 - val_loss: 0.1946 - val_accuracy: 0.9425\n",
            "Epoch 1939/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2489 - accuracy: 0.9205 - val_loss: 0.1930 - val_accuracy: 0.9435\n",
            "Epoch 1940/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2363 - accuracy: 0.9222 - val_loss: 0.1938 - val_accuracy: 0.9445\n",
            "Epoch 1941/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2274 - accuracy: 0.9250 - val_loss: 0.1926 - val_accuracy: 0.9435\n",
            "Epoch 1942/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2389 - accuracy: 0.9275 - val_loss: 0.1916 - val_accuracy: 0.9430\n",
            "Epoch 1943/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2346 - accuracy: 0.9250 - val_loss: 0.1879 - val_accuracy: 0.9440\n",
            "Epoch 1944/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2371 - accuracy: 0.9246 - val_loss: 0.1874 - val_accuracy: 0.9445\n",
            "Epoch 1945/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2423 - accuracy: 0.9221 - val_loss: 0.1931 - val_accuracy: 0.9440\n",
            "Epoch 1946/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2281 - accuracy: 0.9254 - val_loss: 0.1929 - val_accuracy: 0.9445\n",
            "Epoch 1947/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2346 - accuracy: 0.9236 - val_loss: 0.1895 - val_accuracy: 0.9440\n",
            "Epoch 1948/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2394 - accuracy: 0.9231 - val_loss: 0.1886 - val_accuracy: 0.9435\n",
            "Epoch 1949/6000\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2472 - accuracy: 0.9235 - val_loss: 0.1919 - val_accuracy: 0.9450\n",
            "Epoch 1950/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2391 - accuracy: 0.9252 - val_loss: 0.1939 - val_accuracy: 0.9445\n",
            "Epoch 1951/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2347 - accuracy: 0.9240 - val_loss: 0.1962 - val_accuracy: 0.9435\n",
            "Epoch 1952/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2429 - accuracy: 0.9185 - val_loss: 0.1960 - val_accuracy: 0.9420\n",
            "Epoch 1953/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2382 - accuracy: 0.9205 - val_loss: 0.2016 - val_accuracy: 0.9425\n",
            "Epoch 1954/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2327 - accuracy: 0.9259 - val_loss: 0.1940 - val_accuracy: 0.9445\n",
            "Epoch 1955/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2464 - accuracy: 0.9240 - val_loss: 0.1899 - val_accuracy: 0.9435\n",
            "Epoch 1956/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2338 - accuracy: 0.9254 - val_loss: 0.1955 - val_accuracy: 0.9450\n",
            "Epoch 1957/6000\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2332 - accuracy: 0.9234 - val_loss: 0.1955 - val_accuracy: 0.9420\n",
            "Epoch 1958/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2336 - accuracy: 0.9212 - val_loss: 0.1942 - val_accuracy: 0.9435\n",
            "Epoch 1959/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2282 - accuracy: 0.9258 - val_loss: 0.1930 - val_accuracy: 0.9435\n",
            "Epoch 1960/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2386 - accuracy: 0.9219 - val_loss: 0.1950 - val_accuracy: 0.9440\n",
            "Epoch 1961/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2339 - accuracy: 0.9251 - val_loss: 0.1910 - val_accuracy: 0.9440\n",
            "Epoch 1962/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2429 - accuracy: 0.9239 - val_loss: 0.1929 - val_accuracy: 0.9445\n",
            "Epoch 1963/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2386 - accuracy: 0.9279 - val_loss: 0.1953 - val_accuracy: 0.9455\n",
            "Epoch 1964/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2328 - accuracy: 0.9247 - val_loss: 0.1944 - val_accuracy: 0.9445\n",
            "Epoch 1965/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2356 - accuracy: 0.9260 - val_loss: 0.1979 - val_accuracy: 0.9445\n",
            "Epoch 1966/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2301 - accuracy: 0.9256 - val_loss: 0.1911 - val_accuracy: 0.9440\n",
            "Epoch 1967/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2303 - accuracy: 0.9249 - val_loss: 0.1908 - val_accuracy: 0.9425\n",
            "Epoch 1968/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2296 - accuracy: 0.9249 - val_loss: 0.1944 - val_accuracy: 0.9440\n",
            "Epoch 1969/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2469 - accuracy: 0.9226 - val_loss: 0.1910 - val_accuracy: 0.9455\n",
            "Epoch 1970/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2314 - accuracy: 0.9266 - val_loss: 0.1918 - val_accuracy: 0.9440\n",
            "Epoch 1971/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2361 - accuracy: 0.9243 - val_loss: 0.1964 - val_accuracy: 0.9410\n",
            "Epoch 1972/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2386 - accuracy: 0.9226 - val_loss: 0.1944 - val_accuracy: 0.9435\n",
            "Epoch 1973/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2302 - accuracy: 0.9225 - val_loss: 0.1905 - val_accuracy: 0.9445\n",
            "Epoch 1974/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2286 - accuracy: 0.9245 - val_loss: 0.1947 - val_accuracy: 0.9435\n",
            "Epoch 1975/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2425 - accuracy: 0.9240 - val_loss: 0.1988 - val_accuracy: 0.9450\n",
            "Epoch 1976/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2352 - accuracy: 0.9247 - val_loss: 0.1928 - val_accuracy: 0.9415\n",
            "Epoch 1977/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2367 - accuracy: 0.9218 - val_loss: 0.1956 - val_accuracy: 0.9435\n",
            "Epoch 1978/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2389 - accuracy: 0.9244 - val_loss: 0.1912 - val_accuracy: 0.9420\n",
            "Epoch 1979/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2471 - accuracy: 0.9231 - val_loss: 0.1969 - val_accuracy: 0.9435\n",
            "Epoch 1980/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2329 - accuracy: 0.9254 - val_loss: 0.1902 - val_accuracy: 0.9445\n",
            "Epoch 1981/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2413 - accuracy: 0.9225 - val_loss: 0.1885 - val_accuracy: 0.9445\n",
            "Epoch 1982/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2313 - accuracy: 0.9255 - val_loss: 0.1963 - val_accuracy: 0.9450\n",
            "Epoch 1983/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2283 - accuracy: 0.9269 - val_loss: 0.1937 - val_accuracy: 0.9425\n",
            "Epoch 1984/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2377 - accuracy: 0.9255 - val_loss: 0.1923 - val_accuracy: 0.9425\n",
            "Epoch 1985/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2346 - accuracy: 0.9264 - val_loss: 0.1919 - val_accuracy: 0.9440\n",
            "Epoch 1986/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2519 - accuracy: 0.9183 - val_loss: 0.1929 - val_accuracy: 0.9445\n",
            "Epoch 1987/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2352 - accuracy: 0.9201 - val_loss: 0.1981 - val_accuracy: 0.9435\n",
            "Epoch 1988/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2275 - accuracy: 0.9280 - val_loss: 0.1983 - val_accuracy: 0.9445\n",
            "Epoch 1989/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2255 - accuracy: 0.9264 - val_loss: 0.1933 - val_accuracy: 0.9435\n",
            "Epoch 1990/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2362 - accuracy: 0.9258 - val_loss: 0.1898 - val_accuracy: 0.9435\n",
            "Epoch 1991/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2364 - accuracy: 0.9229 - val_loss: 0.1937 - val_accuracy: 0.9440\n",
            "Epoch 1992/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2330 - accuracy: 0.9202 - val_loss: 0.1930 - val_accuracy: 0.9430\n",
            "Epoch 1993/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2337 - accuracy: 0.9237 - val_loss: 0.1943 - val_accuracy: 0.9440\n",
            "Epoch 1994/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2410 - accuracy: 0.9216 - val_loss: 0.1903 - val_accuracy: 0.9425\n",
            "Epoch 1995/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2293 - accuracy: 0.9284 - val_loss: 0.2005 - val_accuracy: 0.9410\n",
            "Epoch 1996/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2332 - accuracy: 0.9250 - val_loss: 0.1904 - val_accuracy: 0.9425\n",
            "Epoch 1997/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2393 - accuracy: 0.9229 - val_loss: 0.1963 - val_accuracy: 0.9445\n",
            "Epoch 1998/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2284 - accuracy: 0.9259 - val_loss: 0.1914 - val_accuracy: 0.9440\n",
            "Epoch 1999/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2399 - accuracy: 0.9265 - val_loss: 0.1900 - val_accuracy: 0.9440\n",
            "Epoch 2000/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2360 - accuracy: 0.9215 - val_loss: 0.1916 - val_accuracy: 0.9415\n",
            "Epoch 2001/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2321 - accuracy: 0.9255 - val_loss: 0.1942 - val_accuracy: 0.9445\n",
            "Epoch 2002/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2597 - accuracy: 0.9189 - val_loss: 0.1949 - val_accuracy: 0.9435\n",
            "Epoch 2003/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2279 - accuracy: 0.9275 - val_loss: 0.1906 - val_accuracy: 0.9450\n",
            "Epoch 2004/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2277 - accuracy: 0.9265 - val_loss: 0.1934 - val_accuracy: 0.9435\n",
            "Epoch 2005/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2294 - accuracy: 0.9274 - val_loss: 0.1954 - val_accuracy: 0.9435\n",
            "Epoch 2006/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2484 - accuracy: 0.9211 - val_loss: 0.1974 - val_accuracy: 0.9440\n",
            "Epoch 2007/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2291 - accuracy: 0.9251 - val_loss: 0.1900 - val_accuracy: 0.9435\n",
            "Epoch 2008/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2407 - accuracy: 0.9236 - val_loss: 0.1940 - val_accuracy: 0.9425\n",
            "Epoch 2009/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2358 - accuracy: 0.9246 - val_loss: 0.1909 - val_accuracy: 0.9430\n",
            "Epoch 2010/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2349 - accuracy: 0.9256 - val_loss: 0.1902 - val_accuracy: 0.9440\n",
            "Epoch 2011/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2343 - accuracy: 0.9244 - val_loss: 0.1955 - val_accuracy: 0.9450\n",
            "Epoch 2012/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2445 - accuracy: 0.9251 - val_loss: 0.1917 - val_accuracy: 0.9445\n",
            "Epoch 2013/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2405 - accuracy: 0.9224 - val_loss: 0.1968 - val_accuracy: 0.9435\n",
            "Epoch 2014/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2516 - accuracy: 0.9212 - val_loss: 0.1922 - val_accuracy: 0.9425\n",
            "Epoch 2015/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2359 - accuracy: 0.9274 - val_loss: 0.1947 - val_accuracy: 0.9455\n",
            "Epoch 2016/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2376 - accuracy: 0.9245 - val_loss: 0.1909 - val_accuracy: 0.9450\n",
            "Epoch 2017/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2449 - accuracy: 0.9230 - val_loss: 0.1938 - val_accuracy: 0.9445\n",
            "Epoch 2018/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2374 - accuracy: 0.9235 - val_loss: 0.1979 - val_accuracy: 0.9435\n",
            "Epoch 2019/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2448 - accuracy: 0.9205 - val_loss: 0.1962 - val_accuracy: 0.9430\n",
            "Epoch 2020/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2395 - accuracy: 0.9236 - val_loss: 0.1904 - val_accuracy: 0.9455\n",
            "Epoch 2021/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2263 - accuracy: 0.9261 - val_loss: 0.1903 - val_accuracy: 0.9440\n",
            "Epoch 2022/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2325 - accuracy: 0.9241 - val_loss: 0.1899 - val_accuracy: 0.9440\n",
            "Epoch 2023/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2341 - accuracy: 0.9221 - val_loss: 0.1943 - val_accuracy: 0.9440\n",
            "Epoch 2024/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2394 - accuracy: 0.9222 - val_loss: 0.1984 - val_accuracy: 0.9445\n",
            "Epoch 2025/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2338 - accuracy: 0.9252 - val_loss: 0.1966 - val_accuracy: 0.9450\n",
            "Epoch 2026/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2272 - accuracy: 0.9258 - val_loss: 0.1930 - val_accuracy: 0.9440\n",
            "Epoch 2027/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2432 - accuracy: 0.9230 - val_loss: 0.1929 - val_accuracy: 0.9435\n",
            "Epoch 2028/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2375 - accuracy: 0.9214 - val_loss: 0.1924 - val_accuracy: 0.9445\n",
            "Epoch 2029/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2354 - accuracy: 0.9252 - val_loss: 0.1951 - val_accuracy: 0.9445\n",
            "Epoch 2030/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2326 - accuracy: 0.9245 - val_loss: 0.1938 - val_accuracy: 0.9465\n",
            "Epoch 2031/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2319 - accuracy: 0.9269 - val_loss: 0.2057 - val_accuracy: 0.9400\n",
            "Epoch 2032/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2325 - accuracy: 0.9234 - val_loss: 0.1980 - val_accuracy: 0.9450\n",
            "Epoch 2033/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2262 - accuracy: 0.9269 - val_loss: 0.1911 - val_accuracy: 0.9445\n",
            "Epoch 2034/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2375 - accuracy: 0.9216 - val_loss: 0.1931 - val_accuracy: 0.9440\n",
            "Epoch 2035/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2255 - accuracy: 0.9308 - val_loss: 0.1984 - val_accuracy: 0.9430\n",
            "Epoch 2036/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2283 - accuracy: 0.9250 - val_loss: 0.1953 - val_accuracy: 0.9430\n",
            "Epoch 2037/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2443 - accuracy: 0.9218 - val_loss: 0.1943 - val_accuracy: 0.9460\n",
            "Epoch 2038/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2281 - accuracy: 0.9252 - val_loss: 0.1942 - val_accuracy: 0.9450\n",
            "Epoch 2039/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2404 - accuracy: 0.9224 - val_loss: 0.1916 - val_accuracy: 0.9440\n",
            "Epoch 2040/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2436 - accuracy: 0.9209 - val_loss: 0.1903 - val_accuracy: 0.9440\n",
            "Epoch 2041/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2348 - accuracy: 0.9235 - val_loss: 0.1969 - val_accuracy: 0.9445\n",
            "Epoch 2042/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2299 - accuracy: 0.9258 - val_loss: 0.1931 - val_accuracy: 0.9450\n",
            "Epoch 2043/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2430 - accuracy: 0.9221 - val_loss: 0.1929 - val_accuracy: 0.9455\n",
            "Epoch 2044/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2404 - accuracy: 0.9261 - val_loss: 0.1902 - val_accuracy: 0.9445\n",
            "Epoch 2045/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2363 - accuracy: 0.9244 - val_loss: 0.1988 - val_accuracy: 0.9445\n",
            "Epoch 2046/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2261 - accuracy: 0.9270 - val_loss: 0.1920 - val_accuracy: 0.9430\n",
            "Epoch 2047/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2344 - accuracy: 0.9271 - val_loss: 0.1921 - val_accuracy: 0.9445\n",
            "Epoch 2048/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2280 - accuracy: 0.9275 - val_loss: 0.1919 - val_accuracy: 0.9420\n",
            "Epoch 2049/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2465 - accuracy: 0.9239 - val_loss: 0.1947 - val_accuracy: 0.9430\n",
            "Epoch 2050/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2346 - accuracy: 0.9231 - val_loss: 0.1897 - val_accuracy: 0.9450\n",
            "Epoch 2051/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2412 - accuracy: 0.9225 - val_loss: 0.1913 - val_accuracy: 0.9450\n",
            "Epoch 2052/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2341 - accuracy: 0.9262 - val_loss: 0.1924 - val_accuracy: 0.9455\n",
            "Epoch 2053/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2335 - accuracy: 0.9266 - val_loss: 0.1923 - val_accuracy: 0.9460\n",
            "Epoch 2054/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2298 - accuracy: 0.9283 - val_loss: 0.1895 - val_accuracy: 0.9435\n",
            "Epoch 2055/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2361 - accuracy: 0.9235 - val_loss: 0.1918 - val_accuracy: 0.9440\n",
            "Epoch 2056/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2388 - accuracy: 0.9231 - val_loss: 0.1911 - val_accuracy: 0.9440\n",
            "Epoch 2057/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2294 - accuracy: 0.9249 - val_loss: 0.1946 - val_accuracy: 0.9440\n",
            "Epoch 2058/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2290 - accuracy: 0.9264 - val_loss: 0.1947 - val_accuracy: 0.9455\n",
            "Epoch 2059/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2365 - accuracy: 0.9233 - val_loss: 0.2007 - val_accuracy: 0.9435\n",
            "Epoch 2060/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2363 - accuracy: 0.9260 - val_loss: 0.1963 - val_accuracy: 0.9445\n",
            "Epoch 2061/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2360 - accuracy: 0.9224 - val_loss: 0.1963 - val_accuracy: 0.9440\n",
            "Epoch 2062/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2390 - accuracy: 0.9201 - val_loss: 0.1932 - val_accuracy: 0.9440\n",
            "Epoch 2063/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2341 - accuracy: 0.9246 - val_loss: 0.1937 - val_accuracy: 0.9440\n",
            "Epoch 2064/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2407 - accuracy: 0.9224 - val_loss: 0.1915 - val_accuracy: 0.9455\n",
            "Epoch 2065/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2404 - accuracy: 0.9247 - val_loss: 0.1956 - val_accuracy: 0.9435\n",
            "Epoch 2066/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2335 - accuracy: 0.9241 - val_loss: 0.1949 - val_accuracy: 0.9450\n",
            "Epoch 2067/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2379 - accuracy: 0.9247 - val_loss: 0.1923 - val_accuracy: 0.9450\n",
            "Epoch 2068/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2400 - accuracy: 0.9229 - val_loss: 0.1928 - val_accuracy: 0.9435\n",
            "Epoch 2069/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2464 - accuracy: 0.9216 - val_loss: 0.1909 - val_accuracy: 0.9435\n",
            "Epoch 2070/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2333 - accuracy: 0.9259 - val_loss: 0.1879 - val_accuracy: 0.9475\n",
            "Epoch 2071/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2444 - accuracy: 0.9222 - val_loss: 0.1908 - val_accuracy: 0.9460\n",
            "Epoch 2072/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2303 - accuracy: 0.9227 - val_loss: 0.1964 - val_accuracy: 0.9450\n",
            "Epoch 2073/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2414 - accuracy: 0.9235 - val_loss: 0.1892 - val_accuracy: 0.9455\n",
            "Epoch 2074/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2373 - accuracy: 0.9218 - val_loss: 0.1902 - val_accuracy: 0.9445\n",
            "Epoch 2075/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2338 - accuracy: 0.9215 - val_loss: 0.1915 - val_accuracy: 0.9440\n",
            "Epoch 2076/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2268 - accuracy: 0.9279 - val_loss: 0.1936 - val_accuracy: 0.9435\n",
            "Epoch 2077/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2346 - accuracy: 0.9235 - val_loss: 0.1905 - val_accuracy: 0.9445\n",
            "Epoch 2078/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2368 - accuracy: 0.9240 - val_loss: 0.1916 - val_accuracy: 0.9440\n",
            "Epoch 2079/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2455 - accuracy: 0.9233 - val_loss: 0.1979 - val_accuracy: 0.9445\n",
            "Epoch 2080/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2366 - accuracy: 0.9260 - val_loss: 0.1919 - val_accuracy: 0.9445\n",
            "Epoch 2081/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2306 - accuracy: 0.9249 - val_loss: 0.1941 - val_accuracy: 0.9455\n",
            "Epoch 2082/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2261 - accuracy: 0.9269 - val_loss: 0.1970 - val_accuracy: 0.9435\n",
            "Epoch 2083/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2331 - accuracy: 0.9235 - val_loss: 0.1967 - val_accuracy: 0.9440\n",
            "Epoch 2084/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2362 - accuracy: 0.9239 - val_loss: 0.1925 - val_accuracy: 0.9435\n",
            "Epoch 2085/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2359 - accuracy: 0.9250 - val_loss: 0.1966 - val_accuracy: 0.9430\n",
            "Epoch 2086/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2295 - accuracy: 0.9262 - val_loss: 0.1969 - val_accuracy: 0.9440\n",
            "Epoch 2087/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2406 - accuracy: 0.9222 - val_loss: 0.1969 - val_accuracy: 0.9445\n",
            "Epoch 2088/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2312 - accuracy: 0.9245 - val_loss: 0.1951 - val_accuracy: 0.9430\n",
            "Epoch 2089/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2332 - accuracy: 0.9255 - val_loss: 0.1905 - val_accuracy: 0.9440\n",
            "Epoch 2090/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2255 - accuracy: 0.9283 - val_loss: 0.1922 - val_accuracy: 0.9415\n",
            "Epoch 2091/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2383 - accuracy: 0.9229 - val_loss: 0.1913 - val_accuracy: 0.9430\n",
            "Epoch 2092/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2316 - accuracy: 0.9260 - val_loss: 0.1898 - val_accuracy: 0.9435\n",
            "Epoch 2093/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2311 - accuracy: 0.9255 - val_loss: 0.1897 - val_accuracy: 0.9440\n",
            "Epoch 2094/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2336 - accuracy: 0.9251 - val_loss: 0.1972 - val_accuracy: 0.9455\n",
            "Epoch 2095/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2448 - accuracy: 0.9240 - val_loss: 0.2018 - val_accuracy: 0.9430\n",
            "Epoch 2096/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2306 - accuracy: 0.9241 - val_loss: 0.1983 - val_accuracy: 0.9435\n",
            "Epoch 2097/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2324 - accuracy: 0.9277 - val_loss: 0.1904 - val_accuracy: 0.9430\n",
            "Epoch 2098/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2460 - accuracy: 0.9233 - val_loss: 0.1933 - val_accuracy: 0.9420\n",
            "Epoch 2099/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2393 - accuracy: 0.9231 - val_loss: 0.1966 - val_accuracy: 0.9450\n",
            "Epoch 2100/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2313 - accuracy: 0.9247 - val_loss: 0.2013 - val_accuracy: 0.9445\n",
            "Epoch 2101/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2416 - accuracy: 0.9240 - val_loss: 0.1963 - val_accuracy: 0.9450\n",
            "Epoch 2102/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2328 - accuracy: 0.9250 - val_loss: 0.1931 - val_accuracy: 0.9450\n",
            "Epoch 2103/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2292 - accuracy: 0.9266 - val_loss: 0.1911 - val_accuracy: 0.9435\n",
            "Epoch 2104/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2299 - accuracy: 0.9243 - val_loss: 0.1954 - val_accuracy: 0.9450\n",
            "Epoch 2105/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2334 - accuracy: 0.9244 - val_loss: 0.1960 - val_accuracy: 0.9455\n",
            "Epoch 2106/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2368 - accuracy: 0.9243 - val_loss: 0.1920 - val_accuracy: 0.9450\n",
            "Epoch 2107/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2444 - accuracy: 0.9256 - val_loss: 0.1899 - val_accuracy: 0.9440\n",
            "Epoch 2108/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2371 - accuracy: 0.9231 - val_loss: 0.1948 - val_accuracy: 0.9435\n",
            "Epoch 2109/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2326 - accuracy: 0.9254 - val_loss: 0.1950 - val_accuracy: 0.9455\n",
            "Epoch 2110/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2230 - accuracy: 0.9262 - val_loss: 0.1924 - val_accuracy: 0.9450\n",
            "Epoch 2111/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2358 - accuracy: 0.9229 - val_loss: 0.1934 - val_accuracy: 0.9440\n",
            "Epoch 2112/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2518 - accuracy: 0.9224 - val_loss: 0.1888 - val_accuracy: 0.9440\n",
            "Epoch 2113/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2406 - accuracy: 0.9244 - val_loss: 0.1888 - val_accuracy: 0.9435\n",
            "Epoch 2114/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2322 - accuracy: 0.9225 - val_loss: 0.1952 - val_accuracy: 0.9415\n",
            "Epoch 2115/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2334 - accuracy: 0.9220 - val_loss: 0.1918 - val_accuracy: 0.9445\n",
            "Epoch 2116/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2304 - accuracy: 0.9259 - val_loss: 0.1942 - val_accuracy: 0.9460\n",
            "Epoch 2117/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2356 - accuracy: 0.9234 - val_loss: 0.1976 - val_accuracy: 0.9465\n",
            "Epoch 2118/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2272 - accuracy: 0.9280 - val_loss: 0.1918 - val_accuracy: 0.9465\n",
            "Epoch 2119/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2273 - accuracy: 0.9265 - val_loss: 0.1957 - val_accuracy: 0.9440\n",
            "Epoch 2120/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2270 - accuracy: 0.9266 - val_loss: 0.1923 - val_accuracy: 0.9425\n",
            "Epoch 2121/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2338 - accuracy: 0.9241 - val_loss: 0.1929 - val_accuracy: 0.9450\n",
            "Epoch 2122/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2396 - accuracy: 0.9225 - val_loss: 0.1943 - val_accuracy: 0.9415\n",
            "Epoch 2123/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2311 - accuracy: 0.9249 - val_loss: 0.1926 - val_accuracy: 0.9450\n",
            "Epoch 2124/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2284 - accuracy: 0.9247 - val_loss: 0.1967 - val_accuracy: 0.9460\n",
            "Epoch 2125/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2325 - accuracy: 0.9246 - val_loss: 0.1923 - val_accuracy: 0.9440\n",
            "Epoch 2126/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2348 - accuracy: 0.9256 - val_loss: 0.1922 - val_accuracy: 0.9455\n",
            "Epoch 2127/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2361 - accuracy: 0.9239 - val_loss: 0.1903 - val_accuracy: 0.9440\n",
            "Epoch 2128/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2330 - accuracy: 0.9251 - val_loss: 0.1955 - val_accuracy: 0.9425\n",
            "Epoch 2129/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2253 - accuracy: 0.9261 - val_loss: 0.1932 - val_accuracy: 0.9445\n",
            "Epoch 2130/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2342 - accuracy: 0.9236 - val_loss: 0.1945 - val_accuracy: 0.9440\n",
            "Epoch 2131/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2465 - accuracy: 0.9250 - val_loss: 0.1917 - val_accuracy: 0.9455\n",
            "Epoch 2132/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2376 - accuracy: 0.9256 - val_loss: 0.1984 - val_accuracy: 0.9425\n",
            "Epoch 2133/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2370 - accuracy: 0.9250 - val_loss: 0.1908 - val_accuracy: 0.9445\n",
            "Epoch 2134/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2291 - accuracy: 0.9296 - val_loss: 0.1942 - val_accuracy: 0.9435\n",
            "Epoch 2135/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2297 - accuracy: 0.9256 - val_loss: 0.1931 - val_accuracy: 0.9450\n",
            "Epoch 2136/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2456 - accuracy: 0.9235 - val_loss: 0.1906 - val_accuracy: 0.9445\n",
            "Epoch 2137/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2261 - accuracy: 0.9256 - val_loss: 0.1939 - val_accuracy: 0.9440\n",
            "Epoch 2138/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2323 - accuracy: 0.9279 - val_loss: 0.1919 - val_accuracy: 0.9445\n",
            "Epoch 2139/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2446 - accuracy: 0.9250 - val_loss: 0.1895 - val_accuracy: 0.9455\n",
            "Epoch 2140/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2331 - accuracy: 0.9241 - val_loss: 0.1915 - val_accuracy: 0.9425\n",
            "Epoch 2141/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2317 - accuracy: 0.9258 - val_loss: 0.1918 - val_accuracy: 0.9450\n",
            "Epoch 2142/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2360 - accuracy: 0.9250 - val_loss: 0.1923 - val_accuracy: 0.9430\n",
            "Epoch 2143/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2332 - accuracy: 0.9252 - val_loss: 0.1929 - val_accuracy: 0.9445\n",
            "Epoch 2144/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2304 - accuracy: 0.9255 - val_loss: 0.1962 - val_accuracy: 0.9435\n",
            "Epoch 2145/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2377 - accuracy: 0.9260 - val_loss: 0.1958 - val_accuracy: 0.9415\n",
            "Epoch 2146/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2392 - accuracy: 0.9201 - val_loss: 0.1954 - val_accuracy: 0.9440\n",
            "Epoch 2147/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2406 - accuracy: 0.9219 - val_loss: 0.1960 - val_accuracy: 0.9455\n",
            "Epoch 2148/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2422 - accuracy: 0.9202 - val_loss: 0.1949 - val_accuracy: 0.9460\n",
            "Epoch 2149/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2348 - accuracy: 0.9258 - val_loss: 0.1945 - val_accuracy: 0.9435\n",
            "Epoch 2150/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2313 - accuracy: 0.9239 - val_loss: 0.1967 - val_accuracy: 0.9450\n",
            "Epoch 2151/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2408 - accuracy: 0.9269 - val_loss: 0.1909 - val_accuracy: 0.9435\n",
            "Epoch 2152/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2335 - accuracy: 0.9224 - val_loss: 0.1968 - val_accuracy: 0.9460\n",
            "Epoch 2153/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2439 - accuracy: 0.9214 - val_loss: 0.1937 - val_accuracy: 0.9450\n",
            "Epoch 2154/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2417 - accuracy: 0.9208 - val_loss: 0.1946 - val_accuracy: 0.9450\n",
            "Epoch 2155/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2410 - accuracy: 0.9222 - val_loss: 0.1890 - val_accuracy: 0.9465\n",
            "Epoch 2156/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2330 - accuracy: 0.9251 - val_loss: 0.1906 - val_accuracy: 0.9455\n",
            "Epoch 2157/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2312 - accuracy: 0.9250 - val_loss: 0.1934 - val_accuracy: 0.9440\n",
            "Epoch 2158/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2333 - accuracy: 0.9236 - val_loss: 0.1953 - val_accuracy: 0.9445\n",
            "Epoch 2159/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2316 - accuracy: 0.9247 - val_loss: 0.1984 - val_accuracy: 0.9430\n",
            "Epoch 2160/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2341 - accuracy: 0.9271 - val_loss: 0.1946 - val_accuracy: 0.9445\n",
            "Epoch 2161/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2348 - accuracy: 0.9249 - val_loss: 0.1957 - val_accuracy: 0.9425\n",
            "Epoch 2162/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2342 - accuracy: 0.9237 - val_loss: 0.1937 - val_accuracy: 0.9455\n",
            "Epoch 2163/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2328 - accuracy: 0.9239 - val_loss: 0.1942 - val_accuracy: 0.9445\n",
            "Epoch 2164/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2304 - accuracy: 0.9259 - val_loss: 0.1953 - val_accuracy: 0.9425\n",
            "Epoch 2165/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2356 - accuracy: 0.9240 - val_loss: 0.1921 - val_accuracy: 0.9460\n",
            "Epoch 2166/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2250 - accuracy: 0.9260 - val_loss: 0.1900 - val_accuracy: 0.9455\n",
            "Epoch 2167/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2354 - accuracy: 0.9262 - val_loss: 0.1914 - val_accuracy: 0.9430\n",
            "Epoch 2168/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2274 - accuracy: 0.9266 - val_loss: 0.1962 - val_accuracy: 0.9445\n",
            "Epoch 2169/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2352 - accuracy: 0.9268 - val_loss: 0.1929 - val_accuracy: 0.9430\n",
            "Epoch 2170/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2243 - accuracy: 0.9289 - val_loss: 0.1870 - val_accuracy: 0.9445\n",
            "Epoch 2171/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2345 - accuracy: 0.9237 - val_loss: 0.1955 - val_accuracy: 0.9455\n",
            "Epoch 2172/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2302 - accuracy: 0.9250 - val_loss: 0.1946 - val_accuracy: 0.9435\n",
            "Epoch 2173/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2385 - accuracy: 0.9206 - val_loss: 0.1936 - val_accuracy: 0.9445\n",
            "Epoch 2174/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2314 - accuracy: 0.9254 - val_loss: 0.1927 - val_accuracy: 0.9465\n",
            "Epoch 2175/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2304 - accuracy: 0.9252 - val_loss: 0.1930 - val_accuracy: 0.9460\n",
            "Epoch 2176/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2373 - accuracy: 0.9268 - val_loss: 0.1955 - val_accuracy: 0.9430\n",
            "Epoch 2177/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2340 - accuracy: 0.9256 - val_loss: 0.1905 - val_accuracy: 0.9450\n",
            "Epoch 2178/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2258 - accuracy: 0.9284 - val_loss: 0.1908 - val_accuracy: 0.9455\n",
            "Epoch 2179/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2446 - accuracy: 0.9216 - val_loss: 0.1923 - val_accuracy: 0.9445\n",
            "Epoch 2180/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2373 - accuracy: 0.9233 - val_loss: 0.1977 - val_accuracy: 0.9440\n",
            "Epoch 2181/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2379 - accuracy: 0.9229 - val_loss: 0.1906 - val_accuracy: 0.9465\n",
            "Epoch 2182/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2431 - accuracy: 0.9211 - val_loss: 0.1961 - val_accuracy: 0.9465\n",
            "Epoch 2183/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2347 - accuracy: 0.9255 - val_loss: 0.1978 - val_accuracy: 0.9450\n",
            "Epoch 2184/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2355 - accuracy: 0.9233 - val_loss: 0.1885 - val_accuracy: 0.9455\n",
            "Epoch 2185/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2331 - accuracy: 0.9246 - val_loss: 0.1924 - val_accuracy: 0.9455\n",
            "Epoch 2186/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2421 - accuracy: 0.9254 - val_loss: 0.1929 - val_accuracy: 0.9455\n",
            "Epoch 2187/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2366 - accuracy: 0.9243 - val_loss: 0.1915 - val_accuracy: 0.9440\n",
            "Epoch 2188/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2347 - accuracy: 0.9237 - val_loss: 0.1902 - val_accuracy: 0.9435\n",
            "Epoch 2189/6000\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2289 - accuracy: 0.9244 - val_loss: 0.1928 - val_accuracy: 0.9450\n",
            "Epoch 2190/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2344 - accuracy: 0.9219 - val_loss: 0.1916 - val_accuracy: 0.9445\n",
            "Epoch 2191/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2289 - accuracy: 0.9266 - val_loss: 0.1904 - val_accuracy: 0.9450\n",
            "Epoch 2192/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2335 - accuracy: 0.9231 - val_loss: 0.1929 - val_accuracy: 0.9445\n",
            "Epoch 2193/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2355 - accuracy: 0.9245 - val_loss: 0.1950 - val_accuracy: 0.9440\n",
            "Epoch 2194/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2367 - accuracy: 0.9239 - val_loss: 0.2015 - val_accuracy: 0.9410\n",
            "Epoch 2195/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2397 - accuracy: 0.9244 - val_loss: 0.1899 - val_accuracy: 0.9435\n",
            "Epoch 2196/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2276 - accuracy: 0.9279 - val_loss: 0.1892 - val_accuracy: 0.9450\n",
            "Epoch 2197/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2321 - accuracy: 0.9274 - val_loss: 0.1903 - val_accuracy: 0.9450\n",
            "Epoch 2198/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2317 - accuracy: 0.9247 - val_loss: 0.1939 - val_accuracy: 0.9445\n",
            "Epoch 2199/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2383 - accuracy: 0.9220 - val_loss: 0.1942 - val_accuracy: 0.9430\n",
            "Epoch 2200/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2423 - accuracy: 0.9212 - val_loss: 0.1973 - val_accuracy: 0.9445\n",
            "Epoch 2201/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2387 - accuracy: 0.9256 - val_loss: 0.1931 - val_accuracy: 0.9435\n",
            "Epoch 2202/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2338 - accuracy: 0.9245 - val_loss: 0.1884 - val_accuracy: 0.9440\n",
            "Epoch 2203/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2294 - accuracy: 0.9250 - val_loss: 0.1967 - val_accuracy: 0.9435\n",
            "Epoch 2204/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2272 - accuracy: 0.9251 - val_loss: 0.2020 - val_accuracy: 0.9385\n",
            "Epoch 2205/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2467 - accuracy: 0.9219 - val_loss: 0.1953 - val_accuracy: 0.9420\n",
            "Epoch 2206/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2398 - accuracy: 0.9246 - val_loss: 0.1927 - val_accuracy: 0.9440\n",
            "Epoch 2207/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2323 - accuracy: 0.9254 - val_loss: 0.1944 - val_accuracy: 0.9430\n",
            "Epoch 2208/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2397 - accuracy: 0.9206 - val_loss: 0.1872 - val_accuracy: 0.9460\n",
            "Epoch 2209/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2367 - accuracy: 0.9214 - val_loss: 0.1927 - val_accuracy: 0.9440\n",
            "Epoch 2210/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2365 - accuracy: 0.9216 - val_loss: 0.1958 - val_accuracy: 0.9430\n",
            "Epoch 2211/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2438 - accuracy: 0.9246 - val_loss: 0.1937 - val_accuracy: 0.9440\n",
            "Epoch 2212/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2282 - accuracy: 0.9275 - val_loss: 0.1971 - val_accuracy: 0.9445\n",
            "Epoch 2213/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2322 - accuracy: 0.9218 - val_loss: 0.1904 - val_accuracy: 0.9460\n",
            "Epoch 2214/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2355 - accuracy: 0.9235 - val_loss: 0.1948 - val_accuracy: 0.9435\n",
            "Epoch 2215/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2358 - accuracy: 0.9231 - val_loss: 0.1965 - val_accuracy: 0.9445\n",
            "Epoch 2216/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2403 - accuracy: 0.9204 - val_loss: 0.1956 - val_accuracy: 0.9445\n",
            "Epoch 2217/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2287 - accuracy: 0.9252 - val_loss: 0.1936 - val_accuracy: 0.9450\n",
            "Epoch 2218/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2359 - accuracy: 0.9225 - val_loss: 0.1901 - val_accuracy: 0.9445\n",
            "Epoch 2219/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2374 - accuracy: 0.9241 - val_loss: 0.1938 - val_accuracy: 0.9450\n",
            "Epoch 2220/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2390 - accuracy: 0.9212 - val_loss: 0.1950 - val_accuracy: 0.9455\n",
            "Epoch 2221/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2320 - accuracy: 0.9265 - val_loss: 0.1964 - val_accuracy: 0.9455\n",
            "Epoch 2222/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2371 - accuracy: 0.9237 - val_loss: 0.1905 - val_accuracy: 0.9435\n",
            "Epoch 2223/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2425 - accuracy: 0.9258 - val_loss: 0.1926 - val_accuracy: 0.9435\n",
            "Epoch 2224/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2372 - accuracy: 0.9219 - val_loss: 0.1941 - val_accuracy: 0.9475\n",
            "Epoch 2225/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2328 - accuracy: 0.9239 - val_loss: 0.1904 - val_accuracy: 0.9475\n",
            "Epoch 2226/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2328 - accuracy: 0.9240 - val_loss: 0.1908 - val_accuracy: 0.9460\n",
            "Epoch 2227/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2336 - accuracy: 0.9262 - val_loss: 0.1989 - val_accuracy: 0.9450\n",
            "Epoch 2228/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2332 - accuracy: 0.9261 - val_loss: 0.1917 - val_accuracy: 0.9440\n",
            "Epoch 2229/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2307 - accuracy: 0.9239 - val_loss: 0.1895 - val_accuracy: 0.9450\n",
            "Epoch 2230/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2363 - accuracy: 0.9239 - val_loss: 0.1921 - val_accuracy: 0.9450\n",
            "Epoch 2231/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2333 - accuracy: 0.9239 - val_loss: 0.1926 - val_accuracy: 0.9450\n",
            "Epoch 2232/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2323 - accuracy: 0.9239 - val_loss: 0.1904 - val_accuracy: 0.9445\n",
            "Epoch 2233/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2371 - accuracy: 0.9252 - val_loss: 0.1879 - val_accuracy: 0.9445\n",
            "Epoch 2234/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2234 - accuracy: 0.9261 - val_loss: 0.1903 - val_accuracy: 0.9435\n",
            "Epoch 2235/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2385 - accuracy: 0.9226 - val_loss: 0.1899 - val_accuracy: 0.9450\n",
            "Epoch 2236/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2280 - accuracy: 0.9235 - val_loss: 0.1928 - val_accuracy: 0.9460\n",
            "Epoch 2237/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2299 - accuracy: 0.9273 - val_loss: 0.1896 - val_accuracy: 0.9465\n",
            "Epoch 2238/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2248 - accuracy: 0.9276 - val_loss: 0.1914 - val_accuracy: 0.9440\n",
            "Epoch 2239/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2414 - accuracy: 0.9220 - val_loss: 0.1908 - val_accuracy: 0.9440\n",
            "Epoch 2240/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2339 - accuracy: 0.9230 - val_loss: 0.1909 - val_accuracy: 0.9435\n",
            "Epoch 2241/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2347 - accuracy: 0.9249 - val_loss: 0.1887 - val_accuracy: 0.9435\n",
            "Epoch 2242/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2478 - accuracy: 0.9225 - val_loss: 0.1972 - val_accuracy: 0.9440\n",
            "Epoch 2243/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2391 - accuracy: 0.9250 - val_loss: 0.1927 - val_accuracy: 0.9450\n",
            "Epoch 2244/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2352 - accuracy: 0.9230 - val_loss: 0.1906 - val_accuracy: 0.9440\n",
            "Epoch 2245/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2424 - accuracy: 0.9237 - val_loss: 0.1913 - val_accuracy: 0.9450\n",
            "Epoch 2246/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2393 - accuracy: 0.9247 - val_loss: 0.1939 - val_accuracy: 0.9450\n",
            "Epoch 2247/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2382 - accuracy: 0.9273 - val_loss: 0.1922 - val_accuracy: 0.9450\n",
            "Epoch 2248/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2267 - accuracy: 0.9264 - val_loss: 0.1896 - val_accuracy: 0.9475\n",
            "Epoch 2249/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2449 - accuracy: 0.9243 - val_loss: 0.1975 - val_accuracy: 0.9450\n",
            "Epoch 2250/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2459 - accuracy: 0.9239 - val_loss: 0.1960 - val_accuracy: 0.9440\n",
            "Epoch 2251/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2382 - accuracy: 0.9200 - val_loss: 0.1929 - val_accuracy: 0.9440\n",
            "Epoch 2252/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2309 - accuracy: 0.9252 - val_loss: 0.1897 - val_accuracy: 0.9450\n",
            "Epoch 2253/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2356 - accuracy: 0.9256 - val_loss: 0.1936 - val_accuracy: 0.9440\n",
            "Epoch 2254/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2326 - accuracy: 0.9269 - val_loss: 0.1903 - val_accuracy: 0.9445\n",
            "Epoch 2255/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2285 - accuracy: 0.9250 - val_loss: 0.1917 - val_accuracy: 0.9445\n",
            "Epoch 2256/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2328 - accuracy: 0.9279 - val_loss: 0.1917 - val_accuracy: 0.9450\n",
            "Epoch 2257/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2464 - accuracy: 0.9199 - val_loss: 0.2002 - val_accuracy: 0.9440\n",
            "Epoch 2258/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2299 - accuracy: 0.9245 - val_loss: 0.1881 - val_accuracy: 0.9435\n",
            "Epoch 2259/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2488 - accuracy: 0.9269 - val_loss: 0.1890 - val_accuracy: 0.9460\n",
            "Epoch 2260/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2392 - accuracy: 0.9246 - val_loss: 0.1948 - val_accuracy: 0.9460\n",
            "Epoch 2261/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2354 - accuracy: 0.9231 - val_loss: 0.1925 - val_accuracy: 0.9440\n",
            "Epoch 2262/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2320 - accuracy: 0.9246 - val_loss: 0.1897 - val_accuracy: 0.9440\n",
            "Epoch 2263/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2354 - accuracy: 0.9256 - val_loss: 0.1955 - val_accuracy: 0.9435\n",
            "Epoch 2264/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2368 - accuracy: 0.9246 - val_loss: 0.1918 - val_accuracy: 0.9455\n",
            "Epoch 2265/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2285 - accuracy: 0.9239 - val_loss: 0.1916 - val_accuracy: 0.9440\n",
            "Epoch 2266/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2479 - accuracy: 0.9235 - val_loss: 0.1939 - val_accuracy: 0.9445\n",
            "Epoch 2267/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2210 - accuracy: 0.9299 - val_loss: 0.1931 - val_accuracy: 0.9465\n",
            "Epoch 2268/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2295 - accuracy: 0.9270 - val_loss: 0.1951 - val_accuracy: 0.9430\n",
            "Epoch 2269/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2300 - accuracy: 0.9279 - val_loss: 0.1934 - val_accuracy: 0.9450\n",
            "Epoch 2270/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2274 - accuracy: 0.9277 - val_loss: 0.1948 - val_accuracy: 0.9450\n",
            "Epoch 2271/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2273 - accuracy: 0.9281 - val_loss: 0.1916 - val_accuracy: 0.9455\n",
            "Epoch 2272/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2427 - accuracy: 0.9236 - val_loss: 0.1937 - val_accuracy: 0.9440\n",
            "Epoch 2273/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2332 - accuracy: 0.9219 - val_loss: 0.1911 - val_accuracy: 0.9425\n",
            "Epoch 2274/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2339 - accuracy: 0.9240 - val_loss: 0.1931 - val_accuracy: 0.9445\n",
            "Epoch 2275/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2272 - accuracy: 0.9245 - val_loss: 0.1948 - val_accuracy: 0.9450\n",
            "Epoch 2276/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2328 - accuracy: 0.9240 - val_loss: 0.1955 - val_accuracy: 0.9425\n",
            "Epoch 2277/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2304 - accuracy: 0.9271 - val_loss: 0.1946 - val_accuracy: 0.9450\n",
            "Epoch 2278/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2405 - accuracy: 0.9237 - val_loss: 0.1890 - val_accuracy: 0.9465\n",
            "Epoch 2279/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2398 - accuracy: 0.9250 - val_loss: 0.1913 - val_accuracy: 0.9445\n",
            "Epoch 2280/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2349 - accuracy: 0.9241 - val_loss: 0.1934 - val_accuracy: 0.9485\n",
            "Epoch 2281/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2359 - accuracy: 0.9252 - val_loss: 0.1901 - val_accuracy: 0.9450\n",
            "Epoch 2282/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2363 - accuracy: 0.9256 - val_loss: 0.1923 - val_accuracy: 0.9450\n",
            "Epoch 2283/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2358 - accuracy: 0.9249 - val_loss: 0.1949 - val_accuracy: 0.9435\n",
            "Epoch 2284/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2342 - accuracy: 0.9250 - val_loss: 0.1921 - val_accuracy: 0.9445\n",
            "Epoch 2285/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2334 - accuracy: 0.9251 - val_loss: 0.1912 - val_accuracy: 0.9445\n",
            "Epoch 2286/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2285 - accuracy: 0.9249 - val_loss: 0.1922 - val_accuracy: 0.9450\n",
            "Epoch 2287/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2384 - accuracy: 0.9222 - val_loss: 0.1918 - val_accuracy: 0.9440\n",
            "Epoch 2288/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2325 - accuracy: 0.9256 - val_loss: 0.1957 - val_accuracy: 0.9435\n",
            "Epoch 2289/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2332 - accuracy: 0.9235 - val_loss: 0.1933 - val_accuracy: 0.9455\n",
            "Epoch 2290/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2345 - accuracy: 0.9215 - val_loss: 0.1939 - val_accuracy: 0.9430\n",
            "Epoch 2291/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2421 - accuracy: 0.9244 - val_loss: 0.1893 - val_accuracy: 0.9440\n",
            "Epoch 2292/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2304 - accuracy: 0.9252 - val_loss: 0.1950 - val_accuracy: 0.9435\n",
            "Epoch 2293/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2392 - accuracy: 0.9226 - val_loss: 0.1929 - val_accuracy: 0.9440\n",
            "Epoch 2294/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2368 - accuracy: 0.9264 - val_loss: 0.1924 - val_accuracy: 0.9455\n",
            "Epoch 2295/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2359 - accuracy: 0.9224 - val_loss: 0.1954 - val_accuracy: 0.9445\n",
            "Epoch 2296/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2382 - accuracy: 0.9234 - val_loss: 0.1927 - val_accuracy: 0.9460\n",
            "Epoch 2297/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2314 - accuracy: 0.9255 - val_loss: 0.1955 - val_accuracy: 0.9460\n",
            "Epoch 2298/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2326 - accuracy: 0.9260 - val_loss: 0.1943 - val_accuracy: 0.9450\n",
            "Epoch 2299/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2311 - accuracy: 0.9247 - val_loss: 0.1937 - val_accuracy: 0.9460\n",
            "Epoch 2300/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2487 - accuracy: 0.9243 - val_loss: 0.1912 - val_accuracy: 0.9450\n",
            "Epoch 2301/6000\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2336 - accuracy: 0.9236 - val_loss: 0.1925 - val_accuracy: 0.9425\n",
            "Epoch 2302/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2378 - accuracy: 0.9255 - val_loss: 0.1971 - val_accuracy: 0.9450\n",
            "Epoch 2303/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2327 - accuracy: 0.9277 - val_loss: 0.1916 - val_accuracy: 0.9435\n",
            "Epoch 2304/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2304 - accuracy: 0.9246 - val_loss: 0.1926 - val_accuracy: 0.9430\n",
            "Epoch 2305/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2319 - accuracy: 0.9240 - val_loss: 0.1937 - val_accuracy: 0.9440\n",
            "Epoch 2306/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2272 - accuracy: 0.9247 - val_loss: 0.1951 - val_accuracy: 0.9435\n",
            "Epoch 2307/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2421 - accuracy: 0.9205 - val_loss: 0.1938 - val_accuracy: 0.9415\n",
            "Epoch 2308/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2340 - accuracy: 0.9235 - val_loss: 0.1912 - val_accuracy: 0.9425\n",
            "Epoch 2309/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2304 - accuracy: 0.9259 - val_loss: 0.1930 - val_accuracy: 0.9440\n",
            "Epoch 2310/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2399 - accuracy: 0.9252 - val_loss: 0.1932 - val_accuracy: 0.9430\n",
            "Epoch 2311/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2333 - accuracy: 0.9241 - val_loss: 0.1962 - val_accuracy: 0.9430\n",
            "Epoch 2312/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2359 - accuracy: 0.9226 - val_loss: 0.1889 - val_accuracy: 0.9450\n",
            "Epoch 2313/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2395 - accuracy: 0.9237 - val_loss: 0.1916 - val_accuracy: 0.9425\n",
            "Epoch 2314/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2320 - accuracy: 0.9251 - val_loss: 0.1942 - val_accuracy: 0.9440\n",
            "Epoch 2315/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2397 - accuracy: 0.9247 - val_loss: 0.1912 - val_accuracy: 0.9430\n",
            "Epoch 2316/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2308 - accuracy: 0.9243 - val_loss: 0.1898 - val_accuracy: 0.9440\n",
            "Epoch 2317/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2367 - accuracy: 0.9227 - val_loss: 0.1963 - val_accuracy: 0.9435\n",
            "Epoch 2318/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2396 - accuracy: 0.9227 - val_loss: 0.1896 - val_accuracy: 0.9450\n",
            "Epoch 2319/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2281 - accuracy: 0.9235 - val_loss: 0.1981 - val_accuracy: 0.9440\n",
            "Epoch 2320/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2252 - accuracy: 0.9241 - val_loss: 0.1928 - val_accuracy: 0.9435\n",
            "Epoch 2321/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2366 - accuracy: 0.9246 - val_loss: 0.1951 - val_accuracy: 0.9440\n",
            "Epoch 2322/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2283 - accuracy: 0.9270 - val_loss: 0.1957 - val_accuracy: 0.9460\n",
            "Epoch 2323/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2227 - accuracy: 0.9273 - val_loss: 0.1976 - val_accuracy: 0.9440\n",
            "Epoch 2324/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2319 - accuracy: 0.9222 - val_loss: 0.1921 - val_accuracy: 0.9475\n",
            "Epoch 2325/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2372 - accuracy: 0.9249 - val_loss: 0.1894 - val_accuracy: 0.9445\n",
            "Epoch 2326/6000\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2257 - accuracy: 0.9271 - val_loss: 0.1903 - val_accuracy: 0.9445\n",
            "Epoch 2327/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2223 - accuracy: 0.9310 - val_loss: 0.1921 - val_accuracy: 0.9430\n",
            "Epoch 2328/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2354 - accuracy: 0.9259 - val_loss: 0.1947 - val_accuracy: 0.9435\n",
            "Epoch 2329/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2231 - accuracy: 0.9260 - val_loss: 0.1928 - val_accuracy: 0.9460\n",
            "Epoch 2330/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2348 - accuracy: 0.9240 - val_loss: 0.1903 - val_accuracy: 0.9425\n",
            "Epoch 2331/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2424 - accuracy: 0.9229 - val_loss: 0.1920 - val_accuracy: 0.9455\n",
            "Epoch 2332/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2407 - accuracy: 0.9264 - val_loss: 0.1933 - val_accuracy: 0.9445\n",
            "Epoch 2333/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2488 - accuracy: 0.9225 - val_loss: 0.1863 - val_accuracy: 0.9445\n",
            "Epoch 2334/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2390 - accuracy: 0.9221 - val_loss: 0.1918 - val_accuracy: 0.9450\n",
            "Epoch 2335/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2421 - accuracy: 0.9289 - val_loss: 0.1933 - val_accuracy: 0.9435\n",
            "Epoch 2336/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2409 - accuracy: 0.9233 - val_loss: 0.1936 - val_accuracy: 0.9440\n",
            "Epoch 2337/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2290 - accuracy: 0.9222 - val_loss: 0.2012 - val_accuracy: 0.9415\n",
            "Epoch 2338/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2402 - accuracy: 0.9205 - val_loss: 0.1952 - val_accuracy: 0.9440\n",
            "Epoch 2339/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2305 - accuracy: 0.9241 - val_loss: 0.1933 - val_accuracy: 0.9440\n",
            "Epoch 2340/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2306 - accuracy: 0.9274 - val_loss: 0.1910 - val_accuracy: 0.9445\n",
            "Epoch 2341/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2295 - accuracy: 0.9243 - val_loss: 0.1951 - val_accuracy: 0.9460\n",
            "Epoch 2342/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2501 - accuracy: 0.9240 - val_loss: 0.1922 - val_accuracy: 0.9450\n",
            "Epoch 2343/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2338 - accuracy: 0.9239 - val_loss: 0.1914 - val_accuracy: 0.9425\n",
            "Epoch 2344/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2300 - accuracy: 0.9283 - val_loss: 0.1918 - val_accuracy: 0.9440\n",
            "Epoch 2345/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2440 - accuracy: 0.9290 - val_loss: 0.1972 - val_accuracy: 0.9440\n",
            "Epoch 2346/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2298 - accuracy: 0.9289 - val_loss: 0.1929 - val_accuracy: 0.9460\n",
            "Epoch 2347/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2410 - accuracy: 0.9236 - val_loss: 0.1924 - val_accuracy: 0.9460\n",
            "Epoch 2348/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2515 - accuracy: 0.9215 - val_loss: 0.1907 - val_accuracy: 0.9455\n",
            "Epoch 2349/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2359 - accuracy: 0.9243 - val_loss: 0.1894 - val_accuracy: 0.9445\n",
            "Epoch 2350/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2402 - accuracy: 0.9219 - val_loss: 0.1934 - val_accuracy: 0.9455\n",
            "Epoch 2351/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2446 - accuracy: 0.9205 - val_loss: 0.1959 - val_accuracy: 0.9460\n",
            "Epoch 2352/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2370 - accuracy: 0.9243 - val_loss: 0.1917 - val_accuracy: 0.9460\n",
            "Epoch 2353/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2321 - accuracy: 0.9270 - val_loss: 0.1930 - val_accuracy: 0.9450\n",
            "Epoch 2354/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2357 - accuracy: 0.9261 - val_loss: 0.1972 - val_accuracy: 0.9455\n",
            "Epoch 2355/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2454 - accuracy: 0.9241 - val_loss: 0.1945 - val_accuracy: 0.9455\n",
            "Epoch 2356/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2289 - accuracy: 0.9268 - val_loss: 0.1945 - val_accuracy: 0.9435\n",
            "Epoch 2357/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2315 - accuracy: 0.9252 - val_loss: 0.1942 - val_accuracy: 0.9435\n",
            "Epoch 2358/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2473 - accuracy: 0.9240 - val_loss: 0.1998 - val_accuracy: 0.9445\n",
            "Epoch 2359/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2444 - accuracy: 0.9264 - val_loss: 0.1915 - val_accuracy: 0.9450\n",
            "Epoch 2360/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2288 - accuracy: 0.9270 - val_loss: 0.1946 - val_accuracy: 0.9440\n",
            "Epoch 2361/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2264 - accuracy: 0.9264 - val_loss: 0.1918 - val_accuracy: 0.9465\n",
            "Epoch 2362/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2315 - accuracy: 0.9264 - val_loss: 0.1934 - val_accuracy: 0.9420\n",
            "Epoch 2363/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2352 - accuracy: 0.9240 - val_loss: 0.1943 - val_accuracy: 0.9440\n",
            "Epoch 2364/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2361 - accuracy: 0.9244 - val_loss: 0.1955 - val_accuracy: 0.9425\n",
            "Epoch 2365/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2386 - accuracy: 0.9268 - val_loss: 0.1919 - val_accuracy: 0.9470\n",
            "Epoch 2366/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2292 - accuracy: 0.9255 - val_loss: 0.1914 - val_accuracy: 0.9450\n",
            "Epoch 2367/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2433 - accuracy: 0.9209 - val_loss: 0.1941 - val_accuracy: 0.9475\n",
            "Epoch 2368/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2392 - accuracy: 0.9229 - val_loss: 0.1914 - val_accuracy: 0.9450\n",
            "Epoch 2369/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2327 - accuracy: 0.9254 - val_loss: 0.1937 - val_accuracy: 0.9430\n",
            "Epoch 2370/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2347 - accuracy: 0.9269 - val_loss: 0.1920 - val_accuracy: 0.9465\n",
            "Epoch 2371/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2561 - accuracy: 0.9258 - val_loss: 0.1920 - val_accuracy: 0.9445\n",
            "Epoch 2372/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2422 - accuracy: 0.9258 - val_loss: 0.1916 - val_accuracy: 0.9440\n",
            "Epoch 2373/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2284 - accuracy: 0.9260 - val_loss: 0.1939 - val_accuracy: 0.9450\n",
            "Epoch 2374/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2346 - accuracy: 0.9230 - val_loss: 0.1938 - val_accuracy: 0.9450\n",
            "Epoch 2375/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2264 - accuracy: 0.9264 - val_loss: 0.1946 - val_accuracy: 0.9435\n",
            "Epoch 2376/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2346 - accuracy: 0.9247 - val_loss: 0.1964 - val_accuracy: 0.9450\n",
            "Epoch 2377/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2335 - accuracy: 0.9240 - val_loss: 0.1983 - val_accuracy: 0.9440\n",
            "Epoch 2378/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2360 - accuracy: 0.9250 - val_loss: 0.1893 - val_accuracy: 0.9435\n",
            "Epoch 2379/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2606 - accuracy: 0.9189 - val_loss: 0.1939 - val_accuracy: 0.9470\n",
            "Epoch 2380/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2239 - accuracy: 0.9265 - val_loss: 0.1895 - val_accuracy: 0.9450\n",
            "Epoch 2381/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2258 - accuracy: 0.9249 - val_loss: 0.1936 - val_accuracy: 0.9475\n",
            "Epoch 2382/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2325 - accuracy: 0.9252 - val_loss: 0.1946 - val_accuracy: 0.9435\n",
            "Epoch 2383/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2296 - accuracy: 0.9259 - val_loss: 0.1917 - val_accuracy: 0.9445\n",
            "Epoch 2384/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2351 - accuracy: 0.9262 - val_loss: 0.1908 - val_accuracy: 0.9450\n",
            "Epoch 2385/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2402 - accuracy: 0.9216 - val_loss: 0.1896 - val_accuracy: 0.9435\n",
            "Epoch 2386/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2443 - accuracy: 0.9218 - val_loss: 0.1955 - val_accuracy: 0.9435\n",
            "Epoch 2387/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2226 - accuracy: 0.9283 - val_loss: 0.1904 - val_accuracy: 0.9440\n",
            "Epoch 2388/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2594 - accuracy: 0.9246 - val_loss: 0.1941 - val_accuracy: 0.9445\n",
            "Epoch 2389/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2394 - accuracy: 0.9215 - val_loss: 0.1915 - val_accuracy: 0.9440\n",
            "Epoch 2390/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2322 - accuracy: 0.9209 - val_loss: 0.1915 - val_accuracy: 0.9430\n",
            "Epoch 2391/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2345 - accuracy: 0.9251 - val_loss: 0.1930 - val_accuracy: 0.9440\n",
            "Epoch 2392/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2369 - accuracy: 0.9190 - val_loss: 0.1940 - val_accuracy: 0.9430\n",
            "Epoch 2393/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2427 - accuracy: 0.9196 - val_loss: 0.1946 - val_accuracy: 0.9450\n",
            "Epoch 2394/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2308 - accuracy: 0.9240 - val_loss: 0.1953 - val_accuracy: 0.9430\n",
            "Epoch 2395/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2236 - accuracy: 0.9279 - val_loss: 0.1911 - val_accuracy: 0.9415\n",
            "Epoch 2396/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2320 - accuracy: 0.9265 - val_loss: 0.1957 - val_accuracy: 0.9445\n",
            "Epoch 2397/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2424 - accuracy: 0.9241 - val_loss: 0.1918 - val_accuracy: 0.9445\n",
            "Epoch 2398/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2346 - accuracy: 0.9243 - val_loss: 0.1893 - val_accuracy: 0.9455\n",
            "Epoch 2399/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2312 - accuracy: 0.9230 - val_loss: 0.1934 - val_accuracy: 0.9445\n",
            "Epoch 2400/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2336 - accuracy: 0.9254 - val_loss: 0.1940 - val_accuracy: 0.9440\n",
            "Epoch 2401/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2307 - accuracy: 0.9233 - val_loss: 0.1965 - val_accuracy: 0.9425\n",
            "Epoch 2402/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2413 - accuracy: 0.9226 - val_loss: 0.1959 - val_accuracy: 0.9440\n",
            "Epoch 2403/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2384 - accuracy: 0.9268 - val_loss: 0.1920 - val_accuracy: 0.9445\n",
            "Epoch 2404/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2290 - accuracy: 0.9264 - val_loss: 0.1861 - val_accuracy: 0.9465\n",
            "Epoch 2405/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2334 - accuracy: 0.9261 - val_loss: 0.1982 - val_accuracy: 0.9440\n",
            "Epoch 2406/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2263 - accuracy: 0.9270 - val_loss: 0.1924 - val_accuracy: 0.9440\n",
            "Epoch 2407/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2483 - accuracy: 0.9251 - val_loss: 0.1906 - val_accuracy: 0.9455\n",
            "Epoch 2408/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2298 - accuracy: 0.9240 - val_loss: 0.1958 - val_accuracy: 0.9440\n",
            "Epoch 2409/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2300 - accuracy: 0.9245 - val_loss: 0.1921 - val_accuracy: 0.9435\n",
            "Epoch 2410/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2389 - accuracy: 0.9194 - val_loss: 0.1933 - val_accuracy: 0.9450\n",
            "Epoch 2411/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2246 - accuracy: 0.9268 - val_loss: 0.1900 - val_accuracy: 0.9430\n",
            "Epoch 2412/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2420 - accuracy: 0.9204 - val_loss: 0.1943 - val_accuracy: 0.9425\n",
            "Epoch 2413/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2251 - accuracy: 0.9264 - val_loss: 0.1904 - val_accuracy: 0.9435\n",
            "Epoch 2414/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2248 - accuracy: 0.9265 - val_loss: 0.1940 - val_accuracy: 0.9460\n",
            "Epoch 2415/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2281 - accuracy: 0.9279 - val_loss: 0.1939 - val_accuracy: 0.9465\n",
            "Epoch 2416/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2358 - accuracy: 0.9226 - val_loss: 0.1960 - val_accuracy: 0.9455\n",
            "Epoch 2417/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2378 - accuracy: 0.9265 - val_loss: 0.1935 - val_accuracy: 0.9470\n",
            "Epoch 2418/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2385 - accuracy: 0.9243 - val_loss: 0.1953 - val_accuracy: 0.9465\n",
            "Epoch 2419/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2328 - accuracy: 0.9265 - val_loss: 0.1930 - val_accuracy: 0.9450\n",
            "Epoch 2420/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2408 - accuracy: 0.9231 - val_loss: 0.1877 - val_accuracy: 0.9450\n",
            "Epoch 2421/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2357 - accuracy: 0.9241 - val_loss: 0.1915 - val_accuracy: 0.9465\n",
            "Epoch 2422/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2260 - accuracy: 0.9270 - val_loss: 0.1899 - val_accuracy: 0.9450\n",
            "Epoch 2423/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2280 - accuracy: 0.9262 - val_loss: 0.1939 - val_accuracy: 0.9445\n",
            "Epoch 2424/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2338 - accuracy: 0.9259 - val_loss: 0.1943 - val_accuracy: 0.9440\n",
            "Epoch 2425/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2297 - accuracy: 0.9261 - val_loss: 0.1926 - val_accuracy: 0.9460\n",
            "Epoch 2426/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2318 - accuracy: 0.9221 - val_loss: 0.1924 - val_accuracy: 0.9435\n",
            "Epoch 2427/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2328 - accuracy: 0.9247 - val_loss: 0.1906 - val_accuracy: 0.9435\n",
            "Epoch 2428/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2328 - accuracy: 0.9252 - val_loss: 0.1911 - val_accuracy: 0.9445\n",
            "Epoch 2429/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2314 - accuracy: 0.9245 - val_loss: 0.1916 - val_accuracy: 0.9455\n",
            "Epoch 2430/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2306 - accuracy: 0.9254 - val_loss: 0.1897 - val_accuracy: 0.9440\n",
            "Epoch 2431/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2318 - accuracy: 0.9241 - val_loss: 0.1928 - val_accuracy: 0.9430\n",
            "Epoch 2432/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2336 - accuracy: 0.9259 - val_loss: 0.1898 - val_accuracy: 0.9460\n",
            "Epoch 2433/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2375 - accuracy: 0.9234 - val_loss: 0.1913 - val_accuracy: 0.9445\n",
            "Epoch 2434/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2297 - accuracy: 0.9258 - val_loss: 0.1933 - val_accuracy: 0.9460\n",
            "Epoch 2435/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2288 - accuracy: 0.9261 - val_loss: 0.1962 - val_accuracy: 0.9440\n",
            "Epoch 2436/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2381 - accuracy: 0.9259 - val_loss: 0.1938 - val_accuracy: 0.9440\n",
            "Epoch 2437/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2300 - accuracy: 0.9233 - val_loss: 0.1917 - val_accuracy: 0.9440\n",
            "Epoch 2438/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2363 - accuracy: 0.9236 - val_loss: 0.1917 - val_accuracy: 0.9460\n",
            "Epoch 2439/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2267 - accuracy: 0.9290 - val_loss: 0.1908 - val_accuracy: 0.9450\n",
            "Epoch 2440/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2336 - accuracy: 0.9240 - val_loss: 0.1953 - val_accuracy: 0.9435\n",
            "Epoch 2441/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2326 - accuracy: 0.9269 - val_loss: 0.1923 - val_accuracy: 0.9430\n",
            "Epoch 2442/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2409 - accuracy: 0.9234 - val_loss: 0.2012 - val_accuracy: 0.9410\n",
            "Epoch 2443/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2444 - accuracy: 0.9251 - val_loss: 0.1929 - val_accuracy: 0.9450\n",
            "Epoch 2444/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2300 - accuracy: 0.9289 - val_loss: 0.1951 - val_accuracy: 0.9445\n",
            "Epoch 2445/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2329 - accuracy: 0.9258 - val_loss: 0.1955 - val_accuracy: 0.9450\n",
            "Epoch 2446/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2411 - accuracy: 0.9237 - val_loss: 0.1945 - val_accuracy: 0.9450\n",
            "Epoch 2447/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2324 - accuracy: 0.9250 - val_loss: 0.1960 - val_accuracy: 0.9450\n",
            "Epoch 2448/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2296 - accuracy: 0.9240 - val_loss: 0.1929 - val_accuracy: 0.9450\n",
            "Epoch 2449/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2334 - accuracy: 0.9256 - val_loss: 0.1926 - val_accuracy: 0.9465\n",
            "Epoch 2450/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2237 - accuracy: 0.9273 - val_loss: 0.1894 - val_accuracy: 0.9455\n",
            "Epoch 2451/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2249 - accuracy: 0.9273 - val_loss: 0.1947 - val_accuracy: 0.9460\n",
            "Epoch 2452/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2409 - accuracy: 0.9258 - val_loss: 0.1910 - val_accuracy: 0.9450\n",
            "Epoch 2453/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2331 - accuracy: 0.9255 - val_loss: 0.1899 - val_accuracy: 0.9470\n",
            "Epoch 2454/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2332 - accuracy: 0.9231 - val_loss: 0.1904 - val_accuracy: 0.9440\n",
            "Epoch 2455/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2283 - accuracy: 0.9246 - val_loss: 0.1936 - val_accuracy: 0.9425\n",
            "Epoch 2456/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2314 - accuracy: 0.9264 - val_loss: 0.1969 - val_accuracy: 0.9450\n",
            "Epoch 2457/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2340 - accuracy: 0.9243 - val_loss: 0.1917 - val_accuracy: 0.9465\n",
            "Epoch 2458/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2281 - accuracy: 0.9291 - val_loss: 0.1942 - val_accuracy: 0.9445\n",
            "Epoch 2459/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2295 - accuracy: 0.9283 - val_loss: 0.1918 - val_accuracy: 0.9455\n",
            "Epoch 2460/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2357 - accuracy: 0.9256 - val_loss: 0.1909 - val_accuracy: 0.9450\n",
            "Epoch 2461/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2493 - accuracy: 0.9199 - val_loss: 0.1916 - val_accuracy: 0.9455\n",
            "Epoch 2462/6000\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2257 - accuracy: 0.9249 - val_loss: 0.1887 - val_accuracy: 0.9460\n",
            "Epoch 2463/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2300 - accuracy: 0.9245 - val_loss: 0.1928 - val_accuracy: 0.9440\n",
            "Epoch 2464/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2328 - accuracy: 0.9249 - val_loss: 0.1928 - val_accuracy: 0.9445\n",
            "Epoch 2465/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2382 - accuracy: 0.9246 - val_loss: 0.1972 - val_accuracy: 0.9420\n",
            "Epoch 2466/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2329 - accuracy: 0.9243 - val_loss: 0.1987 - val_accuracy: 0.9435\n",
            "Epoch 2467/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2453 - accuracy: 0.9254 - val_loss: 0.1939 - val_accuracy: 0.9455\n",
            "Epoch 2468/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2457 - accuracy: 0.9249 - val_loss: 0.1954 - val_accuracy: 0.9445\n",
            "Epoch 2469/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2319 - accuracy: 0.9249 - val_loss: 0.1901 - val_accuracy: 0.9460\n",
            "Epoch 2470/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2290 - accuracy: 0.9227 - val_loss: 0.1911 - val_accuracy: 0.9445\n",
            "Epoch 2471/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2316 - accuracy: 0.9266 - val_loss: 0.1884 - val_accuracy: 0.9455\n",
            "Epoch 2472/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2311 - accuracy: 0.9251 - val_loss: 0.1949 - val_accuracy: 0.9455\n",
            "Epoch 2473/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2291 - accuracy: 0.9243 - val_loss: 0.1923 - val_accuracy: 0.9455\n",
            "Epoch 2474/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2427 - accuracy: 0.9231 - val_loss: 0.1987 - val_accuracy: 0.9430\n",
            "Epoch 2475/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2351 - accuracy: 0.9230 - val_loss: 0.1970 - val_accuracy: 0.9430\n",
            "Epoch 2476/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2312 - accuracy: 0.9266 - val_loss: 0.1924 - val_accuracy: 0.9455\n",
            "Epoch 2477/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2290 - accuracy: 0.9256 - val_loss: 0.1922 - val_accuracy: 0.9450\n",
            "Epoch 2478/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2416 - accuracy: 0.9204 - val_loss: 0.1930 - val_accuracy: 0.9460\n",
            "Epoch 2479/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2345 - accuracy: 0.9226 - val_loss: 0.1957 - val_accuracy: 0.9440\n",
            "Epoch 2480/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2351 - accuracy: 0.9258 - val_loss: 0.1949 - val_accuracy: 0.9440\n",
            "Epoch 2481/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2357 - accuracy: 0.9250 - val_loss: 0.1941 - val_accuracy: 0.9440\n",
            "Epoch 2482/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2322 - accuracy: 0.9258 - val_loss: 0.1926 - val_accuracy: 0.9460\n",
            "Epoch 2483/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2281 - accuracy: 0.9274 - val_loss: 0.1909 - val_accuracy: 0.9440\n",
            "Epoch 2484/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2382 - accuracy: 0.9254 - val_loss: 0.1972 - val_accuracy: 0.9420\n",
            "Epoch 2485/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2327 - accuracy: 0.9244 - val_loss: 0.1902 - val_accuracy: 0.9440\n",
            "Epoch 2486/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2411 - accuracy: 0.9259 - val_loss: 0.1922 - val_accuracy: 0.9455\n",
            "Epoch 2487/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2309 - accuracy: 0.9256 - val_loss: 0.1913 - val_accuracy: 0.9455\n",
            "Epoch 2488/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2331 - accuracy: 0.9229 - val_loss: 0.1908 - val_accuracy: 0.9435\n",
            "Epoch 2489/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2318 - accuracy: 0.9285 - val_loss: 0.1886 - val_accuracy: 0.9445\n",
            "Epoch 2490/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2293 - accuracy: 0.9260 - val_loss: 0.1932 - val_accuracy: 0.9435\n",
            "Epoch 2491/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2367 - accuracy: 0.9252 - val_loss: 0.1927 - val_accuracy: 0.9465\n",
            "Epoch 2492/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2388 - accuracy: 0.9233 - val_loss: 0.1891 - val_accuracy: 0.9450\n",
            "Epoch 2493/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2354 - accuracy: 0.9271 - val_loss: 0.1907 - val_accuracy: 0.9455\n",
            "Epoch 2494/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2423 - accuracy: 0.9216 - val_loss: 0.1907 - val_accuracy: 0.9445\n",
            "Epoch 2495/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2416 - accuracy: 0.9240 - val_loss: 0.1902 - val_accuracy: 0.9450\n",
            "Epoch 2496/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2338 - accuracy: 0.9234 - val_loss: 0.1920 - val_accuracy: 0.9470\n",
            "Epoch 2497/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2413 - accuracy: 0.9224 - val_loss: 0.1899 - val_accuracy: 0.9465\n",
            "Epoch 2498/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2369 - accuracy: 0.9250 - val_loss: 0.1893 - val_accuracy: 0.9465\n",
            "Epoch 2499/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2324 - accuracy: 0.9266 - val_loss: 0.1948 - val_accuracy: 0.9460\n",
            "Epoch 2500/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2387 - accuracy: 0.9240 - val_loss: 0.1917 - val_accuracy: 0.9450\n",
            "Epoch 2501/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2312 - accuracy: 0.9250 - val_loss: 0.1968 - val_accuracy: 0.9435\n",
            "Epoch 2502/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2347 - accuracy: 0.9255 - val_loss: 0.1907 - val_accuracy: 0.9445\n",
            "Epoch 2503/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2278 - accuracy: 0.9258 - val_loss: 0.1893 - val_accuracy: 0.9450\n",
            "Epoch 2504/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2298 - accuracy: 0.9235 - val_loss: 0.1985 - val_accuracy: 0.9445\n",
            "Epoch 2505/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2280 - accuracy: 0.9256 - val_loss: 0.1918 - val_accuracy: 0.9435\n",
            "Epoch 2506/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2413 - accuracy: 0.9218 - val_loss: 0.1885 - val_accuracy: 0.9450\n",
            "Epoch 2507/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2308 - accuracy: 0.9226 - val_loss: 0.1895 - val_accuracy: 0.9460\n",
            "Epoch 2508/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2347 - accuracy: 0.9247 - val_loss: 0.1986 - val_accuracy: 0.9455\n",
            "Epoch 2509/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2503 - accuracy: 0.9227 - val_loss: 0.1887 - val_accuracy: 0.9465\n",
            "Epoch 2510/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2248 - accuracy: 0.9255 - val_loss: 0.1895 - val_accuracy: 0.9440\n",
            "Epoch 2511/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2385 - accuracy: 0.9235 - val_loss: 0.1926 - val_accuracy: 0.9430\n",
            "Epoch 2512/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2290 - accuracy: 0.9258 - val_loss: 0.1949 - val_accuracy: 0.9430\n",
            "Epoch 2513/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2490 - accuracy: 0.9244 - val_loss: 0.1966 - val_accuracy: 0.9455\n",
            "Epoch 2514/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2316 - accuracy: 0.9270 - val_loss: 0.1968 - val_accuracy: 0.9445\n",
            "Epoch 2515/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2342 - accuracy: 0.9249 - val_loss: 0.1958 - val_accuracy: 0.9435\n",
            "Epoch 2516/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2320 - accuracy: 0.9276 - val_loss: 0.1925 - val_accuracy: 0.9455\n",
            "Epoch 2517/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2320 - accuracy: 0.9252 - val_loss: 0.1915 - val_accuracy: 0.9460\n",
            "Epoch 2518/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2525 - accuracy: 0.9233 - val_loss: 0.1983 - val_accuracy: 0.9435\n",
            "Epoch 2519/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2272 - accuracy: 0.9252 - val_loss: 0.1939 - val_accuracy: 0.9440\n",
            "Epoch 2520/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2411 - accuracy: 0.9251 - val_loss: 0.1968 - val_accuracy: 0.9460\n",
            "Epoch 2521/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2295 - accuracy: 0.9255 - val_loss: 0.1990 - val_accuracy: 0.9440\n",
            "Epoch 2522/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2295 - accuracy: 0.9274 - val_loss: 0.1888 - val_accuracy: 0.9445\n",
            "Epoch 2523/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2402 - accuracy: 0.9245 - val_loss: 0.1962 - val_accuracy: 0.9440\n",
            "Epoch 2524/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2329 - accuracy: 0.9240 - val_loss: 0.1932 - val_accuracy: 0.9445\n",
            "Epoch 2525/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2347 - accuracy: 0.9246 - val_loss: 0.2007 - val_accuracy: 0.9395\n",
            "Epoch 2526/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2327 - accuracy: 0.9273 - val_loss: 0.1924 - val_accuracy: 0.9440\n",
            "Epoch 2527/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2387 - accuracy: 0.9231 - val_loss: 0.1935 - val_accuracy: 0.9445\n",
            "Epoch 2528/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2289 - accuracy: 0.9273 - val_loss: 0.1926 - val_accuracy: 0.9440\n",
            "Epoch 2529/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2392 - accuracy: 0.9264 - val_loss: 0.1971 - val_accuracy: 0.9430\n",
            "Epoch 2530/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2330 - accuracy: 0.9241 - val_loss: 0.1931 - val_accuracy: 0.9445\n",
            "Epoch 2531/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2393 - accuracy: 0.9219 - val_loss: 0.1968 - val_accuracy: 0.9440\n",
            "Epoch 2532/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2440 - accuracy: 0.9224 - val_loss: 0.1987 - val_accuracy: 0.9425\n",
            "Epoch 2533/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2374 - accuracy: 0.9243 - val_loss: 0.1934 - val_accuracy: 0.9445\n",
            "Epoch 2534/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2445 - accuracy: 0.9195 - val_loss: 0.1913 - val_accuracy: 0.9450\n",
            "Epoch 2535/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2365 - accuracy: 0.9264 - val_loss: 0.1922 - val_accuracy: 0.9440\n",
            "Epoch 2536/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2497 - accuracy: 0.9252 - val_loss: 0.1962 - val_accuracy: 0.9425\n",
            "Epoch 2537/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2334 - accuracy: 0.9259 - val_loss: 0.1882 - val_accuracy: 0.9450\n",
            "Epoch 2538/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2381 - accuracy: 0.9245 - val_loss: 0.1895 - val_accuracy: 0.9445\n",
            "Epoch 2539/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2394 - accuracy: 0.9251 - val_loss: 0.1927 - val_accuracy: 0.9440\n",
            "Epoch 2540/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2267 - accuracy: 0.9308 - val_loss: 0.1928 - val_accuracy: 0.9445\n",
            "Epoch 2541/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2308 - accuracy: 0.9274 - val_loss: 0.1925 - val_accuracy: 0.9440\n",
            "Epoch 2542/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2255 - accuracy: 0.9275 - val_loss: 0.1886 - val_accuracy: 0.9450\n",
            "Epoch 2543/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2348 - accuracy: 0.9230 - val_loss: 0.1915 - val_accuracy: 0.9460\n",
            "Epoch 2544/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2374 - accuracy: 0.9236 - val_loss: 0.1983 - val_accuracy: 0.9445\n",
            "Epoch 2545/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2347 - accuracy: 0.9251 - val_loss: 0.1915 - val_accuracy: 0.9445\n",
            "Epoch 2546/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2342 - accuracy: 0.9284 - val_loss: 0.1937 - val_accuracy: 0.9455\n",
            "Epoch 2547/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2269 - accuracy: 0.9277 - val_loss: 0.1961 - val_accuracy: 0.9440\n",
            "Epoch 2548/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2476 - accuracy: 0.9249 - val_loss: 0.1938 - val_accuracy: 0.9450\n",
            "Epoch 2549/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2363 - accuracy: 0.9270 - val_loss: 0.1946 - val_accuracy: 0.9435\n",
            "Epoch 2550/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2324 - accuracy: 0.9243 - val_loss: 0.1946 - val_accuracy: 0.9450\n",
            "Epoch 2551/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2333 - accuracy: 0.9235 - val_loss: 0.1932 - val_accuracy: 0.9450\n",
            "Epoch 2552/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2341 - accuracy: 0.9259 - val_loss: 0.1892 - val_accuracy: 0.9450\n",
            "Epoch 2553/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2288 - accuracy: 0.9264 - val_loss: 0.1882 - val_accuracy: 0.9460\n",
            "Epoch 2554/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2409 - accuracy: 0.9251 - val_loss: 0.1951 - val_accuracy: 0.9445\n",
            "Epoch 2555/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2319 - accuracy: 0.9269 - val_loss: 0.1917 - val_accuracy: 0.9465\n",
            "Epoch 2556/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2449 - accuracy: 0.9196 - val_loss: 0.1923 - val_accuracy: 0.9450\n",
            "Epoch 2557/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2323 - accuracy: 0.9261 - val_loss: 0.1874 - val_accuracy: 0.9445\n",
            "Epoch 2558/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2287 - accuracy: 0.9264 - val_loss: 0.1920 - val_accuracy: 0.9450\n",
            "Epoch 2559/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2399 - accuracy: 0.9233 - val_loss: 0.1982 - val_accuracy: 0.9425\n",
            "Epoch 2560/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2437 - accuracy: 0.9258 - val_loss: 0.1936 - val_accuracy: 0.9450\n",
            "Epoch 2561/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2392 - accuracy: 0.9255 - val_loss: 0.1973 - val_accuracy: 0.9430\n",
            "Epoch 2562/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2295 - accuracy: 0.9243 - val_loss: 0.1965 - val_accuracy: 0.9430\n",
            "Epoch 2563/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2355 - accuracy: 0.9224 - val_loss: 0.1927 - val_accuracy: 0.9450\n",
            "Epoch 2564/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2276 - accuracy: 0.9275 - val_loss: 0.1924 - val_accuracy: 0.9460\n",
            "Epoch 2565/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2302 - accuracy: 0.9249 - val_loss: 0.1899 - val_accuracy: 0.9450\n",
            "Epoch 2566/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2289 - accuracy: 0.9269 - val_loss: 0.1941 - val_accuracy: 0.9450\n",
            "Epoch 2567/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2317 - accuracy: 0.9250 - val_loss: 0.1918 - val_accuracy: 0.9440\n",
            "Epoch 2568/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2254 - accuracy: 0.9259 - val_loss: 0.1962 - val_accuracy: 0.9440\n",
            "Epoch 2569/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2349 - accuracy: 0.9235 - val_loss: 0.1929 - val_accuracy: 0.9445\n",
            "Epoch 2570/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2370 - accuracy: 0.9225 - val_loss: 0.1919 - val_accuracy: 0.9430\n",
            "Epoch 2571/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2257 - accuracy: 0.9261 - val_loss: 0.1908 - val_accuracy: 0.9445\n",
            "Epoch 2572/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2405 - accuracy: 0.9208 - val_loss: 0.1972 - val_accuracy: 0.9435\n",
            "Epoch 2573/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2358 - accuracy: 0.9251 - val_loss: 0.1922 - val_accuracy: 0.9460\n",
            "Epoch 2574/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2217 - accuracy: 0.9289 - val_loss: 0.1909 - val_accuracy: 0.9435\n",
            "Epoch 2575/6000\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2388 - accuracy: 0.9261 - val_loss: 0.1932 - val_accuracy: 0.9445\n",
            "Epoch 2576/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2392 - accuracy: 0.9241 - val_loss: 0.1887 - val_accuracy: 0.9460\n",
            "Epoch 2577/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2307 - accuracy: 0.9259 - val_loss: 0.1902 - val_accuracy: 0.9460\n",
            "Epoch 2578/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2408 - accuracy: 0.9235 - val_loss: 0.1947 - val_accuracy: 0.9455\n",
            "Epoch 2579/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2343 - accuracy: 0.9234 - val_loss: 0.1940 - val_accuracy: 0.9450\n",
            "Epoch 2580/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2275 - accuracy: 0.9252 - val_loss: 0.1965 - val_accuracy: 0.9440\n",
            "Epoch 2581/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2397 - accuracy: 0.9216 - val_loss: 0.1957 - val_accuracy: 0.9435\n",
            "Epoch 2582/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2306 - accuracy: 0.9252 - val_loss: 0.1932 - val_accuracy: 0.9435\n",
            "Epoch 2583/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2268 - accuracy: 0.9241 - val_loss: 0.1941 - val_accuracy: 0.9450\n",
            "Epoch 2584/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2316 - accuracy: 0.9260 - val_loss: 0.1940 - val_accuracy: 0.9445\n",
            "Epoch 2585/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2481 - accuracy: 0.9244 - val_loss: 0.1946 - val_accuracy: 0.9450\n",
            "Epoch 2586/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2366 - accuracy: 0.9247 - val_loss: 0.1967 - val_accuracy: 0.9440\n",
            "Epoch 2587/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2366 - accuracy: 0.9239 - val_loss: 0.1931 - val_accuracy: 0.9445\n",
            "Epoch 2588/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2340 - accuracy: 0.9279 - val_loss: 0.1935 - val_accuracy: 0.9435\n",
            "Epoch 2589/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2325 - accuracy: 0.9249 - val_loss: 0.1957 - val_accuracy: 0.9445\n",
            "Epoch 2590/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2401 - accuracy: 0.9233 - val_loss: 0.1959 - val_accuracy: 0.9445\n",
            "Epoch 2591/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2332 - accuracy: 0.9233 - val_loss: 0.1905 - val_accuracy: 0.9450\n",
            "Epoch 2592/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2328 - accuracy: 0.9260 - val_loss: 0.1909 - val_accuracy: 0.9450\n",
            "Epoch 2593/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2317 - accuracy: 0.9250 - val_loss: 0.1938 - val_accuracy: 0.9440\n",
            "Epoch 2594/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2380 - accuracy: 0.9241 - val_loss: 0.1951 - val_accuracy: 0.9440\n",
            "Epoch 2595/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2302 - accuracy: 0.9251 - val_loss: 0.1951 - val_accuracy: 0.9460\n",
            "Epoch 2596/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2268 - accuracy: 0.9241 - val_loss: 0.1912 - val_accuracy: 0.9460\n",
            "Epoch 2597/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2319 - accuracy: 0.9234 - val_loss: 0.1932 - val_accuracy: 0.9445\n",
            "Epoch 2598/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2329 - accuracy: 0.9247 - val_loss: 0.1971 - val_accuracy: 0.9450\n",
            "Epoch 2599/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2458 - accuracy: 0.9237 - val_loss: 0.1965 - val_accuracy: 0.9435\n",
            "Epoch 2600/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2361 - accuracy: 0.9230 - val_loss: 0.1947 - val_accuracy: 0.9435\n",
            "Epoch 2601/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2307 - accuracy: 0.9225 - val_loss: 0.1947 - val_accuracy: 0.9425\n",
            "Epoch 2602/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2379 - accuracy: 0.9240 - val_loss: 0.1923 - val_accuracy: 0.9440\n",
            "Epoch 2603/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2317 - accuracy: 0.9235 - val_loss: 0.1943 - val_accuracy: 0.9435\n",
            "Epoch 2604/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2281 - accuracy: 0.9233 - val_loss: 0.1917 - val_accuracy: 0.9440\n",
            "Epoch 2605/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2388 - accuracy: 0.9258 - val_loss: 0.1970 - val_accuracy: 0.9435\n",
            "Epoch 2606/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2316 - accuracy: 0.9247 - val_loss: 0.1971 - val_accuracy: 0.9450\n",
            "Epoch 2607/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2378 - accuracy: 0.9276 - val_loss: 0.1957 - val_accuracy: 0.9435\n",
            "Epoch 2608/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2317 - accuracy: 0.9270 - val_loss: 0.1914 - val_accuracy: 0.9445\n",
            "Epoch 2609/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2360 - accuracy: 0.9226 - val_loss: 0.1953 - val_accuracy: 0.9450\n",
            "Epoch 2610/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2357 - accuracy: 0.9243 - val_loss: 0.1919 - val_accuracy: 0.9440\n",
            "Epoch 2611/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2389 - accuracy: 0.9224 - val_loss: 0.1929 - val_accuracy: 0.9440\n",
            "Epoch 2612/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2360 - accuracy: 0.9249 - val_loss: 0.1932 - val_accuracy: 0.9450\n",
            "Epoch 2613/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2345 - accuracy: 0.9286 - val_loss: 0.1904 - val_accuracy: 0.9455\n",
            "Epoch 2614/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2353 - accuracy: 0.9235 - val_loss: 0.1911 - val_accuracy: 0.9460\n",
            "Epoch 2615/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2370 - accuracy: 0.9266 - val_loss: 0.1908 - val_accuracy: 0.9450\n",
            "Epoch 2616/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2270 - accuracy: 0.9246 - val_loss: 0.1978 - val_accuracy: 0.9430\n",
            "Epoch 2617/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2241 - accuracy: 0.9281 - val_loss: 0.1912 - val_accuracy: 0.9430\n",
            "Epoch 2618/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2270 - accuracy: 0.9261 - val_loss: 0.1938 - val_accuracy: 0.9435\n",
            "Epoch 2619/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2310 - accuracy: 0.9239 - val_loss: 0.1929 - val_accuracy: 0.9450\n",
            "Epoch 2620/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2253 - accuracy: 0.9275 - val_loss: 0.1971 - val_accuracy: 0.9425\n",
            "Epoch 2621/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2292 - accuracy: 0.9249 - val_loss: 0.2016 - val_accuracy: 0.9415\n",
            "Epoch 2622/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2296 - accuracy: 0.9268 - val_loss: 0.1921 - val_accuracy: 0.9435\n",
            "Epoch 2623/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2276 - accuracy: 0.9277 - val_loss: 0.1943 - val_accuracy: 0.9460\n",
            "Epoch 2624/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2272 - accuracy: 0.9254 - val_loss: 0.1927 - val_accuracy: 0.9450\n",
            "Epoch 2625/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2422 - accuracy: 0.9251 - val_loss: 0.1926 - val_accuracy: 0.9440\n",
            "Epoch 2626/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2271 - accuracy: 0.9286 - val_loss: 0.1922 - val_accuracy: 0.9435\n",
            "Epoch 2627/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2327 - accuracy: 0.9245 - val_loss: 0.1961 - val_accuracy: 0.9435\n",
            "Epoch 2628/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2325 - accuracy: 0.9271 - val_loss: 0.1915 - val_accuracy: 0.9425\n",
            "Epoch 2629/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2262 - accuracy: 0.9301 - val_loss: 0.1939 - val_accuracy: 0.9440\n",
            "Epoch 2630/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2374 - accuracy: 0.9236 - val_loss: 0.1876 - val_accuracy: 0.9445\n",
            "Epoch 2631/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2266 - accuracy: 0.9239 - val_loss: 0.1906 - val_accuracy: 0.9420\n",
            "Epoch 2632/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2349 - accuracy: 0.9233 - val_loss: 0.1934 - val_accuracy: 0.9445\n",
            "Epoch 2633/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2383 - accuracy: 0.9261 - val_loss: 0.1919 - val_accuracy: 0.9460\n",
            "Epoch 2634/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2310 - accuracy: 0.9256 - val_loss: 0.1931 - val_accuracy: 0.9435\n",
            "Epoch 2635/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2360 - accuracy: 0.9233 - val_loss: 0.1959 - val_accuracy: 0.9445\n",
            "Epoch 2636/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2300 - accuracy: 0.9245 - val_loss: 0.1925 - val_accuracy: 0.9450\n",
            "Epoch 2637/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2299 - accuracy: 0.9261 - val_loss: 0.1943 - val_accuracy: 0.9440\n",
            "Epoch 2638/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2260 - accuracy: 0.9285 - val_loss: 0.1939 - val_accuracy: 0.9450\n",
            "Epoch 2639/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2421 - accuracy: 0.9227 - val_loss: 0.1912 - val_accuracy: 0.9450\n",
            "Epoch 2640/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2381 - accuracy: 0.9266 - val_loss: 0.1904 - val_accuracy: 0.9450\n",
            "Epoch 2641/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2242 - accuracy: 0.9280 - val_loss: 0.1906 - val_accuracy: 0.9440\n",
            "Epoch 2642/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2271 - accuracy: 0.9269 - val_loss: 0.1902 - val_accuracy: 0.9445\n",
            "Epoch 2643/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2295 - accuracy: 0.9264 - val_loss: 0.1911 - val_accuracy: 0.9445\n",
            "Epoch 2644/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2388 - accuracy: 0.9258 - val_loss: 0.1897 - val_accuracy: 0.9450\n",
            "Epoch 2645/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2331 - accuracy: 0.9250 - val_loss: 0.1919 - val_accuracy: 0.9450\n",
            "Epoch 2646/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2293 - accuracy: 0.9259 - val_loss: 0.1928 - val_accuracy: 0.9440\n",
            "Epoch 2647/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2355 - accuracy: 0.9243 - val_loss: 0.1885 - val_accuracy: 0.9445\n",
            "Epoch 2648/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2280 - accuracy: 0.9261 - val_loss: 0.1923 - val_accuracy: 0.9460\n",
            "Epoch 2649/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2360 - accuracy: 0.9226 - val_loss: 0.1913 - val_accuracy: 0.9445\n",
            "Epoch 2650/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2322 - accuracy: 0.9244 - val_loss: 0.1961 - val_accuracy: 0.9440\n",
            "Epoch 2651/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2249 - accuracy: 0.9261 - val_loss: 0.1942 - val_accuracy: 0.9430\n",
            "Epoch 2652/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2350 - accuracy: 0.9251 - val_loss: 0.1882 - val_accuracy: 0.9445\n",
            "Epoch 2653/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2315 - accuracy: 0.9255 - val_loss: 0.1912 - val_accuracy: 0.9440\n",
            "Epoch 2654/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2384 - accuracy: 0.9237 - val_loss: 0.1933 - val_accuracy: 0.9435\n",
            "Epoch 2655/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2331 - accuracy: 0.9264 - val_loss: 0.1924 - val_accuracy: 0.9455\n",
            "Epoch 2656/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2356 - accuracy: 0.9209 - val_loss: 0.1912 - val_accuracy: 0.9470\n",
            "Epoch 2657/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2343 - accuracy: 0.9265 - val_loss: 0.1969 - val_accuracy: 0.9445\n",
            "Epoch 2658/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2378 - accuracy: 0.9245 - val_loss: 0.1978 - val_accuracy: 0.9440\n",
            "Epoch 2659/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2365 - accuracy: 0.9250 - val_loss: 0.1880 - val_accuracy: 0.9445\n",
            "Epoch 2660/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2322 - accuracy: 0.9237 - val_loss: 0.1974 - val_accuracy: 0.9455\n",
            "Epoch 2661/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2369 - accuracy: 0.9256 - val_loss: 0.1916 - val_accuracy: 0.9450\n",
            "Epoch 2662/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2281 - accuracy: 0.9279 - val_loss: 0.1926 - val_accuracy: 0.9460\n",
            "Epoch 2663/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2361 - accuracy: 0.9247 - val_loss: 0.1937 - val_accuracy: 0.9440\n",
            "Epoch 2664/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2335 - accuracy: 0.9225 - val_loss: 0.1934 - val_accuracy: 0.9455\n",
            "Epoch 2665/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2283 - accuracy: 0.9258 - val_loss: 0.1944 - val_accuracy: 0.9430\n",
            "Epoch 2666/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2401 - accuracy: 0.9237 - val_loss: 0.1894 - val_accuracy: 0.9455\n",
            "Epoch 2667/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2301 - accuracy: 0.9259 - val_loss: 0.1967 - val_accuracy: 0.9445\n",
            "Epoch 2668/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2223 - accuracy: 0.9283 - val_loss: 0.1978 - val_accuracy: 0.9435\n",
            "Epoch 2669/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2472 - accuracy: 0.9260 - val_loss: 0.1940 - val_accuracy: 0.9450\n",
            "Epoch 2670/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2283 - accuracy: 0.9268 - val_loss: 0.1941 - val_accuracy: 0.9445\n",
            "Epoch 2671/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2305 - accuracy: 0.9240 - val_loss: 0.1883 - val_accuracy: 0.9460\n",
            "Epoch 2672/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2314 - accuracy: 0.9229 - val_loss: 0.1953 - val_accuracy: 0.9430\n",
            "Epoch 2673/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2372 - accuracy: 0.9252 - val_loss: 0.1952 - val_accuracy: 0.9440\n",
            "Epoch 2674/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2308 - accuracy: 0.9231 - val_loss: 0.1877 - val_accuracy: 0.9435\n",
            "Epoch 2675/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2355 - accuracy: 0.9271 - val_loss: 0.1900 - val_accuracy: 0.9445\n",
            "Epoch 2676/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2343 - accuracy: 0.9240 - val_loss: 0.1898 - val_accuracy: 0.9445\n",
            "Epoch 2677/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2427 - accuracy: 0.9260 - val_loss: 0.1921 - val_accuracy: 0.9455\n",
            "Epoch 2678/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2387 - accuracy: 0.9239 - val_loss: 0.1877 - val_accuracy: 0.9460\n",
            "Epoch 2679/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2257 - accuracy: 0.9262 - val_loss: 0.1894 - val_accuracy: 0.9455\n",
            "Epoch 2680/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2279 - accuracy: 0.9270 - val_loss: 0.1937 - val_accuracy: 0.9460\n",
            "Epoch 2681/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2327 - accuracy: 0.9241 - val_loss: 0.1914 - val_accuracy: 0.9450\n",
            "Epoch 2682/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2416 - accuracy: 0.9233 - val_loss: 0.1923 - val_accuracy: 0.9435\n",
            "Epoch 2683/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2415 - accuracy: 0.9237 - val_loss: 0.1881 - val_accuracy: 0.9450\n",
            "Epoch 2684/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2344 - accuracy: 0.9255 - val_loss: 0.1947 - val_accuracy: 0.9425\n",
            "Epoch 2685/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2330 - accuracy: 0.9226 - val_loss: 0.1945 - val_accuracy: 0.9440\n",
            "Epoch 2686/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2383 - accuracy: 0.9239 - val_loss: 0.1953 - val_accuracy: 0.9450\n",
            "Epoch 2687/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2470 - accuracy: 0.9246 - val_loss: 0.1935 - val_accuracy: 0.9450\n",
            "Epoch 2688/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2301 - accuracy: 0.9255 - val_loss: 0.1958 - val_accuracy: 0.9445\n",
            "Epoch 2689/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2350 - accuracy: 0.9258 - val_loss: 0.1930 - val_accuracy: 0.9470\n",
            "Epoch 2690/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2441 - accuracy: 0.9225 - val_loss: 0.1960 - val_accuracy: 0.9435\n",
            "Epoch 2691/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2338 - accuracy: 0.9256 - val_loss: 0.1930 - val_accuracy: 0.9455\n",
            "Epoch 2692/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2311 - accuracy: 0.9227 - val_loss: 0.1914 - val_accuracy: 0.9455\n",
            "Epoch 2693/6000\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2254 - accuracy: 0.9258 - val_loss: 0.1945 - val_accuracy: 0.9455\n",
            "Epoch 2694/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2489 - accuracy: 0.9245 - val_loss: 0.1914 - val_accuracy: 0.9435\n",
            "Epoch 2695/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2379 - accuracy: 0.9245 - val_loss: 0.1922 - val_accuracy: 0.9450\n",
            "Epoch 2696/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2260 - accuracy: 0.9260 - val_loss: 0.1927 - val_accuracy: 0.9450\n",
            "Epoch 2697/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2373 - accuracy: 0.9233 - val_loss: 0.1957 - val_accuracy: 0.9440\n",
            "Epoch 2698/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2351 - accuracy: 0.9250 - val_loss: 0.1917 - val_accuracy: 0.9455\n",
            "Epoch 2699/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2322 - accuracy: 0.9250 - val_loss: 0.1900 - val_accuracy: 0.9445\n",
            "Epoch 2700/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2285 - accuracy: 0.9241 - val_loss: 0.1909 - val_accuracy: 0.9460\n",
            "Epoch 2701/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2414 - accuracy: 0.9268 - val_loss: 0.1925 - val_accuracy: 0.9465\n",
            "Epoch 2702/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2299 - accuracy: 0.9259 - val_loss: 0.1912 - val_accuracy: 0.9460\n",
            "Epoch 2703/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2281 - accuracy: 0.9265 - val_loss: 0.1897 - val_accuracy: 0.9460\n",
            "Epoch 2704/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2340 - accuracy: 0.9252 - val_loss: 0.1893 - val_accuracy: 0.9440\n",
            "Epoch 2705/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2425 - accuracy: 0.9260 - val_loss: 0.1947 - val_accuracy: 0.9445\n",
            "Epoch 2706/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2360 - accuracy: 0.9252 - val_loss: 0.1873 - val_accuracy: 0.9465\n",
            "Epoch 2707/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2287 - accuracy: 0.9247 - val_loss: 0.1903 - val_accuracy: 0.9460\n",
            "Epoch 2708/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2357 - accuracy: 0.9264 - val_loss: 0.1940 - val_accuracy: 0.9455\n",
            "Epoch 2709/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2295 - accuracy: 0.9247 - val_loss: 0.1901 - val_accuracy: 0.9460\n",
            "Epoch 2710/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2279 - accuracy: 0.9256 - val_loss: 0.1909 - val_accuracy: 0.9460\n",
            "Epoch 2711/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2310 - accuracy: 0.9281 - val_loss: 0.1894 - val_accuracy: 0.9440\n",
            "Epoch 2712/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2336 - accuracy: 0.9264 - val_loss: 0.1921 - val_accuracy: 0.9460\n",
            "Epoch 2713/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2348 - accuracy: 0.9244 - val_loss: 0.1957 - val_accuracy: 0.9445\n",
            "Epoch 2714/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2419 - accuracy: 0.9249 - val_loss: 0.1937 - val_accuracy: 0.9455\n",
            "Epoch 2715/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2451 - accuracy: 0.9211 - val_loss: 0.1916 - val_accuracy: 0.9445\n",
            "Epoch 2716/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2287 - accuracy: 0.9251 - val_loss: 0.1925 - val_accuracy: 0.9440\n",
            "Epoch 2717/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2355 - accuracy: 0.9259 - val_loss: 0.1920 - val_accuracy: 0.9450\n",
            "Epoch 2718/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2259 - accuracy: 0.9283 - val_loss: 0.1936 - val_accuracy: 0.9460\n",
            "Epoch 2719/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2390 - accuracy: 0.9193 - val_loss: 0.1949 - val_accuracy: 0.9435\n",
            "Epoch 2720/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2415 - accuracy: 0.9244 - val_loss: 0.1908 - val_accuracy: 0.9450\n",
            "Epoch 2721/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2307 - accuracy: 0.9264 - val_loss: 0.1937 - val_accuracy: 0.9455\n",
            "Epoch 2722/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2313 - accuracy: 0.9268 - val_loss: 0.1939 - val_accuracy: 0.9460\n",
            "Epoch 2723/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2292 - accuracy: 0.9235 - val_loss: 0.1936 - val_accuracy: 0.9440\n",
            "Epoch 2724/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2310 - accuracy: 0.9237 - val_loss: 0.1926 - val_accuracy: 0.9455\n",
            "Epoch 2725/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2347 - accuracy: 0.9236 - val_loss: 0.1928 - val_accuracy: 0.9460\n",
            "Epoch 2726/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2318 - accuracy: 0.9246 - val_loss: 0.1971 - val_accuracy: 0.9440\n",
            "Epoch 2727/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2422 - accuracy: 0.9219 - val_loss: 0.2008 - val_accuracy: 0.9430\n",
            "Epoch 2728/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2275 - accuracy: 0.9262 - val_loss: 0.1957 - val_accuracy: 0.9435\n",
            "Epoch 2729/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2354 - accuracy: 0.9220 - val_loss: 0.1921 - val_accuracy: 0.9445\n",
            "Epoch 2730/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2386 - accuracy: 0.9235 - val_loss: 0.1939 - val_accuracy: 0.9455\n",
            "Epoch 2731/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2535 - accuracy: 0.9247 - val_loss: 0.1984 - val_accuracy: 0.9430\n",
            "Epoch 2732/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2337 - accuracy: 0.9276 - val_loss: 0.1922 - val_accuracy: 0.9445\n",
            "Epoch 2733/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2268 - accuracy: 0.9262 - val_loss: 0.1906 - val_accuracy: 0.9460\n",
            "Epoch 2734/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2220 - accuracy: 0.9283 - val_loss: 0.1930 - val_accuracy: 0.9450\n",
            "Epoch 2735/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2223 - accuracy: 0.9274 - val_loss: 0.1922 - val_accuracy: 0.9450\n",
            "Epoch 2736/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2295 - accuracy: 0.9241 - val_loss: 0.1886 - val_accuracy: 0.9460\n",
            "Epoch 2737/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2280 - accuracy: 0.9275 - val_loss: 0.1955 - val_accuracy: 0.9450\n",
            "Epoch 2738/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2408 - accuracy: 0.9243 - val_loss: 0.1946 - val_accuracy: 0.9435\n",
            "Epoch 2739/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2176 - accuracy: 0.9293 - val_loss: 0.1893 - val_accuracy: 0.9465\n",
            "Epoch 2740/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2358 - accuracy: 0.9254 - val_loss: 0.1891 - val_accuracy: 0.9445\n",
            "Epoch 2741/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2357 - accuracy: 0.9224 - val_loss: 0.1975 - val_accuracy: 0.9425\n",
            "Epoch 2742/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2305 - accuracy: 0.9264 - val_loss: 0.1877 - val_accuracy: 0.9450\n",
            "Epoch 2743/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2293 - accuracy: 0.9245 - val_loss: 0.1939 - val_accuracy: 0.9440\n",
            "Epoch 2744/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2303 - accuracy: 0.9262 - val_loss: 0.2014 - val_accuracy: 0.9405\n",
            "Epoch 2745/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2371 - accuracy: 0.9259 - val_loss: 0.1949 - val_accuracy: 0.9450\n",
            "Epoch 2746/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2282 - accuracy: 0.9241 - val_loss: 0.1919 - val_accuracy: 0.9440\n",
            "Epoch 2747/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2293 - accuracy: 0.9280 - val_loss: 0.1909 - val_accuracy: 0.9445\n",
            "Epoch 2748/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2372 - accuracy: 0.9243 - val_loss: 0.1893 - val_accuracy: 0.9455\n",
            "Epoch 2749/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2245 - accuracy: 0.9284 - val_loss: 0.1918 - val_accuracy: 0.9470\n",
            "Epoch 2750/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2293 - accuracy: 0.9275 - val_loss: 0.1894 - val_accuracy: 0.9460\n",
            "Epoch 2751/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2340 - accuracy: 0.9227 - val_loss: 0.1966 - val_accuracy: 0.9415\n",
            "Epoch 2752/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2368 - accuracy: 0.9222 - val_loss: 0.1956 - val_accuracy: 0.9450\n",
            "Epoch 2753/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2314 - accuracy: 0.9244 - val_loss: 0.1931 - val_accuracy: 0.9450\n",
            "Epoch 2754/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2309 - accuracy: 0.9259 - val_loss: 0.1948 - val_accuracy: 0.9440\n",
            "Epoch 2755/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2369 - accuracy: 0.9244 - val_loss: 0.1988 - val_accuracy: 0.9425\n",
            "Epoch 2756/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2299 - accuracy: 0.9261 - val_loss: 0.1908 - val_accuracy: 0.9430\n",
            "Epoch 2757/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2571 - accuracy: 0.9202 - val_loss: 0.1916 - val_accuracy: 0.9440\n",
            "Epoch 2758/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2443 - accuracy: 0.9252 - val_loss: 0.1904 - val_accuracy: 0.9450\n",
            "Epoch 2759/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2332 - accuracy: 0.9229 - val_loss: 0.1923 - val_accuracy: 0.9420\n",
            "Epoch 2760/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2271 - accuracy: 0.9268 - val_loss: 0.1908 - val_accuracy: 0.9455\n",
            "Epoch 2761/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2293 - accuracy: 0.9280 - val_loss: 0.1942 - val_accuracy: 0.9430\n",
            "Epoch 2762/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2271 - accuracy: 0.9262 - val_loss: 0.1912 - val_accuracy: 0.9455\n",
            "Epoch 2763/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2351 - accuracy: 0.9258 - val_loss: 0.1906 - val_accuracy: 0.9430\n",
            "Epoch 2764/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2441 - accuracy: 0.9234 - val_loss: 0.1927 - val_accuracy: 0.9440\n",
            "Epoch 2765/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2366 - accuracy: 0.9226 - val_loss: 0.1900 - val_accuracy: 0.9445\n",
            "Epoch 2766/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2238 - accuracy: 0.9256 - val_loss: 0.1925 - val_accuracy: 0.9435\n",
            "Epoch 2767/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2357 - accuracy: 0.9275 - val_loss: 0.1941 - val_accuracy: 0.9455\n",
            "Epoch 2768/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2287 - accuracy: 0.9261 - val_loss: 0.1910 - val_accuracy: 0.9435\n",
            "Epoch 2769/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2263 - accuracy: 0.9264 - val_loss: 0.1919 - val_accuracy: 0.9450\n",
            "Epoch 2770/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2599 - accuracy: 0.9245 - val_loss: 0.1893 - val_accuracy: 0.9445\n",
            "Epoch 2771/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2300 - accuracy: 0.9277 - val_loss: 0.1933 - val_accuracy: 0.9440\n",
            "Epoch 2772/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2277 - accuracy: 0.9254 - val_loss: 0.1913 - val_accuracy: 0.9420\n",
            "Epoch 2773/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2329 - accuracy: 0.9260 - val_loss: 0.1927 - val_accuracy: 0.9440\n",
            "Epoch 2774/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2354 - accuracy: 0.9236 - val_loss: 0.1932 - val_accuracy: 0.9425\n",
            "Epoch 2775/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2221 - accuracy: 0.9273 - val_loss: 0.1901 - val_accuracy: 0.9445\n",
            "Epoch 2776/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2346 - accuracy: 0.9250 - val_loss: 0.1935 - val_accuracy: 0.9435\n",
            "Epoch 2777/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2255 - accuracy: 0.9301 - val_loss: 0.1871 - val_accuracy: 0.9435\n",
            "Epoch 2778/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2368 - accuracy: 0.9226 - val_loss: 0.1899 - val_accuracy: 0.9435\n",
            "Epoch 2779/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2259 - accuracy: 0.9271 - val_loss: 0.1938 - val_accuracy: 0.9445\n",
            "Epoch 2780/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2211 - accuracy: 0.9305 - val_loss: 0.1924 - val_accuracy: 0.9460\n",
            "Epoch 2781/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2292 - accuracy: 0.9239 - val_loss: 0.1955 - val_accuracy: 0.9445\n",
            "Epoch 2782/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2357 - accuracy: 0.9262 - val_loss: 0.1941 - val_accuracy: 0.9430\n",
            "Epoch 2783/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2361 - accuracy: 0.9258 - val_loss: 0.1919 - val_accuracy: 0.9435\n",
            "Epoch 2784/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2300 - accuracy: 0.9259 - val_loss: 0.1943 - val_accuracy: 0.9425\n",
            "Epoch 2785/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2301 - accuracy: 0.9268 - val_loss: 0.1964 - val_accuracy: 0.9430\n",
            "Epoch 2786/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2407 - accuracy: 0.9243 - val_loss: 0.1921 - val_accuracy: 0.9440\n",
            "Epoch 2787/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2347 - accuracy: 0.9251 - val_loss: 0.1923 - val_accuracy: 0.9440\n",
            "Epoch 2788/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2303 - accuracy: 0.9271 - val_loss: 0.1923 - val_accuracy: 0.9450\n",
            "Epoch 2789/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2308 - accuracy: 0.9266 - val_loss: 0.1925 - val_accuracy: 0.9455\n",
            "Epoch 2790/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2441 - accuracy: 0.9199 - val_loss: 0.1993 - val_accuracy: 0.9415\n",
            "Epoch 2791/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2280 - accuracy: 0.9264 - val_loss: 0.1901 - val_accuracy: 0.9430\n",
            "Epoch 2792/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2292 - accuracy: 0.9236 - val_loss: 0.1911 - val_accuracy: 0.9435\n",
            "Epoch 2793/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2294 - accuracy: 0.9246 - val_loss: 0.1884 - val_accuracy: 0.9450\n",
            "Epoch 2794/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2327 - accuracy: 0.9247 - val_loss: 0.1942 - val_accuracy: 0.9455\n",
            "Epoch 2795/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2272 - accuracy: 0.9283 - val_loss: 0.1939 - val_accuracy: 0.9445\n",
            "Epoch 2796/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2312 - accuracy: 0.9256 - val_loss: 0.1894 - val_accuracy: 0.9455\n",
            "Epoch 2797/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2378 - accuracy: 0.9230 - val_loss: 0.1918 - val_accuracy: 0.9455\n",
            "Epoch 2798/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2391 - accuracy: 0.9236 - val_loss: 0.1951 - val_accuracy: 0.9465\n",
            "Epoch 2799/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2429 - accuracy: 0.9243 - val_loss: 0.1955 - val_accuracy: 0.9445\n",
            "Epoch 2800/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2324 - accuracy: 0.9245 - val_loss: 0.1973 - val_accuracy: 0.9420\n",
            "Epoch 2801/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2277 - accuracy: 0.9264 - val_loss: 0.1921 - val_accuracy: 0.9430\n",
            "Epoch 2802/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2282 - accuracy: 0.9258 - val_loss: 0.1965 - val_accuracy: 0.9425\n",
            "Epoch 2803/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2366 - accuracy: 0.9255 - val_loss: 0.1910 - val_accuracy: 0.9455\n",
            "Epoch 2804/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2324 - accuracy: 0.9243 - val_loss: 0.1926 - val_accuracy: 0.9455\n",
            "Epoch 2805/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2338 - accuracy: 0.9222 - val_loss: 0.1944 - val_accuracy: 0.9455\n",
            "Epoch 2806/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2330 - accuracy: 0.9247 - val_loss: 0.1942 - val_accuracy: 0.9445\n",
            "Epoch 2807/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2319 - accuracy: 0.9276 - val_loss: 0.1924 - val_accuracy: 0.9445\n",
            "Epoch 2808/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2279 - accuracy: 0.9276 - val_loss: 0.1960 - val_accuracy: 0.9430\n",
            "Epoch 2809/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2355 - accuracy: 0.9237 - val_loss: 0.1927 - val_accuracy: 0.9445\n",
            "Epoch 2810/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2337 - accuracy: 0.9259 - val_loss: 0.1914 - val_accuracy: 0.9460\n",
            "Epoch 2811/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2369 - accuracy: 0.9211 - val_loss: 0.1938 - val_accuracy: 0.9420\n",
            "Epoch 2812/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2457 - accuracy: 0.9260 - val_loss: 0.1921 - val_accuracy: 0.9455\n",
            "Epoch 2813/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2364 - accuracy: 0.9227 - val_loss: 0.1941 - val_accuracy: 0.9450\n",
            "Epoch 2814/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2257 - accuracy: 0.9256 - val_loss: 0.1922 - val_accuracy: 0.9470\n",
            "Epoch 2815/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2219 - accuracy: 0.9291 - val_loss: 0.1956 - val_accuracy: 0.9440\n",
            "Epoch 2816/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2298 - accuracy: 0.9262 - val_loss: 0.1935 - val_accuracy: 0.9450\n",
            "Epoch 2817/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2314 - accuracy: 0.9255 - val_loss: 0.1908 - val_accuracy: 0.9460\n",
            "Epoch 2818/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2354 - accuracy: 0.9271 - val_loss: 0.1924 - val_accuracy: 0.9440\n",
            "Epoch 2819/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2300 - accuracy: 0.9239 - val_loss: 0.1926 - val_accuracy: 0.9435\n",
            "Epoch 2820/6000\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2316 - accuracy: 0.9245 - val_loss: 0.1934 - val_accuracy: 0.9420\n",
            "Epoch 2821/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2321 - accuracy: 0.9245 - val_loss: 0.1954 - val_accuracy: 0.9435\n",
            "Epoch 2822/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2380 - accuracy: 0.9225 - val_loss: 0.1933 - val_accuracy: 0.9430\n",
            "Epoch 2823/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2379 - accuracy: 0.9271 - val_loss: 0.1893 - val_accuracy: 0.9445\n",
            "Epoch 2824/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2268 - accuracy: 0.9269 - val_loss: 0.1942 - val_accuracy: 0.9450\n",
            "Epoch 2825/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2363 - accuracy: 0.9262 - val_loss: 0.1896 - val_accuracy: 0.9450\n",
            "Epoch 2826/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2267 - accuracy: 0.9250 - val_loss: 0.1903 - val_accuracy: 0.9435\n",
            "Epoch 2827/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2261 - accuracy: 0.9255 - val_loss: 0.1954 - val_accuracy: 0.9430\n",
            "Epoch 2828/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2347 - accuracy: 0.9287 - val_loss: 0.1905 - val_accuracy: 0.9440\n",
            "Epoch 2829/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2445 - accuracy: 0.9240 - val_loss: 0.1920 - val_accuracy: 0.9440\n",
            "Epoch 2830/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2325 - accuracy: 0.9241 - val_loss: 0.1916 - val_accuracy: 0.9440\n",
            "Epoch 2831/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2469 - accuracy: 0.9250 - val_loss: 0.1954 - val_accuracy: 0.9445\n",
            "Epoch 2832/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2373 - accuracy: 0.9273 - val_loss: 0.1943 - val_accuracy: 0.9445\n",
            "Epoch 2833/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2310 - accuracy: 0.9243 - val_loss: 0.1922 - val_accuracy: 0.9450\n",
            "Epoch 2834/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2342 - accuracy: 0.9251 - val_loss: 0.1904 - val_accuracy: 0.9450\n",
            "Epoch 2835/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2290 - accuracy: 0.9256 - val_loss: 0.1934 - val_accuracy: 0.9440\n",
            "Epoch 2836/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2306 - accuracy: 0.9247 - val_loss: 0.1921 - val_accuracy: 0.9435\n",
            "Epoch 2837/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2402 - accuracy: 0.9250 - val_loss: 0.1906 - val_accuracy: 0.9420\n",
            "Epoch 2838/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2285 - accuracy: 0.9250 - val_loss: 0.1891 - val_accuracy: 0.9460\n",
            "Epoch 2839/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2296 - accuracy: 0.9256 - val_loss: 0.1903 - val_accuracy: 0.9440\n",
            "Epoch 2840/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2309 - accuracy: 0.9245 - val_loss: 0.1909 - val_accuracy: 0.9445\n",
            "Epoch 2841/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2340 - accuracy: 0.9231 - val_loss: 0.1945 - val_accuracy: 0.9430\n",
            "Epoch 2842/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2333 - accuracy: 0.9251 - val_loss: 0.1960 - val_accuracy: 0.9425\n",
            "Epoch 2843/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2357 - accuracy: 0.9235 - val_loss: 0.1894 - val_accuracy: 0.9455\n",
            "Epoch 2844/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2323 - accuracy: 0.9274 - val_loss: 0.1963 - val_accuracy: 0.9455\n",
            "Epoch 2845/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2274 - accuracy: 0.9265 - val_loss: 0.1901 - val_accuracy: 0.9455\n",
            "Epoch 2846/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2311 - accuracy: 0.9264 - val_loss: 0.1948 - val_accuracy: 0.9440\n",
            "Epoch 2847/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2414 - accuracy: 0.9265 - val_loss: 0.1940 - val_accuracy: 0.9440\n",
            "Epoch 2848/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2339 - accuracy: 0.9261 - val_loss: 0.1902 - val_accuracy: 0.9450\n",
            "Epoch 2849/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2398 - accuracy: 0.9261 - val_loss: 0.1939 - val_accuracy: 0.9450\n",
            "Epoch 2850/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2272 - accuracy: 0.9250 - val_loss: 0.1927 - val_accuracy: 0.9460\n",
            "Epoch 2851/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2369 - accuracy: 0.9226 - val_loss: 0.1952 - val_accuracy: 0.9435\n",
            "Epoch 2852/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2261 - accuracy: 0.9274 - val_loss: 0.1946 - val_accuracy: 0.9445\n",
            "Epoch 2853/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2309 - accuracy: 0.9226 - val_loss: 0.1932 - val_accuracy: 0.9450\n",
            "Epoch 2854/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2354 - accuracy: 0.9220 - val_loss: 0.1898 - val_accuracy: 0.9450\n",
            "Epoch 2855/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2335 - accuracy: 0.9215 - val_loss: 0.1944 - val_accuracy: 0.9445\n",
            "Epoch 2856/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2340 - accuracy: 0.9244 - val_loss: 0.1959 - val_accuracy: 0.9445\n",
            "Epoch 2857/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2278 - accuracy: 0.9277 - val_loss: 0.1931 - val_accuracy: 0.9445\n",
            "Epoch 2858/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2374 - accuracy: 0.9254 - val_loss: 0.1885 - val_accuracy: 0.9460\n",
            "Epoch 2859/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2344 - accuracy: 0.9255 - val_loss: 0.1898 - val_accuracy: 0.9450\n",
            "Epoch 2860/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2293 - accuracy: 0.9249 - val_loss: 0.1919 - val_accuracy: 0.9455\n",
            "Epoch 2861/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2349 - accuracy: 0.9247 - val_loss: 0.1886 - val_accuracy: 0.9460\n",
            "Epoch 2862/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2329 - accuracy: 0.9259 - val_loss: 0.1895 - val_accuracy: 0.9450\n",
            "Epoch 2863/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2258 - accuracy: 0.9266 - val_loss: 0.1915 - val_accuracy: 0.9455\n",
            "Epoch 2864/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2345 - accuracy: 0.9255 - val_loss: 0.1914 - val_accuracy: 0.9445\n",
            "Epoch 2865/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2390 - accuracy: 0.9211 - val_loss: 0.1941 - val_accuracy: 0.9435\n",
            "Epoch 2866/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2366 - accuracy: 0.9216 - val_loss: 0.1939 - val_accuracy: 0.9430\n",
            "Epoch 2867/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2304 - accuracy: 0.9254 - val_loss: 0.1952 - val_accuracy: 0.9440\n",
            "Epoch 2868/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2333 - accuracy: 0.9255 - val_loss: 0.1907 - val_accuracy: 0.9440\n",
            "Epoch 2869/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2270 - accuracy: 0.9298 - val_loss: 0.1916 - val_accuracy: 0.9445\n",
            "Epoch 2870/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2596 - accuracy: 0.9240 - val_loss: 0.1914 - val_accuracy: 0.9450\n",
            "Epoch 2871/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2402 - accuracy: 0.9244 - val_loss: 0.1880 - val_accuracy: 0.9465\n",
            "Epoch 2872/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2292 - accuracy: 0.9259 - val_loss: 0.1890 - val_accuracy: 0.9455\n",
            "Epoch 2873/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2279 - accuracy: 0.9283 - val_loss: 0.1891 - val_accuracy: 0.9440\n",
            "Epoch 2874/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2278 - accuracy: 0.9268 - val_loss: 0.1916 - val_accuracy: 0.9435\n",
            "Epoch 2875/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2394 - accuracy: 0.9268 - val_loss: 0.1948 - val_accuracy: 0.9425\n",
            "Epoch 2876/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2351 - accuracy: 0.9227 - val_loss: 0.1929 - val_accuracy: 0.9430\n",
            "Epoch 2877/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2286 - accuracy: 0.9276 - val_loss: 0.1943 - val_accuracy: 0.9425\n",
            "Epoch 2878/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2304 - accuracy: 0.9249 - val_loss: 0.1969 - val_accuracy: 0.9420\n",
            "Epoch 2879/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2287 - accuracy: 0.9270 - val_loss: 0.1913 - val_accuracy: 0.9445\n",
            "Epoch 2880/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2305 - accuracy: 0.9261 - val_loss: 0.1887 - val_accuracy: 0.9445\n",
            "Epoch 2881/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2275 - accuracy: 0.9247 - val_loss: 0.1910 - val_accuracy: 0.9445\n",
            "Epoch 2882/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2289 - accuracy: 0.9224 - val_loss: 0.1920 - val_accuracy: 0.9425\n",
            "Epoch 2883/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2322 - accuracy: 0.9261 - val_loss: 0.1867 - val_accuracy: 0.9445\n",
            "Epoch 2884/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2361 - accuracy: 0.9280 - val_loss: 0.1928 - val_accuracy: 0.9460\n",
            "Epoch 2885/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2359 - accuracy: 0.9212 - val_loss: 0.1926 - val_accuracy: 0.9450\n",
            "Epoch 2886/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2318 - accuracy: 0.9234 - val_loss: 0.1919 - val_accuracy: 0.9445\n",
            "Epoch 2887/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2272 - accuracy: 0.9275 - val_loss: 0.1949 - val_accuracy: 0.9415\n",
            "Epoch 2888/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2294 - accuracy: 0.9247 - val_loss: 0.1912 - val_accuracy: 0.9440\n",
            "Epoch 2889/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2331 - accuracy: 0.9241 - val_loss: 0.1903 - val_accuracy: 0.9455\n",
            "Epoch 2890/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2448 - accuracy: 0.9227 - val_loss: 0.1897 - val_accuracy: 0.9430\n",
            "Epoch 2891/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2302 - accuracy: 0.9255 - val_loss: 0.1933 - val_accuracy: 0.9430\n",
            "Epoch 2892/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2298 - accuracy: 0.9258 - val_loss: 0.1874 - val_accuracy: 0.9440\n",
            "Epoch 2893/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2443 - accuracy: 0.9224 - val_loss: 0.1929 - val_accuracy: 0.9420\n",
            "Epoch 2894/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2313 - accuracy: 0.9271 - val_loss: 0.1903 - val_accuracy: 0.9455\n",
            "Epoch 2895/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2288 - accuracy: 0.9246 - val_loss: 0.1928 - val_accuracy: 0.9455\n",
            "Epoch 2896/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2265 - accuracy: 0.9266 - val_loss: 0.1877 - val_accuracy: 0.9460\n",
            "Epoch 2897/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2389 - accuracy: 0.9283 - val_loss: 0.1871 - val_accuracy: 0.9450\n",
            "Epoch 2898/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2177 - accuracy: 0.9296 - val_loss: 0.1931 - val_accuracy: 0.9420\n",
            "Epoch 2899/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2252 - accuracy: 0.9260 - val_loss: 0.1922 - val_accuracy: 0.9435\n",
            "Epoch 2900/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2351 - accuracy: 0.9240 - val_loss: 0.1873 - val_accuracy: 0.9435\n",
            "Epoch 2901/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2267 - accuracy: 0.9285 - val_loss: 0.1909 - val_accuracy: 0.9435\n",
            "Epoch 2902/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2324 - accuracy: 0.9256 - val_loss: 0.1910 - val_accuracy: 0.9420\n",
            "Epoch 2903/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2343 - accuracy: 0.9260 - val_loss: 0.1857 - val_accuracy: 0.9455\n",
            "Epoch 2904/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2274 - accuracy: 0.9241 - val_loss: 0.1978 - val_accuracy: 0.9445\n",
            "Epoch 2905/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2294 - accuracy: 0.9276 - val_loss: 0.1949 - val_accuracy: 0.9440\n",
            "Epoch 2906/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2373 - accuracy: 0.9211 - val_loss: 0.1884 - val_accuracy: 0.9435\n",
            "Epoch 2907/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2273 - accuracy: 0.9269 - val_loss: 0.1916 - val_accuracy: 0.9440\n",
            "Epoch 2908/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2345 - accuracy: 0.9240 - val_loss: 0.1887 - val_accuracy: 0.9455\n",
            "Epoch 2909/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2289 - accuracy: 0.9260 - val_loss: 0.1887 - val_accuracy: 0.9455\n",
            "Epoch 2910/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2266 - accuracy: 0.9260 - val_loss: 0.1957 - val_accuracy: 0.9440\n",
            "Epoch 2911/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2312 - accuracy: 0.9237 - val_loss: 0.1893 - val_accuracy: 0.9450\n",
            "Epoch 2912/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2346 - accuracy: 0.9255 - val_loss: 0.1924 - val_accuracy: 0.9430\n",
            "Epoch 2913/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2287 - accuracy: 0.9261 - val_loss: 0.1961 - val_accuracy: 0.9450\n",
            "Epoch 2914/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2329 - accuracy: 0.9226 - val_loss: 0.1900 - val_accuracy: 0.9445\n",
            "Epoch 2915/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2325 - accuracy: 0.9246 - val_loss: 0.1904 - val_accuracy: 0.9445\n",
            "Epoch 2916/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2410 - accuracy: 0.9221 - val_loss: 0.1922 - val_accuracy: 0.9435\n",
            "Epoch 2917/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2379 - accuracy: 0.9275 - val_loss: 0.1942 - val_accuracy: 0.9450\n",
            "Epoch 2918/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2322 - accuracy: 0.9229 - val_loss: 0.1926 - val_accuracy: 0.9430\n",
            "Epoch 2919/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2348 - accuracy: 0.9247 - val_loss: 0.1930 - val_accuracy: 0.9440\n",
            "Epoch 2920/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2328 - accuracy: 0.9275 - val_loss: 0.1864 - val_accuracy: 0.9450\n",
            "Epoch 2921/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2384 - accuracy: 0.9219 - val_loss: 0.1947 - val_accuracy: 0.9425\n",
            "Epoch 2922/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2328 - accuracy: 0.9295 - val_loss: 0.1920 - val_accuracy: 0.9430\n",
            "Epoch 2923/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2287 - accuracy: 0.9270 - val_loss: 0.1921 - val_accuracy: 0.9425\n",
            "Epoch 2924/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2319 - accuracy: 0.9266 - val_loss: 0.1938 - val_accuracy: 0.9435\n",
            "Epoch 2925/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2349 - accuracy: 0.9240 - val_loss: 0.1912 - val_accuracy: 0.9440\n",
            "Epoch 2926/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2339 - accuracy: 0.9227 - val_loss: 0.1897 - val_accuracy: 0.9455\n",
            "Epoch 2927/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2391 - accuracy: 0.9236 - val_loss: 0.1914 - val_accuracy: 0.9455\n",
            "Epoch 2928/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2355 - accuracy: 0.9219 - val_loss: 0.1911 - val_accuracy: 0.9435\n",
            "Epoch 2929/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2323 - accuracy: 0.9285 - val_loss: 0.1911 - val_accuracy: 0.9445\n",
            "Epoch 2930/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2339 - accuracy: 0.9245 - val_loss: 0.1916 - val_accuracy: 0.9450\n",
            "Epoch 2931/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2370 - accuracy: 0.9287 - val_loss: 0.1897 - val_accuracy: 0.9440\n",
            "Epoch 2932/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2249 - accuracy: 0.9298 - val_loss: 0.1899 - val_accuracy: 0.9430\n",
            "Epoch 2933/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2383 - accuracy: 0.9230 - val_loss: 0.1921 - val_accuracy: 0.9430\n",
            "Epoch 2934/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2308 - accuracy: 0.9265 - val_loss: 0.1861 - val_accuracy: 0.9465\n",
            "Epoch 2935/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2262 - accuracy: 0.9241 - val_loss: 0.1896 - val_accuracy: 0.9440\n",
            "Epoch 2936/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2308 - accuracy: 0.9262 - val_loss: 0.1911 - val_accuracy: 0.9440\n",
            "Epoch 2937/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2251 - accuracy: 0.9259 - val_loss: 0.1912 - val_accuracy: 0.9455\n",
            "Epoch 2938/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2292 - accuracy: 0.9244 - val_loss: 0.1914 - val_accuracy: 0.9455\n",
            "Epoch 2939/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2296 - accuracy: 0.9271 - val_loss: 0.1930 - val_accuracy: 0.9435\n",
            "Epoch 2940/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2338 - accuracy: 0.9259 - val_loss: 0.1913 - val_accuracy: 0.9435\n",
            "Epoch 2941/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2239 - accuracy: 0.9279 - val_loss: 0.1906 - val_accuracy: 0.9440\n",
            "Epoch 2942/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2366 - accuracy: 0.9254 - val_loss: 0.1917 - val_accuracy: 0.9450\n",
            "Epoch 2943/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2373 - accuracy: 0.9226 - val_loss: 0.1935 - val_accuracy: 0.9455\n",
            "Epoch 2944/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2380 - accuracy: 0.9245 - val_loss: 0.1921 - val_accuracy: 0.9455\n",
            "Epoch 2945/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2383 - accuracy: 0.9240 - val_loss: 0.1933 - val_accuracy: 0.9440\n",
            "Epoch 2946/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2317 - accuracy: 0.9247 - val_loss: 0.1925 - val_accuracy: 0.9450\n",
            "Epoch 2947/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2272 - accuracy: 0.9256 - val_loss: 0.1896 - val_accuracy: 0.9460\n",
            "Epoch 2948/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2369 - accuracy: 0.9230 - val_loss: 0.1952 - val_accuracy: 0.9440\n",
            "Epoch 2949/6000\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2389 - accuracy: 0.9273 - val_loss: 0.1887 - val_accuracy: 0.9455\n",
            "Epoch 2950/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2313 - accuracy: 0.9276 - val_loss: 0.1937 - val_accuracy: 0.9440\n",
            "Epoch 2951/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2366 - accuracy: 0.9235 - val_loss: 0.1940 - val_accuracy: 0.9450\n",
            "Epoch 2952/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2219 - accuracy: 0.9290 - val_loss: 0.1936 - val_accuracy: 0.9435\n",
            "Epoch 2953/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2360 - accuracy: 0.9225 - val_loss: 0.1964 - val_accuracy: 0.9440\n",
            "Epoch 2954/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2280 - accuracy: 0.9247 - val_loss: 0.1900 - val_accuracy: 0.9450\n",
            "Epoch 2955/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2412 - accuracy: 0.9261 - val_loss: 0.1875 - val_accuracy: 0.9450\n",
            "Epoch 2956/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2262 - accuracy: 0.9265 - val_loss: 0.1872 - val_accuracy: 0.9450\n",
            "Epoch 2957/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2412 - accuracy: 0.9240 - val_loss: 0.1909 - val_accuracy: 0.9450\n",
            "Epoch 2958/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2392 - accuracy: 0.9233 - val_loss: 0.1954 - val_accuracy: 0.9455\n",
            "Epoch 2959/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2312 - accuracy: 0.9236 - val_loss: 0.1910 - val_accuracy: 0.9435\n",
            "Epoch 2960/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2275 - accuracy: 0.9254 - val_loss: 0.1955 - val_accuracy: 0.9425\n",
            "Epoch 2961/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2302 - accuracy: 0.9234 - val_loss: 0.1878 - val_accuracy: 0.9445\n",
            "Epoch 2962/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2362 - accuracy: 0.9237 - val_loss: 0.1910 - val_accuracy: 0.9430\n",
            "Epoch 2963/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2361 - accuracy: 0.9254 - val_loss: 0.1891 - val_accuracy: 0.9455\n",
            "Epoch 2964/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2321 - accuracy: 0.9239 - val_loss: 0.1940 - val_accuracy: 0.9450\n",
            "Epoch 2965/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2357 - accuracy: 0.9255 - val_loss: 0.1958 - val_accuracy: 0.9405\n",
            "Epoch 2966/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2403 - accuracy: 0.9241 - val_loss: 0.1899 - val_accuracy: 0.9425\n",
            "Epoch 2967/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2269 - accuracy: 0.9271 - val_loss: 0.1902 - val_accuracy: 0.9455\n",
            "Epoch 2968/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2270 - accuracy: 0.9285 - val_loss: 0.1906 - val_accuracy: 0.9460\n",
            "Epoch 2969/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2295 - accuracy: 0.9249 - val_loss: 0.1915 - val_accuracy: 0.9430\n",
            "Epoch 2970/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2271 - accuracy: 0.9281 - val_loss: 0.1935 - val_accuracy: 0.9430\n",
            "Epoch 2971/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2360 - accuracy: 0.9260 - val_loss: 0.1941 - val_accuracy: 0.9450\n",
            "Epoch 2972/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2332 - accuracy: 0.9235 - val_loss: 0.1966 - val_accuracy: 0.9455\n",
            "Epoch 2973/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2352 - accuracy: 0.9256 - val_loss: 0.1910 - val_accuracy: 0.9445\n",
            "Epoch 2974/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2414 - accuracy: 0.9206 - val_loss: 0.1901 - val_accuracy: 0.9435\n",
            "Epoch 2975/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2260 - accuracy: 0.9260 - val_loss: 0.1932 - val_accuracy: 0.9435\n",
            "Epoch 2976/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2333 - accuracy: 0.9243 - val_loss: 0.1951 - val_accuracy: 0.9430\n",
            "Epoch 2977/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2486 - accuracy: 0.9219 - val_loss: 0.1952 - val_accuracy: 0.9435\n",
            "Epoch 2978/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2297 - accuracy: 0.9268 - val_loss: 0.1994 - val_accuracy: 0.9410\n",
            "Epoch 2979/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2284 - accuracy: 0.9285 - val_loss: 0.1885 - val_accuracy: 0.9435\n",
            "Epoch 2980/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2286 - accuracy: 0.9250 - val_loss: 0.1886 - val_accuracy: 0.9455\n",
            "Epoch 2981/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2267 - accuracy: 0.9273 - val_loss: 0.1926 - val_accuracy: 0.9440\n",
            "Epoch 2982/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2301 - accuracy: 0.9264 - val_loss: 0.1897 - val_accuracy: 0.9450\n",
            "Epoch 2983/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2210 - accuracy: 0.9289 - val_loss: 0.1899 - val_accuracy: 0.9455\n",
            "Epoch 2984/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2303 - accuracy: 0.9260 - val_loss: 0.1897 - val_accuracy: 0.9450\n",
            "Epoch 2985/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2287 - accuracy: 0.9252 - val_loss: 0.1914 - val_accuracy: 0.9455\n",
            "Epoch 2986/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2362 - accuracy: 0.9264 - val_loss: 0.1907 - val_accuracy: 0.9445\n",
            "Epoch 2987/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2281 - accuracy: 0.9265 - val_loss: 0.1886 - val_accuracy: 0.9450\n",
            "Epoch 2988/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2286 - accuracy: 0.9261 - val_loss: 0.1890 - val_accuracy: 0.9445\n",
            "Epoch 2989/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2285 - accuracy: 0.9283 - val_loss: 0.1901 - val_accuracy: 0.9460\n",
            "Epoch 2990/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2269 - accuracy: 0.9280 - val_loss: 0.1916 - val_accuracy: 0.9460\n",
            "Epoch 2991/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2342 - accuracy: 0.9285 - val_loss: 0.1878 - val_accuracy: 0.9465\n",
            "Epoch 2992/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2285 - accuracy: 0.9271 - val_loss: 0.1887 - val_accuracy: 0.9460\n",
            "Epoch 2993/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2364 - accuracy: 0.9224 - val_loss: 0.1916 - val_accuracy: 0.9440\n",
            "Epoch 2994/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2374 - accuracy: 0.9252 - val_loss: 0.1921 - val_accuracy: 0.9440\n",
            "Epoch 2995/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2351 - accuracy: 0.9251 - val_loss: 0.1934 - val_accuracy: 0.9440\n",
            "Epoch 2996/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2261 - accuracy: 0.9281 - val_loss: 0.1911 - val_accuracy: 0.9450\n",
            "Epoch 2997/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2259 - accuracy: 0.9273 - val_loss: 0.1899 - val_accuracy: 0.9445\n",
            "Epoch 2998/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2326 - accuracy: 0.9245 - val_loss: 0.1900 - val_accuracy: 0.9445\n",
            "Epoch 2999/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2297 - accuracy: 0.9270 - val_loss: 0.1896 - val_accuracy: 0.9460\n",
            "Epoch 3000/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2306 - accuracy: 0.9247 - val_loss: 0.1970 - val_accuracy: 0.9430\n",
            "Epoch 3001/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2309 - accuracy: 0.9255 - val_loss: 0.1894 - val_accuracy: 0.9425\n",
            "Epoch 3002/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2288 - accuracy: 0.9246 - val_loss: 0.1882 - val_accuracy: 0.9450\n",
            "Epoch 3003/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2329 - accuracy: 0.9245 - val_loss: 0.1912 - val_accuracy: 0.9430\n",
            "Epoch 3004/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2349 - accuracy: 0.9244 - val_loss: 0.1925 - val_accuracy: 0.9425\n",
            "Epoch 3005/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2312 - accuracy: 0.9241 - val_loss: 0.1917 - val_accuracy: 0.9445\n",
            "Epoch 3006/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2295 - accuracy: 0.9251 - val_loss: 0.1923 - val_accuracy: 0.9440\n",
            "Epoch 3007/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2445 - accuracy: 0.9206 - val_loss: 0.1978 - val_accuracy: 0.9415\n",
            "Epoch 3008/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2273 - accuracy: 0.9259 - val_loss: 0.1898 - val_accuracy: 0.9450\n",
            "Epoch 3009/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2368 - accuracy: 0.9216 - val_loss: 0.1892 - val_accuracy: 0.9435\n",
            "Epoch 3010/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2263 - accuracy: 0.9280 - val_loss: 0.1889 - val_accuracy: 0.9455\n",
            "Epoch 3011/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2383 - accuracy: 0.9233 - val_loss: 0.1939 - val_accuracy: 0.9440\n",
            "Epoch 3012/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2389 - accuracy: 0.9244 - val_loss: 0.1876 - val_accuracy: 0.9450\n",
            "Epoch 3013/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2358 - accuracy: 0.9255 - val_loss: 0.1937 - val_accuracy: 0.9445\n",
            "Epoch 3014/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2282 - accuracy: 0.9259 - val_loss: 0.1937 - val_accuracy: 0.9430\n",
            "Epoch 3015/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2296 - accuracy: 0.9259 - val_loss: 0.1919 - val_accuracy: 0.9455\n",
            "Epoch 3016/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2398 - accuracy: 0.9256 - val_loss: 0.1924 - val_accuracy: 0.9445\n",
            "Epoch 3017/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2294 - accuracy: 0.9235 - val_loss: 0.1923 - val_accuracy: 0.9435\n",
            "Epoch 3018/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2326 - accuracy: 0.9240 - val_loss: 0.1873 - val_accuracy: 0.9450\n",
            "Epoch 3019/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2249 - accuracy: 0.9290 - val_loss: 0.1920 - val_accuracy: 0.9435\n",
            "Epoch 3020/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2254 - accuracy: 0.9266 - val_loss: 0.1965 - val_accuracy: 0.9420\n",
            "Epoch 3021/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2537 - accuracy: 0.9250 - val_loss: 0.1901 - val_accuracy: 0.9450\n",
            "Epoch 3022/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2287 - accuracy: 0.9245 - val_loss: 0.1910 - val_accuracy: 0.9440\n",
            "Epoch 3023/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2444 - accuracy: 0.9230 - val_loss: 0.1911 - val_accuracy: 0.9445\n",
            "Epoch 3024/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2332 - accuracy: 0.9256 - val_loss: 0.1873 - val_accuracy: 0.9450\n",
            "Epoch 3025/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2316 - accuracy: 0.9255 - val_loss: 0.1941 - val_accuracy: 0.9435\n",
            "Epoch 3026/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2292 - accuracy: 0.9244 - val_loss: 0.1922 - val_accuracy: 0.9455\n",
            "Epoch 3027/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2367 - accuracy: 0.9243 - val_loss: 0.1973 - val_accuracy: 0.9420\n",
            "Epoch 3028/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2266 - accuracy: 0.9255 - val_loss: 0.1960 - val_accuracy: 0.9420\n",
            "Epoch 3029/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2370 - accuracy: 0.9233 - val_loss: 0.1930 - val_accuracy: 0.9440\n",
            "Epoch 3030/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2380 - accuracy: 0.9227 - val_loss: 0.1925 - val_accuracy: 0.9435\n",
            "Epoch 3031/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2399 - accuracy: 0.9209 - val_loss: 0.1955 - val_accuracy: 0.9400\n",
            "Epoch 3032/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2301 - accuracy: 0.9229 - val_loss: 0.1960 - val_accuracy: 0.9405\n",
            "Epoch 3033/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2419 - accuracy: 0.9246 - val_loss: 0.1917 - val_accuracy: 0.9455\n",
            "Epoch 3034/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2411 - accuracy: 0.9224 - val_loss: 0.1929 - val_accuracy: 0.9450\n",
            "Epoch 3035/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2280 - accuracy: 0.9268 - val_loss: 0.1922 - val_accuracy: 0.9450\n",
            "Epoch 3036/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2311 - accuracy: 0.9218 - val_loss: 0.1907 - val_accuracy: 0.9460\n",
            "Epoch 3037/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2370 - accuracy: 0.9233 - val_loss: 0.1926 - val_accuracy: 0.9445\n",
            "Epoch 3038/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2290 - accuracy: 0.9265 - val_loss: 0.1952 - val_accuracy: 0.9435\n",
            "Epoch 3039/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2307 - accuracy: 0.9260 - val_loss: 0.1920 - val_accuracy: 0.9450\n",
            "Epoch 3040/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2321 - accuracy: 0.9241 - val_loss: 0.1898 - val_accuracy: 0.9430\n",
            "Epoch 3041/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2257 - accuracy: 0.9286 - val_loss: 0.1890 - val_accuracy: 0.9445\n",
            "Epoch 3042/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2294 - accuracy: 0.9246 - val_loss: 0.1988 - val_accuracy: 0.9420\n",
            "Epoch 3043/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2217 - accuracy: 0.9290 - val_loss: 0.1896 - val_accuracy: 0.9455\n",
            "Epoch 3044/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2298 - accuracy: 0.9222 - val_loss: 0.1921 - val_accuracy: 0.9450\n",
            "Epoch 3045/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2339 - accuracy: 0.9216 - val_loss: 0.1932 - val_accuracy: 0.9445\n",
            "Epoch 3046/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2312 - accuracy: 0.9255 - val_loss: 0.1908 - val_accuracy: 0.9440\n",
            "Epoch 3047/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2273 - accuracy: 0.9249 - val_loss: 0.1977 - val_accuracy: 0.9435\n",
            "Epoch 3048/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2316 - accuracy: 0.9258 - val_loss: 0.1890 - val_accuracy: 0.9455\n",
            "Epoch 3049/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2396 - accuracy: 0.9222 - val_loss: 0.1921 - val_accuracy: 0.9425\n",
            "Epoch 3050/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2476 - accuracy: 0.9239 - val_loss: 0.1923 - val_accuracy: 0.9420\n",
            "Epoch 3051/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2325 - accuracy: 0.9216 - val_loss: 0.1916 - val_accuracy: 0.9450\n",
            "Epoch 3052/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2346 - accuracy: 0.9218 - val_loss: 0.1876 - val_accuracy: 0.9435\n",
            "Epoch 3053/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2283 - accuracy: 0.9280 - val_loss: 0.1897 - val_accuracy: 0.9435\n",
            "Epoch 3054/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2340 - accuracy: 0.9246 - val_loss: 0.1934 - val_accuracy: 0.9440\n",
            "Epoch 3055/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2261 - accuracy: 0.9255 - val_loss: 0.1913 - val_accuracy: 0.9430\n",
            "Epoch 3056/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2294 - accuracy: 0.9254 - val_loss: 0.1901 - val_accuracy: 0.9455\n",
            "Epoch 3057/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2280 - accuracy: 0.9270 - val_loss: 0.1859 - val_accuracy: 0.9460\n",
            "Epoch 3058/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2242 - accuracy: 0.9265 - val_loss: 0.1879 - val_accuracy: 0.9445\n",
            "Epoch 3059/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2302 - accuracy: 0.9275 - val_loss: 0.1876 - val_accuracy: 0.9455\n",
            "Epoch 3060/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2287 - accuracy: 0.9259 - val_loss: 0.1865 - val_accuracy: 0.9460\n",
            "Epoch 3061/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2346 - accuracy: 0.9249 - val_loss: 0.1934 - val_accuracy: 0.9470\n",
            "Epoch 3062/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2283 - accuracy: 0.9273 - val_loss: 0.1954 - val_accuracy: 0.9455\n",
            "Epoch 3063/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2310 - accuracy: 0.9255 - val_loss: 0.1872 - val_accuracy: 0.9450\n",
            "Epoch 3064/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2331 - accuracy: 0.9268 - val_loss: 0.1909 - val_accuracy: 0.9460\n",
            "Epoch 3065/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2246 - accuracy: 0.9254 - val_loss: 0.1971 - val_accuracy: 0.9415\n",
            "Epoch 3066/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2347 - accuracy: 0.9258 - val_loss: 0.1938 - val_accuracy: 0.9445\n",
            "Epoch 3067/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2328 - accuracy: 0.9245 - val_loss: 0.1884 - val_accuracy: 0.9450\n",
            "Epoch 3068/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2273 - accuracy: 0.9261 - val_loss: 0.1919 - val_accuracy: 0.9435\n",
            "Epoch 3069/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2263 - accuracy: 0.9251 - val_loss: 0.1946 - val_accuracy: 0.9425\n",
            "Epoch 3070/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2252 - accuracy: 0.9266 - val_loss: 0.1963 - val_accuracy: 0.9435\n",
            "Epoch 3071/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2408 - accuracy: 0.9216 - val_loss: 0.1941 - val_accuracy: 0.9450\n",
            "Epoch 3072/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2516 - accuracy: 0.9246 - val_loss: 0.1955 - val_accuracy: 0.9425\n",
            "Epoch 3073/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2372 - accuracy: 0.9254 - val_loss: 0.1877 - val_accuracy: 0.9445\n",
            "Epoch 3074/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2223 - accuracy: 0.9275 - val_loss: 0.1946 - val_accuracy: 0.9420\n",
            "Epoch 3075/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2291 - accuracy: 0.9235 - val_loss: 0.1915 - val_accuracy: 0.9455\n",
            "Epoch 3076/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2347 - accuracy: 0.9266 - val_loss: 0.1861 - val_accuracy: 0.9445\n",
            "Epoch 3077/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2354 - accuracy: 0.9229 - val_loss: 0.1902 - val_accuracy: 0.9425\n",
            "Epoch 3078/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2293 - accuracy: 0.9274 - val_loss: 0.1900 - val_accuracy: 0.9435\n",
            "Epoch 3079/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2279 - accuracy: 0.9274 - val_loss: 0.1933 - val_accuracy: 0.9445\n",
            "Epoch 3080/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2382 - accuracy: 0.9276 - val_loss: 0.1954 - val_accuracy: 0.9410\n",
            "Epoch 3081/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2422 - accuracy: 0.9227 - val_loss: 0.1941 - val_accuracy: 0.9425\n",
            "Epoch 3082/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2339 - accuracy: 0.9243 - val_loss: 0.1954 - val_accuracy: 0.9435\n",
            "Epoch 3083/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2354 - accuracy: 0.9236 - val_loss: 0.1894 - val_accuracy: 0.9445\n",
            "Epoch 3084/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2463 - accuracy: 0.9221 - val_loss: 0.1909 - val_accuracy: 0.9425\n",
            "Epoch 3085/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2212 - accuracy: 0.9259 - val_loss: 0.1894 - val_accuracy: 0.9450\n",
            "Epoch 3086/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2358 - accuracy: 0.9276 - val_loss: 0.1902 - val_accuracy: 0.9450\n",
            "Epoch 3087/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2267 - accuracy: 0.9252 - val_loss: 0.1909 - val_accuracy: 0.9440\n",
            "Epoch 3088/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2383 - accuracy: 0.9240 - val_loss: 0.1952 - val_accuracy: 0.9440\n",
            "Epoch 3089/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2294 - accuracy: 0.9259 - val_loss: 0.1908 - val_accuracy: 0.9430\n",
            "Epoch 3090/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2300 - accuracy: 0.9251 - val_loss: 0.1920 - val_accuracy: 0.9445\n",
            "Epoch 3091/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2313 - accuracy: 0.9247 - val_loss: 0.1897 - val_accuracy: 0.9435\n",
            "Epoch 3092/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2335 - accuracy: 0.9234 - val_loss: 0.1894 - val_accuracy: 0.9445\n",
            "Epoch 3093/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2269 - accuracy: 0.9280 - val_loss: 0.1909 - val_accuracy: 0.9460\n",
            "Epoch 3094/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2287 - accuracy: 0.9255 - val_loss: 0.1926 - val_accuracy: 0.9460\n",
            "Epoch 3095/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2340 - accuracy: 0.9247 - val_loss: 0.1893 - val_accuracy: 0.9450\n",
            "Epoch 3096/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2447 - accuracy: 0.9239 - val_loss: 0.1935 - val_accuracy: 0.9430\n",
            "Epoch 3097/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2275 - accuracy: 0.9262 - val_loss: 0.1891 - val_accuracy: 0.9425\n",
            "Epoch 3098/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2294 - accuracy: 0.9254 - val_loss: 0.1887 - val_accuracy: 0.9435\n",
            "Epoch 3099/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2245 - accuracy: 0.9277 - val_loss: 0.1871 - val_accuracy: 0.9440\n",
            "Epoch 3100/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2274 - accuracy: 0.9254 - val_loss: 0.1915 - val_accuracy: 0.9435\n",
            "Epoch 3101/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2273 - accuracy: 0.9246 - val_loss: 0.1971 - val_accuracy: 0.9440\n",
            "Epoch 3102/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2295 - accuracy: 0.9224 - val_loss: 0.1984 - val_accuracy: 0.9425\n",
            "Epoch 3103/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2328 - accuracy: 0.9245 - val_loss: 0.1947 - val_accuracy: 0.9440\n",
            "Epoch 3104/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2254 - accuracy: 0.9274 - val_loss: 0.1920 - val_accuracy: 0.9425\n",
            "Epoch 3105/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2277 - accuracy: 0.9250 - val_loss: 0.1877 - val_accuracy: 0.9445\n",
            "Epoch 3106/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2263 - accuracy: 0.9281 - val_loss: 0.1937 - val_accuracy: 0.9455\n",
            "Epoch 3107/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2308 - accuracy: 0.9265 - val_loss: 0.1912 - val_accuracy: 0.9455\n",
            "Epoch 3108/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2317 - accuracy: 0.9235 - val_loss: 0.1922 - val_accuracy: 0.9445\n",
            "Epoch 3109/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2322 - accuracy: 0.9235 - val_loss: 0.1893 - val_accuracy: 0.9450\n",
            "Epoch 3110/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2400 - accuracy: 0.9243 - val_loss: 0.1898 - val_accuracy: 0.9460\n",
            "Epoch 3111/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2276 - accuracy: 0.9256 - val_loss: 0.1884 - val_accuracy: 0.9445\n",
            "Epoch 3112/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2251 - accuracy: 0.9281 - val_loss: 0.1947 - val_accuracy: 0.9435\n",
            "Epoch 3113/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2278 - accuracy: 0.9265 - val_loss: 0.1878 - val_accuracy: 0.9455\n",
            "Epoch 3114/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2336 - accuracy: 0.9255 - val_loss: 0.1935 - val_accuracy: 0.9405\n",
            "Epoch 3115/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2388 - accuracy: 0.9265 - val_loss: 0.1903 - val_accuracy: 0.9425\n",
            "Epoch 3116/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2330 - accuracy: 0.9230 - val_loss: 0.1962 - val_accuracy: 0.9440\n",
            "Epoch 3117/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2357 - accuracy: 0.9227 - val_loss: 0.1936 - val_accuracy: 0.9450\n",
            "Epoch 3118/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2341 - accuracy: 0.9243 - val_loss: 0.1945 - val_accuracy: 0.9445\n",
            "Epoch 3119/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2350 - accuracy: 0.9215 - val_loss: 0.1928 - val_accuracy: 0.9450\n",
            "Epoch 3120/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2391 - accuracy: 0.9241 - val_loss: 0.1915 - val_accuracy: 0.9440\n",
            "Epoch 3121/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2338 - accuracy: 0.9229 - val_loss: 0.1918 - val_accuracy: 0.9445\n",
            "Epoch 3122/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2422 - accuracy: 0.9250 - val_loss: 0.1961 - val_accuracy: 0.9425\n",
            "Epoch 3123/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2421 - accuracy: 0.9256 - val_loss: 0.1935 - val_accuracy: 0.9450\n",
            "Epoch 3124/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2241 - accuracy: 0.9259 - val_loss: 0.1887 - val_accuracy: 0.9455\n",
            "Epoch 3125/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2320 - accuracy: 0.9246 - val_loss: 0.1912 - val_accuracy: 0.9455\n",
            "Epoch 3126/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2434 - accuracy: 0.9234 - val_loss: 0.1909 - val_accuracy: 0.9445\n",
            "Epoch 3127/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2309 - accuracy: 0.9231 - val_loss: 0.1938 - val_accuracy: 0.9445\n",
            "Epoch 3128/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2327 - accuracy: 0.9225 - val_loss: 0.1929 - val_accuracy: 0.9450\n",
            "Epoch 3129/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2284 - accuracy: 0.9275 - val_loss: 0.1919 - val_accuracy: 0.9445\n",
            "Epoch 3130/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2288 - accuracy: 0.9251 - val_loss: 0.1903 - val_accuracy: 0.9450\n",
            "Epoch 3131/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2218 - accuracy: 0.9290 - val_loss: 0.1914 - val_accuracy: 0.9460\n",
            "Epoch 3132/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2206 - accuracy: 0.9276 - val_loss: 0.1912 - val_accuracy: 0.9450\n",
            "Epoch 3133/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2377 - accuracy: 0.9225 - val_loss: 0.1895 - val_accuracy: 0.9450\n",
            "Epoch 3134/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2407 - accuracy: 0.9241 - val_loss: 0.1895 - val_accuracy: 0.9460\n",
            "Epoch 3135/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2275 - accuracy: 0.9262 - val_loss: 0.1870 - val_accuracy: 0.9455\n",
            "Epoch 3136/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2302 - accuracy: 0.9237 - val_loss: 0.1937 - val_accuracy: 0.9410\n",
            "Epoch 3137/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2405 - accuracy: 0.9222 - val_loss: 0.1870 - val_accuracy: 0.9450\n",
            "Epoch 3138/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2296 - accuracy: 0.9264 - val_loss: 0.1878 - val_accuracy: 0.9440\n",
            "Epoch 3139/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2273 - accuracy: 0.9259 - val_loss: 0.1861 - val_accuracy: 0.9465\n",
            "Epoch 3140/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2329 - accuracy: 0.9259 - val_loss: 0.1901 - val_accuracy: 0.9455\n",
            "Epoch 3141/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2372 - accuracy: 0.9280 - val_loss: 0.1936 - val_accuracy: 0.9440\n",
            "Epoch 3142/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2444 - accuracy: 0.9241 - val_loss: 0.1910 - val_accuracy: 0.9460\n",
            "Epoch 3143/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2430 - accuracy: 0.9240 - val_loss: 0.1925 - val_accuracy: 0.9450\n",
            "Epoch 3144/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2259 - accuracy: 0.9275 - val_loss: 0.1909 - val_accuracy: 0.9450\n",
            "Epoch 3145/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2344 - accuracy: 0.9227 - val_loss: 0.1912 - val_accuracy: 0.9445\n",
            "Epoch 3146/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2261 - accuracy: 0.9306 - val_loss: 0.1889 - val_accuracy: 0.9435\n",
            "Epoch 3147/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2307 - accuracy: 0.9227 - val_loss: 0.1942 - val_accuracy: 0.9455\n",
            "Epoch 3148/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2393 - accuracy: 0.9237 - val_loss: 0.1905 - val_accuracy: 0.9440\n",
            "Epoch 3149/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2315 - accuracy: 0.9244 - val_loss: 0.1928 - val_accuracy: 0.9440\n",
            "Epoch 3150/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2291 - accuracy: 0.9270 - val_loss: 0.1907 - val_accuracy: 0.9455\n",
            "Epoch 3151/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2277 - accuracy: 0.9262 - val_loss: 0.1887 - val_accuracy: 0.9445\n",
            "Epoch 3152/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2377 - accuracy: 0.9252 - val_loss: 0.1905 - val_accuracy: 0.9445\n",
            "Epoch 3153/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2354 - accuracy: 0.9245 - val_loss: 0.1917 - val_accuracy: 0.9445\n",
            "Epoch 3154/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2292 - accuracy: 0.9252 - val_loss: 0.1894 - val_accuracy: 0.9450\n",
            "Epoch 3155/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2337 - accuracy: 0.9251 - val_loss: 0.1922 - val_accuracy: 0.9445\n",
            "Epoch 3156/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2327 - accuracy: 0.9244 - val_loss: 0.1904 - val_accuracy: 0.9440\n",
            "Epoch 3157/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2386 - accuracy: 0.9215 - val_loss: 0.1892 - val_accuracy: 0.9455\n",
            "Epoch 3158/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2367 - accuracy: 0.9261 - val_loss: 0.1954 - val_accuracy: 0.9430\n",
            "Epoch 3159/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2261 - accuracy: 0.9226 - val_loss: 0.1900 - val_accuracy: 0.9450\n",
            "Epoch 3160/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2299 - accuracy: 0.9281 - val_loss: 0.1883 - val_accuracy: 0.9455\n",
            "Epoch 3161/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2290 - accuracy: 0.9244 - val_loss: 0.1914 - val_accuracy: 0.9415\n",
            "Epoch 3162/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2367 - accuracy: 0.9249 - val_loss: 0.1923 - val_accuracy: 0.9455\n",
            "Epoch 3163/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2303 - accuracy: 0.9255 - val_loss: 0.1923 - val_accuracy: 0.9430\n",
            "Epoch 3164/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2282 - accuracy: 0.9254 - val_loss: 0.1936 - val_accuracy: 0.9435\n",
            "Epoch 3165/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2268 - accuracy: 0.9262 - val_loss: 0.1869 - val_accuracy: 0.9450\n",
            "Epoch 3166/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2282 - accuracy: 0.9277 - val_loss: 0.1938 - val_accuracy: 0.9435\n",
            "Epoch 3167/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2265 - accuracy: 0.9299 - val_loss: 0.1857 - val_accuracy: 0.9450\n",
            "Epoch 3168/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2344 - accuracy: 0.9240 - val_loss: 0.1929 - val_accuracy: 0.9440\n",
            "Epoch 3169/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2296 - accuracy: 0.9244 - val_loss: 0.1919 - val_accuracy: 0.9450\n",
            "Epoch 3170/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2270 - accuracy: 0.9255 - val_loss: 0.1957 - val_accuracy: 0.9425\n",
            "Epoch 3171/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2328 - accuracy: 0.9247 - val_loss: 0.1897 - val_accuracy: 0.9445\n",
            "Epoch 3172/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2335 - accuracy: 0.9273 - val_loss: 0.1945 - val_accuracy: 0.9465\n",
            "Epoch 3173/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2296 - accuracy: 0.9265 - val_loss: 0.1920 - val_accuracy: 0.9440\n",
            "Epoch 3174/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2310 - accuracy: 0.9260 - val_loss: 0.1938 - val_accuracy: 0.9445\n",
            "Epoch 3175/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2332 - accuracy: 0.9286 - val_loss: 0.1912 - val_accuracy: 0.9450\n",
            "Epoch 3176/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2274 - accuracy: 0.9244 - val_loss: 0.1912 - val_accuracy: 0.9450\n",
            "Epoch 3177/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2241 - accuracy: 0.9284 - val_loss: 0.1871 - val_accuracy: 0.9465\n",
            "Epoch 3178/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2519 - accuracy: 0.9215 - val_loss: 0.1950 - val_accuracy: 0.9440\n",
            "Epoch 3179/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2274 - accuracy: 0.9270 - val_loss: 0.1922 - val_accuracy: 0.9445\n",
            "Epoch 3180/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2217 - accuracy: 0.9280 - val_loss: 0.1911 - val_accuracy: 0.9445\n",
            "Epoch 3181/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2363 - accuracy: 0.9245 - val_loss: 0.1950 - val_accuracy: 0.9440\n",
            "Epoch 3182/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2413 - accuracy: 0.9226 - val_loss: 0.1885 - val_accuracy: 0.9455\n",
            "Epoch 3183/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2299 - accuracy: 0.9250 - val_loss: 0.1951 - val_accuracy: 0.9435\n",
            "Epoch 3184/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2258 - accuracy: 0.9243 - val_loss: 0.1930 - val_accuracy: 0.9435\n",
            "Epoch 3185/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2322 - accuracy: 0.9260 - val_loss: 0.1907 - val_accuracy: 0.9455\n",
            "Epoch 3186/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2287 - accuracy: 0.9243 - val_loss: 0.1933 - val_accuracy: 0.9430\n",
            "Epoch 3187/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2306 - accuracy: 0.9258 - val_loss: 0.1917 - val_accuracy: 0.9455\n",
            "Epoch 3188/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2447 - accuracy: 0.9255 - val_loss: 0.1924 - val_accuracy: 0.9445\n",
            "Epoch 3189/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2260 - accuracy: 0.9256 - val_loss: 0.1967 - val_accuracy: 0.9420\n",
            "Epoch 3190/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2407 - accuracy: 0.9234 - val_loss: 0.1931 - val_accuracy: 0.9440\n",
            "Epoch 3191/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2546 - accuracy: 0.9251 - val_loss: 0.1934 - val_accuracy: 0.9425\n",
            "Epoch 3192/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2308 - accuracy: 0.9261 - val_loss: 0.1943 - val_accuracy: 0.9445\n",
            "Epoch 3193/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2337 - accuracy: 0.9270 - val_loss: 0.1892 - val_accuracy: 0.9430\n",
            "Epoch 3194/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2228 - accuracy: 0.9280 - val_loss: 0.1874 - val_accuracy: 0.9450\n",
            "Epoch 3195/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2395 - accuracy: 0.9237 - val_loss: 0.1922 - val_accuracy: 0.9445\n",
            "Epoch 3196/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2353 - accuracy: 0.9254 - val_loss: 0.1936 - val_accuracy: 0.9450\n",
            "Epoch 3197/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2343 - accuracy: 0.9249 - val_loss: 0.1938 - val_accuracy: 0.9430\n",
            "Epoch 3198/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2261 - accuracy: 0.9280 - val_loss: 0.1929 - val_accuracy: 0.9450\n",
            "Epoch 3199/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2327 - accuracy: 0.9237 - val_loss: 0.1943 - val_accuracy: 0.9445\n",
            "Epoch 3200/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2261 - accuracy: 0.9271 - val_loss: 0.1998 - val_accuracy: 0.9425\n",
            "Epoch 3201/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2413 - accuracy: 0.9201 - val_loss: 0.2004 - val_accuracy: 0.9430\n",
            "Epoch 3202/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2347 - accuracy: 0.9234 - val_loss: 0.1957 - val_accuracy: 0.9440\n",
            "Epoch 3203/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2318 - accuracy: 0.9226 - val_loss: 0.1919 - val_accuracy: 0.9440\n",
            "Epoch 3204/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2262 - accuracy: 0.9283 - val_loss: 0.1923 - val_accuracy: 0.9455\n",
            "Epoch 3205/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2288 - accuracy: 0.9260 - val_loss: 0.1982 - val_accuracy: 0.9420\n",
            "Epoch 3206/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2315 - accuracy: 0.9269 - val_loss: 0.1981 - val_accuracy: 0.9430\n",
            "Epoch 3207/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2355 - accuracy: 0.9241 - val_loss: 0.1944 - val_accuracy: 0.9430\n",
            "Epoch 3208/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2338 - accuracy: 0.9220 - val_loss: 0.1913 - val_accuracy: 0.9450\n",
            "Epoch 3209/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2294 - accuracy: 0.9234 - val_loss: 0.1933 - val_accuracy: 0.9455\n",
            "Epoch 3210/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2262 - accuracy: 0.9249 - val_loss: 0.1911 - val_accuracy: 0.9460\n",
            "Epoch 3211/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2337 - accuracy: 0.9243 - val_loss: 0.1898 - val_accuracy: 0.9445\n",
            "Epoch 3212/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2390 - accuracy: 0.9266 - val_loss: 0.1910 - val_accuracy: 0.9445\n",
            "Epoch 3213/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2389 - accuracy: 0.9225 - val_loss: 0.1932 - val_accuracy: 0.9430\n",
            "Epoch 3214/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2280 - accuracy: 0.9273 - val_loss: 0.1937 - val_accuracy: 0.9420\n",
            "Epoch 3215/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2646 - accuracy: 0.9194 - val_loss: 0.1914 - val_accuracy: 0.9440\n",
            "Epoch 3216/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2279 - accuracy: 0.9258 - val_loss: 0.1924 - val_accuracy: 0.9450\n",
            "Epoch 3217/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2344 - accuracy: 0.9227 - val_loss: 0.1937 - val_accuracy: 0.9455\n",
            "Epoch 3218/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2298 - accuracy: 0.9244 - val_loss: 0.1929 - val_accuracy: 0.9430\n",
            "Epoch 3219/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2340 - accuracy: 0.9216 - val_loss: 0.1943 - val_accuracy: 0.9430\n",
            "Epoch 3220/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2376 - accuracy: 0.9259 - val_loss: 0.1932 - val_accuracy: 0.9440\n",
            "Epoch 3221/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2354 - accuracy: 0.9233 - val_loss: 0.1914 - val_accuracy: 0.9440\n",
            "Epoch 3222/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2349 - accuracy: 0.9269 - val_loss: 0.1908 - val_accuracy: 0.9465\n",
            "Epoch 3223/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2249 - accuracy: 0.9295 - val_loss: 0.1926 - val_accuracy: 0.9435\n",
            "Epoch 3224/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2286 - accuracy: 0.9283 - val_loss: 0.1942 - val_accuracy: 0.9445\n",
            "Epoch 3225/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2297 - accuracy: 0.9239 - val_loss: 0.1930 - val_accuracy: 0.9460\n",
            "Epoch 3226/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2308 - accuracy: 0.9259 - val_loss: 0.1891 - val_accuracy: 0.9450\n",
            "Epoch 3227/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2318 - accuracy: 0.9235 - val_loss: 0.1995 - val_accuracy: 0.9420\n",
            "Epoch 3228/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2258 - accuracy: 0.9287 - val_loss: 0.1878 - val_accuracy: 0.9450\n",
            "Epoch 3229/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2328 - accuracy: 0.9234 - val_loss: 0.1928 - val_accuracy: 0.9435\n",
            "Epoch 3230/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2338 - accuracy: 0.9277 - val_loss: 0.1912 - val_accuracy: 0.9470\n",
            "Epoch 3231/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2315 - accuracy: 0.9252 - val_loss: 0.1888 - val_accuracy: 0.9450\n",
            "Epoch 3232/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2295 - accuracy: 0.9252 - val_loss: 0.1896 - val_accuracy: 0.9440\n",
            "Epoch 3233/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2396 - accuracy: 0.9237 - val_loss: 0.1876 - val_accuracy: 0.9440\n",
            "Epoch 3234/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2322 - accuracy: 0.9233 - val_loss: 0.1895 - val_accuracy: 0.9455\n",
            "Epoch 3235/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2363 - accuracy: 0.9251 - val_loss: 0.1932 - val_accuracy: 0.9445\n",
            "Epoch 3236/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2377 - accuracy: 0.9250 - val_loss: 0.1916 - val_accuracy: 0.9445\n",
            "Epoch 3237/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2392 - accuracy: 0.9214 - val_loss: 0.1931 - val_accuracy: 0.9460\n",
            "Epoch 3238/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2291 - accuracy: 0.9226 - val_loss: 0.1922 - val_accuracy: 0.9435\n",
            "Epoch 3239/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2275 - accuracy: 0.9259 - val_loss: 0.1924 - val_accuracy: 0.9445\n",
            "Epoch 3240/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2328 - accuracy: 0.9261 - val_loss: 0.1912 - val_accuracy: 0.9465\n",
            "Epoch 3241/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2339 - accuracy: 0.9252 - val_loss: 0.1940 - val_accuracy: 0.9445\n",
            "Epoch 3242/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2354 - accuracy: 0.9266 - val_loss: 0.1912 - val_accuracy: 0.9450\n",
            "Epoch 3243/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2342 - accuracy: 0.9222 - val_loss: 0.1863 - val_accuracy: 0.9480\n",
            "Epoch 3244/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2350 - accuracy: 0.9231 - val_loss: 0.1904 - val_accuracy: 0.9445\n",
            "Epoch 3245/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2327 - accuracy: 0.9265 - val_loss: 0.1923 - val_accuracy: 0.9445\n",
            "Epoch 3246/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2337 - accuracy: 0.9225 - val_loss: 0.1925 - val_accuracy: 0.9445\n",
            "Epoch 3247/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2253 - accuracy: 0.9250 - val_loss: 0.1876 - val_accuracy: 0.9455\n",
            "Epoch 3248/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2284 - accuracy: 0.9276 - val_loss: 0.1863 - val_accuracy: 0.9445\n",
            "Epoch 3249/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2419 - accuracy: 0.9210 - val_loss: 0.1901 - val_accuracy: 0.9440\n",
            "Epoch 3250/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2288 - accuracy: 0.9268 - val_loss: 0.1915 - val_accuracy: 0.9450\n",
            "Epoch 3251/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2287 - accuracy: 0.9270 - val_loss: 0.1928 - val_accuracy: 0.9450\n",
            "Epoch 3252/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2254 - accuracy: 0.9281 - val_loss: 0.1951 - val_accuracy: 0.9425\n",
            "Epoch 3253/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2326 - accuracy: 0.9258 - val_loss: 0.1948 - val_accuracy: 0.9450\n",
            "Epoch 3254/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2375 - accuracy: 0.9245 - val_loss: 0.1871 - val_accuracy: 0.9450\n",
            "Epoch 3255/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2376 - accuracy: 0.9250 - val_loss: 0.1909 - val_accuracy: 0.9445\n",
            "Epoch 3256/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2259 - accuracy: 0.9259 - val_loss: 0.1911 - val_accuracy: 0.9440\n",
            "Epoch 3257/6000\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2290 - accuracy: 0.9289 - val_loss: 0.1905 - val_accuracy: 0.9450\n",
            "Epoch 3258/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2400 - accuracy: 0.9212 - val_loss: 0.1901 - val_accuracy: 0.9455\n",
            "Epoch 3259/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2327 - accuracy: 0.9256 - val_loss: 0.1937 - val_accuracy: 0.9455\n",
            "Epoch 3260/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2274 - accuracy: 0.9274 - val_loss: 0.1880 - val_accuracy: 0.9445\n",
            "Epoch 3261/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2270 - accuracy: 0.9247 - val_loss: 0.1889 - val_accuracy: 0.9445\n",
            "Epoch 3262/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2291 - accuracy: 0.9239 - val_loss: 0.1888 - val_accuracy: 0.9435\n",
            "Epoch 3263/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2279 - accuracy: 0.9260 - val_loss: 0.1911 - val_accuracy: 0.9440\n",
            "Epoch 3264/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2314 - accuracy: 0.9252 - val_loss: 0.1911 - val_accuracy: 0.9430\n",
            "Epoch 3265/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2382 - accuracy: 0.9199 - val_loss: 0.1969 - val_accuracy: 0.9430\n",
            "Epoch 3266/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2298 - accuracy: 0.9241 - val_loss: 0.1888 - val_accuracy: 0.9445\n",
            "Epoch 3267/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2470 - accuracy: 0.9209 - val_loss: 0.1940 - val_accuracy: 0.9415\n",
            "Epoch 3268/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2332 - accuracy: 0.9246 - val_loss: 0.1927 - val_accuracy: 0.9440\n",
            "Epoch 3269/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2304 - accuracy: 0.9256 - val_loss: 0.1880 - val_accuracy: 0.9455\n",
            "Epoch 3270/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2335 - accuracy: 0.9259 - val_loss: 0.1890 - val_accuracy: 0.9460\n",
            "Epoch 3271/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2408 - accuracy: 0.9243 - val_loss: 0.1913 - val_accuracy: 0.9450\n",
            "Epoch 3272/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2255 - accuracy: 0.9273 - val_loss: 0.1963 - val_accuracy: 0.9430\n",
            "Epoch 3273/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2333 - accuracy: 0.9244 - val_loss: 0.1879 - val_accuracy: 0.9450\n",
            "Epoch 3274/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2385 - accuracy: 0.9240 - val_loss: 0.1926 - val_accuracy: 0.9415\n",
            "Epoch 3275/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2411 - accuracy: 0.9235 - val_loss: 0.1933 - val_accuracy: 0.9445\n",
            "Epoch 3276/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2455 - accuracy: 0.9210 - val_loss: 0.1886 - val_accuracy: 0.9455\n",
            "Epoch 3277/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2351 - accuracy: 0.9244 - val_loss: 0.1879 - val_accuracy: 0.9440\n",
            "Epoch 3278/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2333 - accuracy: 0.9265 - val_loss: 0.1926 - val_accuracy: 0.9440\n",
            "Epoch 3279/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2317 - accuracy: 0.9237 - val_loss: 0.1935 - val_accuracy: 0.9440\n",
            "Epoch 3280/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2311 - accuracy: 0.9256 - val_loss: 0.1917 - val_accuracy: 0.9450\n",
            "Epoch 3281/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2261 - accuracy: 0.9269 - val_loss: 0.1896 - val_accuracy: 0.9455\n",
            "Epoch 3282/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2289 - accuracy: 0.9264 - val_loss: 0.1910 - val_accuracy: 0.9435\n",
            "Epoch 3283/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2249 - accuracy: 0.9249 - val_loss: 0.1895 - val_accuracy: 0.9450\n",
            "Epoch 3284/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2277 - accuracy: 0.9250 - val_loss: 0.1960 - val_accuracy: 0.9435\n",
            "Epoch 3285/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2376 - accuracy: 0.9235 - val_loss: 0.1902 - val_accuracy: 0.9450\n",
            "Epoch 3286/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2309 - accuracy: 0.9252 - val_loss: 0.1897 - val_accuracy: 0.9435\n",
            "Epoch 3287/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2272 - accuracy: 0.9286 - val_loss: 0.1914 - val_accuracy: 0.9440\n",
            "Epoch 3288/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2374 - accuracy: 0.9265 - val_loss: 0.1919 - val_accuracy: 0.9450\n",
            "Epoch 3289/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2244 - accuracy: 0.9266 - val_loss: 0.1929 - val_accuracy: 0.9450\n",
            "Epoch 3290/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2415 - accuracy: 0.9235 - val_loss: 0.1902 - val_accuracy: 0.9430\n",
            "Epoch 3291/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2273 - accuracy: 0.9266 - val_loss: 0.1928 - val_accuracy: 0.9440\n",
            "Epoch 3292/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2268 - accuracy: 0.9254 - val_loss: 0.1873 - val_accuracy: 0.9450\n",
            "Epoch 3293/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2269 - accuracy: 0.9256 - val_loss: 0.1900 - val_accuracy: 0.9440\n",
            "Epoch 3294/6000\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2255 - accuracy: 0.9265 - val_loss: 0.1882 - val_accuracy: 0.9435\n",
            "Epoch 3295/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2301 - accuracy: 0.9260 - val_loss: 0.1893 - val_accuracy: 0.9440\n",
            "Epoch 3296/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2278 - accuracy: 0.9251 - val_loss: 0.1903 - val_accuracy: 0.9470\n",
            "Epoch 3297/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2335 - accuracy: 0.9256 - val_loss: 0.1875 - val_accuracy: 0.9470\n",
            "Epoch 3298/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2264 - accuracy: 0.9275 - val_loss: 0.1898 - val_accuracy: 0.9435\n",
            "Epoch 3299/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2334 - accuracy: 0.9231 - val_loss: 0.1895 - val_accuracy: 0.9425\n",
            "Epoch 3300/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2288 - accuracy: 0.9255 - val_loss: 0.1948 - val_accuracy: 0.9435\n",
            "Epoch 3301/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2369 - accuracy: 0.9225 - val_loss: 0.1912 - val_accuracy: 0.9460\n",
            "Epoch 3302/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2259 - accuracy: 0.9251 - val_loss: 0.1895 - val_accuracy: 0.9440\n",
            "Epoch 3303/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2284 - accuracy: 0.9261 - val_loss: 0.1930 - val_accuracy: 0.9465\n",
            "Epoch 3304/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2355 - accuracy: 0.9252 - val_loss: 0.1970 - val_accuracy: 0.9450\n",
            "Epoch 3305/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2259 - accuracy: 0.9296 - val_loss: 0.1853 - val_accuracy: 0.9435\n",
            "Epoch 3306/6000\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2437 - accuracy: 0.9276 - val_loss: 0.1895 - val_accuracy: 0.9440\n",
            "Epoch 3307/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2366 - accuracy: 0.9229 - val_loss: 0.1918 - val_accuracy: 0.9455\n",
            "Epoch 3308/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2323 - accuracy: 0.9255 - val_loss: 0.1941 - val_accuracy: 0.9440\n",
            "Epoch 3309/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2331 - accuracy: 0.9290 - val_loss: 0.1880 - val_accuracy: 0.9465\n",
            "Epoch 3310/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2326 - accuracy: 0.9245 - val_loss: 0.1890 - val_accuracy: 0.9445\n",
            "Epoch 3311/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2292 - accuracy: 0.9260 - val_loss: 0.1897 - val_accuracy: 0.9450\n",
            "Epoch 3312/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2340 - accuracy: 0.9234 - val_loss: 0.1917 - val_accuracy: 0.9450\n",
            "Epoch 3313/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2464 - accuracy: 0.9227 - val_loss: 0.1962 - val_accuracy: 0.9425\n",
            "Epoch 3314/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2298 - accuracy: 0.9252 - val_loss: 0.1941 - val_accuracy: 0.9430\n",
            "Epoch 3315/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2273 - accuracy: 0.9271 - val_loss: 0.1878 - val_accuracy: 0.9455\n",
            "Epoch 3316/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2365 - accuracy: 0.9221 - val_loss: 0.1883 - val_accuracy: 0.9450\n",
            "Epoch 3317/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2337 - accuracy: 0.9258 - val_loss: 0.1896 - val_accuracy: 0.9445\n",
            "Epoch 3318/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2217 - accuracy: 0.9283 - val_loss: 0.1894 - val_accuracy: 0.9455\n",
            "Epoch 3319/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2252 - accuracy: 0.9276 - val_loss: 0.1897 - val_accuracy: 0.9455\n",
            "Epoch 3320/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2353 - accuracy: 0.9273 - val_loss: 0.1896 - val_accuracy: 0.9430\n",
            "Epoch 3321/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2293 - accuracy: 0.9260 - val_loss: 0.1869 - val_accuracy: 0.9460\n",
            "Epoch 3322/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2300 - accuracy: 0.9255 - val_loss: 0.1894 - val_accuracy: 0.9450\n",
            "Epoch 3323/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2300 - accuracy: 0.9254 - val_loss: 0.1939 - val_accuracy: 0.9445\n",
            "Epoch 3324/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2389 - accuracy: 0.9260 - val_loss: 0.1882 - val_accuracy: 0.9450\n",
            "Epoch 3325/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2271 - accuracy: 0.9265 - val_loss: 0.1930 - val_accuracy: 0.9440\n",
            "Epoch 3326/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2277 - accuracy: 0.9243 - val_loss: 0.1905 - val_accuracy: 0.9440\n",
            "Epoch 3327/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2318 - accuracy: 0.9256 - val_loss: 0.1969 - val_accuracy: 0.9440\n",
            "Epoch 3328/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2367 - accuracy: 0.9251 - val_loss: 0.1931 - val_accuracy: 0.9450\n",
            "Epoch 3329/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2280 - accuracy: 0.9254 - val_loss: 0.1893 - val_accuracy: 0.9460\n",
            "Epoch 3330/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2345 - accuracy: 0.9261 - val_loss: 0.1927 - val_accuracy: 0.9435\n",
            "Epoch 3331/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2297 - accuracy: 0.9265 - val_loss: 0.1888 - val_accuracy: 0.9450\n",
            "Epoch 3332/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2355 - accuracy: 0.9219 - val_loss: 0.1892 - val_accuracy: 0.9445\n",
            "Epoch 3333/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2307 - accuracy: 0.9244 - val_loss: 0.1918 - val_accuracy: 0.9455\n",
            "Epoch 3334/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2521 - accuracy: 0.9229 - val_loss: 0.1974 - val_accuracy: 0.9450\n",
            "Epoch 3335/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2302 - accuracy: 0.9250 - val_loss: 0.1886 - val_accuracy: 0.9455\n",
            "Epoch 3336/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2321 - accuracy: 0.9246 - val_loss: 0.1900 - val_accuracy: 0.9435\n",
            "Epoch 3337/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2279 - accuracy: 0.9240 - val_loss: 0.1891 - val_accuracy: 0.9445\n",
            "Epoch 3338/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2337 - accuracy: 0.9215 - val_loss: 0.1875 - val_accuracy: 0.9455\n",
            "Epoch 3339/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2359 - accuracy: 0.9251 - val_loss: 0.1918 - val_accuracy: 0.9465\n",
            "Epoch 3340/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2243 - accuracy: 0.9265 - val_loss: 0.1893 - val_accuracy: 0.9440\n",
            "Epoch 3341/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2255 - accuracy: 0.9285 - val_loss: 0.1887 - val_accuracy: 0.9450\n",
            "Epoch 3342/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2366 - accuracy: 0.9208 - val_loss: 0.1924 - val_accuracy: 0.9445\n",
            "Epoch 3343/6000\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2329 - accuracy: 0.9233 - val_loss: 0.1872 - val_accuracy: 0.9465\n",
            "Epoch 3344/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2300 - accuracy: 0.9252 - val_loss: 0.1941 - val_accuracy: 0.9445\n",
            "Epoch 3345/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2281 - accuracy: 0.9254 - val_loss: 0.1942 - val_accuracy: 0.9415\n",
            "Epoch 3346/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2261 - accuracy: 0.9256 - val_loss: 0.1920 - val_accuracy: 0.9445\n",
            "Epoch 3347/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2339 - accuracy: 0.9222 - val_loss: 0.1890 - val_accuracy: 0.9450\n",
            "Epoch 3348/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2351 - accuracy: 0.9252 - val_loss: 0.1899 - val_accuracy: 0.9465\n",
            "Epoch 3349/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2313 - accuracy: 0.9259 - val_loss: 0.1881 - val_accuracy: 0.9450\n",
            "Epoch 3350/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2311 - accuracy: 0.9249 - val_loss: 0.1901 - val_accuracy: 0.9435\n",
            "Epoch 3351/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2355 - accuracy: 0.9229 - val_loss: 0.1886 - val_accuracy: 0.9445\n",
            "Epoch 3352/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2336 - accuracy: 0.9236 - val_loss: 0.1923 - val_accuracy: 0.9460\n",
            "Epoch 3353/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2316 - accuracy: 0.9256 - val_loss: 0.1865 - val_accuracy: 0.9460\n",
            "Epoch 3354/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2330 - accuracy: 0.9246 - val_loss: 0.1903 - val_accuracy: 0.9475\n",
            "Epoch 3355/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2268 - accuracy: 0.9273 - val_loss: 0.1884 - val_accuracy: 0.9455\n",
            "Epoch 3356/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2339 - accuracy: 0.9274 - val_loss: 0.1891 - val_accuracy: 0.9430\n",
            "Epoch 3357/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2293 - accuracy: 0.9284 - val_loss: 0.1917 - val_accuracy: 0.9450\n",
            "Epoch 3358/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2401 - accuracy: 0.9261 - val_loss: 0.1957 - val_accuracy: 0.9435\n",
            "Epoch 3359/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2242 - accuracy: 0.9254 - val_loss: 0.1952 - val_accuracy: 0.9445\n",
            "Epoch 3360/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2386 - accuracy: 0.9269 - val_loss: 0.1901 - val_accuracy: 0.9450\n",
            "Epoch 3361/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2262 - accuracy: 0.9283 - val_loss: 0.1895 - val_accuracy: 0.9450\n",
            "Epoch 3362/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2367 - accuracy: 0.9241 - val_loss: 0.1919 - val_accuracy: 0.9460\n",
            "Epoch 3363/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2236 - accuracy: 0.9233 - val_loss: 0.1988 - val_accuracy: 0.9425\n",
            "Epoch 3364/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2328 - accuracy: 0.9235 - val_loss: 0.1923 - val_accuracy: 0.9430\n",
            "Epoch 3365/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2293 - accuracy: 0.9251 - val_loss: 0.1979 - val_accuracy: 0.9400\n",
            "Epoch 3366/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2326 - accuracy: 0.9234 - val_loss: 0.1897 - val_accuracy: 0.9450\n",
            "Epoch 3367/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2248 - accuracy: 0.9290 - val_loss: 0.1938 - val_accuracy: 0.9435\n",
            "Epoch 3368/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2273 - accuracy: 0.9271 - val_loss: 0.1906 - val_accuracy: 0.9460\n",
            "Epoch 3369/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2325 - accuracy: 0.9287 - val_loss: 0.1898 - val_accuracy: 0.9450\n",
            "Epoch 3370/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2320 - accuracy: 0.9261 - val_loss: 0.1894 - val_accuracy: 0.9440\n",
            "Epoch 3371/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2364 - accuracy: 0.9230 - val_loss: 0.1964 - val_accuracy: 0.9435\n",
            "Epoch 3372/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2341 - accuracy: 0.9251 - val_loss: 0.1877 - val_accuracy: 0.9455\n",
            "Epoch 3373/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2339 - accuracy: 0.9246 - val_loss: 0.1901 - val_accuracy: 0.9435\n",
            "Epoch 3374/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2276 - accuracy: 0.9277 - val_loss: 0.1912 - val_accuracy: 0.9445\n",
            "Epoch 3375/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2336 - accuracy: 0.9262 - val_loss: 0.1933 - val_accuracy: 0.9420\n",
            "Epoch 3376/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2295 - accuracy: 0.9241 - val_loss: 0.1924 - val_accuracy: 0.9450\n",
            "Epoch 3377/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2277 - accuracy: 0.9285 - val_loss: 0.1943 - val_accuracy: 0.9430\n",
            "Epoch 3378/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2388 - accuracy: 0.9230 - val_loss: 0.1924 - val_accuracy: 0.9450\n",
            "Epoch 3379/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2377 - accuracy: 0.9259 - val_loss: 0.1923 - val_accuracy: 0.9440\n",
            "Epoch 3380/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2491 - accuracy: 0.9262 - val_loss: 0.1951 - val_accuracy: 0.9425\n",
            "Epoch 3381/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2386 - accuracy: 0.9240 - val_loss: 0.1916 - val_accuracy: 0.9435\n",
            "Epoch 3382/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2430 - accuracy: 0.9271 - val_loss: 0.1898 - val_accuracy: 0.9445\n",
            "Epoch 3383/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2289 - accuracy: 0.9250 - val_loss: 0.1886 - val_accuracy: 0.9450\n",
            "Epoch 3384/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2216 - accuracy: 0.9276 - val_loss: 0.1888 - val_accuracy: 0.9440\n",
            "Epoch 3385/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2328 - accuracy: 0.9237 - val_loss: 0.1847 - val_accuracy: 0.9455\n",
            "Epoch 3386/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2229 - accuracy: 0.9262 - val_loss: 0.1899 - val_accuracy: 0.9455\n",
            "Epoch 3387/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2352 - accuracy: 0.9233 - val_loss: 0.1911 - val_accuracy: 0.9440\n",
            "Epoch 3388/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2378 - accuracy: 0.9246 - val_loss: 0.1969 - val_accuracy: 0.9440\n",
            "Epoch 3389/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2342 - accuracy: 0.9262 - val_loss: 0.1920 - val_accuracy: 0.9445\n",
            "Epoch 3390/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2448 - accuracy: 0.9239 - val_loss: 0.1882 - val_accuracy: 0.9450\n",
            "Epoch 3391/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2298 - accuracy: 0.9264 - val_loss: 0.1891 - val_accuracy: 0.9435\n",
            "Epoch 3392/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2325 - accuracy: 0.9247 - val_loss: 0.1952 - val_accuracy: 0.9425\n",
            "Epoch 3393/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2248 - accuracy: 0.9256 - val_loss: 0.1927 - val_accuracy: 0.9430\n",
            "Epoch 3394/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2325 - accuracy: 0.9245 - val_loss: 0.1900 - val_accuracy: 0.9440\n",
            "Epoch 3395/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2293 - accuracy: 0.9265 - val_loss: 0.1919 - val_accuracy: 0.9445\n",
            "Epoch 3396/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2372 - accuracy: 0.9243 - val_loss: 0.1884 - val_accuracy: 0.9445\n",
            "Epoch 3397/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2279 - accuracy: 0.9250 - val_loss: 0.1905 - val_accuracy: 0.9445\n",
            "Epoch 3398/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2363 - accuracy: 0.9286 - val_loss: 0.1907 - val_accuracy: 0.9435\n",
            "Epoch 3399/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2310 - accuracy: 0.9246 - val_loss: 0.1905 - val_accuracy: 0.9440\n",
            "Epoch 3400/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2323 - accuracy: 0.9251 - val_loss: 0.1934 - val_accuracy: 0.9445\n",
            "Epoch 3401/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2299 - accuracy: 0.9261 - val_loss: 0.1898 - val_accuracy: 0.9435\n",
            "Epoch 3402/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2392 - accuracy: 0.9245 - val_loss: 0.1921 - val_accuracy: 0.9430\n",
            "Epoch 3403/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2340 - accuracy: 0.9221 - val_loss: 0.1909 - val_accuracy: 0.9450\n",
            "Epoch 3404/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2297 - accuracy: 0.9230 - val_loss: 0.1874 - val_accuracy: 0.9455\n",
            "Epoch 3405/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2280 - accuracy: 0.9210 - val_loss: 0.1948 - val_accuracy: 0.9405\n",
            "Epoch 3406/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2237 - accuracy: 0.9264 - val_loss: 0.1899 - val_accuracy: 0.9445\n",
            "Epoch 3407/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2256 - accuracy: 0.9273 - val_loss: 0.1914 - val_accuracy: 0.9455\n",
            "Epoch 3408/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2312 - accuracy: 0.9258 - val_loss: 0.1903 - val_accuracy: 0.9455\n",
            "Epoch 3409/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2378 - accuracy: 0.9264 - val_loss: 0.1902 - val_accuracy: 0.9445\n",
            "Epoch 3410/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2303 - accuracy: 0.9270 - val_loss: 0.1915 - val_accuracy: 0.9445\n",
            "Epoch 3411/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2345 - accuracy: 0.9274 - val_loss: 0.1912 - val_accuracy: 0.9450\n",
            "Epoch 3412/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2336 - accuracy: 0.9234 - val_loss: 0.1941 - val_accuracy: 0.9440\n",
            "Epoch 3413/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2324 - accuracy: 0.9233 - val_loss: 0.1882 - val_accuracy: 0.9440\n",
            "Epoch 3414/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2307 - accuracy: 0.9251 - val_loss: 0.1956 - val_accuracy: 0.9435\n",
            "Epoch 3415/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2333 - accuracy: 0.9265 - val_loss: 0.1882 - val_accuracy: 0.9440\n",
            "Epoch 3416/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2326 - accuracy: 0.9218 - val_loss: 0.1923 - val_accuracy: 0.9420\n",
            "Epoch 3417/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2297 - accuracy: 0.9234 - val_loss: 0.1898 - val_accuracy: 0.9440\n",
            "Epoch 3418/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2303 - accuracy: 0.9277 - val_loss: 0.1955 - val_accuracy: 0.9455\n",
            "Epoch 3419/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2346 - accuracy: 0.9226 - val_loss: 0.1918 - val_accuracy: 0.9445\n",
            "Epoch 3420/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2291 - accuracy: 0.9274 - val_loss: 0.1918 - val_accuracy: 0.9445\n",
            "Epoch 3421/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2265 - accuracy: 0.9245 - val_loss: 0.1897 - val_accuracy: 0.9435\n",
            "Epoch 3422/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2387 - accuracy: 0.9244 - val_loss: 0.1910 - val_accuracy: 0.9425\n",
            "Epoch 3423/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2270 - accuracy: 0.9280 - val_loss: 0.2000 - val_accuracy: 0.9410\n",
            "Epoch 3424/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2260 - accuracy: 0.9287 - val_loss: 0.1908 - val_accuracy: 0.9445\n",
            "Epoch 3425/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2359 - accuracy: 0.9243 - val_loss: 0.1930 - val_accuracy: 0.9440\n",
            "Epoch 3426/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2292 - accuracy: 0.9239 - val_loss: 0.1911 - val_accuracy: 0.9445\n",
            "Epoch 3427/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2322 - accuracy: 0.9261 - val_loss: 0.1914 - val_accuracy: 0.9455\n",
            "Epoch 3428/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2386 - accuracy: 0.9231 - val_loss: 0.1929 - val_accuracy: 0.9440\n",
            "Epoch 3429/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2303 - accuracy: 0.9269 - val_loss: 0.1887 - val_accuracy: 0.9455\n",
            "Epoch 3430/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2313 - accuracy: 0.9270 - val_loss: 0.1898 - val_accuracy: 0.9455\n",
            "Epoch 3431/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2358 - accuracy: 0.9240 - val_loss: 0.1912 - val_accuracy: 0.9440\n",
            "Epoch 3432/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2313 - accuracy: 0.9241 - val_loss: 0.1930 - val_accuracy: 0.9430\n",
            "Epoch 3433/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2347 - accuracy: 0.9281 - val_loss: 0.1917 - val_accuracy: 0.9440\n",
            "Epoch 3434/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2407 - accuracy: 0.9216 - val_loss: 0.1947 - val_accuracy: 0.9445\n",
            "Epoch 3435/6000\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2377 - accuracy: 0.9224 - val_loss: 0.1966 - val_accuracy: 0.9435\n",
            "Epoch 3436/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2433 - accuracy: 0.9225 - val_loss: 0.1915 - val_accuracy: 0.9430\n",
            "Epoch 3437/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2392 - accuracy: 0.9241 - val_loss: 0.1883 - val_accuracy: 0.9440\n",
            "Epoch 3438/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2292 - accuracy: 0.9244 - val_loss: 0.1985 - val_accuracy: 0.9415\n",
            "Epoch 3439/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2376 - accuracy: 0.9243 - val_loss: 0.1862 - val_accuracy: 0.9455\n",
            "Epoch 3440/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2332 - accuracy: 0.9236 - val_loss: 0.1887 - val_accuracy: 0.9435\n",
            "Epoch 3441/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2292 - accuracy: 0.9240 - val_loss: 0.1882 - val_accuracy: 0.9470\n",
            "Epoch 3442/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2265 - accuracy: 0.9270 - val_loss: 0.1913 - val_accuracy: 0.9435\n",
            "Epoch 3443/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2312 - accuracy: 0.9259 - val_loss: 0.1905 - val_accuracy: 0.9430\n",
            "Epoch 3444/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2309 - accuracy: 0.9268 - val_loss: 0.1958 - val_accuracy: 0.9425\n",
            "Epoch 3445/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2547 - accuracy: 0.9234 - val_loss: 0.1925 - val_accuracy: 0.9455\n",
            "Epoch 3446/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2389 - accuracy: 0.9214 - val_loss: 0.1886 - val_accuracy: 0.9440\n",
            "Epoch 3447/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2333 - accuracy: 0.9250 - val_loss: 0.1892 - val_accuracy: 0.9460\n",
            "Epoch 3448/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2372 - accuracy: 0.9233 - val_loss: 0.1923 - val_accuracy: 0.9435\n",
            "Epoch 3449/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2344 - accuracy: 0.9243 - val_loss: 0.1919 - val_accuracy: 0.9460\n",
            "Epoch 3450/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2217 - accuracy: 0.9276 - val_loss: 0.1860 - val_accuracy: 0.9460\n",
            "Epoch 3451/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2331 - accuracy: 0.9237 - val_loss: 0.1889 - val_accuracy: 0.9435\n",
            "Epoch 3452/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2381 - accuracy: 0.9254 - val_loss: 0.1908 - val_accuracy: 0.9430\n",
            "Epoch 3453/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2289 - accuracy: 0.9256 - val_loss: 0.1893 - val_accuracy: 0.9440\n",
            "Epoch 3454/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2420 - accuracy: 0.9214 - val_loss: 0.1914 - val_accuracy: 0.9440\n",
            "Epoch 3455/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2326 - accuracy: 0.9229 - val_loss: 0.1908 - val_accuracy: 0.9445\n",
            "Epoch 3456/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2236 - accuracy: 0.9300 - val_loss: 0.1880 - val_accuracy: 0.9445\n",
            "Epoch 3457/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2389 - accuracy: 0.9245 - val_loss: 0.1966 - val_accuracy: 0.9435\n",
            "Epoch 3458/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2338 - accuracy: 0.9237 - val_loss: 0.1872 - val_accuracy: 0.9445\n",
            "Epoch 3459/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2299 - accuracy: 0.9275 - val_loss: 0.1909 - val_accuracy: 0.9465\n",
            "Epoch 3460/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2281 - accuracy: 0.9269 - val_loss: 0.1957 - val_accuracy: 0.9435\n",
            "Epoch 3461/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2301 - accuracy: 0.9265 - val_loss: 0.1896 - val_accuracy: 0.9440\n",
            "Epoch 3462/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2290 - accuracy: 0.9260 - val_loss: 0.1898 - val_accuracy: 0.9465\n",
            "Epoch 3463/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2312 - accuracy: 0.9261 - val_loss: 0.1945 - val_accuracy: 0.9435\n",
            "Epoch 3464/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2284 - accuracy: 0.9271 - val_loss: 0.1937 - val_accuracy: 0.9440\n",
            "Epoch 3465/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2369 - accuracy: 0.9251 - val_loss: 0.1921 - val_accuracy: 0.9460\n",
            "Epoch 3466/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2332 - accuracy: 0.9262 - val_loss: 0.1894 - val_accuracy: 0.9460\n",
            "Epoch 3467/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2299 - accuracy: 0.9260 - val_loss: 0.1910 - val_accuracy: 0.9430\n",
            "Epoch 3468/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2412 - accuracy: 0.9197 - val_loss: 0.1925 - val_accuracy: 0.9440\n",
            "Epoch 3469/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2299 - accuracy: 0.9230 - val_loss: 0.1947 - val_accuracy: 0.9440\n",
            "Epoch 3470/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2326 - accuracy: 0.9247 - val_loss: 0.1865 - val_accuracy: 0.9455\n",
            "Epoch 3471/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2318 - accuracy: 0.9239 - val_loss: 0.1924 - val_accuracy: 0.9445\n",
            "Epoch 3472/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2288 - accuracy: 0.9246 - val_loss: 0.1927 - val_accuracy: 0.9455\n",
            "Epoch 3473/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2278 - accuracy: 0.9283 - val_loss: 0.1877 - val_accuracy: 0.9460\n",
            "Epoch 3474/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2306 - accuracy: 0.9245 - val_loss: 0.1905 - val_accuracy: 0.9445\n",
            "Epoch 3475/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2291 - accuracy: 0.9239 - val_loss: 0.1953 - val_accuracy: 0.9445\n",
            "Epoch 3476/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2350 - accuracy: 0.9259 - val_loss: 0.1948 - val_accuracy: 0.9415\n",
            "Epoch 3477/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2290 - accuracy: 0.9280 - val_loss: 0.1917 - val_accuracy: 0.9445\n",
            "Epoch 3478/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2273 - accuracy: 0.9262 - val_loss: 0.1884 - val_accuracy: 0.9440\n",
            "Epoch 3479/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2322 - accuracy: 0.9271 - val_loss: 0.1915 - val_accuracy: 0.9435\n",
            "Epoch 3480/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2336 - accuracy: 0.9250 - val_loss: 0.1937 - val_accuracy: 0.9445\n",
            "Epoch 3481/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2301 - accuracy: 0.9269 - val_loss: 0.1891 - val_accuracy: 0.9435\n",
            "Epoch 3482/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2299 - accuracy: 0.9256 - val_loss: 0.1905 - val_accuracy: 0.9430\n",
            "Epoch 3483/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2218 - accuracy: 0.9281 - val_loss: 0.1928 - val_accuracy: 0.9440\n",
            "Epoch 3484/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2308 - accuracy: 0.9256 - val_loss: 0.1932 - val_accuracy: 0.9435\n",
            "Epoch 3485/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2342 - accuracy: 0.9268 - val_loss: 0.1913 - val_accuracy: 0.9450\n",
            "Epoch 3486/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2265 - accuracy: 0.9262 - val_loss: 0.1975 - val_accuracy: 0.9455\n",
            "Epoch 3487/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2381 - accuracy: 0.9230 - val_loss: 0.1923 - val_accuracy: 0.9425\n",
            "Epoch 3488/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2330 - accuracy: 0.9254 - val_loss: 0.1916 - val_accuracy: 0.9450\n",
            "Epoch 3489/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2320 - accuracy: 0.9225 - val_loss: 0.1921 - val_accuracy: 0.9450\n",
            "Epoch 3490/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2358 - accuracy: 0.9229 - val_loss: 0.1883 - val_accuracy: 0.9435\n",
            "Epoch 3491/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2271 - accuracy: 0.9259 - val_loss: 0.1949 - val_accuracy: 0.9435\n",
            "Epoch 3492/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2361 - accuracy: 0.9281 - val_loss: 0.1883 - val_accuracy: 0.9445\n",
            "Epoch 3493/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2233 - accuracy: 0.9290 - val_loss: 0.1908 - val_accuracy: 0.9445\n",
            "Epoch 3494/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2257 - accuracy: 0.9287 - val_loss: 0.1880 - val_accuracy: 0.9470\n",
            "Epoch 3495/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2310 - accuracy: 0.9239 - val_loss: 0.1903 - val_accuracy: 0.9445\n",
            "Epoch 3496/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2447 - accuracy: 0.9258 - val_loss: 0.1879 - val_accuracy: 0.9450\n",
            "Epoch 3497/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2392 - accuracy: 0.9231 - val_loss: 0.1875 - val_accuracy: 0.9460\n",
            "Epoch 3498/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2423 - accuracy: 0.9225 - val_loss: 0.1921 - val_accuracy: 0.9450\n",
            "Epoch 3499/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2212 - accuracy: 0.9264 - val_loss: 0.1879 - val_accuracy: 0.9440\n",
            "Epoch 3500/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2380 - accuracy: 0.9229 - val_loss: 0.1889 - val_accuracy: 0.9465\n",
            "Epoch 3501/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2313 - accuracy: 0.9261 - val_loss: 0.1933 - val_accuracy: 0.9435\n",
            "Epoch 3502/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2357 - accuracy: 0.9251 - val_loss: 0.1872 - val_accuracy: 0.9435\n",
            "Epoch 3503/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2244 - accuracy: 0.9283 - val_loss: 0.1955 - val_accuracy: 0.9425\n",
            "Epoch 3504/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2341 - accuracy: 0.9226 - val_loss: 0.1897 - val_accuracy: 0.9440\n",
            "Epoch 3505/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2377 - accuracy: 0.9270 - val_loss: 0.1872 - val_accuracy: 0.9430\n",
            "Epoch 3506/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2279 - accuracy: 0.9237 - val_loss: 0.1887 - val_accuracy: 0.9440\n",
            "Epoch 3507/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2335 - accuracy: 0.9279 - val_loss: 0.1913 - val_accuracy: 0.9430\n",
            "Epoch 3508/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2271 - accuracy: 0.9244 - val_loss: 0.1903 - val_accuracy: 0.9455\n",
            "Epoch 3509/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2308 - accuracy: 0.9249 - val_loss: 0.1926 - val_accuracy: 0.9445\n",
            "Epoch 3510/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2327 - accuracy: 0.9249 - val_loss: 0.1900 - val_accuracy: 0.9435\n",
            "Epoch 3511/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2381 - accuracy: 0.9246 - val_loss: 0.2020 - val_accuracy: 0.9400\n",
            "Epoch 3512/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2297 - accuracy: 0.9258 - val_loss: 0.1912 - val_accuracy: 0.9450\n",
            "Epoch 3513/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2333 - accuracy: 0.9244 - val_loss: 0.1970 - val_accuracy: 0.9440\n",
            "Epoch 3514/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2339 - accuracy: 0.9246 - val_loss: 0.1903 - val_accuracy: 0.9435\n",
            "Epoch 3515/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2259 - accuracy: 0.9255 - val_loss: 0.1912 - val_accuracy: 0.9450\n",
            "Epoch 3516/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2368 - accuracy: 0.9243 - val_loss: 0.1911 - val_accuracy: 0.9445\n",
            "Epoch 3517/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2434 - accuracy: 0.9235 - val_loss: 0.1900 - val_accuracy: 0.9450\n",
            "Epoch 3518/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2296 - accuracy: 0.9279 - val_loss: 0.1901 - val_accuracy: 0.9435\n",
            "Epoch 3519/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2414 - accuracy: 0.9237 - val_loss: 0.1879 - val_accuracy: 0.9455\n",
            "Epoch 3520/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2313 - accuracy: 0.9258 - val_loss: 0.1913 - val_accuracy: 0.9450\n",
            "Epoch 3521/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2454 - accuracy: 0.9268 - val_loss: 0.1946 - val_accuracy: 0.9435\n",
            "Epoch 3522/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2353 - accuracy: 0.9260 - val_loss: 0.1922 - val_accuracy: 0.9425\n",
            "Epoch 3523/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2332 - accuracy: 0.9254 - val_loss: 0.1880 - val_accuracy: 0.9440\n",
            "Epoch 3524/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2298 - accuracy: 0.9276 - val_loss: 0.1890 - val_accuracy: 0.9440\n",
            "Epoch 3525/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2486 - accuracy: 0.9247 - val_loss: 0.1855 - val_accuracy: 0.9440\n",
            "Epoch 3526/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2308 - accuracy: 0.9230 - val_loss: 0.1878 - val_accuracy: 0.9430\n",
            "Epoch 3527/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2300 - accuracy: 0.9254 - val_loss: 0.1932 - val_accuracy: 0.9445\n",
            "Epoch 3528/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2418 - accuracy: 0.9256 - val_loss: 0.1880 - val_accuracy: 0.9460\n",
            "Epoch 3529/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2404 - accuracy: 0.9254 - val_loss: 0.1862 - val_accuracy: 0.9440\n",
            "Epoch 3530/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2300 - accuracy: 0.9246 - val_loss: 0.1883 - val_accuracy: 0.9435\n",
            "Epoch 3531/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2300 - accuracy: 0.9275 - val_loss: 0.1926 - val_accuracy: 0.9445\n",
            "Epoch 3532/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2360 - accuracy: 0.9252 - val_loss: 0.1868 - val_accuracy: 0.9455\n",
            "Epoch 3533/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2335 - accuracy: 0.9275 - val_loss: 0.1895 - val_accuracy: 0.9430\n",
            "Epoch 3534/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2425 - accuracy: 0.9237 - val_loss: 0.1887 - val_accuracy: 0.9445\n",
            "Epoch 3535/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2409 - accuracy: 0.9258 - val_loss: 0.1922 - val_accuracy: 0.9430\n",
            "Epoch 3536/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2298 - accuracy: 0.9262 - val_loss: 0.1897 - val_accuracy: 0.9440\n",
            "Epoch 3537/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2358 - accuracy: 0.9247 - val_loss: 0.1917 - val_accuracy: 0.9430\n",
            "Epoch 3538/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2275 - accuracy: 0.9256 - val_loss: 0.1894 - val_accuracy: 0.9445\n",
            "Epoch 3539/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2368 - accuracy: 0.9221 - val_loss: 0.1903 - val_accuracy: 0.9440\n",
            "Epoch 3540/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2390 - accuracy: 0.9233 - val_loss: 0.1908 - val_accuracy: 0.9450\n",
            "Epoch 3541/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2290 - accuracy: 0.9243 - val_loss: 0.1920 - val_accuracy: 0.9455\n",
            "Epoch 3542/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2223 - accuracy: 0.9268 - val_loss: 0.1880 - val_accuracy: 0.9450\n",
            "Epoch 3543/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2342 - accuracy: 0.9235 - val_loss: 0.1899 - val_accuracy: 0.9445\n",
            "Epoch 3544/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2327 - accuracy: 0.9236 - val_loss: 0.1940 - val_accuracy: 0.9445\n",
            "Epoch 3545/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2313 - accuracy: 0.9256 - val_loss: 0.1904 - val_accuracy: 0.9445\n",
            "Epoch 3546/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2303 - accuracy: 0.9243 - val_loss: 0.1883 - val_accuracy: 0.9455\n",
            "Epoch 3547/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2300 - accuracy: 0.9260 - val_loss: 0.1864 - val_accuracy: 0.9445\n",
            "Epoch 3548/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2419 - accuracy: 0.9212 - val_loss: 0.1921 - val_accuracy: 0.9455\n",
            "Epoch 3549/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2261 - accuracy: 0.9274 - val_loss: 0.1893 - val_accuracy: 0.9460\n",
            "Epoch 3550/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2338 - accuracy: 0.9245 - val_loss: 0.1863 - val_accuracy: 0.9445\n",
            "Epoch 3551/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2375 - accuracy: 0.9252 - val_loss: 0.1906 - val_accuracy: 0.9450\n",
            "Epoch 3552/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2293 - accuracy: 0.9244 - val_loss: 0.1887 - val_accuracy: 0.9445\n",
            "Epoch 3553/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2346 - accuracy: 0.9251 - val_loss: 0.1899 - val_accuracy: 0.9465\n",
            "Epoch 3554/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2293 - accuracy: 0.9266 - val_loss: 0.1874 - val_accuracy: 0.9480\n",
            "Epoch 3555/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2307 - accuracy: 0.9296 - val_loss: 0.1938 - val_accuracy: 0.9460\n",
            "Epoch 3556/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2312 - accuracy: 0.9225 - val_loss: 0.1893 - val_accuracy: 0.9440\n",
            "Epoch 3557/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2350 - accuracy: 0.9239 - val_loss: 0.1904 - val_accuracy: 0.9455\n",
            "Epoch 3558/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2485 - accuracy: 0.9237 - val_loss: 0.1933 - val_accuracy: 0.9465\n",
            "Epoch 3559/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2427 - accuracy: 0.9235 - val_loss: 0.1904 - val_accuracy: 0.9450\n",
            "Epoch 3560/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2250 - accuracy: 0.9247 - val_loss: 0.1894 - val_accuracy: 0.9435\n",
            "Epoch 3561/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2330 - accuracy: 0.9231 - val_loss: 0.1913 - val_accuracy: 0.9455\n",
            "Epoch 3562/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2313 - accuracy: 0.9261 - val_loss: 0.1909 - val_accuracy: 0.9455\n",
            "Epoch 3563/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2237 - accuracy: 0.9284 - val_loss: 0.1926 - val_accuracy: 0.9450\n",
            "Epoch 3564/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2371 - accuracy: 0.9240 - val_loss: 0.1910 - val_accuracy: 0.9465\n",
            "Epoch 3565/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2351 - accuracy: 0.9258 - val_loss: 0.1908 - val_accuracy: 0.9435\n",
            "Epoch 3566/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2390 - accuracy: 0.9241 - val_loss: 0.1853 - val_accuracy: 0.9460\n",
            "Epoch 3567/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2348 - accuracy: 0.9275 - val_loss: 0.1959 - val_accuracy: 0.9440\n",
            "Epoch 3568/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2383 - accuracy: 0.9233 - val_loss: 0.1906 - val_accuracy: 0.9455\n",
            "Epoch 3569/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2328 - accuracy: 0.9254 - val_loss: 0.1892 - val_accuracy: 0.9450\n",
            "Epoch 3570/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2295 - accuracy: 0.9260 - val_loss: 0.1922 - val_accuracy: 0.9420\n",
            "Epoch 3571/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2317 - accuracy: 0.9262 - val_loss: 0.1908 - val_accuracy: 0.9445\n",
            "Epoch 3572/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2249 - accuracy: 0.9319 - val_loss: 0.1870 - val_accuracy: 0.9465\n",
            "Epoch 3573/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2261 - accuracy: 0.9279 - val_loss: 0.1949 - val_accuracy: 0.9460\n",
            "Epoch 3574/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2288 - accuracy: 0.9275 - val_loss: 0.1932 - val_accuracy: 0.9440\n",
            "Epoch 3575/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2391 - accuracy: 0.9255 - val_loss: 0.1907 - val_accuracy: 0.9445\n",
            "Epoch 3576/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2302 - accuracy: 0.9251 - val_loss: 0.1894 - val_accuracy: 0.9450\n",
            "Epoch 3577/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2307 - accuracy: 0.9231 - val_loss: 0.1926 - val_accuracy: 0.9440\n",
            "Epoch 3578/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2224 - accuracy: 0.9293 - val_loss: 0.1866 - val_accuracy: 0.9450\n",
            "Epoch 3579/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2325 - accuracy: 0.9247 - val_loss: 0.1873 - val_accuracy: 0.9450\n",
            "Epoch 3580/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2353 - accuracy: 0.9246 - val_loss: 0.1910 - val_accuracy: 0.9430\n",
            "Epoch 3581/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2339 - accuracy: 0.9237 - val_loss: 0.1899 - val_accuracy: 0.9450\n",
            "Epoch 3582/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2311 - accuracy: 0.9237 - val_loss: 0.1895 - val_accuracy: 0.9460\n",
            "Epoch 3583/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2271 - accuracy: 0.9256 - val_loss: 0.1899 - val_accuracy: 0.9440\n",
            "Epoch 3584/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2289 - accuracy: 0.9275 - val_loss: 0.1895 - val_accuracy: 0.9445\n",
            "Epoch 3585/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2301 - accuracy: 0.9265 - val_loss: 0.1902 - val_accuracy: 0.9450\n",
            "Epoch 3586/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2252 - accuracy: 0.9255 - val_loss: 0.1922 - val_accuracy: 0.9450\n",
            "Epoch 3587/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2407 - accuracy: 0.9251 - val_loss: 0.1912 - val_accuracy: 0.9440\n",
            "Epoch 3588/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2332 - accuracy: 0.9237 - val_loss: 0.1890 - val_accuracy: 0.9450\n",
            "Epoch 3589/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2292 - accuracy: 0.9252 - val_loss: 0.1905 - val_accuracy: 0.9455\n",
            "Epoch 3590/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2246 - accuracy: 0.9286 - val_loss: 0.1879 - val_accuracy: 0.9460\n",
            "Epoch 3591/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2322 - accuracy: 0.9250 - val_loss: 0.1888 - val_accuracy: 0.9465\n",
            "Epoch 3592/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2251 - accuracy: 0.9287 - val_loss: 0.1911 - val_accuracy: 0.9425\n",
            "Epoch 3593/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2336 - accuracy: 0.9234 - val_loss: 0.1929 - val_accuracy: 0.9440\n",
            "Epoch 3594/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2336 - accuracy: 0.9276 - val_loss: 0.1924 - val_accuracy: 0.9440\n",
            "Epoch 3595/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2348 - accuracy: 0.9230 - val_loss: 0.1981 - val_accuracy: 0.9430\n",
            "Epoch 3596/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2377 - accuracy: 0.9236 - val_loss: 0.1979 - val_accuracy: 0.9425\n",
            "Epoch 3597/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2271 - accuracy: 0.9270 - val_loss: 0.1909 - val_accuracy: 0.9460\n",
            "Epoch 3598/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2307 - accuracy: 0.9280 - val_loss: 0.1945 - val_accuracy: 0.9430\n",
            "Epoch 3599/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2267 - accuracy: 0.9291 - val_loss: 0.1917 - val_accuracy: 0.9435\n",
            "Epoch 3600/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2265 - accuracy: 0.9277 - val_loss: 0.1895 - val_accuracy: 0.9465\n",
            "Epoch 3601/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2349 - accuracy: 0.9243 - val_loss: 0.1884 - val_accuracy: 0.9450\n",
            "Epoch 3602/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2287 - accuracy: 0.9239 - val_loss: 0.1905 - val_accuracy: 0.9465\n",
            "Epoch 3603/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2259 - accuracy: 0.9259 - val_loss: 0.1916 - val_accuracy: 0.9465\n",
            "Epoch 3604/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2340 - accuracy: 0.9265 - val_loss: 0.1904 - val_accuracy: 0.9445\n",
            "Epoch 3605/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2256 - accuracy: 0.9285 - val_loss: 0.1938 - val_accuracy: 0.9455\n",
            "Epoch 3606/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2327 - accuracy: 0.9252 - val_loss: 0.1879 - val_accuracy: 0.9455\n",
            "Epoch 3607/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2363 - accuracy: 0.9243 - val_loss: 0.1857 - val_accuracy: 0.9450\n",
            "Epoch 3608/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2271 - accuracy: 0.9244 - val_loss: 0.1877 - val_accuracy: 0.9455\n",
            "Epoch 3609/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2284 - accuracy: 0.9254 - val_loss: 0.1938 - val_accuracy: 0.9430\n",
            "Epoch 3610/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2382 - accuracy: 0.9195 - val_loss: 0.1890 - val_accuracy: 0.9435\n",
            "Epoch 3611/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2202 - accuracy: 0.9275 - val_loss: 0.1886 - val_accuracy: 0.9450\n",
            "Epoch 3612/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2329 - accuracy: 0.9233 - val_loss: 0.1918 - val_accuracy: 0.9445\n",
            "Epoch 3613/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2258 - accuracy: 0.9234 - val_loss: 0.1890 - val_accuracy: 0.9445\n",
            "Epoch 3614/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2320 - accuracy: 0.9241 - val_loss: 0.1916 - val_accuracy: 0.9435\n",
            "Epoch 3615/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2236 - accuracy: 0.9259 - val_loss: 0.1898 - val_accuracy: 0.9430\n",
            "Epoch 3616/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2309 - accuracy: 0.9244 - val_loss: 0.1877 - val_accuracy: 0.9445\n",
            "Epoch 3617/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2338 - accuracy: 0.9229 - val_loss: 0.1871 - val_accuracy: 0.9450\n",
            "Epoch 3618/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2326 - accuracy: 0.9247 - val_loss: 0.1894 - val_accuracy: 0.9465\n",
            "Epoch 3619/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2308 - accuracy: 0.9251 - val_loss: 0.1873 - val_accuracy: 0.9450\n",
            "Epoch 3620/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2263 - accuracy: 0.9262 - val_loss: 0.1907 - val_accuracy: 0.9445\n",
            "Epoch 3621/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2513 - accuracy: 0.9249 - val_loss: 0.1942 - val_accuracy: 0.9450\n",
            "Epoch 3622/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2245 - accuracy: 0.9252 - val_loss: 0.1899 - val_accuracy: 0.9460\n",
            "Epoch 3623/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2253 - accuracy: 0.9286 - val_loss: 0.1889 - val_accuracy: 0.9455\n",
            "Epoch 3624/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2260 - accuracy: 0.9274 - val_loss: 0.1916 - val_accuracy: 0.9435\n",
            "Epoch 3625/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2232 - accuracy: 0.9260 - val_loss: 0.1858 - val_accuracy: 0.9445\n",
            "Epoch 3626/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2297 - accuracy: 0.9252 - val_loss: 0.1915 - val_accuracy: 0.9450\n",
            "Epoch 3627/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2317 - accuracy: 0.9275 - val_loss: 0.1921 - val_accuracy: 0.9450\n",
            "Epoch 3628/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2324 - accuracy: 0.9261 - val_loss: 0.1884 - val_accuracy: 0.9440\n",
            "Epoch 3629/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2339 - accuracy: 0.9247 - val_loss: 0.1860 - val_accuracy: 0.9455\n",
            "Epoch 3630/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2290 - accuracy: 0.9243 - val_loss: 0.1887 - val_accuracy: 0.9450\n",
            "Epoch 3631/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2314 - accuracy: 0.9255 - val_loss: 0.1905 - val_accuracy: 0.9460\n",
            "Epoch 3632/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2304 - accuracy: 0.9251 - val_loss: 0.1875 - val_accuracy: 0.9460\n",
            "Epoch 3633/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2279 - accuracy: 0.9285 - val_loss: 0.1890 - val_accuracy: 0.9460\n",
            "Epoch 3634/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2279 - accuracy: 0.9256 - val_loss: 0.1936 - val_accuracy: 0.9440\n",
            "Epoch 3635/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2273 - accuracy: 0.9227 - val_loss: 0.1893 - val_accuracy: 0.9455\n",
            "Epoch 3636/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2270 - accuracy: 0.9231 - val_loss: 0.1994 - val_accuracy: 0.9405\n",
            "Epoch 3637/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2316 - accuracy: 0.9271 - val_loss: 0.1847 - val_accuracy: 0.9435\n",
            "Epoch 3638/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2274 - accuracy: 0.9241 - val_loss: 0.1950 - val_accuracy: 0.9415\n",
            "Epoch 3639/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2242 - accuracy: 0.9271 - val_loss: 0.1876 - val_accuracy: 0.9450\n",
            "Epoch 3640/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2287 - accuracy: 0.9259 - val_loss: 0.1876 - val_accuracy: 0.9440\n",
            "Epoch 3641/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2293 - accuracy: 0.9256 - val_loss: 0.1869 - val_accuracy: 0.9445\n",
            "Epoch 3642/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2355 - accuracy: 0.9247 - val_loss: 0.1877 - val_accuracy: 0.9440\n",
            "Epoch 3643/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2345 - accuracy: 0.9234 - val_loss: 0.1928 - val_accuracy: 0.9435\n",
            "Epoch 3644/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2307 - accuracy: 0.9240 - val_loss: 0.1908 - val_accuracy: 0.9425\n",
            "Epoch 3645/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2316 - accuracy: 0.9254 - val_loss: 0.1900 - val_accuracy: 0.9440\n",
            "Epoch 3646/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2310 - accuracy: 0.9256 - val_loss: 0.1888 - val_accuracy: 0.9450\n",
            "Epoch 3647/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2310 - accuracy: 0.9241 - val_loss: 0.1922 - val_accuracy: 0.9445\n",
            "Epoch 3648/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2318 - accuracy: 0.9261 - val_loss: 0.1930 - val_accuracy: 0.9430\n",
            "Epoch 3649/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2318 - accuracy: 0.9241 - val_loss: 0.1921 - val_accuracy: 0.9435\n",
            "Epoch 3650/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2268 - accuracy: 0.9256 - val_loss: 0.1952 - val_accuracy: 0.9435\n",
            "Epoch 3651/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2424 - accuracy: 0.9210 - val_loss: 0.1905 - val_accuracy: 0.9450\n",
            "Epoch 3652/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2282 - accuracy: 0.9241 - val_loss: 0.1915 - val_accuracy: 0.9465\n",
            "Epoch 3653/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2249 - accuracy: 0.9283 - val_loss: 0.1845 - val_accuracy: 0.9445\n",
            "Epoch 3654/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2268 - accuracy: 0.9262 - val_loss: 0.1903 - val_accuracy: 0.9455\n",
            "Epoch 3655/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2288 - accuracy: 0.9260 - val_loss: 0.1868 - val_accuracy: 0.9455\n",
            "Epoch 3656/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2289 - accuracy: 0.9276 - val_loss: 0.1867 - val_accuracy: 0.9460\n",
            "Epoch 3657/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2408 - accuracy: 0.9250 - val_loss: 0.1952 - val_accuracy: 0.9435\n",
            "Epoch 3658/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2313 - accuracy: 0.9236 - val_loss: 0.1911 - val_accuracy: 0.9425\n",
            "Epoch 3659/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2477 - accuracy: 0.9261 - val_loss: 0.1898 - val_accuracy: 0.9460\n",
            "Epoch 3660/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2262 - accuracy: 0.9264 - val_loss: 0.1906 - val_accuracy: 0.9460\n",
            "Epoch 3661/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2335 - accuracy: 0.9249 - val_loss: 0.1885 - val_accuracy: 0.9445\n",
            "Epoch 3662/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2345 - accuracy: 0.9244 - val_loss: 0.1922 - val_accuracy: 0.9450\n",
            "Epoch 3663/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2249 - accuracy: 0.9295 - val_loss: 0.1879 - val_accuracy: 0.9450\n",
            "Epoch 3664/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2295 - accuracy: 0.9246 - val_loss: 0.1987 - val_accuracy: 0.9425\n",
            "Epoch 3665/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2308 - accuracy: 0.9268 - val_loss: 0.1898 - val_accuracy: 0.9450\n",
            "Epoch 3666/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2318 - accuracy: 0.9265 - val_loss: 0.1918 - val_accuracy: 0.9435\n",
            "Epoch 3667/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2265 - accuracy: 0.9284 - val_loss: 0.1874 - val_accuracy: 0.9440\n",
            "Epoch 3668/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2384 - accuracy: 0.9254 - val_loss: 0.1860 - val_accuracy: 0.9450\n",
            "Epoch 3669/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2335 - accuracy: 0.9231 - val_loss: 0.1909 - val_accuracy: 0.9450\n",
            "Epoch 3670/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2247 - accuracy: 0.9270 - val_loss: 0.1917 - val_accuracy: 0.9445\n",
            "Epoch 3671/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2344 - accuracy: 0.9254 - val_loss: 0.1909 - val_accuracy: 0.9440\n",
            "Epoch 3672/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2225 - accuracy: 0.9276 - val_loss: 0.1909 - val_accuracy: 0.9440\n",
            "Epoch 3673/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2345 - accuracy: 0.9277 - val_loss: 0.1886 - val_accuracy: 0.9450\n",
            "Epoch 3674/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2318 - accuracy: 0.9266 - val_loss: 0.1923 - val_accuracy: 0.9455\n",
            "Epoch 3675/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2323 - accuracy: 0.9250 - val_loss: 0.1920 - val_accuracy: 0.9460\n",
            "Epoch 3676/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2241 - accuracy: 0.9279 - val_loss: 0.1923 - val_accuracy: 0.9440\n",
            "Epoch 3677/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2341 - accuracy: 0.9227 - val_loss: 0.1892 - val_accuracy: 0.9455\n",
            "Epoch 3678/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2367 - accuracy: 0.9244 - val_loss: 0.1898 - val_accuracy: 0.9425\n",
            "Epoch 3679/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2428 - accuracy: 0.9245 - val_loss: 0.1914 - val_accuracy: 0.9415\n",
            "Epoch 3680/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2372 - accuracy: 0.9246 - val_loss: 0.1878 - val_accuracy: 0.9435\n",
            "Epoch 3681/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2327 - accuracy: 0.9241 - val_loss: 0.1924 - val_accuracy: 0.9445\n",
            "Epoch 3682/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2330 - accuracy: 0.9244 - val_loss: 0.1879 - val_accuracy: 0.9450\n",
            "Epoch 3683/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2324 - accuracy: 0.9258 - val_loss: 0.1893 - val_accuracy: 0.9445\n",
            "Epoch 3684/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2232 - accuracy: 0.9299 - val_loss: 0.1871 - val_accuracy: 0.9445\n",
            "Epoch 3685/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2334 - accuracy: 0.9221 - val_loss: 0.1871 - val_accuracy: 0.9450\n",
            "Epoch 3686/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2327 - accuracy: 0.9277 - val_loss: 0.1893 - val_accuracy: 0.9455\n",
            "Epoch 3687/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2275 - accuracy: 0.9249 - val_loss: 0.1874 - val_accuracy: 0.9440\n",
            "Epoch 3688/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2268 - accuracy: 0.9273 - val_loss: 0.1892 - val_accuracy: 0.9450\n",
            "Epoch 3689/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2261 - accuracy: 0.9259 - val_loss: 0.1885 - val_accuracy: 0.9460\n",
            "Epoch 3690/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2310 - accuracy: 0.9260 - val_loss: 0.1870 - val_accuracy: 0.9460\n",
            "Epoch 3691/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2276 - accuracy: 0.9236 - val_loss: 0.1887 - val_accuracy: 0.9460\n",
            "Epoch 3692/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2281 - accuracy: 0.9243 - val_loss: 0.1900 - val_accuracy: 0.9445\n",
            "Epoch 3693/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2516 - accuracy: 0.9269 - val_loss: 0.1884 - val_accuracy: 0.9450\n",
            "Epoch 3694/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2234 - accuracy: 0.9295 - val_loss: 0.1956 - val_accuracy: 0.9450\n",
            "Epoch 3695/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2335 - accuracy: 0.9254 - val_loss: 0.1895 - val_accuracy: 0.9465\n",
            "Epoch 3696/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2309 - accuracy: 0.9231 - val_loss: 0.1881 - val_accuracy: 0.9455\n",
            "Epoch 3697/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2272 - accuracy: 0.9258 - val_loss: 0.1921 - val_accuracy: 0.9445\n",
            "Epoch 3698/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2334 - accuracy: 0.9244 - val_loss: 0.1910 - val_accuracy: 0.9445\n",
            "Epoch 3699/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2318 - accuracy: 0.9276 - val_loss: 0.1867 - val_accuracy: 0.9460\n",
            "Epoch 3700/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2245 - accuracy: 0.9270 - val_loss: 0.1895 - val_accuracy: 0.9460\n",
            "Epoch 3701/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2392 - accuracy: 0.9259 - val_loss: 0.1871 - val_accuracy: 0.9465\n",
            "Epoch 3702/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2483 - accuracy: 0.9218 - val_loss: 0.1870 - val_accuracy: 0.9450\n",
            "Epoch 3703/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2352 - accuracy: 0.9246 - val_loss: 0.1899 - val_accuracy: 0.9470\n",
            "Epoch 3704/6000\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2328 - accuracy: 0.9268 - val_loss: 0.1884 - val_accuracy: 0.9455\n",
            "Epoch 3705/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2254 - accuracy: 0.9262 - val_loss: 0.1907 - val_accuracy: 0.9480\n",
            "Epoch 3706/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2282 - accuracy: 0.9245 - val_loss: 0.1866 - val_accuracy: 0.9465\n",
            "Epoch 3707/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2318 - accuracy: 0.9265 - val_loss: 0.1876 - val_accuracy: 0.9465\n",
            "Epoch 3708/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2350 - accuracy: 0.9287 - val_loss: 0.1863 - val_accuracy: 0.9470\n",
            "Epoch 3709/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2293 - accuracy: 0.9249 - val_loss: 0.1886 - val_accuracy: 0.9455\n",
            "Epoch 3710/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2299 - accuracy: 0.9277 - val_loss: 0.1854 - val_accuracy: 0.9460\n",
            "Epoch 3711/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2379 - accuracy: 0.9236 - val_loss: 0.1875 - val_accuracy: 0.9465\n",
            "Epoch 3712/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2247 - accuracy: 0.9239 - val_loss: 0.1893 - val_accuracy: 0.9460\n",
            "Epoch 3713/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2350 - accuracy: 0.9240 - val_loss: 0.1923 - val_accuracy: 0.9455\n",
            "Epoch 3714/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2290 - accuracy: 0.9255 - val_loss: 0.1907 - val_accuracy: 0.9465\n",
            "Epoch 3715/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2295 - accuracy: 0.9276 - val_loss: 0.1910 - val_accuracy: 0.9460\n",
            "Epoch 3716/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2454 - accuracy: 0.9279 - val_loss: 0.1916 - val_accuracy: 0.9460\n",
            "Epoch 3717/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2284 - accuracy: 0.9255 - val_loss: 0.1904 - val_accuracy: 0.9450\n",
            "Epoch 3718/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2412 - accuracy: 0.9255 - val_loss: 0.1889 - val_accuracy: 0.9445\n",
            "Epoch 3719/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2276 - accuracy: 0.9294 - val_loss: 0.1890 - val_accuracy: 0.9440\n",
            "Epoch 3720/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2298 - accuracy: 0.9251 - val_loss: 0.1884 - val_accuracy: 0.9460\n",
            "Epoch 3721/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2368 - accuracy: 0.9260 - val_loss: 0.1931 - val_accuracy: 0.9450\n",
            "Epoch 3722/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2375 - accuracy: 0.9209 - val_loss: 0.1955 - val_accuracy: 0.9440\n",
            "Epoch 3723/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2327 - accuracy: 0.9241 - val_loss: 0.1904 - val_accuracy: 0.9425\n",
            "Epoch 3724/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2350 - accuracy: 0.9237 - val_loss: 0.1894 - val_accuracy: 0.9445\n",
            "Epoch 3725/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2222 - accuracy: 0.9281 - val_loss: 0.1911 - val_accuracy: 0.9440\n",
            "Epoch 3726/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2340 - accuracy: 0.9287 - val_loss: 0.1933 - val_accuracy: 0.9430\n",
            "Epoch 3727/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2359 - accuracy: 0.9284 - val_loss: 0.1907 - val_accuracy: 0.9455\n",
            "Epoch 3728/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2251 - accuracy: 0.9284 - val_loss: 0.1874 - val_accuracy: 0.9445\n",
            "Epoch 3729/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2260 - accuracy: 0.9276 - val_loss: 0.1917 - val_accuracy: 0.9470\n",
            "Epoch 3730/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2223 - accuracy: 0.9286 - val_loss: 0.1860 - val_accuracy: 0.9460\n",
            "Epoch 3731/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2297 - accuracy: 0.9250 - val_loss: 0.1911 - val_accuracy: 0.9465\n",
            "Epoch 3732/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2348 - accuracy: 0.9240 - val_loss: 0.1904 - val_accuracy: 0.9475\n",
            "Epoch 3733/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2344 - accuracy: 0.9269 - val_loss: 0.1856 - val_accuracy: 0.9455\n",
            "Epoch 3734/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2282 - accuracy: 0.9273 - val_loss: 0.1893 - val_accuracy: 0.9455\n",
            "Epoch 3735/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2273 - accuracy: 0.9268 - val_loss: 0.1877 - val_accuracy: 0.9455\n",
            "Epoch 3736/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2251 - accuracy: 0.9255 - val_loss: 0.1894 - val_accuracy: 0.9440\n",
            "Epoch 3737/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2288 - accuracy: 0.9249 - val_loss: 0.1883 - val_accuracy: 0.9455\n",
            "Epoch 3738/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2342 - accuracy: 0.9279 - val_loss: 0.1890 - val_accuracy: 0.9465\n",
            "Epoch 3739/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2393 - accuracy: 0.9247 - val_loss: 0.1893 - val_accuracy: 0.9465\n",
            "Epoch 3740/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2358 - accuracy: 0.9258 - val_loss: 0.1875 - val_accuracy: 0.9470\n",
            "Epoch 3741/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2449 - accuracy: 0.9255 - val_loss: 0.1896 - val_accuracy: 0.9475\n",
            "Epoch 3742/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2331 - accuracy: 0.9241 - val_loss: 0.1917 - val_accuracy: 0.9455\n",
            "Epoch 3743/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2286 - accuracy: 0.9271 - val_loss: 0.1868 - val_accuracy: 0.9455\n",
            "Epoch 3744/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2250 - accuracy: 0.9249 - val_loss: 0.1895 - val_accuracy: 0.9460\n",
            "Epoch 3745/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2234 - accuracy: 0.9234 - val_loss: 0.1887 - val_accuracy: 0.9455\n",
            "Epoch 3746/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2262 - accuracy: 0.9270 - val_loss: 0.1908 - val_accuracy: 0.9460\n",
            "Epoch 3747/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2329 - accuracy: 0.9246 - val_loss: 0.1928 - val_accuracy: 0.9445\n",
            "Epoch 3748/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2353 - accuracy: 0.9241 - val_loss: 0.1879 - val_accuracy: 0.9445\n",
            "Epoch 3749/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2265 - accuracy: 0.9259 - val_loss: 0.1859 - val_accuracy: 0.9465\n",
            "Epoch 3750/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2353 - accuracy: 0.9206 - val_loss: 0.1898 - val_accuracy: 0.9450\n",
            "Epoch 3751/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2322 - accuracy: 0.9227 - val_loss: 0.1910 - val_accuracy: 0.9450\n",
            "Epoch 3752/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2369 - accuracy: 0.9251 - val_loss: 0.1911 - val_accuracy: 0.9445\n",
            "Epoch 3753/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2319 - accuracy: 0.9254 - val_loss: 0.1910 - val_accuracy: 0.9445\n",
            "Epoch 3754/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2366 - accuracy: 0.9215 - val_loss: 0.1925 - val_accuracy: 0.9455\n",
            "Epoch 3755/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2312 - accuracy: 0.9264 - val_loss: 0.1914 - val_accuracy: 0.9445\n",
            "Epoch 3756/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2237 - accuracy: 0.9291 - val_loss: 0.1896 - val_accuracy: 0.9455\n",
            "Epoch 3757/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2415 - accuracy: 0.9258 - val_loss: 0.1900 - val_accuracy: 0.9455\n",
            "Epoch 3758/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2347 - accuracy: 0.9274 - val_loss: 0.1836 - val_accuracy: 0.9465\n",
            "Epoch 3759/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2408 - accuracy: 0.9245 - val_loss: 0.1881 - val_accuracy: 0.9450\n",
            "Epoch 3760/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2281 - accuracy: 0.9244 - val_loss: 0.1887 - val_accuracy: 0.9450\n",
            "Epoch 3761/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2249 - accuracy: 0.9266 - val_loss: 0.1885 - val_accuracy: 0.9450\n",
            "Epoch 3762/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2323 - accuracy: 0.9265 - val_loss: 0.1898 - val_accuracy: 0.9440\n",
            "Epoch 3763/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2302 - accuracy: 0.9261 - val_loss: 0.1864 - val_accuracy: 0.9460\n",
            "Epoch 3764/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2287 - accuracy: 0.9258 - val_loss: 0.1893 - val_accuracy: 0.9460\n",
            "Epoch 3765/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2318 - accuracy: 0.9279 - val_loss: 0.1909 - val_accuracy: 0.9455\n",
            "Epoch 3766/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2368 - accuracy: 0.9230 - val_loss: 0.1900 - val_accuracy: 0.9460\n",
            "Epoch 3767/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2354 - accuracy: 0.9240 - val_loss: 0.1919 - val_accuracy: 0.9445\n",
            "Epoch 3768/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2468 - accuracy: 0.9262 - val_loss: 0.1910 - val_accuracy: 0.9455\n",
            "Epoch 3769/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2332 - accuracy: 0.9241 - val_loss: 0.1922 - val_accuracy: 0.9470\n",
            "Epoch 3770/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2223 - accuracy: 0.9306 - val_loss: 0.1866 - val_accuracy: 0.9450\n",
            "Epoch 3771/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2293 - accuracy: 0.9249 - val_loss: 0.1894 - val_accuracy: 0.9455\n",
            "Epoch 3772/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2334 - accuracy: 0.9256 - val_loss: 0.1878 - val_accuracy: 0.9465\n",
            "Epoch 3773/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2357 - accuracy: 0.9251 - val_loss: 0.1868 - val_accuracy: 0.9450\n",
            "Epoch 3774/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2367 - accuracy: 0.9256 - val_loss: 0.1954 - val_accuracy: 0.9435\n",
            "Epoch 3775/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2343 - accuracy: 0.9269 - val_loss: 0.1888 - val_accuracy: 0.9455\n",
            "Epoch 3776/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2298 - accuracy: 0.9254 - val_loss: 0.1909 - val_accuracy: 0.9450\n",
            "Epoch 3777/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2246 - accuracy: 0.9276 - val_loss: 0.1857 - val_accuracy: 0.9460\n",
            "Epoch 3778/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2290 - accuracy: 0.9236 - val_loss: 0.1925 - val_accuracy: 0.9435\n",
            "Epoch 3779/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2248 - accuracy: 0.9271 - val_loss: 0.1892 - val_accuracy: 0.9470\n",
            "Epoch 3780/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2311 - accuracy: 0.9246 - val_loss: 0.1855 - val_accuracy: 0.9465\n",
            "Epoch 3781/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2253 - accuracy: 0.9261 - val_loss: 0.1897 - val_accuracy: 0.9450\n",
            "Epoch 3782/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2298 - accuracy: 0.9268 - val_loss: 0.1865 - val_accuracy: 0.9465\n",
            "Epoch 3783/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2280 - accuracy: 0.9260 - val_loss: 0.1878 - val_accuracy: 0.9450\n",
            "Epoch 3784/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2276 - accuracy: 0.9262 - val_loss: 0.1923 - val_accuracy: 0.9455\n",
            "Epoch 3785/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2286 - accuracy: 0.9271 - val_loss: 0.1847 - val_accuracy: 0.9455\n",
            "Epoch 3786/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2266 - accuracy: 0.9291 - val_loss: 0.1900 - val_accuracy: 0.9455\n",
            "Epoch 3787/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2312 - accuracy: 0.9252 - val_loss: 0.1893 - val_accuracy: 0.9450\n",
            "Epoch 3788/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2368 - accuracy: 0.9239 - val_loss: 0.1907 - val_accuracy: 0.9455\n",
            "Epoch 3789/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2397 - accuracy: 0.9251 - val_loss: 0.1885 - val_accuracy: 0.9455\n",
            "Epoch 3790/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2406 - accuracy: 0.9258 - val_loss: 0.1882 - val_accuracy: 0.9420\n",
            "Epoch 3791/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2315 - accuracy: 0.9235 - val_loss: 0.1934 - val_accuracy: 0.9440\n",
            "Epoch 3792/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2332 - accuracy: 0.9234 - val_loss: 0.1852 - val_accuracy: 0.9460\n",
            "Epoch 3793/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2281 - accuracy: 0.9283 - val_loss: 0.1906 - val_accuracy: 0.9460\n",
            "Epoch 3794/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2381 - accuracy: 0.9226 - val_loss: 0.1880 - val_accuracy: 0.9445\n",
            "Epoch 3795/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2241 - accuracy: 0.9277 - val_loss: 0.1874 - val_accuracy: 0.9455\n",
            "Epoch 3796/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2292 - accuracy: 0.9262 - val_loss: 0.1900 - val_accuracy: 0.9455\n",
            "Epoch 3797/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2377 - accuracy: 0.9261 - val_loss: 0.1911 - val_accuracy: 0.9465\n",
            "Epoch 3798/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2255 - accuracy: 0.9275 - val_loss: 0.1918 - val_accuracy: 0.9445\n",
            "Epoch 3799/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2338 - accuracy: 0.9240 - val_loss: 0.1948 - val_accuracy: 0.9440\n",
            "Epoch 3800/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2243 - accuracy: 0.9259 - val_loss: 0.1889 - val_accuracy: 0.9440\n",
            "Epoch 3801/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2275 - accuracy: 0.9277 - val_loss: 0.1891 - val_accuracy: 0.9445\n",
            "Epoch 3802/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2296 - accuracy: 0.9271 - val_loss: 0.1947 - val_accuracy: 0.9450\n",
            "Epoch 3803/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2342 - accuracy: 0.9274 - val_loss: 0.1942 - val_accuracy: 0.9440\n",
            "Epoch 3804/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2262 - accuracy: 0.9224 - val_loss: 0.1898 - val_accuracy: 0.9450\n",
            "Epoch 3805/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2285 - accuracy: 0.9240 - val_loss: 0.1905 - val_accuracy: 0.9435\n",
            "Epoch 3806/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2309 - accuracy: 0.9252 - val_loss: 0.1932 - val_accuracy: 0.9455\n",
            "Epoch 3807/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2320 - accuracy: 0.9265 - val_loss: 0.1894 - val_accuracy: 0.9455\n",
            "Epoch 3808/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2222 - accuracy: 0.9295 - val_loss: 0.1884 - val_accuracy: 0.9475\n",
            "Epoch 3809/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2285 - accuracy: 0.9274 - val_loss: 0.1843 - val_accuracy: 0.9455\n",
            "Epoch 3810/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2350 - accuracy: 0.9243 - val_loss: 0.1916 - val_accuracy: 0.9450\n",
            "Epoch 3811/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2298 - accuracy: 0.9260 - val_loss: 0.1906 - val_accuracy: 0.9435\n",
            "Epoch 3812/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2352 - accuracy: 0.9230 - val_loss: 0.1939 - val_accuracy: 0.9445\n",
            "Epoch 3813/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2207 - accuracy: 0.9286 - val_loss: 0.1870 - val_accuracy: 0.9440\n",
            "Epoch 3814/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2324 - accuracy: 0.9240 - val_loss: 0.1903 - val_accuracy: 0.9455\n",
            "Epoch 3815/6000\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2319 - accuracy: 0.9246 - val_loss: 0.1891 - val_accuracy: 0.9450\n",
            "Epoch 3816/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2325 - accuracy: 0.9237 - val_loss: 0.1912 - val_accuracy: 0.9460\n",
            "Epoch 3817/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2357 - accuracy: 0.9233 - val_loss: 0.1880 - val_accuracy: 0.9435\n",
            "Epoch 3818/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2289 - accuracy: 0.9285 - val_loss: 0.1892 - val_accuracy: 0.9450\n",
            "Epoch 3819/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2311 - accuracy: 0.9256 - val_loss: 0.1863 - val_accuracy: 0.9440\n",
            "Epoch 3820/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2251 - accuracy: 0.9281 - val_loss: 0.1883 - val_accuracy: 0.9435\n",
            "Epoch 3821/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2340 - accuracy: 0.9265 - val_loss: 0.1900 - val_accuracy: 0.9450\n",
            "Epoch 3822/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2302 - accuracy: 0.9247 - val_loss: 0.1877 - val_accuracy: 0.9440\n",
            "Epoch 3823/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2383 - accuracy: 0.9251 - val_loss: 0.1917 - val_accuracy: 0.9445\n",
            "Epoch 3824/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2217 - accuracy: 0.9270 - val_loss: 0.1910 - val_accuracy: 0.9470\n",
            "Epoch 3825/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2334 - accuracy: 0.9251 - val_loss: 0.1867 - val_accuracy: 0.9450\n",
            "Epoch 3826/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2340 - accuracy: 0.9260 - val_loss: 0.1839 - val_accuracy: 0.9455\n",
            "Epoch 3827/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2410 - accuracy: 0.9229 - val_loss: 0.1894 - val_accuracy: 0.9450\n",
            "Epoch 3828/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2358 - accuracy: 0.9256 - val_loss: 0.1921 - val_accuracy: 0.9455\n",
            "Epoch 3829/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2325 - accuracy: 0.9235 - val_loss: 0.1950 - val_accuracy: 0.9440\n",
            "Epoch 3830/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2372 - accuracy: 0.9224 - val_loss: 0.1917 - val_accuracy: 0.9460\n",
            "Epoch 3831/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2404 - accuracy: 0.9252 - val_loss: 0.1900 - val_accuracy: 0.9450\n",
            "Epoch 3832/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2270 - accuracy: 0.9294 - val_loss: 0.1901 - val_accuracy: 0.9440\n",
            "Epoch 3833/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2272 - accuracy: 0.9285 - val_loss: 0.1865 - val_accuracy: 0.9455\n",
            "Epoch 3834/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2295 - accuracy: 0.9265 - val_loss: 0.1892 - val_accuracy: 0.9455\n",
            "Epoch 3835/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2282 - accuracy: 0.9262 - val_loss: 0.1896 - val_accuracy: 0.9455\n",
            "Epoch 3836/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2299 - accuracy: 0.9246 - val_loss: 0.1921 - val_accuracy: 0.9450\n",
            "Epoch 3837/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2314 - accuracy: 0.9266 - val_loss: 0.1893 - val_accuracy: 0.9430\n",
            "Epoch 3838/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2303 - accuracy: 0.9260 - val_loss: 0.1916 - val_accuracy: 0.9445\n",
            "Epoch 3839/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2407 - accuracy: 0.9239 - val_loss: 0.1924 - val_accuracy: 0.9465\n",
            "Epoch 3840/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2352 - accuracy: 0.9247 - val_loss: 0.1933 - val_accuracy: 0.9430\n",
            "Epoch 3841/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2372 - accuracy: 0.9236 - val_loss: 0.1927 - val_accuracy: 0.9410\n",
            "Epoch 3842/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2254 - accuracy: 0.9256 - val_loss: 0.1908 - val_accuracy: 0.9445\n",
            "Epoch 3843/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2320 - accuracy: 0.9249 - val_loss: 0.1860 - val_accuracy: 0.9450\n",
            "Epoch 3844/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2280 - accuracy: 0.9240 - val_loss: 0.1883 - val_accuracy: 0.9450\n",
            "Epoch 3845/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2315 - accuracy: 0.9246 - val_loss: 0.1857 - val_accuracy: 0.9440\n",
            "Epoch 3846/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2342 - accuracy: 0.9283 - val_loss: 0.1952 - val_accuracy: 0.9420\n",
            "Epoch 3847/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2353 - accuracy: 0.9259 - val_loss: 0.1899 - val_accuracy: 0.9420\n",
            "Epoch 3848/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2381 - accuracy: 0.9211 - val_loss: 0.1924 - val_accuracy: 0.9455\n",
            "Epoch 3849/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2253 - accuracy: 0.9259 - val_loss: 0.1925 - val_accuracy: 0.9450\n",
            "Epoch 3850/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2331 - accuracy: 0.9250 - val_loss: 0.1897 - val_accuracy: 0.9435\n",
            "Epoch 3851/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2413 - accuracy: 0.9235 - val_loss: 0.1905 - val_accuracy: 0.9460\n",
            "Epoch 3852/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2268 - accuracy: 0.9266 - val_loss: 0.1901 - val_accuracy: 0.9440\n",
            "Epoch 3853/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2287 - accuracy: 0.9281 - val_loss: 0.1877 - val_accuracy: 0.9460\n",
            "Epoch 3854/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2294 - accuracy: 0.9252 - val_loss: 0.1887 - val_accuracy: 0.9465\n",
            "Epoch 3855/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2294 - accuracy: 0.9283 - val_loss: 0.1853 - val_accuracy: 0.9445\n",
            "Epoch 3856/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2475 - accuracy: 0.9256 - val_loss: 0.1867 - val_accuracy: 0.9455\n",
            "Epoch 3857/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2319 - accuracy: 0.9222 - val_loss: 0.1884 - val_accuracy: 0.9435\n",
            "Epoch 3858/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2329 - accuracy: 0.9211 - val_loss: 0.1914 - val_accuracy: 0.9440\n",
            "Epoch 3859/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2362 - accuracy: 0.9249 - val_loss: 0.1910 - val_accuracy: 0.9460\n",
            "Epoch 3860/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2286 - accuracy: 0.9262 - val_loss: 0.1863 - val_accuracy: 0.9480\n",
            "Epoch 3861/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2320 - accuracy: 0.9285 - val_loss: 0.1909 - val_accuracy: 0.9450\n",
            "Epoch 3862/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2287 - accuracy: 0.9249 - val_loss: 0.1898 - val_accuracy: 0.9445\n",
            "Epoch 3863/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2277 - accuracy: 0.9269 - val_loss: 0.1901 - val_accuracy: 0.9465\n",
            "Epoch 3864/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2275 - accuracy: 0.9275 - val_loss: 0.1885 - val_accuracy: 0.9460\n",
            "Epoch 3865/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2287 - accuracy: 0.9261 - val_loss: 0.1904 - val_accuracy: 0.9450\n",
            "Epoch 3866/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2355 - accuracy: 0.9259 - val_loss: 0.1926 - val_accuracy: 0.9465\n",
            "Epoch 3867/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2345 - accuracy: 0.9230 - val_loss: 0.1882 - val_accuracy: 0.9470\n",
            "Epoch 3868/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2315 - accuracy: 0.9266 - val_loss: 0.1912 - val_accuracy: 0.9460\n",
            "Epoch 3869/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2319 - accuracy: 0.9243 - val_loss: 0.1876 - val_accuracy: 0.9455\n",
            "Epoch 3870/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2293 - accuracy: 0.9277 - val_loss: 0.1875 - val_accuracy: 0.9450\n",
            "Epoch 3871/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2272 - accuracy: 0.9293 - val_loss: 0.1915 - val_accuracy: 0.9455\n",
            "Epoch 3872/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2276 - accuracy: 0.9261 - val_loss: 0.1863 - val_accuracy: 0.9450\n",
            "Epoch 3873/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2285 - accuracy: 0.9258 - val_loss: 0.1902 - val_accuracy: 0.9450\n",
            "Epoch 3874/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2349 - accuracy: 0.9237 - val_loss: 0.1871 - val_accuracy: 0.9450\n",
            "Epoch 3875/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2323 - accuracy: 0.9247 - val_loss: 0.1870 - val_accuracy: 0.9460\n",
            "Epoch 3876/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2310 - accuracy: 0.9243 - val_loss: 0.1879 - val_accuracy: 0.9460\n",
            "Epoch 3877/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2338 - accuracy: 0.9256 - val_loss: 0.1840 - val_accuracy: 0.9460\n",
            "Epoch 3878/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2268 - accuracy: 0.9262 - val_loss: 0.1891 - val_accuracy: 0.9455\n",
            "Epoch 3879/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2254 - accuracy: 0.9270 - val_loss: 0.1902 - val_accuracy: 0.9435\n",
            "Epoch 3880/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2293 - accuracy: 0.9226 - val_loss: 0.1898 - val_accuracy: 0.9455\n",
            "Epoch 3881/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2465 - accuracy: 0.9229 - val_loss: 0.1918 - val_accuracy: 0.9470\n",
            "Epoch 3882/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2310 - accuracy: 0.9243 - val_loss: 0.1895 - val_accuracy: 0.9455\n",
            "Epoch 3883/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2245 - accuracy: 0.9277 - val_loss: 0.1866 - val_accuracy: 0.9465\n",
            "Epoch 3884/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2346 - accuracy: 0.9251 - val_loss: 0.1848 - val_accuracy: 0.9455\n",
            "Epoch 3885/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2273 - accuracy: 0.9266 - val_loss: 0.1883 - val_accuracy: 0.9440\n",
            "Epoch 3886/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2297 - accuracy: 0.9240 - val_loss: 0.1909 - val_accuracy: 0.9445\n",
            "Epoch 3887/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2287 - accuracy: 0.9261 - val_loss: 0.1937 - val_accuracy: 0.9435\n",
            "Epoch 3888/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2264 - accuracy: 0.9271 - val_loss: 0.1875 - val_accuracy: 0.9450\n",
            "Epoch 3889/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2312 - accuracy: 0.9239 - val_loss: 0.1887 - val_accuracy: 0.9445\n",
            "Epoch 3890/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2242 - accuracy: 0.9290 - val_loss: 0.1859 - val_accuracy: 0.9440\n",
            "Epoch 3891/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2370 - accuracy: 0.9225 - val_loss: 0.1927 - val_accuracy: 0.9465\n",
            "Epoch 3892/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2490 - accuracy: 0.9264 - val_loss: 0.1889 - val_accuracy: 0.9470\n",
            "Epoch 3893/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2276 - accuracy: 0.9270 - val_loss: 0.1869 - val_accuracy: 0.9455\n",
            "Epoch 3894/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2295 - accuracy: 0.9268 - val_loss: 0.1875 - val_accuracy: 0.9445\n",
            "Epoch 3895/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2290 - accuracy: 0.9283 - val_loss: 0.1906 - val_accuracy: 0.9440\n",
            "Epoch 3896/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2263 - accuracy: 0.9281 - val_loss: 0.1966 - val_accuracy: 0.9435\n",
            "Epoch 3897/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2278 - accuracy: 0.9249 - val_loss: 0.1906 - val_accuracy: 0.9455\n",
            "Epoch 3898/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2523 - accuracy: 0.9261 - val_loss: 0.1950 - val_accuracy: 0.9460\n",
            "Epoch 3899/6000\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2409 - accuracy: 0.9205 - val_loss: 0.1907 - val_accuracy: 0.9430\n",
            "Epoch 3900/6000\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2325 - accuracy: 0.9271 - val_loss: 0.1918 - val_accuracy: 0.9430\n",
            "Epoch 3901/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2356 - accuracy: 0.9239 - val_loss: 0.1893 - val_accuracy: 0.9470\n",
            "Epoch 3902/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2334 - accuracy: 0.9236 - val_loss: 0.1901 - val_accuracy: 0.9445\n",
            "Epoch 3903/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2234 - accuracy: 0.9283 - val_loss: 0.1923 - val_accuracy: 0.9445\n",
            "Epoch 3904/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2228 - accuracy: 0.9268 - val_loss: 0.1924 - val_accuracy: 0.9430\n",
            "Epoch 3905/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2362 - accuracy: 0.9250 - val_loss: 0.1897 - val_accuracy: 0.9460\n",
            "Epoch 3906/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2338 - accuracy: 0.9250 - val_loss: 0.1886 - val_accuracy: 0.9445\n",
            "Epoch 3907/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2365 - accuracy: 0.9245 - val_loss: 0.1945 - val_accuracy: 0.9445\n",
            "Epoch 3908/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2245 - accuracy: 0.9294 - val_loss: 0.1940 - val_accuracy: 0.9460\n",
            "Epoch 3909/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2297 - accuracy: 0.9252 - val_loss: 0.1914 - val_accuracy: 0.9450\n",
            "Epoch 3910/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2261 - accuracy: 0.9291 - val_loss: 0.1844 - val_accuracy: 0.9450\n",
            "Epoch 3911/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2299 - accuracy: 0.9251 - val_loss: 0.1890 - val_accuracy: 0.9460\n",
            "Epoch 3912/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2322 - accuracy: 0.9273 - val_loss: 0.1900 - val_accuracy: 0.9450\n",
            "Epoch 3913/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2302 - accuracy: 0.9249 - val_loss: 0.1886 - val_accuracy: 0.9455\n",
            "Epoch 3914/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2289 - accuracy: 0.9240 - val_loss: 0.1913 - val_accuracy: 0.9455\n",
            "Epoch 3915/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2296 - accuracy: 0.9291 - val_loss: 0.1885 - val_accuracy: 0.9465\n",
            "Epoch 3916/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2241 - accuracy: 0.9293 - val_loss: 0.1880 - val_accuracy: 0.9445\n",
            "Epoch 3917/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2223 - accuracy: 0.9310 - val_loss: 0.1889 - val_accuracy: 0.9435\n",
            "Epoch 3918/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2260 - accuracy: 0.9270 - val_loss: 0.1890 - val_accuracy: 0.9430\n",
            "Epoch 3919/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2240 - accuracy: 0.9256 - val_loss: 0.1880 - val_accuracy: 0.9455\n",
            "Epoch 3920/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2430 - accuracy: 0.9265 - val_loss: 0.1889 - val_accuracy: 0.9455\n",
            "Epoch 3921/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2262 - accuracy: 0.9259 - val_loss: 0.1917 - val_accuracy: 0.9455\n",
            "Epoch 3922/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2345 - accuracy: 0.9251 - val_loss: 0.1877 - val_accuracy: 0.9455\n",
            "Epoch 3923/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2350 - accuracy: 0.9240 - val_loss: 0.1878 - val_accuracy: 0.9455\n",
            "Epoch 3924/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2297 - accuracy: 0.9273 - val_loss: 0.1878 - val_accuracy: 0.9455\n",
            "Epoch 3925/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2264 - accuracy: 0.9276 - val_loss: 0.1867 - val_accuracy: 0.9445\n",
            "Epoch 3926/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2338 - accuracy: 0.9220 - val_loss: 0.1865 - val_accuracy: 0.9450\n",
            "Epoch 3927/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2329 - accuracy: 0.9258 - val_loss: 0.1901 - val_accuracy: 0.9465\n",
            "Epoch 3928/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2310 - accuracy: 0.9261 - val_loss: 0.1905 - val_accuracy: 0.9440\n",
            "Epoch 3929/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2336 - accuracy: 0.9249 - val_loss: 0.1871 - val_accuracy: 0.9440\n",
            "Epoch 3930/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2380 - accuracy: 0.9240 - val_loss: 0.1867 - val_accuracy: 0.9445\n",
            "Epoch 3931/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2324 - accuracy: 0.9259 - val_loss: 0.1866 - val_accuracy: 0.9450\n",
            "Epoch 3932/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2339 - accuracy: 0.9227 - val_loss: 0.1960 - val_accuracy: 0.9435\n",
            "Epoch 3933/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2292 - accuracy: 0.9269 - val_loss: 0.1925 - val_accuracy: 0.9450\n",
            "Epoch 3934/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2330 - accuracy: 0.9254 - val_loss: 0.1926 - val_accuracy: 0.9440\n",
            "Epoch 3935/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2261 - accuracy: 0.9276 - val_loss: 0.1876 - val_accuracy: 0.9465\n",
            "Epoch 3936/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2295 - accuracy: 0.9264 - val_loss: 0.1880 - val_accuracy: 0.9445\n",
            "Epoch 3937/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2317 - accuracy: 0.9240 - val_loss: 0.1884 - val_accuracy: 0.9440\n",
            "Epoch 3938/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2288 - accuracy: 0.9274 - val_loss: 0.1870 - val_accuracy: 0.9450\n",
            "Epoch 3939/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2247 - accuracy: 0.9258 - val_loss: 0.1884 - val_accuracy: 0.9435\n",
            "Epoch 3940/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2340 - accuracy: 0.9243 - val_loss: 0.1849 - val_accuracy: 0.9460\n",
            "Epoch 3941/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2531 - accuracy: 0.9249 - val_loss: 0.1910 - val_accuracy: 0.9445\n",
            "Epoch 3942/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2396 - accuracy: 0.9246 - val_loss: 0.1906 - val_accuracy: 0.9450\n",
            "Epoch 3943/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2289 - accuracy: 0.9268 - val_loss: 0.1902 - val_accuracy: 0.9445\n",
            "Epoch 3944/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2479 - accuracy: 0.9210 - val_loss: 0.1894 - val_accuracy: 0.9450\n",
            "Epoch 3945/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2289 - accuracy: 0.9261 - val_loss: 0.1866 - val_accuracy: 0.9450\n",
            "Epoch 3946/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2274 - accuracy: 0.9255 - val_loss: 0.1880 - val_accuracy: 0.9455\n",
            "Epoch 3947/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2360 - accuracy: 0.9239 - val_loss: 0.1924 - val_accuracy: 0.9460\n",
            "Epoch 3948/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2202 - accuracy: 0.9286 - val_loss: 0.1904 - val_accuracy: 0.9465\n",
            "Epoch 3949/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2397 - accuracy: 0.9250 - val_loss: 0.1869 - val_accuracy: 0.9460\n",
            "Epoch 3950/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2392 - accuracy: 0.9275 - val_loss: 0.1892 - val_accuracy: 0.9460\n",
            "Epoch 3951/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2398 - accuracy: 0.9231 - val_loss: 0.1894 - val_accuracy: 0.9450\n",
            "Epoch 3952/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2301 - accuracy: 0.9256 - val_loss: 0.1823 - val_accuracy: 0.9460\n",
            "Epoch 3953/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2309 - accuracy: 0.9241 - val_loss: 0.1885 - val_accuracy: 0.9465\n",
            "Epoch 3954/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2255 - accuracy: 0.9254 - val_loss: 0.1935 - val_accuracy: 0.9430\n",
            "Epoch 3955/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2209 - accuracy: 0.9311 - val_loss: 0.1902 - val_accuracy: 0.9450\n",
            "Epoch 3956/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2300 - accuracy: 0.9266 - val_loss: 0.1932 - val_accuracy: 0.9435\n",
            "Epoch 3957/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2322 - accuracy: 0.9240 - val_loss: 0.1875 - val_accuracy: 0.9460\n",
            "Epoch 3958/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2231 - accuracy: 0.9291 - val_loss: 0.1880 - val_accuracy: 0.9465\n",
            "Epoch 3959/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2294 - accuracy: 0.9252 - val_loss: 0.1878 - val_accuracy: 0.9445\n",
            "Epoch 3960/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2295 - accuracy: 0.9277 - val_loss: 0.1916 - val_accuracy: 0.9445\n",
            "Epoch 3961/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2242 - accuracy: 0.9265 - val_loss: 0.1866 - val_accuracy: 0.9455\n",
            "Epoch 3962/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2354 - accuracy: 0.9259 - val_loss: 0.1932 - val_accuracy: 0.9430\n",
            "Epoch 3963/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2299 - accuracy: 0.9259 - val_loss: 0.1891 - val_accuracy: 0.9450\n",
            "Epoch 3964/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2285 - accuracy: 0.9261 - val_loss: 0.1891 - val_accuracy: 0.9440\n",
            "Epoch 3965/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2241 - accuracy: 0.9281 - val_loss: 0.1869 - val_accuracy: 0.9450\n",
            "Epoch 3966/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2297 - accuracy: 0.9258 - val_loss: 0.1873 - val_accuracy: 0.9450\n",
            "Epoch 3967/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2305 - accuracy: 0.9241 - val_loss: 0.1918 - val_accuracy: 0.9430\n",
            "Epoch 3968/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2540 - accuracy: 0.9255 - val_loss: 0.1922 - val_accuracy: 0.9445\n",
            "Epoch 3969/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2363 - accuracy: 0.9269 - val_loss: 0.1904 - val_accuracy: 0.9440\n",
            "Epoch 3970/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2324 - accuracy: 0.9266 - val_loss: 0.1904 - val_accuracy: 0.9440\n",
            "Epoch 3971/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2286 - accuracy: 0.9274 - val_loss: 0.1844 - val_accuracy: 0.9460\n",
            "Epoch 3972/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2246 - accuracy: 0.9266 - val_loss: 0.1839 - val_accuracy: 0.9465\n",
            "Epoch 3973/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2316 - accuracy: 0.9252 - val_loss: 0.1855 - val_accuracy: 0.9445\n",
            "Epoch 3974/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2301 - accuracy: 0.9265 - val_loss: 0.1851 - val_accuracy: 0.9440\n",
            "Epoch 3975/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2270 - accuracy: 0.9287 - val_loss: 0.1895 - val_accuracy: 0.9445\n",
            "Epoch 3976/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2380 - accuracy: 0.9233 - val_loss: 0.1871 - val_accuracy: 0.9455\n",
            "Epoch 3977/6000\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2356 - accuracy: 0.9251 - val_loss: 0.1875 - val_accuracy: 0.9455\n",
            "Epoch 3978/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2289 - accuracy: 0.9241 - val_loss: 0.1877 - val_accuracy: 0.9455\n",
            "Epoch 3979/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2363 - accuracy: 0.9230 - val_loss: 0.1927 - val_accuracy: 0.9445\n",
            "Epoch 3980/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2302 - accuracy: 0.9262 - val_loss: 0.1893 - val_accuracy: 0.9440\n",
            "Epoch 3981/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2291 - accuracy: 0.9283 - val_loss: 0.1904 - val_accuracy: 0.9435\n",
            "Epoch 3982/6000\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2277 - accuracy: 0.9252 - val_loss: 0.1867 - val_accuracy: 0.9455\n",
            "Epoch 3983/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2254 - accuracy: 0.9285 - val_loss: 0.1886 - val_accuracy: 0.9455\n",
            "Epoch 3984/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2364 - accuracy: 0.9240 - val_loss: 0.1870 - val_accuracy: 0.9440\n",
            "Epoch 3985/6000\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2289 - accuracy: 0.9262 - val_loss: 0.1863 - val_accuracy: 0.9440\n",
            "Epoch 3986/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2337 - accuracy: 0.9225 - val_loss: 0.1876 - val_accuracy: 0.9435\n",
            "Epoch 3987/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2266 - accuracy: 0.9284 - val_loss: 0.1887 - val_accuracy: 0.9445\n",
            "Epoch 3988/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2339 - accuracy: 0.9271 - val_loss: 0.1889 - val_accuracy: 0.9430\n",
            "Epoch 3989/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2364 - accuracy: 0.9230 - val_loss: 0.1889 - val_accuracy: 0.9440\n",
            "Epoch 3990/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2365 - accuracy: 0.9241 - val_loss: 0.1935 - val_accuracy: 0.9450\n",
            "Epoch 3991/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2297 - accuracy: 0.9259 - val_loss: 0.1880 - val_accuracy: 0.9470\n",
            "Epoch 3992/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2308 - accuracy: 0.9236 - val_loss: 0.1878 - val_accuracy: 0.9460\n",
            "Epoch 3993/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2256 - accuracy: 0.9250 - val_loss: 0.1912 - val_accuracy: 0.9455\n",
            "Epoch 3994/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2299 - accuracy: 0.9258 - val_loss: 0.1851 - val_accuracy: 0.9465\n",
            "Epoch 3995/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2363 - accuracy: 0.9243 - val_loss: 0.1875 - val_accuracy: 0.9465\n",
            "Epoch 3996/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2275 - accuracy: 0.9270 - val_loss: 0.1890 - val_accuracy: 0.9445\n",
            "Epoch 3997/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2317 - accuracy: 0.9245 - val_loss: 0.1894 - val_accuracy: 0.9445\n",
            "Epoch 3998/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2320 - accuracy: 0.9229 - val_loss: 0.1898 - val_accuracy: 0.9460\n",
            "Epoch 3999/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2244 - accuracy: 0.9290 - val_loss: 0.1907 - val_accuracy: 0.9445\n",
            "Epoch 4000/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2251 - accuracy: 0.9281 - val_loss: 0.1902 - val_accuracy: 0.9440\n",
            "Epoch 4001/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2345 - accuracy: 0.9241 - val_loss: 0.1898 - val_accuracy: 0.9450\n",
            "Epoch 4002/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2343 - accuracy: 0.9218 - val_loss: 0.1884 - val_accuracy: 0.9450\n",
            "Epoch 4003/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2177 - accuracy: 0.9294 - val_loss: 0.1883 - val_accuracy: 0.9455\n",
            "Epoch 4004/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2264 - accuracy: 0.9270 - val_loss: 0.1882 - val_accuracy: 0.9440\n",
            "Epoch 4005/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2307 - accuracy: 0.9260 - val_loss: 0.1869 - val_accuracy: 0.9465\n",
            "Epoch 4006/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2260 - accuracy: 0.9290 - val_loss: 0.1893 - val_accuracy: 0.9435\n",
            "Epoch 4007/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2262 - accuracy: 0.9287 - val_loss: 0.1901 - val_accuracy: 0.9460\n",
            "Epoch 4008/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2314 - accuracy: 0.9252 - val_loss: 0.1900 - val_accuracy: 0.9450\n",
            "Epoch 4009/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2257 - accuracy: 0.9261 - val_loss: 0.1879 - val_accuracy: 0.9450\n",
            "Epoch 4010/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2238 - accuracy: 0.9284 - val_loss: 0.1916 - val_accuracy: 0.9440\n",
            "Epoch 4011/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2412 - accuracy: 0.9224 - val_loss: 0.1883 - val_accuracy: 0.9455\n",
            "Epoch 4012/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2273 - accuracy: 0.9246 - val_loss: 0.1927 - val_accuracy: 0.9435\n",
            "Epoch 4013/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2322 - accuracy: 0.9261 - val_loss: 0.1892 - val_accuracy: 0.9440\n",
            "Epoch 4014/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2294 - accuracy: 0.9258 - val_loss: 0.1891 - val_accuracy: 0.9445\n",
            "Epoch 4015/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2299 - accuracy: 0.9224 - val_loss: 0.1901 - val_accuracy: 0.9445\n",
            "Epoch 4016/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2267 - accuracy: 0.9254 - val_loss: 0.1877 - val_accuracy: 0.9430\n",
            "Epoch 4017/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2281 - accuracy: 0.9251 - val_loss: 0.1888 - val_accuracy: 0.9455\n",
            "Epoch 4018/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2238 - accuracy: 0.9284 - val_loss: 0.1929 - val_accuracy: 0.9425\n",
            "Epoch 4019/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2250 - accuracy: 0.9285 - val_loss: 0.1861 - val_accuracy: 0.9440\n",
            "Epoch 4020/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2193 - accuracy: 0.9275 - val_loss: 0.1857 - val_accuracy: 0.9475\n",
            "Epoch 4021/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2357 - accuracy: 0.9250 - val_loss: 0.1889 - val_accuracy: 0.9455\n",
            "Epoch 4022/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2533 - accuracy: 0.9261 - val_loss: 0.1910 - val_accuracy: 0.9450\n",
            "Epoch 4023/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2366 - accuracy: 0.9269 - val_loss: 0.1908 - val_accuracy: 0.9430\n",
            "Epoch 4024/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2311 - accuracy: 0.9249 - val_loss: 0.1875 - val_accuracy: 0.9455\n",
            "Epoch 4025/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2373 - accuracy: 0.9280 - val_loss: 0.1849 - val_accuracy: 0.9455\n",
            "Epoch 4026/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2335 - accuracy: 0.9243 - val_loss: 0.1874 - val_accuracy: 0.9470\n",
            "Epoch 4027/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2385 - accuracy: 0.9231 - val_loss: 0.1932 - val_accuracy: 0.9435\n",
            "Epoch 4028/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2393 - accuracy: 0.9205 - val_loss: 0.1922 - val_accuracy: 0.9445\n",
            "Epoch 4029/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2366 - accuracy: 0.9261 - val_loss: 0.1927 - val_accuracy: 0.9445\n",
            "Epoch 4030/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2267 - accuracy: 0.9259 - val_loss: 0.1907 - val_accuracy: 0.9460\n",
            "Epoch 4031/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2489 - accuracy: 0.9244 - val_loss: 0.1954 - val_accuracy: 0.9440\n",
            "Epoch 4032/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2426 - accuracy: 0.9243 - val_loss: 0.1876 - val_accuracy: 0.9445\n",
            "Epoch 4033/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2263 - accuracy: 0.9281 - val_loss: 0.1926 - val_accuracy: 0.9435\n",
            "Epoch 4034/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2291 - accuracy: 0.9227 - val_loss: 0.1880 - val_accuracy: 0.9445\n",
            "Epoch 4035/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2308 - accuracy: 0.9264 - val_loss: 0.1878 - val_accuracy: 0.9460\n",
            "Epoch 4036/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2311 - accuracy: 0.9262 - val_loss: 0.1874 - val_accuracy: 0.9455\n",
            "Epoch 4037/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2237 - accuracy: 0.9271 - val_loss: 0.1864 - val_accuracy: 0.9460\n",
            "Epoch 4038/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2305 - accuracy: 0.9252 - val_loss: 0.1870 - val_accuracy: 0.9440\n",
            "Epoch 4039/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2273 - accuracy: 0.9285 - val_loss: 0.1899 - val_accuracy: 0.9460\n",
            "Epoch 4040/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2205 - accuracy: 0.9293 - val_loss: 0.1892 - val_accuracy: 0.9455\n",
            "Epoch 4041/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2291 - accuracy: 0.9271 - val_loss: 0.1884 - val_accuracy: 0.9455\n",
            "Epoch 4042/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2309 - accuracy: 0.9274 - val_loss: 0.1905 - val_accuracy: 0.9460\n",
            "Epoch 4043/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2269 - accuracy: 0.9265 - val_loss: 0.1910 - val_accuracy: 0.9445\n",
            "Epoch 4044/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2357 - accuracy: 0.9252 - val_loss: 0.1905 - val_accuracy: 0.9440\n",
            "Epoch 4045/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2279 - accuracy: 0.9284 - val_loss: 0.1886 - val_accuracy: 0.9445\n",
            "Epoch 4046/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2269 - accuracy: 0.9260 - val_loss: 0.1884 - val_accuracy: 0.9460\n",
            "Epoch 4047/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2273 - accuracy: 0.9256 - val_loss: 0.1871 - val_accuracy: 0.9455\n",
            "Epoch 4048/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2228 - accuracy: 0.9287 - val_loss: 0.1886 - val_accuracy: 0.9435\n",
            "Epoch 4049/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2251 - accuracy: 0.9273 - val_loss: 0.1868 - val_accuracy: 0.9450\n",
            "Epoch 4050/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2307 - accuracy: 0.9260 - val_loss: 0.1926 - val_accuracy: 0.9430\n",
            "Epoch 4051/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2377 - accuracy: 0.9226 - val_loss: 0.1913 - val_accuracy: 0.9445\n",
            "Epoch 4052/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2411 - accuracy: 0.9218 - val_loss: 0.1888 - val_accuracy: 0.9450\n",
            "Epoch 4053/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2464 - accuracy: 0.9214 - val_loss: 0.1920 - val_accuracy: 0.9465\n",
            "Epoch 4054/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2253 - accuracy: 0.9258 - val_loss: 0.1873 - val_accuracy: 0.9445\n",
            "Epoch 4055/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2401 - accuracy: 0.9245 - val_loss: 0.1882 - val_accuracy: 0.9440\n",
            "Epoch 4056/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2324 - accuracy: 0.9259 - val_loss: 0.1908 - val_accuracy: 0.9455\n",
            "Epoch 4057/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2243 - accuracy: 0.9276 - val_loss: 0.1920 - val_accuracy: 0.9425\n",
            "Epoch 4058/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2372 - accuracy: 0.9235 - val_loss: 0.1941 - val_accuracy: 0.9425\n",
            "Epoch 4059/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2287 - accuracy: 0.9260 - val_loss: 0.1888 - val_accuracy: 0.9460\n",
            "Epoch 4060/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2235 - accuracy: 0.9300 - val_loss: 0.1881 - val_accuracy: 0.9445\n",
            "Epoch 4061/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2257 - accuracy: 0.9284 - val_loss: 0.1830 - val_accuracy: 0.9455\n",
            "Epoch 4062/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2312 - accuracy: 0.9264 - val_loss: 0.1882 - val_accuracy: 0.9460\n",
            "Epoch 4063/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2337 - accuracy: 0.9245 - val_loss: 0.1913 - val_accuracy: 0.9425\n",
            "Epoch 4064/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2358 - accuracy: 0.9245 - val_loss: 0.1928 - val_accuracy: 0.9445\n",
            "Epoch 4065/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2353 - accuracy: 0.9234 - val_loss: 0.1872 - val_accuracy: 0.9460\n",
            "Epoch 4066/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2274 - accuracy: 0.9269 - val_loss: 0.1897 - val_accuracy: 0.9465\n",
            "Epoch 4067/6000\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2353 - accuracy: 0.9277 - val_loss: 0.1873 - val_accuracy: 0.9460\n",
            "Epoch 4068/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2264 - accuracy: 0.9256 - val_loss: 0.1946 - val_accuracy: 0.9420\n",
            "Epoch 4069/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2316 - accuracy: 0.9266 - val_loss: 0.1879 - val_accuracy: 0.9455\n",
            "Epoch 4070/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2455 - accuracy: 0.9250 - val_loss: 0.1848 - val_accuracy: 0.9455\n",
            "Epoch 4071/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2294 - accuracy: 0.9243 - val_loss: 0.1869 - val_accuracy: 0.9465\n",
            "Epoch 4072/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2312 - accuracy: 0.9286 - val_loss: 0.1869 - val_accuracy: 0.9460\n",
            "Epoch 4073/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2272 - accuracy: 0.9230 - val_loss: 0.1895 - val_accuracy: 0.9460\n",
            "Epoch 4074/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2307 - accuracy: 0.9264 - val_loss: 0.1861 - val_accuracy: 0.9450\n",
            "Epoch 4075/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2419 - accuracy: 0.9234 - val_loss: 0.1880 - val_accuracy: 0.9455\n",
            "Epoch 4076/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2410 - accuracy: 0.9245 - val_loss: 0.1917 - val_accuracy: 0.9445\n",
            "Epoch 4077/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2307 - accuracy: 0.9254 - val_loss: 0.1922 - val_accuracy: 0.9450\n",
            "Epoch 4078/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2374 - accuracy: 0.9199 - val_loss: 0.1917 - val_accuracy: 0.9460\n",
            "Epoch 4079/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2281 - accuracy: 0.9264 - val_loss: 0.1956 - val_accuracy: 0.9425\n",
            "Epoch 4080/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2286 - accuracy: 0.9265 - val_loss: 0.1916 - val_accuracy: 0.9460\n",
            "Epoch 4081/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2297 - accuracy: 0.9249 - val_loss: 0.1887 - val_accuracy: 0.9455\n",
            "Epoch 4082/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2258 - accuracy: 0.9279 - val_loss: 0.1874 - val_accuracy: 0.9455\n",
            "Epoch 4083/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2287 - accuracy: 0.9256 - val_loss: 0.1880 - val_accuracy: 0.9455\n",
            "Epoch 4084/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2251 - accuracy: 0.9268 - val_loss: 0.1911 - val_accuracy: 0.9455\n",
            "Epoch 4085/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2385 - accuracy: 0.9250 - val_loss: 0.1869 - val_accuracy: 0.9455\n",
            "Epoch 4086/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2184 - accuracy: 0.9289 - val_loss: 0.1878 - val_accuracy: 0.9450\n",
            "Epoch 4087/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2418 - accuracy: 0.9252 - val_loss: 0.1923 - val_accuracy: 0.9435\n",
            "Epoch 4088/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2261 - accuracy: 0.9249 - val_loss: 0.1901 - val_accuracy: 0.9450\n",
            "Epoch 4089/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2281 - accuracy: 0.9259 - val_loss: 0.1898 - val_accuracy: 0.9460\n",
            "Epoch 4090/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2302 - accuracy: 0.9252 - val_loss: 0.1872 - val_accuracy: 0.9455\n",
            "Epoch 4091/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2213 - accuracy: 0.9305 - val_loss: 0.1895 - val_accuracy: 0.9440\n",
            "Epoch 4092/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2293 - accuracy: 0.9280 - val_loss: 0.1856 - val_accuracy: 0.9460\n",
            "Epoch 4093/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2276 - accuracy: 0.9261 - val_loss: 0.1855 - val_accuracy: 0.9465\n",
            "Epoch 4094/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2279 - accuracy: 0.9255 - val_loss: 0.1902 - val_accuracy: 0.9445\n",
            "Epoch 4095/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2285 - accuracy: 0.9254 - val_loss: 0.1907 - val_accuracy: 0.9450\n",
            "Epoch 4096/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2290 - accuracy: 0.9260 - val_loss: 0.1903 - val_accuracy: 0.9445\n",
            "Epoch 4097/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2251 - accuracy: 0.9256 - val_loss: 0.1902 - val_accuracy: 0.9440\n",
            "Epoch 4098/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2345 - accuracy: 0.9243 - val_loss: 0.1881 - val_accuracy: 0.9445\n",
            "Epoch 4099/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2279 - accuracy: 0.9264 - val_loss: 0.1905 - val_accuracy: 0.9440\n",
            "Epoch 4100/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2394 - accuracy: 0.9264 - val_loss: 0.1892 - val_accuracy: 0.9470\n",
            "Epoch 4101/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2364 - accuracy: 0.9202 - val_loss: 0.1863 - val_accuracy: 0.9465\n",
            "Epoch 4102/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2310 - accuracy: 0.9286 - val_loss: 0.1894 - val_accuracy: 0.9470\n",
            "Epoch 4103/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2360 - accuracy: 0.9236 - val_loss: 0.1904 - val_accuracy: 0.9460\n",
            "Epoch 4104/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2456 - accuracy: 0.9261 - val_loss: 0.1867 - val_accuracy: 0.9450\n",
            "Epoch 4105/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2251 - accuracy: 0.9268 - val_loss: 0.1889 - val_accuracy: 0.9455\n",
            "Epoch 4106/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2320 - accuracy: 0.9250 - val_loss: 0.1881 - val_accuracy: 0.9455\n",
            "Epoch 4107/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2308 - accuracy: 0.9275 - val_loss: 0.1901 - val_accuracy: 0.9455\n",
            "Epoch 4108/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2357 - accuracy: 0.9258 - val_loss: 0.1920 - val_accuracy: 0.9455\n",
            "Epoch 4109/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2329 - accuracy: 0.9247 - val_loss: 0.1872 - val_accuracy: 0.9440\n",
            "Epoch 4110/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2224 - accuracy: 0.9270 - val_loss: 0.1936 - val_accuracy: 0.9440\n",
            "Epoch 4111/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2359 - accuracy: 0.9202 - val_loss: 0.1915 - val_accuracy: 0.9450\n",
            "Epoch 4112/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2277 - accuracy: 0.9266 - val_loss: 0.1949 - val_accuracy: 0.9420\n",
            "Epoch 4113/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2277 - accuracy: 0.9256 - val_loss: 0.1939 - val_accuracy: 0.9450\n",
            "Epoch 4114/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2332 - accuracy: 0.9254 - val_loss: 0.1858 - val_accuracy: 0.9440\n",
            "Epoch 4115/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2408 - accuracy: 0.9221 - val_loss: 0.1865 - val_accuracy: 0.9450\n",
            "Epoch 4116/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2362 - accuracy: 0.9265 - val_loss: 0.1838 - val_accuracy: 0.9450\n",
            "Epoch 4117/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2282 - accuracy: 0.9225 - val_loss: 0.1882 - val_accuracy: 0.9450\n",
            "Epoch 4118/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2302 - accuracy: 0.9247 - val_loss: 0.1841 - val_accuracy: 0.9460\n",
            "Epoch 4119/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2289 - accuracy: 0.9226 - val_loss: 0.1866 - val_accuracy: 0.9450\n",
            "Epoch 4120/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2269 - accuracy: 0.9251 - val_loss: 0.1900 - val_accuracy: 0.9445\n",
            "Epoch 4121/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2344 - accuracy: 0.9258 - val_loss: 0.1832 - val_accuracy: 0.9460\n",
            "Epoch 4122/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2274 - accuracy: 0.9275 - val_loss: 0.1867 - val_accuracy: 0.9465\n",
            "Epoch 4123/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2343 - accuracy: 0.9243 - val_loss: 0.1899 - val_accuracy: 0.9465\n",
            "Epoch 4124/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2267 - accuracy: 0.9269 - val_loss: 0.1879 - val_accuracy: 0.9460\n",
            "Epoch 4125/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2289 - accuracy: 0.9234 - val_loss: 0.1890 - val_accuracy: 0.9465\n",
            "Epoch 4126/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2291 - accuracy: 0.9275 - val_loss: 0.1920 - val_accuracy: 0.9460\n",
            "Epoch 4127/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2324 - accuracy: 0.9261 - val_loss: 0.1870 - val_accuracy: 0.9460\n",
            "Epoch 4128/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2283 - accuracy: 0.9261 - val_loss: 0.1847 - val_accuracy: 0.9470\n",
            "Epoch 4129/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2280 - accuracy: 0.9258 - val_loss: 0.1901 - val_accuracy: 0.9470\n",
            "Epoch 4130/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2401 - accuracy: 0.9252 - val_loss: 0.1824 - val_accuracy: 0.9445\n",
            "Epoch 4131/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2306 - accuracy: 0.9233 - val_loss: 0.1867 - val_accuracy: 0.9470\n",
            "Epoch 4132/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2302 - accuracy: 0.9279 - val_loss: 0.1911 - val_accuracy: 0.9435\n",
            "Epoch 4133/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2323 - accuracy: 0.9241 - val_loss: 0.1870 - val_accuracy: 0.9450\n",
            "Epoch 4134/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2243 - accuracy: 0.9264 - val_loss: 0.1892 - val_accuracy: 0.9445\n",
            "Epoch 4135/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2297 - accuracy: 0.9273 - val_loss: 0.1853 - val_accuracy: 0.9450\n",
            "Epoch 4136/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2309 - accuracy: 0.9244 - val_loss: 0.1848 - val_accuracy: 0.9455\n",
            "Epoch 4137/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2279 - accuracy: 0.9246 - val_loss: 0.1896 - val_accuracy: 0.9465\n",
            "Epoch 4138/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2272 - accuracy: 0.9268 - val_loss: 0.1907 - val_accuracy: 0.9460\n",
            "Epoch 4139/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2269 - accuracy: 0.9252 - val_loss: 0.1896 - val_accuracy: 0.9455\n",
            "Epoch 4140/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2290 - accuracy: 0.9251 - val_loss: 0.1856 - val_accuracy: 0.9455\n",
            "Epoch 4141/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2444 - accuracy: 0.9218 - val_loss: 0.1916 - val_accuracy: 0.9450\n",
            "Epoch 4142/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2291 - accuracy: 0.9239 - val_loss: 0.1930 - val_accuracy: 0.9430\n",
            "Epoch 4143/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2384 - accuracy: 0.9229 - val_loss: 0.1893 - val_accuracy: 0.9460\n",
            "Epoch 4144/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2352 - accuracy: 0.9233 - val_loss: 0.1916 - val_accuracy: 0.9445\n",
            "Epoch 4145/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2301 - accuracy: 0.9246 - val_loss: 0.1884 - val_accuracy: 0.9465\n",
            "Epoch 4146/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2269 - accuracy: 0.9261 - val_loss: 0.1875 - val_accuracy: 0.9460\n",
            "Epoch 4147/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2288 - accuracy: 0.9249 - val_loss: 0.1919 - val_accuracy: 0.9460\n",
            "Epoch 4148/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2192 - accuracy: 0.9310 - val_loss: 0.1902 - val_accuracy: 0.9460\n",
            "Epoch 4149/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2296 - accuracy: 0.9258 - val_loss: 0.1903 - val_accuracy: 0.9455\n",
            "Epoch 4150/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2339 - accuracy: 0.9265 - val_loss: 0.1928 - val_accuracy: 0.9450\n",
            "Epoch 4151/6000\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2221 - accuracy: 0.9285 - val_loss: 0.1871 - val_accuracy: 0.9460\n",
            "Epoch 4152/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2202 - accuracy: 0.9280 - val_loss: 0.1868 - val_accuracy: 0.9445\n",
            "Epoch 4153/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2195 - accuracy: 0.9295 - val_loss: 0.1882 - val_accuracy: 0.9460\n",
            "Epoch 4154/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2292 - accuracy: 0.9249 - val_loss: 0.1915 - val_accuracy: 0.9445\n",
            "Epoch 4155/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2294 - accuracy: 0.9269 - val_loss: 0.1923 - val_accuracy: 0.9440\n",
            "Epoch 4156/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2416 - accuracy: 0.9212 - val_loss: 0.1853 - val_accuracy: 0.9465\n",
            "Epoch 4157/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2321 - accuracy: 0.9239 - val_loss: 0.1886 - val_accuracy: 0.9465\n",
            "Epoch 4158/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2318 - accuracy: 0.9240 - val_loss: 0.1883 - val_accuracy: 0.9450\n",
            "Epoch 4159/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2444 - accuracy: 0.9235 - val_loss: 0.1920 - val_accuracy: 0.9460\n",
            "Epoch 4160/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2253 - accuracy: 0.9285 - val_loss: 0.1845 - val_accuracy: 0.9470\n",
            "Epoch 4161/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2258 - accuracy: 0.9275 - val_loss: 0.1899 - val_accuracy: 0.9450\n",
            "Epoch 4162/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2290 - accuracy: 0.9260 - val_loss: 0.1882 - val_accuracy: 0.9455\n",
            "Epoch 4163/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2490 - accuracy: 0.9258 - val_loss: 0.1885 - val_accuracy: 0.9470\n",
            "Epoch 4164/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2261 - accuracy: 0.9264 - val_loss: 0.1866 - val_accuracy: 0.9455\n",
            "Epoch 4165/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2293 - accuracy: 0.9276 - val_loss: 0.1853 - val_accuracy: 0.9445\n",
            "Epoch 4166/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2304 - accuracy: 0.9250 - val_loss: 0.1871 - val_accuracy: 0.9455\n",
            "Epoch 4167/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2269 - accuracy: 0.9247 - val_loss: 0.1846 - val_accuracy: 0.9455\n",
            "Epoch 4168/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2273 - accuracy: 0.9298 - val_loss: 0.1867 - val_accuracy: 0.9450\n",
            "Epoch 4169/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2245 - accuracy: 0.9287 - val_loss: 0.1871 - val_accuracy: 0.9445\n",
            "Epoch 4170/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2339 - accuracy: 0.9261 - val_loss: 0.1883 - val_accuracy: 0.9440\n",
            "Epoch 4171/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2232 - accuracy: 0.9290 - val_loss: 0.1825 - val_accuracy: 0.9445\n",
            "Epoch 4172/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2383 - accuracy: 0.9240 - val_loss: 0.1851 - val_accuracy: 0.9455\n",
            "Epoch 4173/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2282 - accuracy: 0.9284 - val_loss: 0.1855 - val_accuracy: 0.9435\n",
            "Epoch 4174/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2277 - accuracy: 0.9252 - val_loss: 0.1847 - val_accuracy: 0.9440\n",
            "Epoch 4175/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2353 - accuracy: 0.9225 - val_loss: 0.1870 - val_accuracy: 0.9460\n",
            "Epoch 4176/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2409 - accuracy: 0.9241 - val_loss: 0.1874 - val_accuracy: 0.9440\n",
            "Epoch 4177/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2327 - accuracy: 0.9244 - val_loss: 0.1843 - val_accuracy: 0.9440\n",
            "Epoch 4178/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2298 - accuracy: 0.9265 - val_loss: 0.1824 - val_accuracy: 0.9455\n",
            "Epoch 4179/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2298 - accuracy: 0.9274 - val_loss: 0.1846 - val_accuracy: 0.9460\n",
            "Epoch 4180/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2355 - accuracy: 0.9255 - val_loss: 0.1899 - val_accuracy: 0.9455\n",
            "Epoch 4181/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2360 - accuracy: 0.9250 - val_loss: 0.1871 - val_accuracy: 0.9450\n",
            "Epoch 4182/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2294 - accuracy: 0.9273 - val_loss: 0.1870 - val_accuracy: 0.9455\n",
            "Epoch 4183/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2270 - accuracy: 0.9244 - val_loss: 0.1873 - val_accuracy: 0.9460\n",
            "Epoch 4184/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2251 - accuracy: 0.9266 - val_loss: 0.1961 - val_accuracy: 0.9410\n",
            "Epoch 4185/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2330 - accuracy: 0.9235 - val_loss: 0.1888 - val_accuracy: 0.9440\n",
            "Epoch 4186/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2301 - accuracy: 0.9229 - val_loss: 0.1939 - val_accuracy: 0.9445\n",
            "Epoch 4187/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2179 - accuracy: 0.9299 - val_loss: 0.1891 - val_accuracy: 0.9440\n",
            "Epoch 4188/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2267 - accuracy: 0.9252 - val_loss: 0.1906 - val_accuracy: 0.9455\n",
            "Epoch 4189/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2353 - accuracy: 0.9258 - val_loss: 0.1892 - val_accuracy: 0.9460\n",
            "Epoch 4190/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2314 - accuracy: 0.9268 - val_loss: 0.1890 - val_accuracy: 0.9425\n",
            "Epoch 4191/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2305 - accuracy: 0.9283 - val_loss: 0.1888 - val_accuracy: 0.9460\n",
            "Epoch 4192/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2207 - accuracy: 0.9275 - val_loss: 0.1929 - val_accuracy: 0.9460\n",
            "Epoch 4193/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2302 - accuracy: 0.9254 - val_loss: 0.1848 - val_accuracy: 0.9465\n",
            "Epoch 4194/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2332 - accuracy: 0.9255 - val_loss: 0.1847 - val_accuracy: 0.9460\n",
            "Epoch 4195/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2517 - accuracy: 0.9266 - val_loss: 0.1862 - val_accuracy: 0.9445\n",
            "Epoch 4196/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2285 - accuracy: 0.9264 - val_loss: 0.1866 - val_accuracy: 0.9465\n",
            "Epoch 4197/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2266 - accuracy: 0.9270 - val_loss: 0.1876 - val_accuracy: 0.9455\n",
            "Epoch 4198/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2314 - accuracy: 0.9240 - val_loss: 0.1912 - val_accuracy: 0.9450\n",
            "Epoch 4199/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2382 - accuracy: 0.9280 - val_loss: 0.1867 - val_accuracy: 0.9450\n",
            "Epoch 4200/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2279 - accuracy: 0.9281 - val_loss: 0.1856 - val_accuracy: 0.9450\n",
            "Epoch 4201/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2283 - accuracy: 0.9281 - val_loss: 0.1896 - val_accuracy: 0.9450\n",
            "Epoch 4202/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2262 - accuracy: 0.9271 - val_loss: 0.1916 - val_accuracy: 0.9435\n",
            "Epoch 4203/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2337 - accuracy: 0.9236 - val_loss: 0.1893 - val_accuracy: 0.9445\n",
            "Epoch 4204/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2288 - accuracy: 0.9247 - val_loss: 0.1896 - val_accuracy: 0.9450\n",
            "Epoch 4205/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2454 - accuracy: 0.9241 - val_loss: 0.1884 - val_accuracy: 0.9425\n",
            "Epoch 4206/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2236 - accuracy: 0.9276 - val_loss: 0.1877 - val_accuracy: 0.9450\n",
            "Epoch 4207/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2316 - accuracy: 0.9251 - val_loss: 0.1852 - val_accuracy: 0.9460\n",
            "Epoch 4208/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2271 - accuracy: 0.9291 - val_loss: 0.1862 - val_accuracy: 0.9460\n",
            "Epoch 4209/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2273 - accuracy: 0.9286 - val_loss: 0.1838 - val_accuracy: 0.9465\n",
            "Epoch 4210/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2322 - accuracy: 0.9227 - val_loss: 0.1828 - val_accuracy: 0.9470\n",
            "Epoch 4211/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2252 - accuracy: 0.9255 - val_loss: 0.1898 - val_accuracy: 0.9450\n",
            "Epoch 4212/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2308 - accuracy: 0.9236 - val_loss: 0.1943 - val_accuracy: 0.9420\n",
            "Epoch 4213/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2351 - accuracy: 0.9259 - val_loss: 0.1866 - val_accuracy: 0.9440\n",
            "Epoch 4214/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2483 - accuracy: 0.9277 - val_loss: 0.1883 - val_accuracy: 0.9465\n",
            "Epoch 4215/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2331 - accuracy: 0.9262 - val_loss: 0.1853 - val_accuracy: 0.9455\n",
            "Epoch 4216/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2311 - accuracy: 0.9244 - val_loss: 0.1895 - val_accuracy: 0.9465\n",
            "Epoch 4217/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2260 - accuracy: 0.9246 - val_loss: 0.1875 - val_accuracy: 0.9455\n",
            "Epoch 4218/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2387 - accuracy: 0.9241 - val_loss: 0.1905 - val_accuracy: 0.9440\n",
            "Epoch 4219/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2327 - accuracy: 0.9254 - val_loss: 0.1874 - val_accuracy: 0.9470\n",
            "Epoch 4220/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2286 - accuracy: 0.9251 - val_loss: 0.1833 - val_accuracy: 0.9465\n",
            "Epoch 4221/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2276 - accuracy: 0.9249 - val_loss: 0.1870 - val_accuracy: 0.9450\n",
            "Epoch 4222/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2310 - accuracy: 0.9255 - val_loss: 0.1868 - val_accuracy: 0.9465\n",
            "Epoch 4223/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2278 - accuracy: 0.9250 - val_loss: 0.1928 - val_accuracy: 0.9445\n",
            "Epoch 4224/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2280 - accuracy: 0.9247 - val_loss: 0.1862 - val_accuracy: 0.9465\n",
            "Epoch 4225/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2387 - accuracy: 0.9205 - val_loss: 0.1882 - val_accuracy: 0.9445\n",
            "Epoch 4226/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2355 - accuracy: 0.9268 - val_loss: 0.1872 - val_accuracy: 0.9450\n",
            "Epoch 4227/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2337 - accuracy: 0.9255 - val_loss: 0.1872 - val_accuracy: 0.9445\n",
            "Epoch 4228/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2433 - accuracy: 0.9219 - val_loss: 0.1902 - val_accuracy: 0.9440\n",
            "Epoch 4229/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2314 - accuracy: 0.9264 - val_loss: 0.1876 - val_accuracy: 0.9435\n",
            "Epoch 4230/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2278 - accuracy: 0.9281 - val_loss: 0.1907 - val_accuracy: 0.9445\n",
            "Epoch 4231/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2258 - accuracy: 0.9287 - val_loss: 0.1903 - val_accuracy: 0.9450\n",
            "Epoch 4232/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2244 - accuracy: 0.9259 - val_loss: 0.1892 - val_accuracy: 0.9455\n",
            "Epoch 4233/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2271 - accuracy: 0.9269 - val_loss: 0.1863 - val_accuracy: 0.9450\n",
            "Epoch 4234/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2274 - accuracy: 0.9259 - val_loss: 0.1910 - val_accuracy: 0.9450\n",
            "Epoch 4235/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2295 - accuracy: 0.9230 - val_loss: 0.1904 - val_accuracy: 0.9435\n",
            "Epoch 4236/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2303 - accuracy: 0.9247 - val_loss: 0.1845 - val_accuracy: 0.9445\n",
            "Epoch 4237/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2357 - accuracy: 0.9202 - val_loss: 0.1903 - val_accuracy: 0.9450\n",
            "Epoch 4238/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2331 - accuracy: 0.9266 - val_loss: 0.1881 - val_accuracy: 0.9435\n",
            "Epoch 4239/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2318 - accuracy: 0.9259 - val_loss: 0.1889 - val_accuracy: 0.9450\n",
            "Epoch 4240/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2327 - accuracy: 0.9261 - val_loss: 0.1854 - val_accuracy: 0.9440\n",
            "Epoch 4241/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2328 - accuracy: 0.9247 - val_loss: 0.1866 - val_accuracy: 0.9450\n",
            "Epoch 4242/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2294 - accuracy: 0.9244 - val_loss: 0.1888 - val_accuracy: 0.9450\n",
            "Epoch 4243/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2321 - accuracy: 0.9271 - val_loss: 0.1909 - val_accuracy: 0.9445\n",
            "Epoch 4244/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2279 - accuracy: 0.9264 - val_loss: 0.1841 - val_accuracy: 0.9440\n",
            "Epoch 4245/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2302 - accuracy: 0.9261 - val_loss: 0.1863 - val_accuracy: 0.9455\n",
            "Epoch 4246/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2288 - accuracy: 0.9279 - val_loss: 0.1861 - val_accuracy: 0.9460\n",
            "Epoch 4247/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2239 - accuracy: 0.9276 - val_loss: 0.1916 - val_accuracy: 0.9455\n",
            "Epoch 4248/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2413 - accuracy: 0.9264 - val_loss: 0.1838 - val_accuracy: 0.9455\n",
            "Epoch 4249/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2326 - accuracy: 0.9261 - val_loss: 0.1887 - val_accuracy: 0.9455\n",
            "Epoch 4250/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2296 - accuracy: 0.9243 - val_loss: 0.1884 - val_accuracy: 0.9435\n",
            "Epoch 4251/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2284 - accuracy: 0.9281 - val_loss: 0.1859 - val_accuracy: 0.9455\n",
            "Epoch 4252/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2234 - accuracy: 0.9275 - val_loss: 0.1856 - val_accuracy: 0.9455\n",
            "Epoch 4253/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2323 - accuracy: 0.9270 - val_loss: 0.1847 - val_accuracy: 0.9465\n",
            "Epoch 4254/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2223 - accuracy: 0.9275 - val_loss: 0.1873 - val_accuracy: 0.9480\n",
            "Epoch 4255/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2262 - accuracy: 0.9280 - val_loss: 0.1880 - val_accuracy: 0.9445\n",
            "Epoch 4256/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2290 - accuracy: 0.9265 - val_loss: 0.1912 - val_accuracy: 0.9440\n",
            "Epoch 4257/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2360 - accuracy: 0.9240 - val_loss: 0.1932 - val_accuracy: 0.9450\n",
            "Epoch 4258/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2347 - accuracy: 0.9271 - val_loss: 0.1891 - val_accuracy: 0.9435\n",
            "Epoch 4259/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2282 - accuracy: 0.9264 - val_loss: 0.1874 - val_accuracy: 0.9455\n",
            "Epoch 4260/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2246 - accuracy: 0.9259 - val_loss: 0.1905 - val_accuracy: 0.9450\n",
            "Epoch 4261/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2281 - accuracy: 0.9241 - val_loss: 0.1858 - val_accuracy: 0.9445\n",
            "Epoch 4262/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2408 - accuracy: 0.9225 - val_loss: 0.1902 - val_accuracy: 0.9440\n",
            "Epoch 4263/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2389 - accuracy: 0.9246 - val_loss: 0.1871 - val_accuracy: 0.9445\n",
            "Epoch 4264/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2266 - accuracy: 0.9266 - val_loss: 0.1841 - val_accuracy: 0.9460\n",
            "Epoch 4265/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2271 - accuracy: 0.9266 - val_loss: 0.1884 - val_accuracy: 0.9440\n",
            "Epoch 4266/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2280 - accuracy: 0.9276 - val_loss: 0.1868 - val_accuracy: 0.9460\n",
            "Epoch 4267/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2324 - accuracy: 0.9234 - val_loss: 0.1880 - val_accuracy: 0.9445\n",
            "Epoch 4268/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2318 - accuracy: 0.9270 - val_loss: 0.1884 - val_accuracy: 0.9440\n",
            "Epoch 4269/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2316 - accuracy: 0.9229 - val_loss: 0.1942 - val_accuracy: 0.9445\n",
            "Epoch 4270/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2313 - accuracy: 0.9245 - val_loss: 0.1927 - val_accuracy: 0.9435\n",
            "Epoch 4271/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2293 - accuracy: 0.9284 - val_loss: 0.1858 - val_accuracy: 0.9455\n",
            "Epoch 4272/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2283 - accuracy: 0.9271 - val_loss: 0.1890 - val_accuracy: 0.9445\n",
            "Epoch 4273/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2323 - accuracy: 0.9258 - val_loss: 0.1893 - val_accuracy: 0.9450\n",
            "Epoch 4274/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2255 - accuracy: 0.9285 - val_loss: 0.1866 - val_accuracy: 0.9445\n",
            "Epoch 4275/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2212 - accuracy: 0.9287 - val_loss: 0.1893 - val_accuracy: 0.9440\n",
            "Epoch 4276/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2281 - accuracy: 0.9247 - val_loss: 0.1866 - val_accuracy: 0.9435\n",
            "Epoch 4277/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2292 - accuracy: 0.9264 - val_loss: 0.1903 - val_accuracy: 0.9440\n",
            "Epoch 4278/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2247 - accuracy: 0.9274 - val_loss: 0.1888 - val_accuracy: 0.9440\n",
            "Epoch 4279/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2321 - accuracy: 0.9237 - val_loss: 0.1865 - val_accuracy: 0.9465\n",
            "Epoch 4280/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2336 - accuracy: 0.9231 - val_loss: 0.1918 - val_accuracy: 0.9455\n",
            "Epoch 4281/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2278 - accuracy: 0.9252 - val_loss: 0.1875 - val_accuracy: 0.9465\n",
            "Epoch 4282/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2311 - accuracy: 0.9252 - val_loss: 0.1903 - val_accuracy: 0.9450\n",
            "Epoch 4283/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2338 - accuracy: 0.9289 - val_loss: 0.1825 - val_accuracy: 0.9460\n",
            "Epoch 4284/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2377 - accuracy: 0.9260 - val_loss: 0.1853 - val_accuracy: 0.9455\n",
            "Epoch 4285/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2245 - accuracy: 0.9241 - val_loss: 0.1890 - val_accuracy: 0.9435\n",
            "Epoch 4286/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2546 - accuracy: 0.9243 - val_loss: 0.1902 - val_accuracy: 0.9445\n",
            "Epoch 4287/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2241 - accuracy: 0.9287 - val_loss: 0.1888 - val_accuracy: 0.9450\n",
            "Epoch 4288/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2221 - accuracy: 0.9274 - val_loss: 0.1874 - val_accuracy: 0.9460\n",
            "Epoch 4289/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2416 - accuracy: 0.9273 - val_loss: 0.1864 - val_accuracy: 0.9445\n",
            "Epoch 4290/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2421 - accuracy: 0.9240 - val_loss: 0.1864 - val_accuracy: 0.9455\n",
            "Epoch 4291/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2472 - accuracy: 0.9234 - val_loss: 0.1980 - val_accuracy: 0.9425\n",
            "Epoch 4292/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2282 - accuracy: 0.9235 - val_loss: 0.1875 - val_accuracy: 0.9455\n",
            "Epoch 4293/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2259 - accuracy: 0.9268 - val_loss: 0.1912 - val_accuracy: 0.9445\n",
            "Epoch 4294/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2277 - accuracy: 0.9249 - val_loss: 0.1889 - val_accuracy: 0.9445\n",
            "Epoch 4295/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2246 - accuracy: 0.9273 - val_loss: 0.1922 - val_accuracy: 0.9440\n",
            "Epoch 4296/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2313 - accuracy: 0.9262 - val_loss: 0.1878 - val_accuracy: 0.9465\n",
            "Epoch 4297/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2291 - accuracy: 0.9269 - val_loss: 0.1851 - val_accuracy: 0.9455\n",
            "Epoch 4298/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2367 - accuracy: 0.9264 - val_loss: 0.1893 - val_accuracy: 0.9460\n",
            "Epoch 4299/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2221 - accuracy: 0.9281 - val_loss: 0.1854 - val_accuracy: 0.9455\n",
            "Epoch 4300/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2263 - accuracy: 0.9286 - val_loss: 0.1858 - val_accuracy: 0.9445\n",
            "Epoch 4301/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2333 - accuracy: 0.9251 - val_loss: 0.1885 - val_accuracy: 0.9440\n",
            "Epoch 4302/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2283 - accuracy: 0.9273 - val_loss: 0.1904 - val_accuracy: 0.9455\n",
            "Epoch 4303/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2333 - accuracy: 0.9252 - val_loss: 0.1865 - val_accuracy: 0.9465\n",
            "Epoch 4304/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2360 - accuracy: 0.9245 - val_loss: 0.1897 - val_accuracy: 0.9460\n",
            "Epoch 4305/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2314 - accuracy: 0.9229 - val_loss: 0.1893 - val_accuracy: 0.9445\n",
            "Epoch 4306/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2299 - accuracy: 0.9246 - val_loss: 0.1860 - val_accuracy: 0.9440\n",
            "Epoch 4307/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2321 - accuracy: 0.9251 - val_loss: 0.1924 - val_accuracy: 0.9445\n",
            "Epoch 4308/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2312 - accuracy: 0.9262 - val_loss: 0.1930 - val_accuracy: 0.9440\n",
            "Epoch 4309/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2374 - accuracy: 0.9211 - val_loss: 0.1874 - val_accuracy: 0.9435\n",
            "Epoch 4310/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2308 - accuracy: 0.9268 - val_loss: 0.1885 - val_accuracy: 0.9460\n",
            "Epoch 4311/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2259 - accuracy: 0.9286 - val_loss: 0.1871 - val_accuracy: 0.9430\n",
            "Epoch 4312/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2349 - accuracy: 0.9271 - val_loss: 0.1902 - val_accuracy: 0.9450\n",
            "Epoch 4313/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2356 - accuracy: 0.9235 - val_loss: 0.1875 - val_accuracy: 0.9440\n",
            "Epoch 4314/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2391 - accuracy: 0.9231 - val_loss: 0.1880 - val_accuracy: 0.9445\n",
            "Epoch 4315/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2291 - accuracy: 0.9269 - val_loss: 0.1883 - val_accuracy: 0.9465\n",
            "Epoch 4316/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2297 - accuracy: 0.9277 - val_loss: 0.1883 - val_accuracy: 0.9460\n",
            "Epoch 4317/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2286 - accuracy: 0.9276 - val_loss: 0.1928 - val_accuracy: 0.9425\n",
            "Epoch 4318/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2317 - accuracy: 0.9234 - val_loss: 0.1902 - val_accuracy: 0.9445\n",
            "Epoch 4319/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2280 - accuracy: 0.9269 - val_loss: 0.1888 - val_accuracy: 0.9450\n",
            "Epoch 4320/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2273 - accuracy: 0.9285 - val_loss: 0.1906 - val_accuracy: 0.9440\n",
            "Epoch 4321/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2318 - accuracy: 0.9271 - val_loss: 0.1900 - val_accuracy: 0.9460\n",
            "Epoch 4322/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2344 - accuracy: 0.9249 - val_loss: 0.1937 - val_accuracy: 0.9445\n",
            "Epoch 4323/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2442 - accuracy: 0.9233 - val_loss: 0.1856 - val_accuracy: 0.9455\n",
            "Epoch 4324/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2337 - accuracy: 0.9249 - val_loss: 0.1851 - val_accuracy: 0.9455\n",
            "Epoch 4325/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2322 - accuracy: 0.9222 - val_loss: 0.1891 - val_accuracy: 0.9445\n",
            "Epoch 4326/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2289 - accuracy: 0.9252 - val_loss: 0.1878 - val_accuracy: 0.9445\n",
            "Epoch 4327/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2323 - accuracy: 0.9258 - val_loss: 0.1932 - val_accuracy: 0.9450\n",
            "Epoch 4328/6000\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2301 - accuracy: 0.9281 - val_loss: 0.1850 - val_accuracy: 0.9455\n",
            "Epoch 4329/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2326 - accuracy: 0.9255 - val_loss: 0.1893 - val_accuracy: 0.9425\n",
            "Epoch 4330/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2203 - accuracy: 0.9299 - val_loss: 0.1879 - val_accuracy: 0.9430\n",
            "Epoch 4331/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2280 - accuracy: 0.9250 - val_loss: 0.1924 - val_accuracy: 0.9425\n",
            "Epoch 4332/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2347 - accuracy: 0.9270 - val_loss: 0.1832 - val_accuracy: 0.9445\n",
            "Epoch 4333/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2261 - accuracy: 0.9265 - val_loss: 0.1888 - val_accuracy: 0.9440\n",
            "Epoch 4334/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2332 - accuracy: 0.9250 - val_loss: 0.1874 - val_accuracy: 0.9450\n",
            "Epoch 4335/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2285 - accuracy: 0.9261 - val_loss: 0.1877 - val_accuracy: 0.9450\n",
            "Epoch 4336/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2284 - accuracy: 0.9261 - val_loss: 0.1892 - val_accuracy: 0.9450\n",
            "Epoch 4337/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2292 - accuracy: 0.9239 - val_loss: 0.1892 - val_accuracy: 0.9460\n",
            "Epoch 4338/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2360 - accuracy: 0.9225 - val_loss: 0.1893 - val_accuracy: 0.9470\n",
            "Epoch 4339/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2230 - accuracy: 0.9255 - val_loss: 0.1887 - val_accuracy: 0.9435\n",
            "Epoch 4340/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2276 - accuracy: 0.9250 - val_loss: 0.1877 - val_accuracy: 0.9460\n",
            "Epoch 4341/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2379 - accuracy: 0.9254 - val_loss: 0.1870 - val_accuracy: 0.9455\n",
            "Epoch 4342/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2293 - accuracy: 0.9247 - val_loss: 0.1852 - val_accuracy: 0.9455\n",
            "Epoch 4343/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2503 - accuracy: 0.9225 - val_loss: 0.1865 - val_accuracy: 0.9450\n",
            "Epoch 4344/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2292 - accuracy: 0.9268 - val_loss: 0.1886 - val_accuracy: 0.9445\n",
            "Epoch 4345/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2390 - accuracy: 0.9240 - val_loss: 0.1868 - val_accuracy: 0.9465\n",
            "Epoch 4346/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2370 - accuracy: 0.9227 - val_loss: 0.1855 - val_accuracy: 0.9445\n",
            "Epoch 4347/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2261 - accuracy: 0.9266 - val_loss: 0.1881 - val_accuracy: 0.9450\n",
            "Epoch 4348/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2224 - accuracy: 0.9291 - val_loss: 0.1850 - val_accuracy: 0.9460\n",
            "Epoch 4349/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2263 - accuracy: 0.9251 - val_loss: 0.1850 - val_accuracy: 0.9450\n",
            "Epoch 4350/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2341 - accuracy: 0.9274 - val_loss: 0.1854 - val_accuracy: 0.9445\n",
            "Epoch 4351/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2441 - accuracy: 0.9258 - val_loss: 0.1858 - val_accuracy: 0.9455\n",
            "Epoch 4352/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2307 - accuracy: 0.9252 - val_loss: 0.1869 - val_accuracy: 0.9460\n",
            "Epoch 4353/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2299 - accuracy: 0.9271 - val_loss: 0.1848 - val_accuracy: 0.9465\n",
            "Epoch 4354/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2301 - accuracy: 0.9249 - val_loss: 0.1888 - val_accuracy: 0.9460\n",
            "Epoch 4355/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2325 - accuracy: 0.9246 - val_loss: 0.1855 - val_accuracy: 0.9445\n",
            "Epoch 4356/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2399 - accuracy: 0.9205 - val_loss: 0.1868 - val_accuracy: 0.9445\n",
            "Epoch 4357/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2355 - accuracy: 0.9237 - val_loss: 0.1933 - val_accuracy: 0.9430\n",
            "Epoch 4358/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2251 - accuracy: 0.9268 - val_loss: 0.1935 - val_accuracy: 0.9445\n",
            "Epoch 4359/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2377 - accuracy: 0.9251 - val_loss: 0.1881 - val_accuracy: 0.9440\n",
            "Epoch 4360/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2285 - accuracy: 0.9240 - val_loss: 0.1912 - val_accuracy: 0.9450\n",
            "Epoch 4361/6000\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2290 - accuracy: 0.9262 - val_loss: 0.1860 - val_accuracy: 0.9450\n",
            "Epoch 4362/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2265 - accuracy: 0.9260 - val_loss: 0.1943 - val_accuracy: 0.9415\n",
            "Epoch 4363/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2275 - accuracy: 0.9264 - val_loss: 0.1893 - val_accuracy: 0.9455\n",
            "Epoch 4364/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2390 - accuracy: 0.9239 - val_loss: 0.1897 - val_accuracy: 0.9440\n",
            "Epoch 4365/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2311 - accuracy: 0.9229 - val_loss: 0.1890 - val_accuracy: 0.9450\n",
            "Epoch 4366/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2351 - accuracy: 0.9196 - val_loss: 0.1887 - val_accuracy: 0.9435\n",
            "Epoch 4367/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2304 - accuracy: 0.9261 - val_loss: 0.1895 - val_accuracy: 0.9455\n",
            "Epoch 4368/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2311 - accuracy: 0.9259 - val_loss: 0.1873 - val_accuracy: 0.9445\n",
            "Epoch 4369/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2271 - accuracy: 0.9284 - val_loss: 0.1883 - val_accuracy: 0.9455\n",
            "Epoch 4370/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2540 - accuracy: 0.9237 - val_loss: 0.1824 - val_accuracy: 0.9460\n",
            "Epoch 4371/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2329 - accuracy: 0.9252 - val_loss: 0.1858 - val_accuracy: 0.9445\n",
            "Epoch 4372/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2350 - accuracy: 0.9260 - val_loss: 0.1842 - val_accuracy: 0.9445\n",
            "Epoch 4373/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2318 - accuracy: 0.9231 - val_loss: 0.1874 - val_accuracy: 0.9450\n",
            "Epoch 4374/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2380 - accuracy: 0.9261 - val_loss: 0.1839 - val_accuracy: 0.9435\n",
            "Epoch 4375/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2210 - accuracy: 0.9266 - val_loss: 0.1848 - val_accuracy: 0.9445\n",
            "Epoch 4376/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2381 - accuracy: 0.9244 - val_loss: 0.1850 - val_accuracy: 0.9445\n",
            "Epoch 4377/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2302 - accuracy: 0.9274 - val_loss: 0.1874 - val_accuracy: 0.9450\n",
            "Epoch 4378/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2328 - accuracy: 0.9227 - val_loss: 0.1893 - val_accuracy: 0.9435\n",
            "Epoch 4379/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2228 - accuracy: 0.9260 - val_loss: 0.1837 - val_accuracy: 0.9450\n",
            "Epoch 4380/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2331 - accuracy: 0.9249 - val_loss: 0.1846 - val_accuracy: 0.9445\n",
            "Epoch 4381/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2353 - accuracy: 0.9233 - val_loss: 0.1902 - val_accuracy: 0.9445\n",
            "Epoch 4382/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2489 - accuracy: 0.9265 - val_loss: 0.1856 - val_accuracy: 0.9460\n",
            "Epoch 4383/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2268 - accuracy: 0.9247 - val_loss: 0.1855 - val_accuracy: 0.9455\n",
            "Epoch 4384/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2273 - accuracy: 0.9274 - val_loss: 0.1848 - val_accuracy: 0.9450\n",
            "Epoch 4385/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2390 - accuracy: 0.9231 - val_loss: 0.1855 - val_accuracy: 0.9435\n",
            "Epoch 4386/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2284 - accuracy: 0.9274 - val_loss: 0.1914 - val_accuracy: 0.9450\n",
            "Epoch 4387/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2401 - accuracy: 0.9254 - val_loss: 0.1852 - val_accuracy: 0.9465\n",
            "Epoch 4388/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2238 - accuracy: 0.9274 - val_loss: 0.1872 - val_accuracy: 0.9440\n",
            "Epoch 4389/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2294 - accuracy: 0.9246 - val_loss: 0.1834 - val_accuracy: 0.9445\n",
            "Epoch 4390/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2284 - accuracy: 0.9283 - val_loss: 0.1895 - val_accuracy: 0.9445\n",
            "Epoch 4391/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2299 - accuracy: 0.9243 - val_loss: 0.1874 - val_accuracy: 0.9455\n",
            "Epoch 4392/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2271 - accuracy: 0.9251 - val_loss: 0.1833 - val_accuracy: 0.9455\n",
            "Epoch 4393/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2304 - accuracy: 0.9265 - val_loss: 0.1834 - val_accuracy: 0.9460\n",
            "Epoch 4394/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2209 - accuracy: 0.9287 - val_loss: 0.1877 - val_accuracy: 0.9445\n",
            "Epoch 4395/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2264 - accuracy: 0.9271 - val_loss: 0.1916 - val_accuracy: 0.9430\n",
            "Epoch 4396/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2492 - accuracy: 0.9166 - val_loss: 0.1879 - val_accuracy: 0.9455\n",
            "Epoch 4397/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2312 - accuracy: 0.9261 - val_loss: 0.1853 - val_accuracy: 0.9470\n",
            "Epoch 4398/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2226 - accuracy: 0.9283 - val_loss: 0.1890 - val_accuracy: 0.9460\n",
            "Epoch 4399/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2375 - accuracy: 0.9236 - val_loss: 0.1890 - val_accuracy: 0.9460\n",
            "Epoch 4400/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2324 - accuracy: 0.9250 - val_loss: 0.1880 - val_accuracy: 0.9440\n",
            "Epoch 4401/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2331 - accuracy: 0.9276 - val_loss: 0.1939 - val_accuracy: 0.9425\n",
            "Epoch 4402/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2405 - accuracy: 0.9258 - val_loss: 0.1882 - val_accuracy: 0.9450\n",
            "Epoch 4403/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2202 - accuracy: 0.9289 - val_loss: 0.1859 - val_accuracy: 0.9455\n",
            "Epoch 4404/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2300 - accuracy: 0.9250 - val_loss: 0.1966 - val_accuracy: 0.9435\n",
            "Epoch 4405/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2314 - accuracy: 0.9231 - val_loss: 0.1913 - val_accuracy: 0.9430\n",
            "Epoch 4406/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2279 - accuracy: 0.9268 - val_loss: 0.1888 - val_accuracy: 0.9445\n",
            "Epoch 4407/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2318 - accuracy: 0.9256 - val_loss: 0.1910 - val_accuracy: 0.9435\n",
            "Epoch 4408/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2293 - accuracy: 0.9258 - val_loss: 0.1864 - val_accuracy: 0.9440\n",
            "Epoch 4409/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2292 - accuracy: 0.9260 - val_loss: 0.1890 - val_accuracy: 0.9460\n",
            "Epoch 4410/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2422 - accuracy: 0.9264 - val_loss: 0.1912 - val_accuracy: 0.9465\n",
            "Epoch 4411/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2270 - accuracy: 0.9276 - val_loss: 0.1866 - val_accuracy: 0.9465\n",
            "Epoch 4412/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2316 - accuracy: 0.9255 - val_loss: 0.1876 - val_accuracy: 0.9455\n",
            "Epoch 4413/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2348 - accuracy: 0.9225 - val_loss: 0.1862 - val_accuracy: 0.9435\n",
            "Epoch 4414/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2320 - accuracy: 0.9251 - val_loss: 0.1842 - val_accuracy: 0.9445\n",
            "Epoch 4415/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2397 - accuracy: 0.9255 - val_loss: 0.1897 - val_accuracy: 0.9445\n",
            "Epoch 4416/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2276 - accuracy: 0.9262 - val_loss: 0.1863 - val_accuracy: 0.9440\n",
            "Epoch 4417/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2310 - accuracy: 0.9241 - val_loss: 0.1855 - val_accuracy: 0.9450\n",
            "Epoch 4418/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2234 - accuracy: 0.9252 - val_loss: 0.1866 - val_accuracy: 0.9445\n",
            "Epoch 4419/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2281 - accuracy: 0.9259 - val_loss: 0.1896 - val_accuracy: 0.9460\n",
            "Epoch 4420/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2358 - accuracy: 0.9229 - val_loss: 0.1852 - val_accuracy: 0.9450\n",
            "Epoch 4421/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2314 - accuracy: 0.9258 - val_loss: 0.1879 - val_accuracy: 0.9450\n",
            "Epoch 4422/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2271 - accuracy: 0.9252 - val_loss: 0.1863 - val_accuracy: 0.9460\n",
            "Epoch 4423/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2296 - accuracy: 0.9239 - val_loss: 0.1815 - val_accuracy: 0.9455\n",
            "Epoch 4424/6000\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2286 - accuracy: 0.9241 - val_loss: 0.1916 - val_accuracy: 0.9435\n",
            "Epoch 4425/6000\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2254 - accuracy: 0.9283 - val_loss: 0.1849 - val_accuracy: 0.9450\n",
            "Epoch 4426/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2297 - accuracy: 0.9284 - val_loss: 0.1877 - val_accuracy: 0.9440\n",
            "Epoch 4427/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2286 - accuracy: 0.9262 - val_loss: 0.1885 - val_accuracy: 0.9430\n",
            "Epoch 4428/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2323 - accuracy: 0.9251 - val_loss: 0.1935 - val_accuracy: 0.9440\n",
            "Epoch 4429/6000\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2326 - accuracy: 0.9261 - val_loss: 0.1837 - val_accuracy: 0.9455\n",
            "Epoch 4430/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2342 - accuracy: 0.9249 - val_loss: 0.1921 - val_accuracy: 0.9435\n",
            "Epoch 4431/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2324 - accuracy: 0.9241 - val_loss: 0.1846 - val_accuracy: 0.9450\n",
            "Epoch 4432/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2363 - accuracy: 0.9231 - val_loss: 0.1909 - val_accuracy: 0.9440\n",
            "Epoch 4433/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2335 - accuracy: 0.9251 - val_loss: 0.1911 - val_accuracy: 0.9455\n",
            "Epoch 4434/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2367 - accuracy: 0.9215 - val_loss: 0.1882 - val_accuracy: 0.9435\n",
            "Epoch 4435/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2286 - accuracy: 0.9285 - val_loss: 0.1879 - val_accuracy: 0.9450\n",
            "Epoch 4436/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2319 - accuracy: 0.9240 - val_loss: 0.1853 - val_accuracy: 0.9450\n",
            "Epoch 4437/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2271 - accuracy: 0.9265 - val_loss: 0.1895 - val_accuracy: 0.9440\n",
            "Epoch 4438/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2361 - accuracy: 0.9264 - val_loss: 0.1861 - val_accuracy: 0.9440\n",
            "Epoch 4439/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2301 - accuracy: 0.9244 - val_loss: 0.1850 - val_accuracy: 0.9450\n",
            "Epoch 4440/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2251 - accuracy: 0.9290 - val_loss: 0.1903 - val_accuracy: 0.9465\n",
            "Epoch 4441/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2287 - accuracy: 0.9266 - val_loss: 0.1916 - val_accuracy: 0.9455\n",
            "Epoch 4442/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2289 - accuracy: 0.9251 - val_loss: 0.1922 - val_accuracy: 0.9455\n",
            "Epoch 4443/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2276 - accuracy: 0.9255 - val_loss: 0.1898 - val_accuracy: 0.9460\n",
            "Epoch 4444/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2461 - accuracy: 0.9271 - val_loss: 0.1883 - val_accuracy: 0.9455\n",
            "Epoch 4445/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2270 - accuracy: 0.9268 - val_loss: 0.1834 - val_accuracy: 0.9460\n",
            "Epoch 4446/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2308 - accuracy: 0.9251 - val_loss: 0.1860 - val_accuracy: 0.9445\n",
            "Epoch 4447/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2427 - accuracy: 0.9215 - val_loss: 0.1841 - val_accuracy: 0.9450\n",
            "Epoch 4448/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2459 - accuracy: 0.9268 - val_loss: 0.1933 - val_accuracy: 0.9450\n",
            "Epoch 4449/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2226 - accuracy: 0.9280 - val_loss: 0.1899 - val_accuracy: 0.9450\n",
            "Epoch 4450/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2332 - accuracy: 0.9266 - val_loss: 0.1898 - val_accuracy: 0.9450\n",
            "Epoch 4451/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2285 - accuracy: 0.9221 - val_loss: 0.1883 - val_accuracy: 0.9450\n",
            "Epoch 4452/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2364 - accuracy: 0.9215 - val_loss: 0.1870 - val_accuracy: 0.9445\n",
            "Epoch 4453/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2276 - accuracy: 0.9268 - val_loss: 0.1851 - val_accuracy: 0.9450\n",
            "Epoch 4454/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2272 - accuracy: 0.9249 - val_loss: 0.1877 - val_accuracy: 0.9440\n",
            "Epoch 4455/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2287 - accuracy: 0.9246 - val_loss: 0.1921 - val_accuracy: 0.9445\n",
            "Epoch 4456/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2254 - accuracy: 0.9265 - val_loss: 0.1859 - val_accuracy: 0.9460\n",
            "Epoch 4457/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2358 - accuracy: 0.9245 - val_loss: 0.1906 - val_accuracy: 0.9440\n",
            "Epoch 4458/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2263 - accuracy: 0.9260 - val_loss: 0.1910 - val_accuracy: 0.9435\n",
            "Epoch 4459/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2270 - accuracy: 0.9249 - val_loss: 0.1961 - val_accuracy: 0.9440\n",
            "Epoch 4460/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2306 - accuracy: 0.9240 - val_loss: 0.1813 - val_accuracy: 0.9460\n",
            "Epoch 4461/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2256 - accuracy: 0.9255 - val_loss: 0.1892 - val_accuracy: 0.9435\n",
            "Epoch 4462/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2404 - accuracy: 0.9230 - val_loss: 0.1874 - val_accuracy: 0.9450\n",
            "Epoch 4463/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2250 - accuracy: 0.9265 - val_loss: 0.1935 - val_accuracy: 0.9460\n",
            "Epoch 4464/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2290 - accuracy: 0.9286 - val_loss: 0.1842 - val_accuracy: 0.9450\n",
            "Epoch 4465/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2295 - accuracy: 0.9264 - val_loss: 0.1896 - val_accuracy: 0.9455\n",
            "Epoch 4466/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2322 - accuracy: 0.9260 - val_loss: 0.1902 - val_accuracy: 0.9460\n",
            "Epoch 4467/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2305 - accuracy: 0.9271 - val_loss: 0.1860 - val_accuracy: 0.9455\n",
            "Epoch 4468/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2273 - accuracy: 0.9271 - val_loss: 0.1898 - val_accuracy: 0.9445\n",
            "Epoch 4469/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2308 - accuracy: 0.9273 - val_loss: 0.1863 - val_accuracy: 0.9430\n",
            "Epoch 4470/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2330 - accuracy: 0.9273 - val_loss: 0.1903 - val_accuracy: 0.9440\n",
            "Epoch 4471/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2338 - accuracy: 0.9250 - val_loss: 0.1894 - val_accuracy: 0.9430\n",
            "Epoch 4472/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2288 - accuracy: 0.9268 - val_loss: 0.1847 - val_accuracy: 0.9450\n",
            "Epoch 4473/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2330 - accuracy: 0.9256 - val_loss: 0.1851 - val_accuracy: 0.9455\n",
            "Epoch 4474/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2286 - accuracy: 0.9270 - val_loss: 0.1867 - val_accuracy: 0.9445\n",
            "Epoch 4475/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2251 - accuracy: 0.9271 - val_loss: 0.1889 - val_accuracy: 0.9465\n",
            "Epoch 4476/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2323 - accuracy: 0.9233 - val_loss: 0.1819 - val_accuracy: 0.9450\n",
            "Epoch 4477/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2274 - accuracy: 0.9271 - val_loss: 0.1869 - val_accuracy: 0.9440\n",
            "Epoch 4478/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2414 - accuracy: 0.9285 - val_loss: 0.1833 - val_accuracy: 0.9455\n",
            "Epoch 4479/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2425 - accuracy: 0.9224 - val_loss: 0.1909 - val_accuracy: 0.9455\n",
            "Epoch 4480/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2240 - accuracy: 0.9296 - val_loss: 0.1843 - val_accuracy: 0.9455\n",
            "Epoch 4481/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2304 - accuracy: 0.9275 - val_loss: 0.1863 - val_accuracy: 0.9455\n",
            "Epoch 4482/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2353 - accuracy: 0.9240 - val_loss: 0.1904 - val_accuracy: 0.9445\n",
            "Epoch 4483/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2387 - accuracy: 0.9226 - val_loss: 0.1864 - val_accuracy: 0.9445\n",
            "Epoch 4484/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2240 - accuracy: 0.9274 - val_loss: 0.1858 - val_accuracy: 0.9455\n",
            "Epoch 4485/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2339 - accuracy: 0.9235 - val_loss: 0.1899 - val_accuracy: 0.9455\n",
            "Epoch 4486/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2367 - accuracy: 0.9233 - val_loss: 0.1861 - val_accuracy: 0.9450\n",
            "Epoch 4487/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2279 - accuracy: 0.9239 - val_loss: 0.1881 - val_accuracy: 0.9440\n",
            "Epoch 4488/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2276 - accuracy: 0.9274 - val_loss: 0.1866 - val_accuracy: 0.9445\n",
            "Epoch 4489/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2322 - accuracy: 0.9234 - val_loss: 0.1874 - val_accuracy: 0.9455\n",
            "Epoch 4490/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2307 - accuracy: 0.9259 - val_loss: 0.1899 - val_accuracy: 0.9445\n",
            "Epoch 4491/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2346 - accuracy: 0.9229 - val_loss: 0.1903 - val_accuracy: 0.9450\n",
            "Epoch 4492/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2226 - accuracy: 0.9304 - val_loss: 0.1866 - val_accuracy: 0.9455\n",
            "Epoch 4493/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2252 - accuracy: 0.9279 - val_loss: 0.1892 - val_accuracy: 0.9455\n",
            "Epoch 4494/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2254 - accuracy: 0.9283 - val_loss: 0.1903 - val_accuracy: 0.9440\n",
            "Epoch 4495/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2253 - accuracy: 0.9281 - val_loss: 0.1888 - val_accuracy: 0.9460\n",
            "Epoch 4496/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2309 - accuracy: 0.9289 - val_loss: 0.1892 - val_accuracy: 0.9465\n",
            "Epoch 4497/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2361 - accuracy: 0.9249 - val_loss: 0.1863 - val_accuracy: 0.9460\n",
            "Epoch 4498/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2280 - accuracy: 0.9260 - val_loss: 0.1884 - val_accuracy: 0.9455\n",
            "Epoch 4499/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2368 - accuracy: 0.9241 - val_loss: 0.1882 - val_accuracy: 0.9450\n",
            "Epoch 4500/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2259 - accuracy: 0.9250 - val_loss: 0.1881 - val_accuracy: 0.9460\n",
            "Epoch 4501/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2237 - accuracy: 0.9289 - val_loss: 0.1905 - val_accuracy: 0.9455\n",
            "Epoch 4502/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2295 - accuracy: 0.9274 - val_loss: 0.1826 - val_accuracy: 0.9465\n",
            "Epoch 4503/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2439 - accuracy: 0.9285 - val_loss: 0.1866 - val_accuracy: 0.9460\n",
            "Epoch 4504/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2302 - accuracy: 0.9276 - val_loss: 0.1878 - val_accuracy: 0.9435\n",
            "Epoch 4505/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2269 - accuracy: 0.9284 - val_loss: 0.1834 - val_accuracy: 0.9465\n",
            "Epoch 4506/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2467 - accuracy: 0.9199 - val_loss: 0.1874 - val_accuracy: 0.9450\n",
            "Epoch 4507/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2246 - accuracy: 0.9260 - val_loss: 0.1823 - val_accuracy: 0.9460\n",
            "Epoch 4508/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2214 - accuracy: 0.9276 - val_loss: 0.1872 - val_accuracy: 0.9460\n",
            "Epoch 4509/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2360 - accuracy: 0.9236 - val_loss: 0.1851 - val_accuracy: 0.9465\n",
            "Epoch 4510/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2303 - accuracy: 0.9262 - val_loss: 0.1885 - val_accuracy: 0.9445\n",
            "Epoch 4511/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2186 - accuracy: 0.9285 - val_loss: 0.1852 - val_accuracy: 0.9465\n",
            "Epoch 4512/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2288 - accuracy: 0.9255 - val_loss: 0.1848 - val_accuracy: 0.9460\n",
            "Epoch 4513/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2338 - accuracy: 0.9254 - val_loss: 0.1872 - val_accuracy: 0.9445\n",
            "Epoch 4514/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2220 - accuracy: 0.9290 - val_loss: 0.1881 - val_accuracy: 0.9475\n",
            "Epoch 4515/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2325 - accuracy: 0.9245 - val_loss: 0.1835 - val_accuracy: 0.9450\n",
            "Epoch 4516/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2326 - accuracy: 0.9261 - val_loss: 0.1835 - val_accuracy: 0.9455\n",
            "Epoch 4517/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2313 - accuracy: 0.9251 - val_loss: 0.1832 - val_accuracy: 0.9450\n",
            "Epoch 4518/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2249 - accuracy: 0.9298 - val_loss: 0.1874 - val_accuracy: 0.9455\n",
            "Epoch 4519/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2343 - accuracy: 0.9233 - val_loss: 0.1878 - val_accuracy: 0.9455\n",
            "Epoch 4520/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2241 - accuracy: 0.9269 - val_loss: 0.1838 - val_accuracy: 0.9470\n",
            "Epoch 4521/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2381 - accuracy: 0.9271 - val_loss: 0.1982 - val_accuracy: 0.9415\n",
            "Epoch 4522/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2379 - accuracy: 0.9233 - val_loss: 0.1915 - val_accuracy: 0.9420\n",
            "Epoch 4523/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2307 - accuracy: 0.9280 - val_loss: 0.1860 - val_accuracy: 0.9455\n",
            "Epoch 4524/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2259 - accuracy: 0.9281 - val_loss: 0.1875 - val_accuracy: 0.9450\n",
            "Epoch 4525/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2274 - accuracy: 0.9270 - val_loss: 0.1879 - val_accuracy: 0.9435\n",
            "Epoch 4526/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2256 - accuracy: 0.9254 - val_loss: 0.1894 - val_accuracy: 0.9440\n",
            "Epoch 4527/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2317 - accuracy: 0.9244 - val_loss: 0.1872 - val_accuracy: 0.9455\n",
            "Epoch 4528/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2329 - accuracy: 0.9261 - val_loss: 0.1886 - val_accuracy: 0.9455\n",
            "Epoch 4529/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2333 - accuracy: 0.9264 - val_loss: 0.1982 - val_accuracy: 0.9400\n",
            "Epoch 4530/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2281 - accuracy: 0.9255 - val_loss: 0.1864 - val_accuracy: 0.9440\n",
            "Epoch 4531/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2236 - accuracy: 0.9279 - val_loss: 0.1914 - val_accuracy: 0.9455\n",
            "Epoch 4532/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2358 - accuracy: 0.9240 - val_loss: 0.1877 - val_accuracy: 0.9465\n",
            "Epoch 4533/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2300 - accuracy: 0.9237 - val_loss: 0.1871 - val_accuracy: 0.9455\n",
            "Epoch 4534/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2213 - accuracy: 0.9268 - val_loss: 0.1873 - val_accuracy: 0.9460\n",
            "Epoch 4535/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2316 - accuracy: 0.9271 - val_loss: 0.1888 - val_accuracy: 0.9455\n",
            "Epoch 4536/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2301 - accuracy: 0.9275 - val_loss: 0.1901 - val_accuracy: 0.9450\n",
            "Epoch 4537/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2283 - accuracy: 0.9266 - val_loss: 0.1862 - val_accuracy: 0.9460\n",
            "Epoch 4538/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2264 - accuracy: 0.9262 - val_loss: 0.1876 - val_accuracy: 0.9445\n",
            "Epoch 4539/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2300 - accuracy: 0.9268 - val_loss: 0.1852 - val_accuracy: 0.9445\n",
            "Epoch 4540/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2353 - accuracy: 0.9246 - val_loss: 0.1894 - val_accuracy: 0.9455\n",
            "Epoch 4541/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2235 - accuracy: 0.9258 - val_loss: 0.1907 - val_accuracy: 0.9435\n",
            "Epoch 4542/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2297 - accuracy: 0.9264 - val_loss: 0.1918 - val_accuracy: 0.9430\n",
            "Epoch 4543/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2386 - accuracy: 0.9220 - val_loss: 0.1892 - val_accuracy: 0.9430\n",
            "Epoch 4544/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2354 - accuracy: 0.9258 - val_loss: 0.1904 - val_accuracy: 0.9445\n",
            "Epoch 4545/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2321 - accuracy: 0.9259 - val_loss: 0.1895 - val_accuracy: 0.9455\n",
            "Epoch 4546/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2301 - accuracy: 0.9264 - val_loss: 0.1865 - val_accuracy: 0.9450\n",
            "Epoch 4547/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2260 - accuracy: 0.9265 - val_loss: 0.1873 - val_accuracy: 0.9460\n",
            "Epoch 4548/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2289 - accuracy: 0.9274 - val_loss: 0.1833 - val_accuracy: 0.9465\n",
            "Epoch 4549/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2333 - accuracy: 0.9243 - val_loss: 0.1856 - val_accuracy: 0.9440\n",
            "Epoch 4550/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2217 - accuracy: 0.9287 - val_loss: 0.1877 - val_accuracy: 0.9445\n",
            "Epoch 4551/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2263 - accuracy: 0.9284 - val_loss: 0.1883 - val_accuracy: 0.9455\n",
            "Epoch 4552/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2255 - accuracy: 0.9312 - val_loss: 0.1835 - val_accuracy: 0.9445\n",
            "Epoch 4553/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2398 - accuracy: 0.9245 - val_loss: 0.1862 - val_accuracy: 0.9455\n",
            "Epoch 4554/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2449 - accuracy: 0.9243 - val_loss: 0.1892 - val_accuracy: 0.9445\n",
            "Epoch 4555/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2297 - accuracy: 0.9249 - val_loss: 0.1850 - val_accuracy: 0.9470\n",
            "Epoch 4556/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2276 - accuracy: 0.9262 - val_loss: 0.1837 - val_accuracy: 0.9460\n",
            "Epoch 4557/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2365 - accuracy: 0.9261 - val_loss: 0.1881 - val_accuracy: 0.9465\n",
            "Epoch 4558/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2394 - accuracy: 0.9226 - val_loss: 0.1897 - val_accuracy: 0.9455\n",
            "Epoch 4559/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2284 - accuracy: 0.9275 - val_loss: 0.1915 - val_accuracy: 0.9465\n",
            "Epoch 4560/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2376 - accuracy: 0.9262 - val_loss: 0.1904 - val_accuracy: 0.9445\n",
            "Epoch 4561/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2395 - accuracy: 0.9256 - val_loss: 0.1903 - val_accuracy: 0.9455\n",
            "Epoch 4562/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2318 - accuracy: 0.9245 - val_loss: 0.1907 - val_accuracy: 0.9450\n",
            "Epoch 4563/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2308 - accuracy: 0.9268 - val_loss: 0.1866 - val_accuracy: 0.9450\n",
            "Epoch 4564/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2269 - accuracy: 0.9271 - val_loss: 0.1860 - val_accuracy: 0.9450\n",
            "Epoch 4565/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2348 - accuracy: 0.9252 - val_loss: 0.1887 - val_accuracy: 0.9445\n",
            "Epoch 4566/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2384 - accuracy: 0.9264 - val_loss: 0.1904 - val_accuracy: 0.9450\n",
            "Epoch 4567/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2292 - accuracy: 0.9271 - val_loss: 0.1888 - val_accuracy: 0.9455\n",
            "Epoch 4568/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2251 - accuracy: 0.9275 - val_loss: 0.1857 - val_accuracy: 0.9465\n",
            "Epoch 4569/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2292 - accuracy: 0.9265 - val_loss: 0.1884 - val_accuracy: 0.9460\n",
            "Epoch 4570/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2281 - accuracy: 0.9266 - val_loss: 0.1877 - val_accuracy: 0.9435\n",
            "Epoch 4571/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2311 - accuracy: 0.9262 - val_loss: 0.1911 - val_accuracy: 0.9445\n",
            "Epoch 4572/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2337 - accuracy: 0.9243 - val_loss: 0.1871 - val_accuracy: 0.9440\n",
            "Epoch 4573/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2292 - accuracy: 0.9252 - val_loss: 0.1844 - val_accuracy: 0.9455\n",
            "Epoch 4574/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2373 - accuracy: 0.9246 - val_loss: 0.1886 - val_accuracy: 0.9430\n",
            "Epoch 4575/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2346 - accuracy: 0.9227 - val_loss: 0.1887 - val_accuracy: 0.9440\n",
            "Epoch 4576/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2242 - accuracy: 0.9275 - val_loss: 0.1837 - val_accuracy: 0.9465\n",
            "Epoch 4577/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2302 - accuracy: 0.9249 - val_loss: 0.1899 - val_accuracy: 0.9440\n",
            "Epoch 4578/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2280 - accuracy: 0.9276 - val_loss: 0.1894 - val_accuracy: 0.9425\n",
            "Epoch 4579/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2344 - accuracy: 0.9237 - val_loss: 0.1856 - val_accuracy: 0.9450\n",
            "Epoch 4580/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2279 - accuracy: 0.9277 - val_loss: 0.1868 - val_accuracy: 0.9445\n",
            "Epoch 4581/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2271 - accuracy: 0.9287 - val_loss: 0.1849 - val_accuracy: 0.9455\n",
            "Epoch 4582/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2181 - accuracy: 0.9285 - val_loss: 0.1853 - val_accuracy: 0.9465\n",
            "Epoch 4583/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2297 - accuracy: 0.9269 - val_loss: 0.1843 - val_accuracy: 0.9465\n",
            "Epoch 4584/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2347 - accuracy: 0.9260 - val_loss: 0.1883 - val_accuracy: 0.9450\n",
            "Epoch 4585/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2405 - accuracy: 0.9244 - val_loss: 0.1873 - val_accuracy: 0.9440\n",
            "Epoch 4586/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2281 - accuracy: 0.9264 - val_loss: 0.1831 - val_accuracy: 0.9445\n",
            "Epoch 4587/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2273 - accuracy: 0.9265 - val_loss: 0.1879 - val_accuracy: 0.9450\n",
            "Epoch 4588/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2257 - accuracy: 0.9271 - val_loss: 0.1872 - val_accuracy: 0.9465\n",
            "Epoch 4589/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2291 - accuracy: 0.9260 - val_loss: 0.1903 - val_accuracy: 0.9430\n",
            "Epoch 4590/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2325 - accuracy: 0.9234 - val_loss: 0.1901 - val_accuracy: 0.9420\n",
            "Epoch 4591/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2348 - accuracy: 0.9234 - val_loss: 0.1878 - val_accuracy: 0.9435\n",
            "Epoch 4592/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2329 - accuracy: 0.9250 - val_loss: 0.1880 - val_accuracy: 0.9435\n",
            "Epoch 4593/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2228 - accuracy: 0.9304 - val_loss: 0.1854 - val_accuracy: 0.9455\n",
            "Epoch 4594/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2375 - accuracy: 0.9266 - val_loss: 0.1901 - val_accuracy: 0.9445\n",
            "Epoch 4595/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2256 - accuracy: 0.9269 - val_loss: 0.1858 - val_accuracy: 0.9450\n",
            "Epoch 4596/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2285 - accuracy: 0.9251 - val_loss: 0.1855 - val_accuracy: 0.9465\n",
            "Epoch 4597/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2322 - accuracy: 0.9254 - val_loss: 0.1916 - val_accuracy: 0.9455\n",
            "Epoch 4598/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2275 - accuracy: 0.9271 - val_loss: 0.1866 - val_accuracy: 0.9445\n",
            "Epoch 4599/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2237 - accuracy: 0.9243 - val_loss: 0.1891 - val_accuracy: 0.9445\n",
            "Epoch 4600/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2278 - accuracy: 0.9306 - val_loss: 0.1876 - val_accuracy: 0.9450\n",
            "Epoch 4601/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2274 - accuracy: 0.9258 - val_loss: 0.1952 - val_accuracy: 0.9425\n",
            "Epoch 4602/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2302 - accuracy: 0.9226 - val_loss: 0.1899 - val_accuracy: 0.9450\n",
            "Epoch 4603/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2292 - accuracy: 0.9265 - val_loss: 0.1873 - val_accuracy: 0.9440\n",
            "Epoch 4604/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2289 - accuracy: 0.9260 - val_loss: 0.1867 - val_accuracy: 0.9450\n",
            "Epoch 4605/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2329 - accuracy: 0.9259 - val_loss: 0.1897 - val_accuracy: 0.9445\n",
            "Epoch 4606/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2427 - accuracy: 0.9260 - val_loss: 0.1891 - val_accuracy: 0.9440\n",
            "Epoch 4607/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2308 - accuracy: 0.9262 - val_loss: 0.1834 - val_accuracy: 0.9450\n",
            "Epoch 4608/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2271 - accuracy: 0.9293 - val_loss: 0.1886 - val_accuracy: 0.9445\n",
            "Epoch 4609/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2306 - accuracy: 0.9231 - val_loss: 0.1901 - val_accuracy: 0.9460\n",
            "Epoch 4610/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2341 - accuracy: 0.9283 - val_loss: 0.1832 - val_accuracy: 0.9455\n",
            "Epoch 4611/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2367 - accuracy: 0.9216 - val_loss: 0.1907 - val_accuracy: 0.9430\n",
            "Epoch 4612/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2248 - accuracy: 0.9262 - val_loss: 0.1839 - val_accuracy: 0.9460\n",
            "Epoch 4613/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2262 - accuracy: 0.9264 - val_loss: 0.1869 - val_accuracy: 0.9445\n",
            "Epoch 4614/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2421 - accuracy: 0.9229 - val_loss: 0.1895 - val_accuracy: 0.9450\n",
            "Epoch 4615/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2401 - accuracy: 0.9251 - val_loss: 0.1910 - val_accuracy: 0.9435\n",
            "Epoch 4616/6000\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2263 - accuracy: 0.9233 - val_loss: 0.1888 - val_accuracy: 0.9445\n",
            "Epoch 4617/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2311 - accuracy: 0.9254 - val_loss: 0.1867 - val_accuracy: 0.9450\n",
            "Epoch 4618/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2216 - accuracy: 0.9304 - val_loss: 0.1891 - val_accuracy: 0.9460\n",
            "Epoch 4619/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2253 - accuracy: 0.9276 - val_loss: 0.1853 - val_accuracy: 0.9465\n",
            "Epoch 4620/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2353 - accuracy: 0.9266 - val_loss: 0.1924 - val_accuracy: 0.9440\n",
            "Epoch 4621/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2310 - accuracy: 0.9277 - val_loss: 0.1844 - val_accuracy: 0.9465\n",
            "Epoch 4622/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2473 - accuracy: 0.9247 - val_loss: 0.1873 - val_accuracy: 0.9450\n",
            "Epoch 4623/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2322 - accuracy: 0.9268 - val_loss: 0.1910 - val_accuracy: 0.9445\n",
            "Epoch 4624/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2260 - accuracy: 0.9270 - val_loss: 0.1898 - val_accuracy: 0.9440\n",
            "Epoch 4625/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2304 - accuracy: 0.9251 - val_loss: 0.1895 - val_accuracy: 0.9440\n",
            "Epoch 4626/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2504 - accuracy: 0.9262 - val_loss: 0.1928 - val_accuracy: 0.9445\n",
            "Epoch 4627/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2259 - accuracy: 0.9287 - val_loss: 0.1912 - val_accuracy: 0.9430\n",
            "Epoch 4628/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2279 - accuracy: 0.9289 - val_loss: 0.1870 - val_accuracy: 0.9460\n",
            "Epoch 4629/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2340 - accuracy: 0.9259 - val_loss: 0.1892 - val_accuracy: 0.9455\n",
            "Epoch 4630/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2175 - accuracy: 0.9289 - val_loss: 0.1916 - val_accuracy: 0.9425\n",
            "Epoch 4631/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2388 - accuracy: 0.9240 - val_loss: 0.1916 - val_accuracy: 0.9430\n",
            "Epoch 4632/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2270 - accuracy: 0.9255 - val_loss: 0.1926 - val_accuracy: 0.9445\n",
            "Epoch 4633/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2308 - accuracy: 0.9236 - val_loss: 0.1885 - val_accuracy: 0.9450\n",
            "Epoch 4634/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2429 - accuracy: 0.9227 - val_loss: 0.1882 - val_accuracy: 0.9455\n",
            "Epoch 4635/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2279 - accuracy: 0.9239 - val_loss: 0.1896 - val_accuracy: 0.9450\n",
            "Epoch 4636/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2298 - accuracy: 0.9256 - val_loss: 0.1891 - val_accuracy: 0.9455\n",
            "Epoch 4637/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2408 - accuracy: 0.9269 - val_loss: 0.1884 - val_accuracy: 0.9450\n",
            "Epoch 4638/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2293 - accuracy: 0.9259 - val_loss: 0.1889 - val_accuracy: 0.9460\n",
            "Epoch 4639/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2298 - accuracy: 0.9261 - val_loss: 0.1888 - val_accuracy: 0.9455\n",
            "Epoch 4640/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2244 - accuracy: 0.9258 - val_loss: 0.1863 - val_accuracy: 0.9455\n",
            "Epoch 4641/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2473 - accuracy: 0.9240 - val_loss: 0.1875 - val_accuracy: 0.9460\n",
            "Epoch 4642/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2281 - accuracy: 0.9274 - val_loss: 0.1941 - val_accuracy: 0.9415\n",
            "Epoch 4643/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2311 - accuracy: 0.9262 - val_loss: 0.1881 - val_accuracy: 0.9445\n",
            "Epoch 4644/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2253 - accuracy: 0.9265 - val_loss: 0.1886 - val_accuracy: 0.9445\n",
            "Epoch 4645/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2203 - accuracy: 0.9285 - val_loss: 0.1873 - val_accuracy: 0.9435\n",
            "Epoch 4646/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2276 - accuracy: 0.9252 - val_loss: 0.1895 - val_accuracy: 0.9445\n",
            "Epoch 4647/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2429 - accuracy: 0.9218 - val_loss: 0.1928 - val_accuracy: 0.9440\n",
            "Epoch 4648/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2297 - accuracy: 0.9250 - val_loss: 0.1883 - val_accuracy: 0.9455\n",
            "Epoch 4649/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2267 - accuracy: 0.9280 - val_loss: 0.1880 - val_accuracy: 0.9445\n",
            "Epoch 4650/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2242 - accuracy: 0.9273 - val_loss: 0.1899 - val_accuracy: 0.9440\n",
            "Epoch 4651/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2258 - accuracy: 0.9299 - val_loss: 0.1873 - val_accuracy: 0.9450\n",
            "Epoch 4652/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2334 - accuracy: 0.9256 - val_loss: 0.1884 - val_accuracy: 0.9455\n",
            "Epoch 4653/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2282 - accuracy: 0.9255 - val_loss: 0.1862 - val_accuracy: 0.9460\n",
            "Epoch 4654/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2301 - accuracy: 0.9293 - val_loss: 0.1851 - val_accuracy: 0.9470\n",
            "Epoch 4655/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2259 - accuracy: 0.9286 - val_loss: 0.1860 - val_accuracy: 0.9460\n",
            "Epoch 4656/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2300 - accuracy: 0.9260 - val_loss: 0.1828 - val_accuracy: 0.9455\n",
            "Epoch 4657/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2288 - accuracy: 0.9276 - val_loss: 0.1954 - val_accuracy: 0.9445\n",
            "Epoch 4658/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2286 - accuracy: 0.9273 - val_loss: 0.1881 - val_accuracy: 0.9460\n",
            "Epoch 4659/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2238 - accuracy: 0.9269 - val_loss: 0.1896 - val_accuracy: 0.9450\n",
            "Epoch 4660/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2280 - accuracy: 0.9247 - val_loss: 0.1922 - val_accuracy: 0.9440\n",
            "Epoch 4661/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2437 - accuracy: 0.9264 - val_loss: 0.1884 - val_accuracy: 0.9455\n",
            "Epoch 4662/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2263 - accuracy: 0.9265 - val_loss: 0.1861 - val_accuracy: 0.9440\n",
            "Epoch 4663/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2301 - accuracy: 0.9243 - val_loss: 0.1884 - val_accuracy: 0.9445\n",
            "Epoch 4664/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2274 - accuracy: 0.9256 - val_loss: 0.1930 - val_accuracy: 0.9435\n",
            "Epoch 4665/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2487 - accuracy: 0.9231 - val_loss: 0.1936 - val_accuracy: 0.9435\n",
            "Epoch 4666/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2229 - accuracy: 0.9274 - val_loss: 0.1877 - val_accuracy: 0.9450\n",
            "Epoch 4667/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2323 - accuracy: 0.9250 - val_loss: 0.1873 - val_accuracy: 0.9445\n",
            "Epoch 4668/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2322 - accuracy: 0.9252 - val_loss: 0.1877 - val_accuracy: 0.9445\n",
            "Epoch 4669/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2311 - accuracy: 0.9285 - val_loss: 0.1866 - val_accuracy: 0.9430\n",
            "Epoch 4670/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2256 - accuracy: 0.9274 - val_loss: 0.1880 - val_accuracy: 0.9430\n",
            "Epoch 4671/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2300 - accuracy: 0.9262 - val_loss: 0.1853 - val_accuracy: 0.9455\n",
            "Epoch 4672/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2298 - accuracy: 0.9265 - val_loss: 0.1861 - val_accuracy: 0.9440\n",
            "Epoch 4673/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2328 - accuracy: 0.9231 - val_loss: 0.1894 - val_accuracy: 0.9460\n",
            "Epoch 4674/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2253 - accuracy: 0.9276 - val_loss: 0.1898 - val_accuracy: 0.9430\n",
            "Epoch 4675/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2306 - accuracy: 0.9268 - val_loss: 0.1855 - val_accuracy: 0.9445\n",
            "Epoch 4676/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2222 - accuracy: 0.9289 - val_loss: 0.1877 - val_accuracy: 0.9450\n",
            "Epoch 4677/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2307 - accuracy: 0.9258 - val_loss: 0.1929 - val_accuracy: 0.9440\n",
            "Epoch 4678/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2263 - accuracy: 0.9271 - val_loss: 0.1872 - val_accuracy: 0.9460\n",
            "Epoch 4679/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2294 - accuracy: 0.9264 - val_loss: 0.1849 - val_accuracy: 0.9460\n",
            "Epoch 4680/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2304 - accuracy: 0.9289 - val_loss: 0.1908 - val_accuracy: 0.9450\n",
            "Epoch 4681/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2228 - accuracy: 0.9295 - val_loss: 0.1878 - val_accuracy: 0.9445\n",
            "Epoch 4682/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2205 - accuracy: 0.9269 - val_loss: 0.1890 - val_accuracy: 0.9440\n",
            "Epoch 4683/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2304 - accuracy: 0.9233 - val_loss: 0.1924 - val_accuracy: 0.9450\n",
            "Epoch 4684/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2553 - accuracy: 0.9259 - val_loss: 0.1906 - val_accuracy: 0.9450\n",
            "Epoch 4685/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2309 - accuracy: 0.9251 - val_loss: 0.1883 - val_accuracy: 0.9455\n",
            "Epoch 4686/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2211 - accuracy: 0.9279 - val_loss: 0.1874 - val_accuracy: 0.9435\n",
            "Epoch 4687/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2366 - accuracy: 0.9240 - val_loss: 0.1897 - val_accuracy: 0.9455\n",
            "Epoch 4688/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2430 - accuracy: 0.9240 - val_loss: 0.1828 - val_accuracy: 0.9450\n",
            "Epoch 4689/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2337 - accuracy: 0.9225 - val_loss: 0.1838 - val_accuracy: 0.9460\n",
            "Epoch 4690/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2262 - accuracy: 0.9268 - val_loss: 0.1854 - val_accuracy: 0.9445\n",
            "Epoch 4691/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2276 - accuracy: 0.9260 - val_loss: 0.1849 - val_accuracy: 0.9460\n",
            "Epoch 4692/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2366 - accuracy: 0.9246 - val_loss: 0.1899 - val_accuracy: 0.9450\n",
            "Epoch 4693/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2252 - accuracy: 0.9268 - val_loss: 0.1857 - val_accuracy: 0.9455\n",
            "Epoch 4694/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2313 - accuracy: 0.9287 - val_loss: 0.1896 - val_accuracy: 0.9445\n",
            "Epoch 4695/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2302 - accuracy: 0.9240 - val_loss: 0.1892 - val_accuracy: 0.9430\n",
            "Epoch 4696/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2373 - accuracy: 0.9259 - val_loss: 0.1904 - val_accuracy: 0.9445\n",
            "Epoch 4697/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2251 - accuracy: 0.9255 - val_loss: 0.1916 - val_accuracy: 0.9440\n",
            "Epoch 4698/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2327 - accuracy: 0.9271 - val_loss: 0.1944 - val_accuracy: 0.9430\n",
            "Epoch 4699/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2276 - accuracy: 0.9311 - val_loss: 0.1959 - val_accuracy: 0.9420\n",
            "Epoch 4700/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2336 - accuracy: 0.9260 - val_loss: 0.1859 - val_accuracy: 0.9435\n",
            "Epoch 4701/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2350 - accuracy: 0.9269 - val_loss: 0.1884 - val_accuracy: 0.9435\n",
            "Epoch 4702/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2352 - accuracy: 0.9230 - val_loss: 0.1866 - val_accuracy: 0.9445\n",
            "Epoch 4703/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2435 - accuracy: 0.9236 - val_loss: 0.1983 - val_accuracy: 0.9410\n",
            "Epoch 4704/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2291 - accuracy: 0.9285 - val_loss: 0.1860 - val_accuracy: 0.9445\n",
            "Epoch 4705/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2387 - accuracy: 0.9237 - val_loss: 0.1854 - val_accuracy: 0.9440\n",
            "Epoch 4706/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2252 - accuracy: 0.9275 - val_loss: 0.1892 - val_accuracy: 0.9445\n",
            "Epoch 4707/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2268 - accuracy: 0.9246 - val_loss: 0.1964 - val_accuracy: 0.9420\n",
            "Epoch 4708/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2362 - accuracy: 0.9210 - val_loss: 0.1882 - val_accuracy: 0.9435\n",
            "Epoch 4709/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2294 - accuracy: 0.9302 - val_loss: 0.1914 - val_accuracy: 0.9430\n",
            "Epoch 4710/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2331 - accuracy: 0.9240 - val_loss: 0.1873 - val_accuracy: 0.9455\n",
            "Epoch 4711/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2311 - accuracy: 0.9264 - val_loss: 0.1884 - val_accuracy: 0.9450\n",
            "Epoch 4712/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2271 - accuracy: 0.9270 - val_loss: 0.1893 - val_accuracy: 0.9455\n",
            "Epoch 4713/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2321 - accuracy: 0.9229 - val_loss: 0.1883 - val_accuracy: 0.9450\n",
            "Epoch 4714/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2328 - accuracy: 0.9256 - val_loss: 0.1847 - val_accuracy: 0.9455\n",
            "Epoch 4715/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2382 - accuracy: 0.9201 - val_loss: 0.1869 - val_accuracy: 0.9445\n",
            "Epoch 4716/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2372 - accuracy: 0.9239 - val_loss: 0.1876 - val_accuracy: 0.9435\n",
            "Epoch 4717/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2259 - accuracy: 0.9308 - val_loss: 0.1837 - val_accuracy: 0.9450\n",
            "Epoch 4718/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2337 - accuracy: 0.9269 - val_loss: 0.1925 - val_accuracy: 0.9455\n",
            "Epoch 4719/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2291 - accuracy: 0.9254 - val_loss: 0.1902 - val_accuracy: 0.9440\n",
            "Epoch 4720/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2366 - accuracy: 0.9219 - val_loss: 0.1895 - val_accuracy: 0.9440\n",
            "Epoch 4721/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2249 - accuracy: 0.9279 - val_loss: 0.1869 - val_accuracy: 0.9425\n",
            "Epoch 4722/6000\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2289 - accuracy: 0.9239 - val_loss: 0.1911 - val_accuracy: 0.9435\n",
            "Epoch 4723/6000\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2252 - accuracy: 0.9283 - val_loss: 0.1930 - val_accuracy: 0.9435\n",
            "Epoch 4724/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2337 - accuracy: 0.9230 - val_loss: 0.1867 - val_accuracy: 0.9455\n",
            "Epoch 4725/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2263 - accuracy: 0.9261 - val_loss: 0.1892 - val_accuracy: 0.9445\n",
            "Epoch 4726/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2317 - accuracy: 0.9261 - val_loss: 0.1877 - val_accuracy: 0.9445\n",
            "Epoch 4727/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2270 - accuracy: 0.9277 - val_loss: 0.1862 - val_accuracy: 0.9445\n",
            "Epoch 4728/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2313 - accuracy: 0.9235 - val_loss: 0.1939 - val_accuracy: 0.9440\n",
            "Epoch 4729/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2428 - accuracy: 0.9258 - val_loss: 0.1910 - val_accuracy: 0.9420\n",
            "Epoch 4730/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2335 - accuracy: 0.9276 - val_loss: 0.1875 - val_accuracy: 0.9440\n",
            "Epoch 4731/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2316 - accuracy: 0.9247 - val_loss: 0.1939 - val_accuracy: 0.9420\n",
            "Epoch 4732/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2272 - accuracy: 0.9252 - val_loss: 0.1862 - val_accuracy: 0.9435\n",
            "Epoch 4733/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2294 - accuracy: 0.9262 - val_loss: 0.1875 - val_accuracy: 0.9460\n",
            "Epoch 4734/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2315 - accuracy: 0.9290 - val_loss: 0.1887 - val_accuracy: 0.9430\n",
            "Epoch 4735/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2318 - accuracy: 0.9256 - val_loss: 0.1893 - val_accuracy: 0.9435\n",
            "Epoch 4736/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2323 - accuracy: 0.9251 - val_loss: 0.1881 - val_accuracy: 0.9450\n",
            "Epoch 4737/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2272 - accuracy: 0.9258 - val_loss: 0.1902 - val_accuracy: 0.9430\n",
            "Epoch 4738/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2509 - accuracy: 0.9265 - val_loss: 0.1901 - val_accuracy: 0.9440\n",
            "Epoch 4739/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2256 - accuracy: 0.9295 - val_loss: 0.1887 - val_accuracy: 0.9465\n",
            "Epoch 4740/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2291 - accuracy: 0.9251 - val_loss: 0.1862 - val_accuracy: 0.9460\n",
            "Epoch 4741/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2354 - accuracy: 0.9279 - val_loss: 0.1897 - val_accuracy: 0.9460\n",
            "Epoch 4742/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2336 - accuracy: 0.9260 - val_loss: 0.1906 - val_accuracy: 0.9450\n",
            "Epoch 4743/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2261 - accuracy: 0.9266 - val_loss: 0.1880 - val_accuracy: 0.9445\n",
            "Epoch 4744/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2380 - accuracy: 0.9273 - val_loss: 0.1875 - val_accuracy: 0.9460\n",
            "Epoch 4745/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2299 - accuracy: 0.9240 - val_loss: 0.1869 - val_accuracy: 0.9455\n",
            "Epoch 4746/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2248 - accuracy: 0.9283 - val_loss: 0.1866 - val_accuracy: 0.9445\n",
            "Epoch 4747/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2309 - accuracy: 0.9287 - val_loss: 0.1852 - val_accuracy: 0.9445\n",
            "Epoch 4748/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2357 - accuracy: 0.9249 - val_loss: 0.1938 - val_accuracy: 0.9445\n",
            "Epoch 4749/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2318 - accuracy: 0.9236 - val_loss: 0.1823 - val_accuracy: 0.9455\n",
            "Epoch 4750/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2377 - accuracy: 0.9275 - val_loss: 0.1839 - val_accuracy: 0.9450\n",
            "Epoch 4751/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2344 - accuracy: 0.9246 - val_loss: 0.1871 - val_accuracy: 0.9440\n",
            "Epoch 4752/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2256 - accuracy: 0.9273 - val_loss: 0.1908 - val_accuracy: 0.9425\n",
            "Epoch 4753/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2319 - accuracy: 0.9256 - val_loss: 0.1866 - val_accuracy: 0.9450\n",
            "Epoch 4754/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2298 - accuracy: 0.9261 - val_loss: 0.1867 - val_accuracy: 0.9440\n",
            "Epoch 4755/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2293 - accuracy: 0.9276 - val_loss: 0.1893 - val_accuracy: 0.9450\n",
            "Epoch 4756/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2306 - accuracy: 0.9255 - val_loss: 0.1876 - val_accuracy: 0.9440\n",
            "Epoch 4757/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2271 - accuracy: 0.9260 - val_loss: 0.1886 - val_accuracy: 0.9450\n",
            "Epoch 4758/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2263 - accuracy: 0.9289 - val_loss: 0.1890 - val_accuracy: 0.9415\n",
            "Epoch 4759/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2447 - accuracy: 0.9265 - val_loss: 0.1849 - val_accuracy: 0.9440\n",
            "Epoch 4760/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2276 - accuracy: 0.9277 - val_loss: 0.1892 - val_accuracy: 0.9445\n",
            "Epoch 4761/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2255 - accuracy: 0.9258 - val_loss: 0.1852 - val_accuracy: 0.9450\n",
            "Epoch 4762/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2356 - accuracy: 0.9255 - val_loss: 0.1872 - val_accuracy: 0.9435\n",
            "Epoch 4763/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2310 - accuracy: 0.9243 - val_loss: 0.1866 - val_accuracy: 0.9450\n",
            "Epoch 4764/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2343 - accuracy: 0.9241 - val_loss: 0.1885 - val_accuracy: 0.9440\n",
            "Epoch 4765/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2307 - accuracy: 0.9280 - val_loss: 0.1923 - val_accuracy: 0.9415\n",
            "Epoch 4766/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2374 - accuracy: 0.9215 - val_loss: 0.1896 - val_accuracy: 0.9430\n",
            "Epoch 4767/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2288 - accuracy: 0.9256 - val_loss: 0.1850 - val_accuracy: 0.9450\n",
            "Epoch 4768/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2362 - accuracy: 0.9244 - val_loss: 0.1889 - val_accuracy: 0.9440\n",
            "Epoch 4769/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2358 - accuracy: 0.9275 - val_loss: 0.1924 - val_accuracy: 0.9420\n",
            "Epoch 4770/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2235 - accuracy: 0.9283 - val_loss: 0.1844 - val_accuracy: 0.9445\n",
            "Epoch 4771/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2430 - accuracy: 0.9237 - val_loss: 0.1856 - val_accuracy: 0.9450\n",
            "Epoch 4772/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2334 - accuracy: 0.9250 - val_loss: 0.1858 - val_accuracy: 0.9445\n",
            "Epoch 4773/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2278 - accuracy: 0.9254 - val_loss: 0.1859 - val_accuracy: 0.9455\n",
            "Epoch 4774/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2273 - accuracy: 0.9250 - val_loss: 0.1876 - val_accuracy: 0.9455\n",
            "Epoch 4775/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2279 - accuracy: 0.9255 - val_loss: 0.1841 - val_accuracy: 0.9445\n",
            "Epoch 4776/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2244 - accuracy: 0.9281 - val_loss: 0.1870 - val_accuracy: 0.9455\n",
            "Epoch 4777/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2249 - accuracy: 0.9280 - val_loss: 0.1838 - val_accuracy: 0.9460\n",
            "Epoch 4778/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2314 - accuracy: 0.9243 - val_loss: 0.1858 - val_accuracy: 0.9445\n",
            "Epoch 4779/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2440 - accuracy: 0.9265 - val_loss: 0.1874 - val_accuracy: 0.9455\n",
            "Epoch 4780/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2305 - accuracy: 0.9262 - val_loss: 0.1865 - val_accuracy: 0.9455\n",
            "Epoch 4781/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2267 - accuracy: 0.9276 - val_loss: 0.1886 - val_accuracy: 0.9445\n",
            "Epoch 4782/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2255 - accuracy: 0.9268 - val_loss: 0.1913 - val_accuracy: 0.9445\n",
            "Epoch 4783/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2254 - accuracy: 0.9291 - val_loss: 0.1838 - val_accuracy: 0.9450\n",
            "Epoch 4784/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2390 - accuracy: 0.9291 - val_loss: 0.1836 - val_accuracy: 0.9455\n",
            "Epoch 4785/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2226 - accuracy: 0.9269 - val_loss: 0.1893 - val_accuracy: 0.9440\n",
            "Epoch 4786/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2398 - accuracy: 0.9259 - val_loss: 0.1924 - val_accuracy: 0.9440\n",
            "Epoch 4787/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2323 - accuracy: 0.9261 - val_loss: 0.1861 - val_accuracy: 0.9445\n",
            "Epoch 4788/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2313 - accuracy: 0.9296 - val_loss: 0.1859 - val_accuracy: 0.9440\n",
            "Epoch 4789/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2301 - accuracy: 0.9290 - val_loss: 0.1878 - val_accuracy: 0.9445\n",
            "Epoch 4790/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2328 - accuracy: 0.9230 - val_loss: 0.1901 - val_accuracy: 0.9445\n",
            "Epoch 4791/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2334 - accuracy: 0.9260 - val_loss: 0.1875 - val_accuracy: 0.9445\n",
            "Epoch 4792/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2357 - accuracy: 0.9244 - val_loss: 0.1927 - val_accuracy: 0.9430\n",
            "Epoch 4793/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2564 - accuracy: 0.9201 - val_loss: 0.1891 - val_accuracy: 0.9450\n",
            "Epoch 4794/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2290 - accuracy: 0.9251 - val_loss: 0.1889 - val_accuracy: 0.9455\n",
            "Epoch 4795/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2339 - accuracy: 0.9259 - val_loss: 0.1886 - val_accuracy: 0.9450\n",
            "Epoch 4796/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2352 - accuracy: 0.9249 - val_loss: 0.1892 - val_accuracy: 0.9445\n",
            "Epoch 4797/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2254 - accuracy: 0.9279 - val_loss: 0.1870 - val_accuracy: 0.9460\n",
            "Epoch 4798/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2251 - accuracy: 0.9268 - val_loss: 0.1865 - val_accuracy: 0.9445\n",
            "Epoch 4799/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2336 - accuracy: 0.9258 - val_loss: 0.1836 - val_accuracy: 0.9450\n",
            "Epoch 4800/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2272 - accuracy: 0.9254 - val_loss: 0.1881 - val_accuracy: 0.9435\n",
            "Epoch 4801/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2365 - accuracy: 0.9264 - val_loss: 0.1890 - val_accuracy: 0.9435\n",
            "Epoch 4802/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2321 - accuracy: 0.9234 - val_loss: 0.1907 - val_accuracy: 0.9445\n",
            "Epoch 4803/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2456 - accuracy: 0.9252 - val_loss: 0.1857 - val_accuracy: 0.9450\n",
            "Epoch 4804/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2408 - accuracy: 0.9280 - val_loss: 0.1906 - val_accuracy: 0.9430\n",
            "Epoch 4805/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2422 - accuracy: 0.9243 - val_loss: 0.1890 - val_accuracy: 0.9455\n",
            "Epoch 4806/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2255 - accuracy: 0.9290 - val_loss: 0.1882 - val_accuracy: 0.9450\n",
            "Epoch 4807/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2323 - accuracy: 0.9269 - val_loss: 0.1863 - val_accuracy: 0.9455\n",
            "Epoch 4808/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2357 - accuracy: 0.9270 - val_loss: 0.1890 - val_accuracy: 0.9440\n",
            "Epoch 4809/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2234 - accuracy: 0.9277 - val_loss: 0.1867 - val_accuracy: 0.9455\n",
            "Epoch 4810/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2317 - accuracy: 0.9277 - val_loss: 0.1862 - val_accuracy: 0.9455\n",
            "Epoch 4811/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2360 - accuracy: 0.9281 - val_loss: 0.1877 - val_accuracy: 0.9445\n",
            "Epoch 4812/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2254 - accuracy: 0.9275 - val_loss: 0.1887 - val_accuracy: 0.9450\n",
            "Epoch 4813/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2280 - accuracy: 0.9283 - val_loss: 0.1890 - val_accuracy: 0.9455\n",
            "Epoch 4814/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2315 - accuracy: 0.9243 - val_loss: 0.1877 - val_accuracy: 0.9435\n",
            "Epoch 4815/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2278 - accuracy: 0.9266 - val_loss: 0.1865 - val_accuracy: 0.9455\n",
            "Epoch 4816/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2329 - accuracy: 0.9258 - val_loss: 0.1837 - val_accuracy: 0.9455\n",
            "Epoch 4817/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2314 - accuracy: 0.9269 - val_loss: 0.1828 - val_accuracy: 0.9450\n",
            "Epoch 4818/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2326 - accuracy: 0.9246 - val_loss: 0.1896 - val_accuracy: 0.9430\n",
            "Epoch 4819/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2269 - accuracy: 0.9261 - val_loss: 0.1864 - val_accuracy: 0.9445\n",
            "Epoch 4820/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2323 - accuracy: 0.9266 - val_loss: 0.1857 - val_accuracy: 0.9455\n",
            "Epoch 4821/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2281 - accuracy: 0.9264 - val_loss: 0.1873 - val_accuracy: 0.9450\n",
            "Epoch 4822/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2286 - accuracy: 0.9270 - val_loss: 0.1876 - val_accuracy: 0.9435\n",
            "Epoch 4823/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2355 - accuracy: 0.9240 - val_loss: 0.1899 - val_accuracy: 0.9410\n",
            "Epoch 4824/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2384 - accuracy: 0.9235 - val_loss: 0.1874 - val_accuracy: 0.9455\n",
            "Epoch 4825/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2308 - accuracy: 0.9259 - val_loss: 0.1939 - val_accuracy: 0.9445\n",
            "Epoch 4826/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2355 - accuracy: 0.9214 - val_loss: 0.1930 - val_accuracy: 0.9430\n",
            "Epoch 4827/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2290 - accuracy: 0.9281 - val_loss: 0.1864 - val_accuracy: 0.9445\n",
            "Epoch 4828/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2321 - accuracy: 0.9249 - val_loss: 0.1892 - val_accuracy: 0.9440\n",
            "Epoch 4829/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2375 - accuracy: 0.9277 - val_loss: 0.1903 - val_accuracy: 0.9450\n",
            "Epoch 4830/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2484 - accuracy: 0.9256 - val_loss: 0.1860 - val_accuracy: 0.9450\n",
            "Epoch 4831/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2254 - accuracy: 0.9250 - val_loss: 0.1874 - val_accuracy: 0.9440\n",
            "Epoch 4832/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2405 - accuracy: 0.9236 - val_loss: 0.1910 - val_accuracy: 0.9435\n",
            "Epoch 4833/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2246 - accuracy: 0.9249 - val_loss: 0.1885 - val_accuracy: 0.9430\n",
            "Epoch 4834/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2199 - accuracy: 0.9305 - val_loss: 0.1876 - val_accuracy: 0.9455\n",
            "Epoch 4835/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2321 - accuracy: 0.9230 - val_loss: 0.1910 - val_accuracy: 0.9445\n",
            "Epoch 4836/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2258 - accuracy: 0.9252 - val_loss: 0.1837 - val_accuracy: 0.9440\n",
            "Epoch 4837/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2350 - accuracy: 0.9221 - val_loss: 0.1876 - val_accuracy: 0.9450\n",
            "Epoch 4838/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2308 - accuracy: 0.9251 - val_loss: 0.1870 - val_accuracy: 0.9450\n",
            "Epoch 4839/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2313 - accuracy: 0.9254 - val_loss: 0.1869 - val_accuracy: 0.9445\n",
            "Epoch 4840/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2395 - accuracy: 0.9245 - val_loss: 0.1915 - val_accuracy: 0.9435\n",
            "Epoch 4841/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2383 - accuracy: 0.9252 - val_loss: 0.1890 - val_accuracy: 0.9440\n",
            "Epoch 4842/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2273 - accuracy: 0.9265 - val_loss: 0.1862 - val_accuracy: 0.9440\n",
            "Epoch 4843/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2275 - accuracy: 0.9280 - val_loss: 0.1883 - val_accuracy: 0.9450\n",
            "Epoch 4844/6000\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2337 - accuracy: 0.9273 - val_loss: 0.1854 - val_accuracy: 0.9450\n",
            "Epoch 4845/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2308 - accuracy: 0.9234 - val_loss: 0.1882 - val_accuracy: 0.9430\n",
            "Epoch 4846/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2255 - accuracy: 0.9270 - val_loss: 0.1868 - val_accuracy: 0.9445\n",
            "Epoch 4847/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2367 - accuracy: 0.9251 - val_loss: 0.1875 - val_accuracy: 0.9455\n",
            "Epoch 4848/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2283 - accuracy: 0.9247 - val_loss: 0.1880 - val_accuracy: 0.9445\n",
            "Epoch 4849/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2278 - accuracy: 0.9259 - val_loss: 0.1880 - val_accuracy: 0.9435\n",
            "Epoch 4850/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2273 - accuracy: 0.9268 - val_loss: 0.1891 - val_accuracy: 0.9440\n",
            "Epoch 4851/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2239 - accuracy: 0.9287 - val_loss: 0.1900 - val_accuracy: 0.9430\n",
            "Epoch 4852/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2291 - accuracy: 0.9245 - val_loss: 0.1925 - val_accuracy: 0.9440\n",
            "Epoch 4853/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2274 - accuracy: 0.9261 - val_loss: 0.1848 - val_accuracy: 0.9455\n",
            "Epoch 4854/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2333 - accuracy: 0.9252 - val_loss: 0.1920 - val_accuracy: 0.9430\n",
            "Epoch 4855/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2320 - accuracy: 0.9260 - val_loss: 0.1846 - val_accuracy: 0.9435\n",
            "Epoch 4856/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2445 - accuracy: 0.9279 - val_loss: 0.1901 - val_accuracy: 0.9440\n",
            "Epoch 4857/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2202 - accuracy: 0.9289 - val_loss: 0.1900 - val_accuracy: 0.9440\n",
            "Epoch 4858/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2355 - accuracy: 0.9273 - val_loss: 0.1888 - val_accuracy: 0.9440\n",
            "Epoch 4859/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2228 - accuracy: 0.9280 - val_loss: 0.1864 - val_accuracy: 0.9445\n",
            "Epoch 4860/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2172 - accuracy: 0.9281 - val_loss: 0.1907 - val_accuracy: 0.9430\n",
            "Epoch 4861/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2335 - accuracy: 0.9259 - val_loss: 0.1867 - val_accuracy: 0.9450\n",
            "Epoch 4862/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2294 - accuracy: 0.9252 - val_loss: 0.1848 - val_accuracy: 0.9455\n",
            "Epoch 4863/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2351 - accuracy: 0.9220 - val_loss: 0.1833 - val_accuracy: 0.9450\n",
            "Epoch 4864/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2225 - accuracy: 0.9280 - val_loss: 0.1831 - val_accuracy: 0.9460\n",
            "Epoch 4865/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2382 - accuracy: 0.9247 - val_loss: 0.1877 - val_accuracy: 0.9460\n",
            "Epoch 4866/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2255 - accuracy: 0.9275 - val_loss: 0.1904 - val_accuracy: 0.9430\n",
            "Epoch 4867/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2292 - accuracy: 0.9246 - val_loss: 0.1852 - val_accuracy: 0.9450\n",
            "Epoch 4868/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2243 - accuracy: 0.9285 - val_loss: 0.1857 - val_accuracy: 0.9435\n",
            "Epoch 4869/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2326 - accuracy: 0.9259 - val_loss: 0.1895 - val_accuracy: 0.9455\n",
            "Epoch 4870/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2342 - accuracy: 0.9249 - val_loss: 0.1980 - val_accuracy: 0.9400\n",
            "Epoch 4871/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2308 - accuracy: 0.9239 - val_loss: 0.1903 - val_accuracy: 0.9435\n",
            "Epoch 4872/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2245 - accuracy: 0.9284 - val_loss: 0.1891 - val_accuracy: 0.9435\n",
            "Epoch 4873/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2219 - accuracy: 0.9294 - val_loss: 0.1877 - val_accuracy: 0.9450\n",
            "Epoch 4874/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2208 - accuracy: 0.9276 - val_loss: 0.1884 - val_accuracy: 0.9450\n",
            "Epoch 4875/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2428 - accuracy: 0.9235 - val_loss: 0.1846 - val_accuracy: 0.9455\n",
            "Epoch 4876/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2317 - accuracy: 0.9255 - val_loss: 0.1945 - val_accuracy: 0.9440\n",
            "Epoch 4877/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2273 - accuracy: 0.9269 - val_loss: 0.1866 - val_accuracy: 0.9430\n",
            "Epoch 4878/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2357 - accuracy: 0.9260 - val_loss: 0.1883 - val_accuracy: 0.9445\n",
            "Epoch 4879/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2356 - accuracy: 0.9254 - val_loss: 0.1876 - val_accuracy: 0.9455\n",
            "Epoch 4880/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2295 - accuracy: 0.9280 - val_loss: 0.1878 - val_accuracy: 0.9435\n",
            "Epoch 4881/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2265 - accuracy: 0.9284 - val_loss: 0.1880 - val_accuracy: 0.9455\n",
            "Epoch 4882/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2430 - accuracy: 0.9225 - val_loss: 0.1842 - val_accuracy: 0.9450\n",
            "Epoch 4883/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2302 - accuracy: 0.9270 - val_loss: 0.1877 - val_accuracy: 0.9455\n",
            "Epoch 4884/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2432 - accuracy: 0.9220 - val_loss: 0.1896 - val_accuracy: 0.9440\n",
            "Epoch 4885/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2393 - accuracy: 0.9241 - val_loss: 0.1886 - val_accuracy: 0.9455\n",
            "Epoch 4886/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2340 - accuracy: 0.9221 - val_loss: 0.1890 - val_accuracy: 0.9450\n",
            "Epoch 4887/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2296 - accuracy: 0.9269 - val_loss: 0.1889 - val_accuracy: 0.9440\n",
            "Epoch 4888/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2333 - accuracy: 0.9239 - val_loss: 0.1875 - val_accuracy: 0.9460\n",
            "Epoch 4889/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2276 - accuracy: 0.9284 - val_loss: 0.1860 - val_accuracy: 0.9445\n",
            "Epoch 4890/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2292 - accuracy: 0.9274 - val_loss: 0.1863 - val_accuracy: 0.9450\n",
            "Epoch 4891/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2264 - accuracy: 0.9245 - val_loss: 0.1866 - val_accuracy: 0.9435\n",
            "Epoch 4892/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2326 - accuracy: 0.9270 - val_loss: 0.1907 - val_accuracy: 0.9435\n",
            "Epoch 4893/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2330 - accuracy: 0.9268 - val_loss: 0.1892 - val_accuracy: 0.9445\n",
            "Epoch 4894/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2348 - accuracy: 0.9234 - val_loss: 0.1925 - val_accuracy: 0.9435\n",
            "Epoch 4895/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2401 - accuracy: 0.9239 - val_loss: 0.1880 - val_accuracy: 0.9425\n",
            "Epoch 4896/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2297 - accuracy: 0.9241 - val_loss: 0.1810 - val_accuracy: 0.9460\n",
            "Epoch 4897/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2279 - accuracy: 0.9252 - val_loss: 0.1894 - val_accuracy: 0.9455\n",
            "Epoch 4898/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2287 - accuracy: 0.9251 - val_loss: 0.1872 - val_accuracy: 0.9425\n",
            "Epoch 4899/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2378 - accuracy: 0.9241 - val_loss: 0.1936 - val_accuracy: 0.9415\n",
            "Epoch 4900/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2340 - accuracy: 0.9279 - val_loss: 0.1857 - val_accuracy: 0.9455\n",
            "Epoch 4901/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2303 - accuracy: 0.9261 - val_loss: 0.1879 - val_accuracy: 0.9430\n",
            "Epoch 4902/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2273 - accuracy: 0.9249 - val_loss: 0.1897 - val_accuracy: 0.9430\n",
            "Epoch 4903/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2299 - accuracy: 0.9286 - val_loss: 0.1867 - val_accuracy: 0.9435\n",
            "Epoch 4904/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2384 - accuracy: 0.9247 - val_loss: 0.1832 - val_accuracy: 0.9450\n",
            "Epoch 4905/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2304 - accuracy: 0.9241 - val_loss: 0.1875 - val_accuracy: 0.9460\n",
            "Epoch 4906/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2352 - accuracy: 0.9268 - val_loss: 0.1876 - val_accuracy: 0.9455\n",
            "Epoch 4907/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2302 - accuracy: 0.9249 - val_loss: 0.1872 - val_accuracy: 0.9450\n",
            "Epoch 4908/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2277 - accuracy: 0.9249 - val_loss: 0.1820 - val_accuracy: 0.9465\n",
            "Epoch 4909/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2302 - accuracy: 0.9254 - val_loss: 0.1912 - val_accuracy: 0.9440\n",
            "Epoch 4910/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2350 - accuracy: 0.9246 - val_loss: 0.1836 - val_accuracy: 0.9460\n",
            "Epoch 4911/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2309 - accuracy: 0.9265 - val_loss: 0.1912 - val_accuracy: 0.9430\n",
            "Epoch 4912/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2406 - accuracy: 0.9208 - val_loss: 0.1883 - val_accuracy: 0.9445\n",
            "Epoch 4913/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2305 - accuracy: 0.9244 - val_loss: 0.1864 - val_accuracy: 0.9440\n",
            "Epoch 4914/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2304 - accuracy: 0.9259 - val_loss: 0.1875 - val_accuracy: 0.9435\n",
            "Epoch 4915/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2246 - accuracy: 0.9293 - val_loss: 0.1896 - val_accuracy: 0.9450\n",
            "Epoch 4916/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2354 - accuracy: 0.9215 - val_loss: 0.1873 - val_accuracy: 0.9430\n",
            "Epoch 4917/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2266 - accuracy: 0.9285 - val_loss: 0.1858 - val_accuracy: 0.9440\n",
            "Epoch 4918/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2293 - accuracy: 0.9251 - val_loss: 0.1854 - val_accuracy: 0.9445\n",
            "Epoch 4919/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2296 - accuracy: 0.9250 - val_loss: 0.1901 - val_accuracy: 0.9450\n",
            "Epoch 4920/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2324 - accuracy: 0.9224 - val_loss: 0.1850 - val_accuracy: 0.9450\n",
            "Epoch 4921/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2300 - accuracy: 0.9244 - val_loss: 0.1870 - val_accuracy: 0.9450\n",
            "Epoch 4922/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2323 - accuracy: 0.9221 - val_loss: 0.1951 - val_accuracy: 0.9420\n",
            "Epoch 4923/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2241 - accuracy: 0.9262 - val_loss: 0.1854 - val_accuracy: 0.9455\n",
            "Epoch 4924/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2285 - accuracy: 0.9287 - val_loss: 0.1858 - val_accuracy: 0.9455\n",
            "Epoch 4925/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2313 - accuracy: 0.9237 - val_loss: 0.1886 - val_accuracy: 0.9450\n",
            "Epoch 4926/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2334 - accuracy: 0.9266 - val_loss: 0.1890 - val_accuracy: 0.9455\n",
            "Epoch 4927/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2270 - accuracy: 0.9266 - val_loss: 0.1866 - val_accuracy: 0.9465\n",
            "Epoch 4928/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2229 - accuracy: 0.9295 - val_loss: 0.1854 - val_accuracy: 0.9440\n",
            "Epoch 4929/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2332 - accuracy: 0.9243 - val_loss: 0.1900 - val_accuracy: 0.9440\n",
            "Epoch 4930/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2330 - accuracy: 0.9249 - val_loss: 0.1881 - val_accuracy: 0.9445\n",
            "Epoch 4931/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2331 - accuracy: 0.9285 - val_loss: 0.1897 - val_accuracy: 0.9450\n",
            "Epoch 4932/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2241 - accuracy: 0.9276 - val_loss: 0.1854 - val_accuracy: 0.9445\n",
            "Epoch 4933/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2294 - accuracy: 0.9262 - val_loss: 0.1904 - val_accuracy: 0.9435\n",
            "Epoch 4934/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2234 - accuracy: 0.9291 - val_loss: 0.1906 - val_accuracy: 0.9435\n",
            "Epoch 4935/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2407 - accuracy: 0.9279 - val_loss: 0.1877 - val_accuracy: 0.9450\n",
            "Epoch 4936/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2259 - accuracy: 0.9259 - val_loss: 0.1825 - val_accuracy: 0.9450\n",
            "Epoch 4937/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2263 - accuracy: 0.9252 - val_loss: 0.1847 - val_accuracy: 0.9450\n",
            "Epoch 4938/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2206 - accuracy: 0.9277 - val_loss: 0.1846 - val_accuracy: 0.9455\n",
            "Epoch 4939/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2377 - accuracy: 0.9239 - val_loss: 0.1901 - val_accuracy: 0.9440\n",
            "Epoch 4940/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2349 - accuracy: 0.9244 - val_loss: 0.1806 - val_accuracy: 0.9455\n",
            "Epoch 4941/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2341 - accuracy: 0.9239 - val_loss: 0.1873 - val_accuracy: 0.9460\n",
            "Epoch 4942/6000\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2337 - accuracy: 0.9255 - val_loss: 0.1864 - val_accuracy: 0.9450\n",
            "Epoch 4943/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2291 - accuracy: 0.9274 - val_loss: 0.1883 - val_accuracy: 0.9440\n",
            "Epoch 4944/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2288 - accuracy: 0.9239 - val_loss: 0.1862 - val_accuracy: 0.9455\n",
            "Epoch 4945/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2293 - accuracy: 0.9258 - val_loss: 0.1832 - val_accuracy: 0.9455\n",
            "Epoch 4946/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2300 - accuracy: 0.9262 - val_loss: 0.1849 - val_accuracy: 0.9455\n",
            "Epoch 4947/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2336 - accuracy: 0.9264 - val_loss: 0.1883 - val_accuracy: 0.9450\n",
            "Epoch 4948/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2315 - accuracy: 0.9252 - val_loss: 0.1842 - val_accuracy: 0.9445\n",
            "Epoch 4949/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2275 - accuracy: 0.9280 - val_loss: 0.1845 - val_accuracy: 0.9455\n",
            "Epoch 4950/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2313 - accuracy: 0.9270 - val_loss: 0.1846 - val_accuracy: 0.9455\n",
            "Epoch 4951/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2352 - accuracy: 0.9243 - val_loss: 0.1840 - val_accuracy: 0.9450\n",
            "Epoch 4952/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2294 - accuracy: 0.9277 - val_loss: 0.1814 - val_accuracy: 0.9450\n",
            "Epoch 4953/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2287 - accuracy: 0.9265 - val_loss: 0.1890 - val_accuracy: 0.9455\n",
            "Epoch 4954/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2321 - accuracy: 0.9256 - val_loss: 0.1900 - val_accuracy: 0.9455\n",
            "Epoch 4955/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2294 - accuracy: 0.9262 - val_loss: 0.1878 - val_accuracy: 0.9450\n",
            "Epoch 4956/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2287 - accuracy: 0.9266 - val_loss: 0.1899 - val_accuracy: 0.9445\n",
            "Epoch 4957/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2403 - accuracy: 0.9273 - val_loss: 0.1852 - val_accuracy: 0.9460\n",
            "Epoch 4958/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2253 - accuracy: 0.9266 - val_loss: 0.1856 - val_accuracy: 0.9445\n",
            "Epoch 4959/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2316 - accuracy: 0.9244 - val_loss: 0.1859 - val_accuracy: 0.9450\n",
            "Epoch 4960/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2290 - accuracy: 0.9236 - val_loss: 0.1881 - val_accuracy: 0.9440\n",
            "Epoch 4961/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2293 - accuracy: 0.9230 - val_loss: 0.1856 - val_accuracy: 0.9440\n",
            "Epoch 4962/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2413 - accuracy: 0.9259 - val_loss: 0.1890 - val_accuracy: 0.9440\n",
            "Epoch 4963/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2351 - accuracy: 0.9233 - val_loss: 0.1847 - val_accuracy: 0.9450\n",
            "Epoch 4964/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2357 - accuracy: 0.9208 - val_loss: 0.1914 - val_accuracy: 0.9450\n",
            "Epoch 4965/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2275 - accuracy: 0.9250 - val_loss: 0.1834 - val_accuracy: 0.9465\n",
            "Epoch 4966/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2256 - accuracy: 0.9285 - val_loss: 0.1835 - val_accuracy: 0.9445\n",
            "Epoch 4967/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2327 - accuracy: 0.9287 - val_loss: 0.1872 - val_accuracy: 0.9430\n",
            "Epoch 4968/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2219 - accuracy: 0.9290 - val_loss: 0.1856 - val_accuracy: 0.9445\n",
            "Epoch 4969/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2271 - accuracy: 0.9290 - val_loss: 0.1850 - val_accuracy: 0.9435\n",
            "Epoch 4970/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2353 - accuracy: 0.9256 - val_loss: 0.1892 - val_accuracy: 0.9425\n",
            "Epoch 4971/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2280 - accuracy: 0.9259 - val_loss: 0.1933 - val_accuracy: 0.9420\n",
            "Epoch 4972/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2376 - accuracy: 0.9273 - val_loss: 0.1936 - val_accuracy: 0.9440\n",
            "Epoch 4973/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2313 - accuracy: 0.9246 - val_loss: 0.1877 - val_accuracy: 0.9460\n",
            "Epoch 4974/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2318 - accuracy: 0.9241 - val_loss: 0.1861 - val_accuracy: 0.9435\n",
            "Epoch 4975/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2255 - accuracy: 0.9269 - val_loss: 0.1873 - val_accuracy: 0.9460\n",
            "Epoch 4976/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2270 - accuracy: 0.9279 - val_loss: 0.1886 - val_accuracy: 0.9430\n",
            "Epoch 4977/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2283 - accuracy: 0.9265 - val_loss: 0.1858 - val_accuracy: 0.9445\n",
            "Epoch 4978/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2490 - accuracy: 0.9243 - val_loss: 0.1886 - val_accuracy: 0.9435\n",
            "Epoch 4979/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2354 - accuracy: 0.9277 - val_loss: 0.1834 - val_accuracy: 0.9455\n",
            "Epoch 4980/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2315 - accuracy: 0.9233 - val_loss: 0.1895 - val_accuracy: 0.9445\n",
            "Epoch 4981/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2297 - accuracy: 0.9261 - val_loss: 0.1904 - val_accuracy: 0.9455\n",
            "Epoch 4982/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2305 - accuracy: 0.9222 - val_loss: 0.1841 - val_accuracy: 0.9440\n",
            "Epoch 4983/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2267 - accuracy: 0.9251 - val_loss: 0.1830 - val_accuracy: 0.9460\n",
            "Epoch 4984/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2374 - accuracy: 0.9276 - val_loss: 0.1906 - val_accuracy: 0.9445\n",
            "Epoch 4985/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2270 - accuracy: 0.9274 - val_loss: 0.1862 - val_accuracy: 0.9440\n",
            "Epoch 4986/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2417 - accuracy: 0.9210 - val_loss: 0.1880 - val_accuracy: 0.9450\n",
            "Epoch 4987/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2302 - accuracy: 0.9245 - val_loss: 0.1882 - val_accuracy: 0.9450\n",
            "Epoch 4988/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2323 - accuracy: 0.9258 - val_loss: 0.1856 - val_accuracy: 0.9450\n",
            "Epoch 4989/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2339 - accuracy: 0.9244 - val_loss: 0.1877 - val_accuracy: 0.9450\n",
            "Epoch 4990/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2386 - accuracy: 0.9234 - val_loss: 0.1857 - val_accuracy: 0.9440\n",
            "Epoch 4991/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2252 - accuracy: 0.9268 - val_loss: 0.1852 - val_accuracy: 0.9450\n",
            "Epoch 4992/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2306 - accuracy: 0.9276 - val_loss: 0.1861 - val_accuracy: 0.9450\n",
            "Epoch 4993/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2273 - accuracy: 0.9275 - val_loss: 0.1859 - val_accuracy: 0.9460\n",
            "Epoch 4994/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2344 - accuracy: 0.9235 - val_loss: 0.1860 - val_accuracy: 0.9460\n",
            "Epoch 4995/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2321 - accuracy: 0.9255 - val_loss: 0.1896 - val_accuracy: 0.9450\n",
            "Epoch 4996/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2332 - accuracy: 0.9231 - val_loss: 0.1895 - val_accuracy: 0.9445\n",
            "Epoch 4997/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2340 - accuracy: 0.9227 - val_loss: 0.1861 - val_accuracy: 0.9435\n",
            "Epoch 4998/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2340 - accuracy: 0.9279 - val_loss: 0.1869 - val_accuracy: 0.9440\n",
            "Epoch 4999/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2289 - accuracy: 0.9255 - val_loss: 0.1883 - val_accuracy: 0.9420\n",
            "Epoch 5000/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2255 - accuracy: 0.9312 - val_loss: 0.1886 - val_accuracy: 0.9435\n",
            "Epoch 5001/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2419 - accuracy: 0.9246 - val_loss: 0.1882 - val_accuracy: 0.9445\n",
            "Epoch 5002/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2258 - accuracy: 0.9275 - val_loss: 0.1859 - val_accuracy: 0.9470\n",
            "Epoch 5003/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2244 - accuracy: 0.9252 - val_loss: 0.1892 - val_accuracy: 0.9455\n",
            "Epoch 5004/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2285 - accuracy: 0.9264 - val_loss: 0.1854 - val_accuracy: 0.9450\n",
            "Epoch 5005/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2260 - accuracy: 0.9241 - val_loss: 0.1854 - val_accuracy: 0.9445\n",
            "Epoch 5006/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2237 - accuracy: 0.9279 - val_loss: 0.1889 - val_accuracy: 0.9440\n",
            "Epoch 5007/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2278 - accuracy: 0.9231 - val_loss: 0.1841 - val_accuracy: 0.9455\n",
            "Epoch 5008/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2363 - accuracy: 0.9236 - val_loss: 0.1890 - val_accuracy: 0.9450\n",
            "Epoch 5009/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2294 - accuracy: 0.9256 - val_loss: 0.1894 - val_accuracy: 0.9425\n",
            "Epoch 5010/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2343 - accuracy: 0.9274 - val_loss: 0.1908 - val_accuracy: 0.9440\n",
            "Epoch 5011/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2355 - accuracy: 0.9268 - val_loss: 0.1877 - val_accuracy: 0.9425\n",
            "Epoch 5012/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2338 - accuracy: 0.9225 - val_loss: 0.1894 - val_accuracy: 0.9435\n",
            "Epoch 5013/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2347 - accuracy: 0.9264 - val_loss: 0.1845 - val_accuracy: 0.9455\n",
            "Epoch 5014/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2300 - accuracy: 0.9225 - val_loss: 0.1935 - val_accuracy: 0.9420\n",
            "Epoch 5015/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2310 - accuracy: 0.9227 - val_loss: 0.1862 - val_accuracy: 0.9450\n",
            "Epoch 5016/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2193 - accuracy: 0.9279 - val_loss: 0.1852 - val_accuracy: 0.9455\n",
            "Epoch 5017/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2313 - accuracy: 0.9262 - val_loss: 0.1888 - val_accuracy: 0.9445\n",
            "Epoch 5018/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2310 - accuracy: 0.9245 - val_loss: 0.1862 - val_accuracy: 0.9465\n",
            "Epoch 5019/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2286 - accuracy: 0.9302 - val_loss: 0.1857 - val_accuracy: 0.9465\n",
            "Epoch 5020/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2230 - accuracy: 0.9265 - val_loss: 0.1910 - val_accuracy: 0.9440\n",
            "Epoch 5021/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2357 - accuracy: 0.9261 - val_loss: 0.1874 - val_accuracy: 0.9440\n",
            "Epoch 5022/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2366 - accuracy: 0.9231 - val_loss: 0.1839 - val_accuracy: 0.9445\n",
            "Epoch 5023/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2250 - accuracy: 0.9271 - val_loss: 0.1864 - val_accuracy: 0.9455\n",
            "Epoch 5024/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2308 - accuracy: 0.9261 - val_loss: 0.1873 - val_accuracy: 0.9460\n",
            "Epoch 5025/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2277 - accuracy: 0.9252 - val_loss: 0.1910 - val_accuracy: 0.9445\n",
            "Epoch 5026/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2268 - accuracy: 0.9289 - val_loss: 0.1867 - val_accuracy: 0.9465\n",
            "Epoch 5027/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2306 - accuracy: 0.9271 - val_loss: 0.1868 - val_accuracy: 0.9440\n",
            "Epoch 5028/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2258 - accuracy: 0.9275 - val_loss: 0.1890 - val_accuracy: 0.9445\n",
            "Epoch 5029/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2273 - accuracy: 0.9279 - val_loss: 0.1901 - val_accuracy: 0.9440\n",
            "Epoch 5030/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2300 - accuracy: 0.9261 - val_loss: 0.1903 - val_accuracy: 0.9450\n",
            "Epoch 5031/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2290 - accuracy: 0.9235 - val_loss: 0.1875 - val_accuracy: 0.9440\n",
            "Epoch 5032/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2320 - accuracy: 0.9273 - val_loss: 0.1898 - val_accuracy: 0.9450\n",
            "Epoch 5033/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2363 - accuracy: 0.9191 - val_loss: 0.1918 - val_accuracy: 0.9450\n",
            "Epoch 5034/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2254 - accuracy: 0.9271 - val_loss: 0.1893 - val_accuracy: 0.9440\n",
            "Epoch 5035/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2271 - accuracy: 0.9251 - val_loss: 0.1931 - val_accuracy: 0.9435\n",
            "Epoch 5036/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2274 - accuracy: 0.9275 - val_loss: 0.1860 - val_accuracy: 0.9465\n",
            "Epoch 5037/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2324 - accuracy: 0.9234 - val_loss: 0.1876 - val_accuracy: 0.9450\n",
            "Epoch 5038/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2382 - accuracy: 0.9258 - val_loss: 0.1872 - val_accuracy: 0.9450\n",
            "Epoch 5039/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2389 - accuracy: 0.9218 - val_loss: 0.1878 - val_accuracy: 0.9455\n",
            "Epoch 5040/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2271 - accuracy: 0.9270 - val_loss: 0.1873 - val_accuracy: 0.9460\n",
            "Epoch 5041/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2473 - accuracy: 0.9266 - val_loss: 0.1882 - val_accuracy: 0.9455\n",
            "Epoch 5042/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2292 - accuracy: 0.9260 - val_loss: 0.1880 - val_accuracy: 0.9440\n",
            "Epoch 5043/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2280 - accuracy: 0.9279 - val_loss: 0.1883 - val_accuracy: 0.9430\n",
            "Epoch 5044/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2262 - accuracy: 0.9258 - val_loss: 0.1861 - val_accuracy: 0.9440\n",
            "Epoch 5045/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2353 - accuracy: 0.9224 - val_loss: 0.1867 - val_accuracy: 0.9450\n",
            "Epoch 5046/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2270 - accuracy: 0.9281 - val_loss: 0.1863 - val_accuracy: 0.9440\n",
            "Epoch 5047/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2321 - accuracy: 0.9254 - val_loss: 0.1916 - val_accuracy: 0.9425\n",
            "Epoch 5048/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2239 - accuracy: 0.9319 - val_loss: 0.1871 - val_accuracy: 0.9435\n",
            "Epoch 5049/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2333 - accuracy: 0.9266 - val_loss: 0.1846 - val_accuracy: 0.9455\n",
            "Epoch 5050/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2350 - accuracy: 0.9250 - val_loss: 0.1874 - val_accuracy: 0.9445\n",
            "Epoch 5051/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2252 - accuracy: 0.9299 - val_loss: 0.1875 - val_accuracy: 0.9455\n",
            "Epoch 5052/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2233 - accuracy: 0.9271 - val_loss: 0.1894 - val_accuracy: 0.9445\n",
            "Epoch 5053/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2309 - accuracy: 0.9274 - val_loss: 0.1902 - val_accuracy: 0.9440\n",
            "Epoch 5054/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2287 - accuracy: 0.9274 - val_loss: 0.1920 - val_accuracy: 0.9445\n",
            "Epoch 5055/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2377 - accuracy: 0.9231 - val_loss: 0.1902 - val_accuracy: 0.9435\n",
            "Epoch 5056/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2305 - accuracy: 0.9264 - val_loss: 0.1885 - val_accuracy: 0.9445\n",
            "Epoch 5057/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2202 - accuracy: 0.9279 - val_loss: 0.1863 - val_accuracy: 0.9455\n",
            "Epoch 5058/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2329 - accuracy: 0.9280 - val_loss: 0.1850 - val_accuracy: 0.9450\n",
            "Epoch 5059/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2249 - accuracy: 0.9279 - val_loss: 0.1878 - val_accuracy: 0.9455\n",
            "Epoch 5060/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2278 - accuracy: 0.9262 - val_loss: 0.1903 - val_accuracy: 0.9435\n",
            "Epoch 5061/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2223 - accuracy: 0.9279 - val_loss: 0.1869 - val_accuracy: 0.9445\n",
            "Epoch 5062/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2221 - accuracy: 0.9277 - val_loss: 0.1883 - val_accuracy: 0.9450\n",
            "Epoch 5063/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2320 - accuracy: 0.9255 - val_loss: 0.1956 - val_accuracy: 0.9405\n",
            "Epoch 5064/6000\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2308 - accuracy: 0.9251 - val_loss: 0.1883 - val_accuracy: 0.9455\n",
            "Epoch 5065/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2282 - accuracy: 0.9271 - val_loss: 0.1907 - val_accuracy: 0.9440\n",
            "Epoch 5066/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2336 - accuracy: 0.9255 - val_loss: 0.1868 - val_accuracy: 0.9440\n",
            "Epoch 5067/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2331 - accuracy: 0.9233 - val_loss: 0.1907 - val_accuracy: 0.9445\n",
            "Epoch 5068/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2196 - accuracy: 0.9298 - val_loss: 0.1945 - val_accuracy: 0.9415\n",
            "Epoch 5069/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2283 - accuracy: 0.9268 - val_loss: 0.1902 - val_accuracy: 0.9450\n",
            "Epoch 5070/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2338 - accuracy: 0.9259 - val_loss: 0.1888 - val_accuracy: 0.9435\n",
            "Epoch 5071/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2276 - accuracy: 0.9249 - val_loss: 0.1905 - val_accuracy: 0.9435\n",
            "Epoch 5072/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2238 - accuracy: 0.9296 - val_loss: 0.1836 - val_accuracy: 0.9450\n",
            "Epoch 5073/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2274 - accuracy: 0.9235 - val_loss: 0.1877 - val_accuracy: 0.9435\n",
            "Epoch 5074/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2212 - accuracy: 0.9283 - val_loss: 0.1926 - val_accuracy: 0.9425\n",
            "Epoch 5075/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2258 - accuracy: 0.9277 - val_loss: 0.1895 - val_accuracy: 0.9425\n",
            "Epoch 5076/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2338 - accuracy: 0.9247 - val_loss: 0.1881 - val_accuracy: 0.9435\n",
            "Epoch 5077/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2259 - accuracy: 0.9259 - val_loss: 0.1923 - val_accuracy: 0.9440\n",
            "Epoch 5078/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2322 - accuracy: 0.9230 - val_loss: 0.1915 - val_accuracy: 0.9435\n",
            "Epoch 5079/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2343 - accuracy: 0.9243 - val_loss: 0.1897 - val_accuracy: 0.9445\n",
            "Epoch 5080/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2369 - accuracy: 0.9275 - val_loss: 0.1901 - val_accuracy: 0.9440\n",
            "Epoch 5081/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2288 - accuracy: 0.9262 - val_loss: 0.1884 - val_accuracy: 0.9440\n",
            "Epoch 5082/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2234 - accuracy: 0.9261 - val_loss: 0.1906 - val_accuracy: 0.9435\n",
            "Epoch 5083/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2268 - accuracy: 0.9262 - val_loss: 0.1891 - val_accuracy: 0.9450\n",
            "Epoch 5084/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2310 - accuracy: 0.9269 - val_loss: 0.1865 - val_accuracy: 0.9450\n",
            "Epoch 5085/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2285 - accuracy: 0.9260 - val_loss: 0.1905 - val_accuracy: 0.9420\n",
            "Epoch 5086/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2325 - accuracy: 0.9239 - val_loss: 0.1942 - val_accuracy: 0.9415\n",
            "Epoch 5087/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2295 - accuracy: 0.9265 - val_loss: 0.1939 - val_accuracy: 0.9420\n",
            "Epoch 5088/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2304 - accuracy: 0.9270 - val_loss: 0.1870 - val_accuracy: 0.9430\n",
            "Epoch 5089/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2259 - accuracy: 0.9281 - val_loss: 0.1902 - val_accuracy: 0.9430\n",
            "Epoch 5090/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2242 - accuracy: 0.9258 - val_loss: 0.1959 - val_accuracy: 0.9405\n",
            "Epoch 5091/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2223 - accuracy: 0.9294 - val_loss: 0.1891 - val_accuracy: 0.9430\n",
            "Epoch 5092/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2224 - accuracy: 0.9280 - val_loss: 0.1894 - val_accuracy: 0.9435\n",
            "Epoch 5093/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2348 - accuracy: 0.9195 - val_loss: 0.1932 - val_accuracy: 0.9425\n",
            "Epoch 5094/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2262 - accuracy: 0.9281 - val_loss: 0.1884 - val_accuracy: 0.9440\n",
            "Epoch 5095/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2342 - accuracy: 0.9256 - val_loss: 0.1875 - val_accuracy: 0.9435\n",
            "Epoch 5096/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2265 - accuracy: 0.9280 - val_loss: 0.1832 - val_accuracy: 0.9445\n",
            "Epoch 5097/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2359 - accuracy: 0.9221 - val_loss: 0.1921 - val_accuracy: 0.9420\n",
            "Epoch 5098/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2262 - accuracy: 0.9260 - val_loss: 0.1868 - val_accuracy: 0.9445\n",
            "Epoch 5099/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2287 - accuracy: 0.9264 - val_loss: 0.1868 - val_accuracy: 0.9440\n",
            "Epoch 5100/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2341 - accuracy: 0.9284 - val_loss: 0.1915 - val_accuracy: 0.9420\n",
            "Epoch 5101/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2476 - accuracy: 0.9256 - val_loss: 0.1847 - val_accuracy: 0.9465\n",
            "Epoch 5102/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2251 - accuracy: 0.9270 - val_loss: 0.1891 - val_accuracy: 0.9445\n",
            "Epoch 5103/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2411 - accuracy: 0.9241 - val_loss: 0.1884 - val_accuracy: 0.9455\n",
            "Epoch 5104/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2203 - accuracy: 0.9273 - val_loss: 0.1846 - val_accuracy: 0.9450\n",
            "Epoch 5105/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2320 - accuracy: 0.9258 - val_loss: 0.1853 - val_accuracy: 0.9465\n",
            "Epoch 5106/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2218 - accuracy: 0.9286 - val_loss: 0.1897 - val_accuracy: 0.9450\n",
            "Epoch 5107/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2300 - accuracy: 0.9264 - val_loss: 0.1859 - val_accuracy: 0.9435\n",
            "Epoch 5108/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2243 - accuracy: 0.9285 - val_loss: 0.1908 - val_accuracy: 0.9435\n",
            "Epoch 5109/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2334 - accuracy: 0.9240 - val_loss: 0.1895 - val_accuracy: 0.9460\n",
            "Epoch 5110/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2252 - accuracy: 0.9261 - val_loss: 0.1900 - val_accuracy: 0.9445\n",
            "Epoch 5111/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2349 - accuracy: 0.9249 - val_loss: 0.1902 - val_accuracy: 0.9440\n",
            "Epoch 5112/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2299 - accuracy: 0.9277 - val_loss: 0.1905 - val_accuracy: 0.9445\n",
            "Epoch 5113/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2271 - accuracy: 0.9236 - val_loss: 0.1863 - val_accuracy: 0.9465\n",
            "Epoch 5114/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2241 - accuracy: 0.9296 - val_loss: 0.1886 - val_accuracy: 0.9450\n",
            "Epoch 5115/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2418 - accuracy: 0.9219 - val_loss: 0.1907 - val_accuracy: 0.9460\n",
            "Epoch 5116/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2238 - accuracy: 0.9302 - val_loss: 0.1887 - val_accuracy: 0.9445\n",
            "Epoch 5117/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2293 - accuracy: 0.9249 - val_loss: 0.1912 - val_accuracy: 0.9435\n",
            "Epoch 5118/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2339 - accuracy: 0.9241 - val_loss: 0.1913 - val_accuracy: 0.9460\n",
            "Epoch 5119/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2256 - accuracy: 0.9269 - val_loss: 0.1861 - val_accuracy: 0.9445\n",
            "Epoch 5120/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2350 - accuracy: 0.9254 - val_loss: 0.1923 - val_accuracy: 0.9430\n",
            "Epoch 5121/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2371 - accuracy: 0.9254 - val_loss: 0.1855 - val_accuracy: 0.9455\n",
            "Epoch 5122/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2297 - accuracy: 0.9281 - val_loss: 0.1927 - val_accuracy: 0.9435\n",
            "Epoch 5123/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2321 - accuracy: 0.9241 - val_loss: 0.1905 - val_accuracy: 0.9440\n",
            "Epoch 5124/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2287 - accuracy: 0.9254 - val_loss: 0.1866 - val_accuracy: 0.9420\n",
            "Epoch 5125/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2366 - accuracy: 0.9243 - val_loss: 0.1834 - val_accuracy: 0.9450\n",
            "Epoch 5126/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2320 - accuracy: 0.9271 - val_loss: 0.1856 - val_accuracy: 0.9455\n",
            "Epoch 5127/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2318 - accuracy: 0.9241 - val_loss: 0.1852 - val_accuracy: 0.9445\n",
            "Epoch 5128/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2286 - accuracy: 0.9237 - val_loss: 0.1880 - val_accuracy: 0.9460\n",
            "Epoch 5129/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2269 - accuracy: 0.9265 - val_loss: 0.1847 - val_accuracy: 0.9445\n",
            "Epoch 5130/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2235 - accuracy: 0.9287 - val_loss: 0.1887 - val_accuracy: 0.9440\n",
            "Epoch 5131/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2287 - accuracy: 0.9270 - val_loss: 0.1888 - val_accuracy: 0.9445\n",
            "Epoch 5132/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2208 - accuracy: 0.9320 - val_loss: 0.1826 - val_accuracy: 0.9460\n",
            "Epoch 5133/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2248 - accuracy: 0.9273 - val_loss: 0.1889 - val_accuracy: 0.9445\n",
            "Epoch 5134/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2265 - accuracy: 0.9273 - val_loss: 0.1905 - val_accuracy: 0.9445\n",
            "Epoch 5135/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2301 - accuracy: 0.9276 - val_loss: 0.1889 - val_accuracy: 0.9430\n",
            "Epoch 5136/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2241 - accuracy: 0.9284 - val_loss: 0.1891 - val_accuracy: 0.9430\n",
            "Epoch 5137/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2263 - accuracy: 0.9251 - val_loss: 0.1891 - val_accuracy: 0.9445\n",
            "Epoch 5138/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2325 - accuracy: 0.9234 - val_loss: 0.1885 - val_accuracy: 0.9445\n",
            "Epoch 5139/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2231 - accuracy: 0.9254 - val_loss: 0.1916 - val_accuracy: 0.9440\n",
            "Epoch 5140/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2386 - accuracy: 0.9220 - val_loss: 0.1885 - val_accuracy: 0.9435\n",
            "Epoch 5141/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2355 - accuracy: 0.9261 - val_loss: 0.1874 - val_accuracy: 0.9440\n",
            "Epoch 5142/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2246 - accuracy: 0.9281 - val_loss: 0.1912 - val_accuracy: 0.9410\n",
            "Epoch 5143/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2243 - accuracy: 0.9294 - val_loss: 0.1867 - val_accuracy: 0.9445\n",
            "Epoch 5144/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2489 - accuracy: 0.9265 - val_loss: 0.1909 - val_accuracy: 0.9440\n",
            "Epoch 5145/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2299 - accuracy: 0.9259 - val_loss: 0.1926 - val_accuracy: 0.9445\n",
            "Epoch 5146/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2439 - accuracy: 0.9254 - val_loss: 0.1880 - val_accuracy: 0.9430\n",
            "Epoch 5147/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2375 - accuracy: 0.9231 - val_loss: 0.1885 - val_accuracy: 0.9460\n",
            "Epoch 5148/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2324 - accuracy: 0.9236 - val_loss: 0.1880 - val_accuracy: 0.9440\n",
            "Epoch 5149/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2289 - accuracy: 0.9251 - val_loss: 0.1857 - val_accuracy: 0.9450\n",
            "Epoch 5150/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2295 - accuracy: 0.9254 - val_loss: 0.1878 - val_accuracy: 0.9465\n",
            "Epoch 5151/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2246 - accuracy: 0.9261 - val_loss: 0.1872 - val_accuracy: 0.9460\n",
            "Epoch 5152/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2296 - accuracy: 0.9239 - val_loss: 0.1910 - val_accuracy: 0.9445\n",
            "Epoch 5153/6000\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2253 - accuracy: 0.9255 - val_loss: 0.1913 - val_accuracy: 0.9455\n",
            "Epoch 5154/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2268 - accuracy: 0.9286 - val_loss: 0.1956 - val_accuracy: 0.9415\n",
            "Epoch 5155/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2309 - accuracy: 0.9295 - val_loss: 0.1883 - val_accuracy: 0.9455\n",
            "Epoch 5156/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2244 - accuracy: 0.9254 - val_loss: 0.1901 - val_accuracy: 0.9455\n",
            "Epoch 5157/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2335 - accuracy: 0.9241 - val_loss: 0.1836 - val_accuracy: 0.9450\n",
            "Epoch 5158/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2248 - accuracy: 0.9274 - val_loss: 0.1868 - val_accuracy: 0.9440\n",
            "Epoch 5159/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2242 - accuracy: 0.9287 - val_loss: 0.1875 - val_accuracy: 0.9435\n",
            "Epoch 5160/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2290 - accuracy: 0.9258 - val_loss: 0.1859 - val_accuracy: 0.9445\n",
            "Epoch 5161/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2300 - accuracy: 0.9243 - val_loss: 0.1941 - val_accuracy: 0.9435\n",
            "Epoch 5162/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2299 - accuracy: 0.9269 - val_loss: 0.1874 - val_accuracy: 0.9455\n",
            "Epoch 5163/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2240 - accuracy: 0.9277 - val_loss: 0.1888 - val_accuracy: 0.9445\n",
            "Epoch 5164/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2374 - accuracy: 0.9294 - val_loss: 0.1882 - val_accuracy: 0.9440\n",
            "Epoch 5165/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2311 - accuracy: 0.9239 - val_loss: 0.1933 - val_accuracy: 0.9420\n",
            "Epoch 5166/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2225 - accuracy: 0.9294 - val_loss: 0.1861 - val_accuracy: 0.9450\n",
            "Epoch 5167/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2258 - accuracy: 0.9265 - val_loss: 0.1871 - val_accuracy: 0.9435\n",
            "Epoch 5168/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2297 - accuracy: 0.9239 - val_loss: 0.1883 - val_accuracy: 0.9450\n",
            "Epoch 5169/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2273 - accuracy: 0.9269 - val_loss: 0.1891 - val_accuracy: 0.9440\n",
            "Epoch 5170/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2268 - accuracy: 0.9294 - val_loss: 0.1864 - val_accuracy: 0.9455\n",
            "Epoch 5171/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2243 - accuracy: 0.9312 - val_loss: 0.1891 - val_accuracy: 0.9440\n",
            "Epoch 5172/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2267 - accuracy: 0.9265 - val_loss: 0.1861 - val_accuracy: 0.9455\n",
            "Epoch 5173/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2287 - accuracy: 0.9256 - val_loss: 0.1872 - val_accuracy: 0.9465\n",
            "Epoch 5174/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2274 - accuracy: 0.9279 - val_loss: 0.1849 - val_accuracy: 0.9455\n",
            "Epoch 5175/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2387 - accuracy: 0.9233 - val_loss: 0.1847 - val_accuracy: 0.9455\n",
            "Epoch 5176/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2354 - accuracy: 0.9262 - val_loss: 0.1886 - val_accuracy: 0.9455\n",
            "Epoch 5177/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2446 - accuracy: 0.9236 - val_loss: 0.1903 - val_accuracy: 0.9455\n",
            "Epoch 5178/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2352 - accuracy: 0.9240 - val_loss: 0.1893 - val_accuracy: 0.9430\n",
            "Epoch 5179/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2319 - accuracy: 0.9279 - val_loss: 0.1900 - val_accuracy: 0.9430\n",
            "Epoch 5180/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2237 - accuracy: 0.9265 - val_loss: 0.1862 - val_accuracy: 0.9445\n",
            "Epoch 5181/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2494 - accuracy: 0.9270 - val_loss: 0.1891 - val_accuracy: 0.9450\n",
            "Epoch 5182/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2313 - accuracy: 0.9261 - val_loss: 0.1854 - val_accuracy: 0.9450\n",
            "Epoch 5183/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2229 - accuracy: 0.9283 - val_loss: 0.1934 - val_accuracy: 0.9410\n",
            "Epoch 5184/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2271 - accuracy: 0.9243 - val_loss: 0.1915 - val_accuracy: 0.9445\n",
            "Epoch 5185/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2303 - accuracy: 0.9254 - val_loss: 0.1878 - val_accuracy: 0.9445\n",
            "Epoch 5186/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2264 - accuracy: 0.9268 - val_loss: 0.1830 - val_accuracy: 0.9455\n",
            "Epoch 5187/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2338 - accuracy: 0.9255 - val_loss: 0.1898 - val_accuracy: 0.9450\n",
            "Epoch 5188/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2276 - accuracy: 0.9280 - val_loss: 0.1868 - val_accuracy: 0.9440\n",
            "Epoch 5189/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2625 - accuracy: 0.9234 - val_loss: 0.1876 - val_accuracy: 0.9460\n",
            "Epoch 5190/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2338 - accuracy: 0.9245 - val_loss: 0.1905 - val_accuracy: 0.9430\n",
            "Epoch 5191/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2275 - accuracy: 0.9258 - val_loss: 0.1903 - val_accuracy: 0.9460\n",
            "Epoch 5192/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2295 - accuracy: 0.9261 - val_loss: 0.1890 - val_accuracy: 0.9440\n",
            "Epoch 5193/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2271 - accuracy: 0.9275 - val_loss: 0.1911 - val_accuracy: 0.9445\n",
            "Epoch 5194/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2304 - accuracy: 0.9264 - val_loss: 0.1893 - val_accuracy: 0.9455\n",
            "Epoch 5195/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2338 - accuracy: 0.9275 - val_loss: 0.1850 - val_accuracy: 0.9455\n",
            "Epoch 5196/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2328 - accuracy: 0.9237 - val_loss: 0.1897 - val_accuracy: 0.9455\n",
            "Epoch 5197/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2261 - accuracy: 0.9276 - val_loss: 0.1843 - val_accuracy: 0.9450\n",
            "Epoch 5198/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2276 - accuracy: 0.9237 - val_loss: 0.1867 - val_accuracy: 0.9455\n",
            "Epoch 5199/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2340 - accuracy: 0.9260 - val_loss: 0.1930 - val_accuracy: 0.9435\n",
            "Epoch 5200/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2319 - accuracy: 0.9264 - val_loss: 0.1894 - val_accuracy: 0.9460\n",
            "Epoch 5201/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2286 - accuracy: 0.9249 - val_loss: 0.1874 - val_accuracy: 0.9450\n",
            "Epoch 5202/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2324 - accuracy: 0.9251 - val_loss: 0.1866 - val_accuracy: 0.9440\n",
            "Epoch 5203/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2360 - accuracy: 0.9230 - val_loss: 0.1886 - val_accuracy: 0.9435\n",
            "Epoch 5204/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2266 - accuracy: 0.9254 - val_loss: 0.1875 - val_accuracy: 0.9445\n",
            "Epoch 5205/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2202 - accuracy: 0.9304 - val_loss: 0.1892 - val_accuracy: 0.9455\n",
            "Epoch 5206/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2316 - accuracy: 0.9258 - val_loss: 0.1872 - val_accuracy: 0.9445\n",
            "Epoch 5207/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2278 - accuracy: 0.9304 - val_loss: 0.1861 - val_accuracy: 0.9450\n",
            "Epoch 5208/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2294 - accuracy: 0.9279 - val_loss: 0.1851 - val_accuracy: 0.9460\n",
            "Epoch 5209/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2348 - accuracy: 0.9240 - val_loss: 0.1867 - val_accuracy: 0.9440\n",
            "Epoch 5210/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2339 - accuracy: 0.9240 - val_loss: 0.1881 - val_accuracy: 0.9425\n",
            "Epoch 5211/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2309 - accuracy: 0.9255 - val_loss: 0.1882 - val_accuracy: 0.9460\n",
            "Epoch 5212/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2270 - accuracy: 0.9290 - val_loss: 0.1855 - val_accuracy: 0.9455\n",
            "Epoch 5213/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2296 - accuracy: 0.9271 - val_loss: 0.1867 - val_accuracy: 0.9445\n",
            "Epoch 5214/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2321 - accuracy: 0.9241 - val_loss: 0.1919 - val_accuracy: 0.9440\n",
            "Epoch 5215/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2283 - accuracy: 0.9251 - val_loss: 0.1866 - val_accuracy: 0.9455\n",
            "Epoch 5216/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2316 - accuracy: 0.9274 - val_loss: 0.1823 - val_accuracy: 0.9460\n",
            "Epoch 5217/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2315 - accuracy: 0.9280 - val_loss: 0.1848 - val_accuracy: 0.9440\n",
            "Epoch 5218/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2291 - accuracy: 0.9273 - val_loss: 0.1862 - val_accuracy: 0.9465\n",
            "Epoch 5219/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2275 - accuracy: 0.9265 - val_loss: 0.1864 - val_accuracy: 0.9445\n",
            "Epoch 5220/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2229 - accuracy: 0.9277 - val_loss: 0.1908 - val_accuracy: 0.9445\n",
            "Epoch 5221/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2252 - accuracy: 0.9298 - val_loss: 0.1881 - val_accuracy: 0.9470\n",
            "Epoch 5222/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2283 - accuracy: 0.9258 - val_loss: 0.1854 - val_accuracy: 0.9460\n",
            "Epoch 5223/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2286 - accuracy: 0.9250 - val_loss: 0.1891 - val_accuracy: 0.9440\n",
            "Epoch 5224/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2402 - accuracy: 0.9291 - val_loss: 0.1867 - val_accuracy: 0.9455\n",
            "Epoch 5225/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2395 - accuracy: 0.9294 - val_loss: 0.1815 - val_accuracy: 0.9465\n",
            "Epoch 5226/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2214 - accuracy: 0.9274 - val_loss: 0.1812 - val_accuracy: 0.9450\n",
            "Epoch 5227/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2342 - accuracy: 0.9243 - val_loss: 0.1904 - val_accuracy: 0.9445\n",
            "Epoch 5228/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2277 - accuracy: 0.9261 - val_loss: 0.1880 - val_accuracy: 0.9475\n",
            "Epoch 5229/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2388 - accuracy: 0.9222 - val_loss: 0.1857 - val_accuracy: 0.9450\n",
            "Epoch 5230/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2349 - accuracy: 0.9260 - val_loss: 0.1902 - val_accuracy: 0.9430\n",
            "Epoch 5231/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2280 - accuracy: 0.9252 - val_loss: 0.1866 - val_accuracy: 0.9450\n",
            "Epoch 5232/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2228 - accuracy: 0.9306 - val_loss: 0.1888 - val_accuracy: 0.9425\n",
            "Epoch 5233/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2259 - accuracy: 0.9256 - val_loss: 0.1827 - val_accuracy: 0.9460\n",
            "Epoch 5234/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2356 - accuracy: 0.9218 - val_loss: 0.1920 - val_accuracy: 0.9435\n",
            "Epoch 5235/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2252 - accuracy: 0.9276 - val_loss: 0.1854 - val_accuracy: 0.9450\n",
            "Epoch 5236/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2275 - accuracy: 0.9260 - val_loss: 0.1867 - val_accuracy: 0.9465\n",
            "Epoch 5237/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2216 - accuracy: 0.9289 - val_loss: 0.1878 - val_accuracy: 0.9460\n",
            "Epoch 5238/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2264 - accuracy: 0.9276 - val_loss: 0.1850 - val_accuracy: 0.9455\n",
            "Epoch 5239/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2352 - accuracy: 0.9235 - val_loss: 0.1824 - val_accuracy: 0.9455\n",
            "Epoch 5240/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2282 - accuracy: 0.9287 - val_loss: 0.1876 - val_accuracy: 0.9455\n",
            "Epoch 5241/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2278 - accuracy: 0.9283 - val_loss: 0.1840 - val_accuracy: 0.9450\n",
            "Epoch 5242/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2524 - accuracy: 0.9262 - val_loss: 0.1897 - val_accuracy: 0.9440\n",
            "Epoch 5243/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2282 - accuracy: 0.9281 - val_loss: 0.1886 - val_accuracy: 0.9440\n",
            "Epoch 5244/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2235 - accuracy: 0.9266 - val_loss: 0.1903 - val_accuracy: 0.9435\n",
            "Epoch 5245/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2288 - accuracy: 0.9258 - val_loss: 0.1901 - val_accuracy: 0.9450\n",
            "Epoch 5246/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2345 - accuracy: 0.9258 - val_loss: 0.1873 - val_accuracy: 0.9430\n",
            "Epoch 5247/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2267 - accuracy: 0.9269 - val_loss: 0.1883 - val_accuracy: 0.9450\n",
            "Epoch 5248/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2280 - accuracy: 0.9266 - val_loss: 0.1868 - val_accuracy: 0.9445\n",
            "Epoch 5249/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2226 - accuracy: 0.9259 - val_loss: 0.1899 - val_accuracy: 0.9450\n",
            "Epoch 5250/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2322 - accuracy: 0.9295 - val_loss: 0.1876 - val_accuracy: 0.9450\n",
            "Epoch 5251/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2280 - accuracy: 0.9258 - val_loss: 0.1887 - val_accuracy: 0.9445\n",
            "Epoch 5252/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2310 - accuracy: 0.9254 - val_loss: 0.1891 - val_accuracy: 0.9445\n",
            "Epoch 5253/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2361 - accuracy: 0.9260 - val_loss: 0.1914 - val_accuracy: 0.9450\n",
            "Epoch 5254/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2245 - accuracy: 0.9258 - val_loss: 0.1889 - val_accuracy: 0.9460\n",
            "Epoch 5255/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2244 - accuracy: 0.9268 - val_loss: 0.1865 - val_accuracy: 0.9450\n",
            "Epoch 5256/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2303 - accuracy: 0.9233 - val_loss: 0.1874 - val_accuracy: 0.9455\n",
            "Epoch 5257/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2280 - accuracy: 0.9268 - val_loss: 0.1903 - val_accuracy: 0.9455\n",
            "Epoch 5258/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2307 - accuracy: 0.9265 - val_loss: 0.1870 - val_accuracy: 0.9460\n",
            "Epoch 5259/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2320 - accuracy: 0.9240 - val_loss: 0.1882 - val_accuracy: 0.9450\n",
            "Epoch 5260/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2301 - accuracy: 0.9270 - val_loss: 0.1858 - val_accuracy: 0.9465\n",
            "Epoch 5261/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2234 - accuracy: 0.9266 - val_loss: 0.1924 - val_accuracy: 0.9455\n",
            "Epoch 5262/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2279 - accuracy: 0.9239 - val_loss: 0.1873 - val_accuracy: 0.9460\n",
            "Epoch 5263/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2232 - accuracy: 0.9283 - val_loss: 0.1899 - val_accuracy: 0.9460\n",
            "Epoch 5264/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2265 - accuracy: 0.9281 - val_loss: 0.1870 - val_accuracy: 0.9455\n",
            "Epoch 5265/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2460 - accuracy: 0.9240 - val_loss: 0.1810 - val_accuracy: 0.9455\n",
            "Epoch 5266/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2266 - accuracy: 0.9237 - val_loss: 0.1881 - val_accuracy: 0.9450\n",
            "Epoch 5267/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2399 - accuracy: 0.9268 - val_loss: 0.1871 - val_accuracy: 0.9460\n",
            "Epoch 5268/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2199 - accuracy: 0.9281 - val_loss: 0.1895 - val_accuracy: 0.9455\n",
            "Epoch 5269/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2292 - accuracy: 0.9239 - val_loss: 0.1900 - val_accuracy: 0.9450\n",
            "Epoch 5270/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2261 - accuracy: 0.9298 - val_loss: 0.1836 - val_accuracy: 0.9470\n",
            "Epoch 5271/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2305 - accuracy: 0.9265 - val_loss: 0.1913 - val_accuracy: 0.9450\n",
            "Epoch 5272/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2300 - accuracy: 0.9265 - val_loss: 0.1891 - val_accuracy: 0.9430\n",
            "Epoch 5273/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2271 - accuracy: 0.9276 - val_loss: 0.1823 - val_accuracy: 0.9465\n",
            "Epoch 5274/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2207 - accuracy: 0.9293 - val_loss: 0.1825 - val_accuracy: 0.9470\n",
            "Epoch 5275/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2251 - accuracy: 0.9266 - val_loss: 0.1936 - val_accuracy: 0.9430\n",
            "Epoch 5276/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2270 - accuracy: 0.9279 - val_loss: 0.1879 - val_accuracy: 0.9460\n",
            "Epoch 5277/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2318 - accuracy: 0.9260 - val_loss: 0.1885 - val_accuracy: 0.9470\n",
            "Epoch 5278/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2405 - accuracy: 0.9260 - val_loss: 0.1875 - val_accuracy: 0.9450\n",
            "Epoch 5279/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2372 - accuracy: 0.9289 - val_loss: 0.1886 - val_accuracy: 0.9440\n",
            "Epoch 5280/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2345 - accuracy: 0.9259 - val_loss: 0.1862 - val_accuracy: 0.9460\n",
            "Epoch 5281/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2253 - accuracy: 0.9277 - val_loss: 0.1910 - val_accuracy: 0.9445\n",
            "Epoch 5282/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2319 - accuracy: 0.9246 - val_loss: 0.1948 - val_accuracy: 0.9430\n",
            "Epoch 5283/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2247 - accuracy: 0.9286 - val_loss: 0.1921 - val_accuracy: 0.9435\n",
            "Epoch 5284/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2296 - accuracy: 0.9251 - val_loss: 0.1849 - val_accuracy: 0.9445\n",
            "Epoch 5285/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2290 - accuracy: 0.9258 - val_loss: 0.1838 - val_accuracy: 0.9455\n",
            "Epoch 5286/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2252 - accuracy: 0.9256 - val_loss: 0.1904 - val_accuracy: 0.9430\n",
            "Epoch 5287/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2368 - accuracy: 0.9227 - val_loss: 0.1898 - val_accuracy: 0.9450\n",
            "Epoch 5288/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2275 - accuracy: 0.9254 - val_loss: 0.1882 - val_accuracy: 0.9450\n",
            "Epoch 5289/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2230 - accuracy: 0.9294 - val_loss: 0.1886 - val_accuracy: 0.9445\n",
            "Epoch 5290/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2318 - accuracy: 0.9240 - val_loss: 0.1883 - val_accuracy: 0.9460\n",
            "Epoch 5291/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2275 - accuracy: 0.9289 - val_loss: 0.1848 - val_accuracy: 0.9460\n",
            "Epoch 5292/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2302 - accuracy: 0.9250 - val_loss: 0.1864 - val_accuracy: 0.9445\n",
            "Epoch 5293/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2281 - accuracy: 0.9246 - val_loss: 0.1885 - val_accuracy: 0.9440\n",
            "Epoch 5294/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2462 - accuracy: 0.9262 - val_loss: 0.1894 - val_accuracy: 0.9445\n",
            "Epoch 5295/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2235 - accuracy: 0.9265 - val_loss: 0.1887 - val_accuracy: 0.9445\n",
            "Epoch 5296/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2334 - accuracy: 0.9240 - val_loss: 0.1857 - val_accuracy: 0.9415\n",
            "Epoch 5297/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2341 - accuracy: 0.9225 - val_loss: 0.1845 - val_accuracy: 0.9445\n",
            "Epoch 5298/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2256 - accuracy: 0.9273 - val_loss: 0.1836 - val_accuracy: 0.9455\n",
            "Epoch 5299/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2330 - accuracy: 0.9262 - val_loss: 0.1896 - val_accuracy: 0.9450\n",
            "Epoch 5300/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2312 - accuracy: 0.9258 - val_loss: 0.1854 - val_accuracy: 0.9455\n",
            "Epoch 5301/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2259 - accuracy: 0.9270 - val_loss: 0.1851 - val_accuracy: 0.9470\n",
            "Epoch 5302/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2244 - accuracy: 0.9273 - val_loss: 0.1812 - val_accuracy: 0.9470\n",
            "Epoch 5303/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2257 - accuracy: 0.9247 - val_loss: 0.1845 - val_accuracy: 0.9450\n",
            "Epoch 5304/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2394 - accuracy: 0.9259 - val_loss: 0.1905 - val_accuracy: 0.9455\n",
            "Epoch 5305/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2317 - accuracy: 0.9243 - val_loss: 0.1846 - val_accuracy: 0.9465\n",
            "Epoch 5306/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2278 - accuracy: 0.9249 - val_loss: 0.1827 - val_accuracy: 0.9465\n",
            "Epoch 5307/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2295 - accuracy: 0.9269 - val_loss: 0.1871 - val_accuracy: 0.9460\n",
            "Epoch 5308/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2320 - accuracy: 0.9251 - val_loss: 0.1858 - val_accuracy: 0.9440\n",
            "Epoch 5309/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2302 - accuracy: 0.9246 - val_loss: 0.1868 - val_accuracy: 0.9435\n",
            "Epoch 5310/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2280 - accuracy: 0.9261 - val_loss: 0.1839 - val_accuracy: 0.9460\n",
            "Epoch 5311/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2268 - accuracy: 0.9261 - val_loss: 0.1883 - val_accuracy: 0.9440\n",
            "Epoch 5312/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2405 - accuracy: 0.9276 - val_loss: 0.1879 - val_accuracy: 0.9445\n",
            "Epoch 5313/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2326 - accuracy: 0.9281 - val_loss: 0.1887 - val_accuracy: 0.9455\n",
            "Epoch 5314/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2269 - accuracy: 0.9243 - val_loss: 0.1858 - val_accuracy: 0.9450\n",
            "Epoch 5315/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2327 - accuracy: 0.9265 - val_loss: 0.1877 - val_accuracy: 0.9450\n",
            "Epoch 5316/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2235 - accuracy: 0.9299 - val_loss: 0.1954 - val_accuracy: 0.9415\n",
            "Epoch 5317/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2293 - accuracy: 0.9258 - val_loss: 0.1890 - val_accuracy: 0.9425\n",
            "Epoch 5318/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2345 - accuracy: 0.9247 - val_loss: 0.1886 - val_accuracy: 0.9420\n",
            "Epoch 5319/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2551 - accuracy: 0.9260 - val_loss: 0.1858 - val_accuracy: 0.9460\n",
            "Epoch 5320/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2238 - accuracy: 0.9270 - val_loss: 0.1901 - val_accuracy: 0.9460\n",
            "Epoch 5321/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2278 - accuracy: 0.9273 - val_loss: 0.1871 - val_accuracy: 0.9460\n",
            "Epoch 5322/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2395 - accuracy: 0.9258 - val_loss: 0.1867 - val_accuracy: 0.9450\n",
            "Epoch 5323/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2244 - accuracy: 0.9289 - val_loss: 0.1878 - val_accuracy: 0.9455\n",
            "Epoch 5324/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2306 - accuracy: 0.9256 - val_loss: 0.1918 - val_accuracy: 0.9430\n",
            "Epoch 5325/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2247 - accuracy: 0.9271 - val_loss: 0.1906 - val_accuracy: 0.9435\n",
            "Epoch 5326/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2247 - accuracy: 0.9283 - val_loss: 0.1853 - val_accuracy: 0.9455\n",
            "Epoch 5327/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2328 - accuracy: 0.9266 - val_loss: 0.1884 - val_accuracy: 0.9455\n",
            "Epoch 5328/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2300 - accuracy: 0.9258 - val_loss: 0.1880 - val_accuracy: 0.9445\n",
            "Epoch 5329/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2301 - accuracy: 0.9270 - val_loss: 0.1876 - val_accuracy: 0.9440\n",
            "Epoch 5330/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2379 - accuracy: 0.9276 - val_loss: 0.1886 - val_accuracy: 0.9455\n",
            "Epoch 5331/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2301 - accuracy: 0.9260 - val_loss: 0.1893 - val_accuracy: 0.9430\n",
            "Epoch 5332/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2276 - accuracy: 0.9255 - val_loss: 0.1892 - val_accuracy: 0.9445\n",
            "Epoch 5333/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2281 - accuracy: 0.9277 - val_loss: 0.1882 - val_accuracy: 0.9435\n",
            "Epoch 5334/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2326 - accuracy: 0.9243 - val_loss: 0.1864 - val_accuracy: 0.9440\n",
            "Epoch 5335/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2269 - accuracy: 0.9290 - val_loss: 0.1840 - val_accuracy: 0.9460\n",
            "Epoch 5336/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2326 - accuracy: 0.9261 - val_loss: 0.1895 - val_accuracy: 0.9440\n",
            "Epoch 5337/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2356 - accuracy: 0.9240 - val_loss: 0.1854 - val_accuracy: 0.9460\n",
            "Epoch 5338/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2312 - accuracy: 0.9275 - val_loss: 0.1885 - val_accuracy: 0.9455\n",
            "Epoch 5339/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2348 - accuracy: 0.9270 - val_loss: 0.1894 - val_accuracy: 0.9445\n",
            "Epoch 5340/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2310 - accuracy: 0.9258 - val_loss: 0.1874 - val_accuracy: 0.9450\n",
            "Epoch 5341/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2326 - accuracy: 0.9250 - val_loss: 0.1906 - val_accuracy: 0.9450\n",
            "Epoch 5342/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2285 - accuracy: 0.9280 - val_loss: 0.1860 - val_accuracy: 0.9450\n",
            "Epoch 5343/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2440 - accuracy: 0.9269 - val_loss: 0.1917 - val_accuracy: 0.9445\n",
            "Epoch 5344/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2264 - accuracy: 0.9287 - val_loss: 0.1857 - val_accuracy: 0.9435\n",
            "Epoch 5345/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2365 - accuracy: 0.9239 - val_loss: 0.1878 - val_accuracy: 0.9440\n",
            "Epoch 5346/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2209 - accuracy: 0.9290 - val_loss: 0.1846 - val_accuracy: 0.9465\n",
            "Epoch 5347/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2337 - accuracy: 0.9280 - val_loss: 0.1874 - val_accuracy: 0.9440\n",
            "Epoch 5348/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2352 - accuracy: 0.9279 - val_loss: 0.1926 - val_accuracy: 0.9420\n",
            "Epoch 5349/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2342 - accuracy: 0.9261 - val_loss: 0.1915 - val_accuracy: 0.9445\n",
            "Epoch 5350/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2267 - accuracy: 0.9289 - val_loss: 0.1891 - val_accuracy: 0.9440\n",
            "Epoch 5351/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2306 - accuracy: 0.9279 - val_loss: 0.1854 - val_accuracy: 0.9445\n",
            "Epoch 5352/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2318 - accuracy: 0.9280 - val_loss: 0.1899 - val_accuracy: 0.9430\n",
            "Epoch 5353/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2297 - accuracy: 0.9241 - val_loss: 0.1866 - val_accuracy: 0.9450\n",
            "Epoch 5354/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2344 - accuracy: 0.9279 - val_loss: 0.1850 - val_accuracy: 0.9450\n",
            "Epoch 5355/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2200 - accuracy: 0.9293 - val_loss: 0.1850 - val_accuracy: 0.9455\n",
            "Epoch 5356/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2253 - accuracy: 0.9275 - val_loss: 0.1866 - val_accuracy: 0.9465\n",
            "Epoch 5357/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2239 - accuracy: 0.9306 - val_loss: 0.1901 - val_accuracy: 0.9450\n",
            "Epoch 5358/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2309 - accuracy: 0.9274 - val_loss: 0.1850 - val_accuracy: 0.9465\n",
            "Epoch 5359/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2464 - accuracy: 0.9262 - val_loss: 0.1909 - val_accuracy: 0.9455\n",
            "Epoch 5360/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2288 - accuracy: 0.9275 - val_loss: 0.1817 - val_accuracy: 0.9460\n",
            "Epoch 5361/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2320 - accuracy: 0.9262 - val_loss: 0.1863 - val_accuracy: 0.9430\n",
            "Epoch 5362/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2242 - accuracy: 0.9279 - val_loss: 0.1892 - val_accuracy: 0.9445\n",
            "Epoch 5363/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2277 - accuracy: 0.9298 - val_loss: 0.1874 - val_accuracy: 0.9445\n",
            "Epoch 5364/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2329 - accuracy: 0.9254 - val_loss: 0.1874 - val_accuracy: 0.9445\n",
            "Epoch 5365/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2277 - accuracy: 0.9258 - val_loss: 0.1884 - val_accuracy: 0.9445\n",
            "Epoch 5366/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2397 - accuracy: 0.9237 - val_loss: 0.1872 - val_accuracy: 0.9445\n",
            "Epoch 5367/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2245 - accuracy: 0.9280 - val_loss: 0.1902 - val_accuracy: 0.9450\n",
            "Epoch 5368/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2232 - accuracy: 0.9293 - val_loss: 0.1904 - val_accuracy: 0.9440\n",
            "Epoch 5369/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2299 - accuracy: 0.9256 - val_loss: 0.1868 - val_accuracy: 0.9445\n",
            "Epoch 5370/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2277 - accuracy: 0.9256 - val_loss: 0.1876 - val_accuracy: 0.9460\n",
            "Epoch 5371/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2342 - accuracy: 0.9247 - val_loss: 0.1840 - val_accuracy: 0.9445\n",
            "Epoch 5372/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2313 - accuracy: 0.9239 - val_loss: 0.1891 - val_accuracy: 0.9450\n",
            "Epoch 5373/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2272 - accuracy: 0.9290 - val_loss: 0.1879 - val_accuracy: 0.9430\n",
            "Epoch 5374/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2288 - accuracy: 0.9261 - val_loss: 0.1914 - val_accuracy: 0.9440\n",
            "Epoch 5375/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2354 - accuracy: 0.9249 - val_loss: 0.1884 - val_accuracy: 0.9450\n",
            "Epoch 5376/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2244 - accuracy: 0.9276 - val_loss: 0.1886 - val_accuracy: 0.9455\n",
            "Epoch 5377/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2345 - accuracy: 0.9260 - val_loss: 0.1901 - val_accuracy: 0.9450\n",
            "Epoch 5378/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2254 - accuracy: 0.9251 - val_loss: 0.1889 - val_accuracy: 0.9455\n",
            "Epoch 5379/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2352 - accuracy: 0.9247 - val_loss: 0.1879 - val_accuracy: 0.9440\n",
            "Epoch 5380/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2341 - accuracy: 0.9233 - val_loss: 0.1887 - val_accuracy: 0.9445\n",
            "Epoch 5381/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2312 - accuracy: 0.9254 - val_loss: 0.1856 - val_accuracy: 0.9455\n",
            "Epoch 5382/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2204 - accuracy: 0.9290 - val_loss: 0.1887 - val_accuracy: 0.9450\n",
            "Epoch 5383/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2255 - accuracy: 0.9295 - val_loss: 0.1944 - val_accuracy: 0.9415\n",
            "Epoch 5384/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2315 - accuracy: 0.9225 - val_loss: 0.1880 - val_accuracy: 0.9445\n",
            "Epoch 5385/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2312 - accuracy: 0.9247 - val_loss: 0.1904 - val_accuracy: 0.9420\n",
            "Epoch 5386/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2262 - accuracy: 0.9254 - val_loss: 0.1898 - val_accuracy: 0.9435\n",
            "Epoch 5387/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2240 - accuracy: 0.9262 - val_loss: 0.1899 - val_accuracy: 0.9445\n",
            "Epoch 5388/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2342 - accuracy: 0.9252 - val_loss: 0.1843 - val_accuracy: 0.9445\n",
            "Epoch 5389/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2199 - accuracy: 0.9299 - val_loss: 0.1856 - val_accuracy: 0.9455\n",
            "Epoch 5390/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2296 - accuracy: 0.9265 - val_loss: 0.1865 - val_accuracy: 0.9455\n",
            "Epoch 5391/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2308 - accuracy: 0.9266 - val_loss: 0.1884 - val_accuracy: 0.9430\n",
            "Epoch 5392/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2296 - accuracy: 0.9258 - val_loss: 0.1879 - val_accuracy: 0.9450\n",
            "Epoch 5393/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2252 - accuracy: 0.9255 - val_loss: 0.1858 - val_accuracy: 0.9445\n",
            "Epoch 5394/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2354 - accuracy: 0.9255 - val_loss: 0.1860 - val_accuracy: 0.9455\n",
            "Epoch 5395/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2273 - accuracy: 0.9239 - val_loss: 0.1863 - val_accuracy: 0.9435\n",
            "Epoch 5396/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2266 - accuracy: 0.9235 - val_loss: 0.1923 - val_accuracy: 0.9425\n",
            "Epoch 5397/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2427 - accuracy: 0.9244 - val_loss: 0.1944 - val_accuracy: 0.9410\n",
            "Epoch 5398/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2318 - accuracy: 0.9266 - val_loss: 0.1875 - val_accuracy: 0.9455\n",
            "Epoch 5399/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2295 - accuracy: 0.9247 - val_loss: 0.1876 - val_accuracy: 0.9445\n",
            "Epoch 5400/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2288 - accuracy: 0.9258 - val_loss: 0.1892 - val_accuracy: 0.9435\n",
            "Epoch 5401/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2275 - accuracy: 0.9283 - val_loss: 0.1892 - val_accuracy: 0.9450\n",
            "Epoch 5402/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2270 - accuracy: 0.9290 - val_loss: 0.1851 - val_accuracy: 0.9465\n",
            "Epoch 5403/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2328 - accuracy: 0.9249 - val_loss: 0.1883 - val_accuracy: 0.9435\n",
            "Epoch 5404/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2396 - accuracy: 0.9224 - val_loss: 0.1846 - val_accuracy: 0.9465\n",
            "Epoch 5405/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2363 - accuracy: 0.9268 - val_loss: 0.1871 - val_accuracy: 0.9445\n",
            "Epoch 5406/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2253 - accuracy: 0.9251 - val_loss: 0.1852 - val_accuracy: 0.9475\n",
            "Epoch 5407/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2348 - accuracy: 0.9262 - val_loss: 0.1837 - val_accuracy: 0.9450\n",
            "Epoch 5408/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2253 - accuracy: 0.9252 - val_loss: 0.1869 - val_accuracy: 0.9440\n",
            "Epoch 5409/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2335 - accuracy: 0.9246 - val_loss: 0.1846 - val_accuracy: 0.9455\n",
            "Epoch 5410/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2328 - accuracy: 0.9252 - val_loss: 0.1817 - val_accuracy: 0.9465\n",
            "Epoch 5411/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2274 - accuracy: 0.9258 - val_loss: 0.1837 - val_accuracy: 0.9445\n",
            "Epoch 5412/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2259 - accuracy: 0.9285 - val_loss: 0.1849 - val_accuracy: 0.9450\n",
            "Epoch 5413/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2339 - accuracy: 0.9227 - val_loss: 0.1856 - val_accuracy: 0.9460\n",
            "Epoch 5414/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2276 - accuracy: 0.9268 - val_loss: 0.1871 - val_accuracy: 0.9460\n",
            "Epoch 5415/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2302 - accuracy: 0.9250 - val_loss: 0.1865 - val_accuracy: 0.9445\n",
            "Epoch 5416/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2258 - accuracy: 0.9266 - val_loss: 0.1835 - val_accuracy: 0.9445\n",
            "Epoch 5417/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2198 - accuracy: 0.9283 - val_loss: 0.1858 - val_accuracy: 0.9455\n",
            "Epoch 5418/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2285 - accuracy: 0.9233 - val_loss: 0.1858 - val_accuracy: 0.9435\n",
            "Epoch 5419/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2334 - accuracy: 0.9251 - val_loss: 0.1852 - val_accuracy: 0.9455\n",
            "Epoch 5420/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2273 - accuracy: 0.9268 - val_loss: 0.1899 - val_accuracy: 0.9435\n",
            "Epoch 5421/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2304 - accuracy: 0.9240 - val_loss: 0.1940 - val_accuracy: 0.9440\n",
            "Epoch 5422/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2461 - accuracy: 0.9233 - val_loss: 0.1855 - val_accuracy: 0.9430\n",
            "Epoch 5423/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2290 - accuracy: 0.9280 - val_loss: 0.1858 - val_accuracy: 0.9450\n",
            "Epoch 5424/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2322 - accuracy: 0.9246 - val_loss: 0.1869 - val_accuracy: 0.9450\n",
            "Epoch 5425/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2314 - accuracy: 0.9284 - val_loss: 0.1908 - val_accuracy: 0.9435\n",
            "Epoch 5426/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2282 - accuracy: 0.9271 - val_loss: 0.1848 - val_accuracy: 0.9460\n",
            "Epoch 5427/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2321 - accuracy: 0.9256 - val_loss: 0.1860 - val_accuracy: 0.9465\n",
            "Epoch 5428/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2326 - accuracy: 0.9247 - val_loss: 0.1875 - val_accuracy: 0.9440\n",
            "Epoch 5429/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2315 - accuracy: 0.9268 - val_loss: 0.1874 - val_accuracy: 0.9445\n",
            "Epoch 5430/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2288 - accuracy: 0.9260 - val_loss: 0.1854 - val_accuracy: 0.9460\n",
            "Epoch 5431/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2443 - accuracy: 0.9222 - val_loss: 0.1865 - val_accuracy: 0.9455\n",
            "Epoch 5432/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2370 - accuracy: 0.9240 - val_loss: 0.1867 - val_accuracy: 0.9440\n",
            "Epoch 5433/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2400 - accuracy: 0.9216 - val_loss: 0.1842 - val_accuracy: 0.9440\n",
            "Epoch 5434/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2331 - accuracy: 0.9229 - val_loss: 0.1854 - val_accuracy: 0.9450\n",
            "Epoch 5435/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2259 - accuracy: 0.9258 - val_loss: 0.1954 - val_accuracy: 0.9410\n",
            "Epoch 5436/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2315 - accuracy: 0.9234 - val_loss: 0.1882 - val_accuracy: 0.9450\n",
            "Epoch 5437/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2264 - accuracy: 0.9290 - val_loss: 0.1902 - val_accuracy: 0.9425\n",
            "Epoch 5438/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2308 - accuracy: 0.9225 - val_loss: 0.1895 - val_accuracy: 0.9425\n",
            "Epoch 5439/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2315 - accuracy: 0.9234 - val_loss: 0.1834 - val_accuracy: 0.9435\n",
            "Epoch 5440/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2275 - accuracy: 0.9246 - val_loss: 0.1853 - val_accuracy: 0.9460\n",
            "Epoch 5441/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2373 - accuracy: 0.9279 - val_loss: 0.1886 - val_accuracy: 0.9450\n",
            "Epoch 5442/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2299 - accuracy: 0.9268 - val_loss: 0.1837 - val_accuracy: 0.9475\n",
            "Epoch 5443/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2282 - accuracy: 0.9258 - val_loss: 0.1879 - val_accuracy: 0.9435\n",
            "Epoch 5444/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2373 - accuracy: 0.9237 - val_loss: 0.1863 - val_accuracy: 0.9450\n",
            "Epoch 5445/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2269 - accuracy: 0.9289 - val_loss: 0.1840 - val_accuracy: 0.9450\n",
            "Epoch 5446/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2243 - accuracy: 0.9301 - val_loss: 0.1870 - val_accuracy: 0.9435\n",
            "Epoch 5447/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2261 - accuracy: 0.9293 - val_loss: 0.1930 - val_accuracy: 0.9440\n",
            "Epoch 5448/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2383 - accuracy: 0.9256 - val_loss: 0.1841 - val_accuracy: 0.9450\n",
            "Epoch 5449/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2239 - accuracy: 0.9277 - val_loss: 0.1947 - val_accuracy: 0.9435\n",
            "Epoch 5450/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2218 - accuracy: 0.9276 - val_loss: 0.1908 - val_accuracy: 0.9425\n",
            "Epoch 5451/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2287 - accuracy: 0.9221 - val_loss: 0.1861 - val_accuracy: 0.9445\n",
            "Epoch 5452/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2236 - accuracy: 0.9271 - val_loss: 0.1903 - val_accuracy: 0.9440\n",
            "Epoch 5453/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2255 - accuracy: 0.9276 - val_loss: 0.1923 - val_accuracy: 0.9430\n",
            "Epoch 5454/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2421 - accuracy: 0.9279 - val_loss: 0.1877 - val_accuracy: 0.9430\n",
            "Epoch 5455/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2326 - accuracy: 0.9281 - val_loss: 0.1908 - val_accuracy: 0.9445\n",
            "Epoch 5456/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2390 - accuracy: 0.9235 - val_loss: 0.1909 - val_accuracy: 0.9430\n",
            "Epoch 5457/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2213 - accuracy: 0.9265 - val_loss: 0.1857 - val_accuracy: 0.9435\n",
            "Epoch 5458/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2281 - accuracy: 0.9275 - val_loss: 0.1851 - val_accuracy: 0.9445\n",
            "Epoch 5459/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2325 - accuracy: 0.9277 - val_loss: 0.1873 - val_accuracy: 0.9450\n",
            "Epoch 5460/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2351 - accuracy: 0.9268 - val_loss: 0.1888 - val_accuracy: 0.9440\n",
            "Epoch 5461/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2324 - accuracy: 0.9280 - val_loss: 0.1868 - val_accuracy: 0.9460\n",
            "Epoch 5462/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2336 - accuracy: 0.9261 - val_loss: 0.1862 - val_accuracy: 0.9455\n",
            "Epoch 5463/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2323 - accuracy: 0.9252 - val_loss: 0.1880 - val_accuracy: 0.9455\n",
            "Epoch 5464/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2293 - accuracy: 0.9259 - val_loss: 0.1856 - val_accuracy: 0.9440\n",
            "Epoch 5465/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2524 - accuracy: 0.9226 - val_loss: 0.1877 - val_accuracy: 0.9455\n",
            "Epoch 5466/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2258 - accuracy: 0.9270 - val_loss: 0.1886 - val_accuracy: 0.9435\n",
            "Epoch 5467/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2254 - accuracy: 0.9264 - val_loss: 0.1838 - val_accuracy: 0.9460\n",
            "Epoch 5468/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2255 - accuracy: 0.9256 - val_loss: 0.1888 - val_accuracy: 0.9450\n",
            "Epoch 5469/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2287 - accuracy: 0.9275 - val_loss: 0.1859 - val_accuracy: 0.9455\n",
            "Epoch 5470/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2272 - accuracy: 0.9237 - val_loss: 0.1859 - val_accuracy: 0.9450\n",
            "Epoch 5471/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2398 - accuracy: 0.9244 - val_loss: 0.1877 - val_accuracy: 0.9465\n",
            "Epoch 5472/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2536 - accuracy: 0.9250 - val_loss: 0.1868 - val_accuracy: 0.9480\n",
            "Epoch 5473/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2308 - accuracy: 0.9240 - val_loss: 0.1921 - val_accuracy: 0.9455\n",
            "Epoch 5474/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2295 - accuracy: 0.9284 - val_loss: 0.1909 - val_accuracy: 0.9450\n",
            "Epoch 5475/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2239 - accuracy: 0.9283 - val_loss: 0.1897 - val_accuracy: 0.9435\n",
            "Epoch 5476/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2295 - accuracy: 0.9256 - val_loss: 0.1872 - val_accuracy: 0.9455\n",
            "Epoch 5477/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2296 - accuracy: 0.9227 - val_loss: 0.1857 - val_accuracy: 0.9455\n",
            "Epoch 5478/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2300 - accuracy: 0.9249 - val_loss: 0.1894 - val_accuracy: 0.9455\n",
            "Epoch 5479/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2471 - accuracy: 0.9261 - val_loss: 0.1906 - val_accuracy: 0.9455\n",
            "Epoch 5480/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2294 - accuracy: 0.9237 - val_loss: 0.1892 - val_accuracy: 0.9450\n",
            "Epoch 5481/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2258 - accuracy: 0.9283 - val_loss: 0.1885 - val_accuracy: 0.9450\n",
            "Epoch 5482/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2298 - accuracy: 0.9271 - val_loss: 0.1836 - val_accuracy: 0.9450\n",
            "Epoch 5483/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2361 - accuracy: 0.9250 - val_loss: 0.1875 - val_accuracy: 0.9435\n",
            "Epoch 5484/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2225 - accuracy: 0.9279 - val_loss: 0.1872 - val_accuracy: 0.9445\n",
            "Epoch 5485/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2309 - accuracy: 0.9256 - val_loss: 0.1893 - val_accuracy: 0.9450\n",
            "Epoch 5486/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2250 - accuracy: 0.9262 - val_loss: 0.1918 - val_accuracy: 0.9440\n",
            "Epoch 5487/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2281 - accuracy: 0.9251 - val_loss: 0.1894 - val_accuracy: 0.9430\n",
            "Epoch 5488/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2272 - accuracy: 0.9250 - val_loss: 0.1864 - val_accuracy: 0.9445\n",
            "Epoch 5489/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2249 - accuracy: 0.9279 - val_loss: 0.1875 - val_accuracy: 0.9445\n",
            "Epoch 5490/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2223 - accuracy: 0.9290 - val_loss: 0.1872 - val_accuracy: 0.9465\n",
            "Epoch 5491/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2255 - accuracy: 0.9283 - val_loss: 0.1915 - val_accuracy: 0.9425\n",
            "Epoch 5492/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2433 - accuracy: 0.9245 - val_loss: 0.1880 - val_accuracy: 0.9445\n",
            "Epoch 5493/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2232 - accuracy: 0.9268 - val_loss: 0.1899 - val_accuracy: 0.9450\n",
            "Epoch 5494/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2257 - accuracy: 0.9287 - val_loss: 0.1852 - val_accuracy: 0.9460\n",
            "Epoch 5495/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2473 - accuracy: 0.9260 - val_loss: 0.1877 - val_accuracy: 0.9440\n",
            "Epoch 5496/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2370 - accuracy: 0.9252 - val_loss: 0.1894 - val_accuracy: 0.9460\n",
            "Epoch 5497/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2428 - accuracy: 0.9249 - val_loss: 0.1838 - val_accuracy: 0.9430\n",
            "Epoch 5498/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2296 - accuracy: 0.9260 - val_loss: 0.1883 - val_accuracy: 0.9430\n",
            "Epoch 5499/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2203 - accuracy: 0.9287 - val_loss: 0.1901 - val_accuracy: 0.9430\n",
            "Epoch 5500/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2279 - accuracy: 0.9281 - val_loss: 0.1866 - val_accuracy: 0.9450\n",
            "Epoch 5501/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2380 - accuracy: 0.9237 - val_loss: 0.1875 - val_accuracy: 0.9460\n",
            "Epoch 5502/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2270 - accuracy: 0.9268 - val_loss: 0.1863 - val_accuracy: 0.9450\n",
            "Epoch 5503/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2268 - accuracy: 0.9245 - val_loss: 0.1842 - val_accuracy: 0.9460\n",
            "Epoch 5504/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2186 - accuracy: 0.9310 - val_loss: 0.1842 - val_accuracy: 0.9460\n",
            "Epoch 5505/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2307 - accuracy: 0.9231 - val_loss: 0.1833 - val_accuracy: 0.9450\n",
            "Epoch 5506/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2309 - accuracy: 0.9239 - val_loss: 0.1859 - val_accuracy: 0.9450\n",
            "Epoch 5507/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2230 - accuracy: 0.9270 - val_loss: 0.1847 - val_accuracy: 0.9445\n",
            "Epoch 5508/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2264 - accuracy: 0.9273 - val_loss: 0.1902 - val_accuracy: 0.9425\n",
            "Epoch 5509/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2243 - accuracy: 0.9302 - val_loss: 0.1836 - val_accuracy: 0.9460\n",
            "Epoch 5510/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2258 - accuracy: 0.9281 - val_loss: 0.1866 - val_accuracy: 0.9450\n",
            "Epoch 5511/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2247 - accuracy: 0.9266 - val_loss: 0.1909 - val_accuracy: 0.9425\n",
            "Epoch 5512/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2207 - accuracy: 0.9296 - val_loss: 0.1857 - val_accuracy: 0.9450\n",
            "Epoch 5513/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2282 - accuracy: 0.9247 - val_loss: 0.1861 - val_accuracy: 0.9440\n",
            "Epoch 5514/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2341 - accuracy: 0.9236 - val_loss: 0.1869 - val_accuracy: 0.9450\n",
            "Epoch 5515/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2245 - accuracy: 0.9262 - val_loss: 0.1861 - val_accuracy: 0.9455\n",
            "Epoch 5516/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2314 - accuracy: 0.9256 - val_loss: 0.1870 - val_accuracy: 0.9445\n",
            "Epoch 5517/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2352 - accuracy: 0.9244 - val_loss: 0.1893 - val_accuracy: 0.9440\n",
            "Epoch 5518/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2240 - accuracy: 0.9306 - val_loss: 0.1852 - val_accuracy: 0.9440\n",
            "Epoch 5519/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2202 - accuracy: 0.9294 - val_loss: 0.1867 - val_accuracy: 0.9435\n",
            "Epoch 5520/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2313 - accuracy: 0.9262 - val_loss: 0.1912 - val_accuracy: 0.9425\n",
            "Epoch 5521/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2290 - accuracy: 0.9265 - val_loss: 0.1853 - val_accuracy: 0.9450\n",
            "Epoch 5522/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2278 - accuracy: 0.9280 - val_loss: 0.1829 - val_accuracy: 0.9445\n",
            "Epoch 5523/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2296 - accuracy: 0.9276 - val_loss: 0.1839 - val_accuracy: 0.9450\n",
            "Epoch 5524/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2245 - accuracy: 0.9277 - val_loss: 0.1829 - val_accuracy: 0.9450\n",
            "Epoch 5525/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2376 - accuracy: 0.9239 - val_loss: 0.1893 - val_accuracy: 0.9440\n",
            "Epoch 5526/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2252 - accuracy: 0.9281 - val_loss: 0.1876 - val_accuracy: 0.9455\n",
            "Epoch 5527/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2323 - accuracy: 0.9260 - val_loss: 0.1933 - val_accuracy: 0.9435\n",
            "Epoch 5528/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2332 - accuracy: 0.9255 - val_loss: 0.1875 - val_accuracy: 0.9465\n",
            "Epoch 5529/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2349 - accuracy: 0.9274 - val_loss: 0.1866 - val_accuracy: 0.9455\n",
            "Epoch 5530/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2441 - accuracy: 0.9275 - val_loss: 0.1838 - val_accuracy: 0.9455\n",
            "Epoch 5531/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2294 - accuracy: 0.9276 - val_loss: 0.1909 - val_accuracy: 0.9420\n",
            "Epoch 5532/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2263 - accuracy: 0.9270 - val_loss: 0.1862 - val_accuracy: 0.9440\n",
            "Epoch 5533/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2291 - accuracy: 0.9244 - val_loss: 0.1887 - val_accuracy: 0.9440\n",
            "Epoch 5534/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2341 - accuracy: 0.9258 - val_loss: 0.1896 - val_accuracy: 0.9435\n",
            "Epoch 5535/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2428 - accuracy: 0.9225 - val_loss: 0.1873 - val_accuracy: 0.9455\n",
            "Epoch 5536/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2312 - accuracy: 0.9240 - val_loss: 0.1891 - val_accuracy: 0.9440\n",
            "Epoch 5537/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2281 - accuracy: 0.9254 - val_loss: 0.1875 - val_accuracy: 0.9440\n",
            "Epoch 5538/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2255 - accuracy: 0.9266 - val_loss: 0.1889 - val_accuracy: 0.9420\n",
            "Epoch 5539/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2390 - accuracy: 0.9252 - val_loss: 0.1864 - val_accuracy: 0.9440\n",
            "Epoch 5540/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2318 - accuracy: 0.9255 - val_loss: 0.1832 - val_accuracy: 0.9460\n",
            "Epoch 5541/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2329 - accuracy: 0.9261 - val_loss: 0.1881 - val_accuracy: 0.9410\n",
            "Epoch 5542/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2277 - accuracy: 0.9246 - val_loss: 0.1890 - val_accuracy: 0.9450\n",
            "Epoch 5543/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2264 - accuracy: 0.9280 - val_loss: 0.1858 - val_accuracy: 0.9445\n",
            "Epoch 5544/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2290 - accuracy: 0.9260 - val_loss: 0.1837 - val_accuracy: 0.9455\n",
            "Epoch 5545/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2249 - accuracy: 0.9279 - val_loss: 0.1840 - val_accuracy: 0.9450\n",
            "Epoch 5546/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2255 - accuracy: 0.9262 - val_loss: 0.1812 - val_accuracy: 0.9465\n",
            "Epoch 5547/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2522 - accuracy: 0.9251 - val_loss: 0.1834 - val_accuracy: 0.9455\n",
            "Epoch 5548/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2294 - accuracy: 0.9264 - val_loss: 0.1839 - val_accuracy: 0.9445\n",
            "Epoch 5549/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2315 - accuracy: 0.9250 - val_loss: 0.1874 - val_accuracy: 0.9460\n",
            "Epoch 5550/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2353 - accuracy: 0.9211 - val_loss: 0.1807 - val_accuracy: 0.9455\n",
            "Epoch 5551/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2224 - accuracy: 0.9280 - val_loss: 0.1824 - val_accuracy: 0.9455\n",
            "Epoch 5552/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2280 - accuracy: 0.9255 - val_loss: 0.1862 - val_accuracy: 0.9455\n",
            "Epoch 5553/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2311 - accuracy: 0.9258 - val_loss: 0.1832 - val_accuracy: 0.9460\n",
            "Epoch 5554/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2307 - accuracy: 0.9262 - val_loss: 0.1858 - val_accuracy: 0.9435\n",
            "Epoch 5555/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2384 - accuracy: 0.9258 - val_loss: 0.1877 - val_accuracy: 0.9445\n",
            "Epoch 5556/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2301 - accuracy: 0.9254 - val_loss: 0.1884 - val_accuracy: 0.9440\n",
            "Epoch 5557/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2270 - accuracy: 0.9275 - val_loss: 0.1909 - val_accuracy: 0.9430\n",
            "Epoch 5558/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2278 - accuracy: 0.9249 - val_loss: 0.1834 - val_accuracy: 0.9455\n",
            "Epoch 5559/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2518 - accuracy: 0.9240 - val_loss: 0.1877 - val_accuracy: 0.9440\n",
            "Epoch 5560/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2267 - accuracy: 0.9268 - val_loss: 0.1843 - val_accuracy: 0.9445\n",
            "Epoch 5561/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2332 - accuracy: 0.9239 - val_loss: 0.1857 - val_accuracy: 0.9440\n",
            "Epoch 5562/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2213 - accuracy: 0.9301 - val_loss: 0.1864 - val_accuracy: 0.9450\n",
            "Epoch 5563/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2237 - accuracy: 0.9284 - val_loss: 0.1850 - val_accuracy: 0.9435\n",
            "Epoch 5564/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2304 - accuracy: 0.9269 - val_loss: 0.1867 - val_accuracy: 0.9440\n",
            "Epoch 5565/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2343 - accuracy: 0.9247 - val_loss: 0.1863 - val_accuracy: 0.9440\n",
            "Epoch 5566/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2327 - accuracy: 0.9262 - val_loss: 0.1867 - val_accuracy: 0.9435\n",
            "Epoch 5567/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2370 - accuracy: 0.9240 - val_loss: 0.1877 - val_accuracy: 0.9435\n",
            "Epoch 5568/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2250 - accuracy: 0.9270 - val_loss: 0.1856 - val_accuracy: 0.9445\n",
            "Epoch 5569/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2278 - accuracy: 0.9266 - val_loss: 0.1868 - val_accuracy: 0.9430\n",
            "Epoch 5570/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2330 - accuracy: 0.9250 - val_loss: 0.1866 - val_accuracy: 0.9440\n",
            "Epoch 5571/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2370 - accuracy: 0.9260 - val_loss: 0.1890 - val_accuracy: 0.9445\n",
            "Epoch 5572/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2292 - accuracy: 0.9268 - val_loss: 0.1900 - val_accuracy: 0.9440\n",
            "Epoch 5573/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2242 - accuracy: 0.9266 - val_loss: 0.1880 - val_accuracy: 0.9440\n",
            "Epoch 5574/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2273 - accuracy: 0.9270 - val_loss: 0.1898 - val_accuracy: 0.9445\n",
            "Epoch 5575/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2262 - accuracy: 0.9255 - val_loss: 0.1879 - val_accuracy: 0.9430\n",
            "Epoch 5576/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2315 - accuracy: 0.9237 - val_loss: 0.1896 - val_accuracy: 0.9445\n",
            "Epoch 5577/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2269 - accuracy: 0.9251 - val_loss: 0.1839 - val_accuracy: 0.9460\n",
            "Epoch 5578/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2316 - accuracy: 0.9264 - val_loss: 0.1881 - val_accuracy: 0.9445\n",
            "Epoch 5579/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2358 - accuracy: 0.9247 - val_loss: 0.1877 - val_accuracy: 0.9435\n",
            "Epoch 5580/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2228 - accuracy: 0.9286 - val_loss: 0.1879 - val_accuracy: 0.9450\n",
            "Epoch 5581/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2270 - accuracy: 0.9260 - val_loss: 0.1867 - val_accuracy: 0.9430\n",
            "Epoch 5582/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2271 - accuracy: 0.9289 - val_loss: 0.1875 - val_accuracy: 0.9425\n",
            "Epoch 5583/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2381 - accuracy: 0.9276 - val_loss: 0.1848 - val_accuracy: 0.9425\n",
            "Epoch 5584/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2340 - accuracy: 0.9250 - val_loss: 0.1831 - val_accuracy: 0.9445\n",
            "Epoch 5585/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2392 - accuracy: 0.9243 - val_loss: 0.1831 - val_accuracy: 0.9455\n",
            "Epoch 5586/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2299 - accuracy: 0.9261 - val_loss: 0.1853 - val_accuracy: 0.9440\n",
            "Epoch 5587/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2270 - accuracy: 0.9273 - val_loss: 0.1887 - val_accuracy: 0.9425\n",
            "Epoch 5588/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2248 - accuracy: 0.9276 - val_loss: 0.1854 - val_accuracy: 0.9435\n",
            "Epoch 5589/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2280 - accuracy: 0.9226 - val_loss: 0.1822 - val_accuracy: 0.9465\n",
            "Epoch 5590/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2301 - accuracy: 0.9222 - val_loss: 0.1855 - val_accuracy: 0.9450\n",
            "Epoch 5591/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2316 - accuracy: 0.9241 - val_loss: 0.1849 - val_accuracy: 0.9445\n",
            "Epoch 5592/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2241 - accuracy: 0.9290 - val_loss: 0.1906 - val_accuracy: 0.9450\n",
            "Epoch 5593/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2171 - accuracy: 0.9308 - val_loss: 0.1850 - val_accuracy: 0.9425\n",
            "Epoch 5594/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2311 - accuracy: 0.9262 - val_loss: 0.1896 - val_accuracy: 0.9440\n",
            "Epoch 5595/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2288 - accuracy: 0.9295 - val_loss: 0.1849 - val_accuracy: 0.9450\n",
            "Epoch 5596/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2269 - accuracy: 0.9258 - val_loss: 0.1851 - val_accuracy: 0.9455\n",
            "Epoch 5597/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2248 - accuracy: 0.9255 - val_loss: 0.1862 - val_accuracy: 0.9445\n",
            "Epoch 5598/6000\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2316 - accuracy: 0.9255 - val_loss: 0.1855 - val_accuracy: 0.9465\n",
            "Epoch 5599/6000\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2207 - accuracy: 0.9277 - val_loss: 0.1941 - val_accuracy: 0.9420\n",
            "Epoch 5600/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2303 - accuracy: 0.9273 - val_loss: 0.1914 - val_accuracy: 0.9440\n",
            "Epoch 5601/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2313 - accuracy: 0.9269 - val_loss: 0.1870 - val_accuracy: 0.9450\n",
            "Epoch 5602/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2274 - accuracy: 0.9279 - val_loss: 0.1848 - val_accuracy: 0.9450\n",
            "Epoch 5603/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2273 - accuracy: 0.9264 - val_loss: 0.1892 - val_accuracy: 0.9455\n",
            "Epoch 5604/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2258 - accuracy: 0.9264 - val_loss: 0.1867 - val_accuracy: 0.9455\n",
            "Epoch 5605/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2279 - accuracy: 0.9240 - val_loss: 0.1897 - val_accuracy: 0.9430\n",
            "Epoch 5606/6000\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2269 - accuracy: 0.9260 - val_loss: 0.1917 - val_accuracy: 0.9440\n",
            "Epoch 5607/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2303 - accuracy: 0.9239 - val_loss: 0.1880 - val_accuracy: 0.9430\n",
            "Epoch 5608/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2348 - accuracy: 0.9236 - val_loss: 0.1867 - val_accuracy: 0.9445\n",
            "Epoch 5609/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2304 - accuracy: 0.9250 - val_loss: 0.1888 - val_accuracy: 0.9455\n",
            "Epoch 5610/6000\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2282 - accuracy: 0.9266 - val_loss: 0.1934 - val_accuracy: 0.9435\n",
            "Epoch 5611/6000\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2349 - accuracy: 0.9235 - val_loss: 0.1914 - val_accuracy: 0.9465\n",
            "Epoch 5612/6000\n",
            " 300/8000 [>.............................] - ETA: 0s - loss: 0.5057 - accuracy: 0.9400"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kqy3EIuFTDkA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_predictions2 = model2.predict(XT2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yipfhgqZXEX7",
        "colab_type": "code",
        "outputId": "d5e9f64b-8af7-4e63-acdc-04986985c8bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "model3 = tf.keras.models.Sequential()\n",
        "model3.add(tf.keras.layers.Dense(20 , input_shape = (10,)))\n",
        "model3.add(tf.keras.layers.Dense(32 , activation = 'relu'))\n",
        "model3.add(tf.keras.layers.Dropout(0.3))\n",
        "model3.add(tf.keras.layers.Dense(12 , activation = 'relu'))\n",
        "model3.add(tf.keras.layers.Dense(4, activation = 'softmax'))\n",
        "model3.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
        "model3.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_7 (Dense)              (None, 20)                220       \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 32)                672       \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 12)                396       \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 4)                 52        \n",
            "=================================================================\n",
            "Total params: 1,340\n",
            "Trainable params: 1,340\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U01GkCIOZOMc",
        "colab_type": "code",
        "outputId": "72bfe87a-9298-4331-a90e-eae4fc56a4d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history3 = model3.fit(X_train, y_train, batch_size  = 200, epochs = 500 ,  validation_data = [X_test, y_test] ,shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8000 samples, validate on 2000 samples\n",
            "Epoch 1/500\n",
            "8000/8000 [==============================] - 0s 29us/sample - loss: 1.4812 - acc: 0.2562 - val_loss: 1.3417 - val_acc: 0.2945\n",
            "Epoch 2/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 1.3274 - acc: 0.3315 - val_loss: 1.2414 - val_acc: 0.3995\n",
            "Epoch 3/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 1.2292 - acc: 0.4189 - val_loss: 1.1307 - val_acc: 0.5165\n",
            "Epoch 4/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 1.1140 - acc: 0.5086 - val_loss: 1.0061 - val_acc: 0.5935\n",
            "Epoch 5/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 1.0087 - acc: 0.5711 - val_loss: 0.8847 - val_acc: 0.6635\n",
            "Epoch 6/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.8995 - acc: 0.6305 - val_loss: 0.7670 - val_acc: 0.7160\n",
            "Epoch 7/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.7992 - acc: 0.6865 - val_loss: 0.6579 - val_acc: 0.7725\n",
            "Epoch 8/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.7163 - acc: 0.7354 - val_loss: 0.5713 - val_acc: 0.8170\n",
            "Epoch 9/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.6474 - acc: 0.7729 - val_loss: 0.5119 - val_acc: 0.8455\n",
            "Epoch 10/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.5904 - acc: 0.8025 - val_loss: 0.4666 - val_acc: 0.8550\n",
            "Epoch 11/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.5430 - acc: 0.8246 - val_loss: 0.4288 - val_acc: 0.8750\n",
            "Epoch 12/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.5280 - acc: 0.8265 - val_loss: 0.4063 - val_acc: 0.8835\n",
            "Epoch 13/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.4900 - acc: 0.8472 - val_loss: 0.3785 - val_acc: 0.8875\n",
            "Epoch 14/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.4731 - acc: 0.8469 - val_loss: 0.3605 - val_acc: 0.8955\n",
            "Epoch 15/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.4498 - acc: 0.8561 - val_loss: 0.3457 - val_acc: 0.8950\n",
            "Epoch 16/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.4379 - acc: 0.8574 - val_loss: 0.3312 - val_acc: 0.8975\n",
            "Epoch 17/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.4275 - acc: 0.8614 - val_loss: 0.3207 - val_acc: 0.9070\n",
            "Epoch 18/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.4125 - acc: 0.8626 - val_loss: 0.3193 - val_acc: 0.9015\n",
            "Epoch 19/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.3924 - acc: 0.8730 - val_loss: 0.3102 - val_acc: 0.9065\n",
            "Epoch 20/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.3856 - acc: 0.8773 - val_loss: 0.3018 - val_acc: 0.9105\n",
            "Epoch 21/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.3830 - acc: 0.8756 - val_loss: 0.2969 - val_acc: 0.9135\n",
            "Epoch 22/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.3744 - acc: 0.8805 - val_loss: 0.2966 - val_acc: 0.9100\n",
            "Epoch 23/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.3625 - acc: 0.8786 - val_loss: 0.2923 - val_acc: 0.9100\n",
            "Epoch 24/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.3651 - acc: 0.8813 - val_loss: 0.2874 - val_acc: 0.9135\n",
            "Epoch 25/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.3602 - acc: 0.8861 - val_loss: 0.2834 - val_acc: 0.9150\n",
            "Epoch 26/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.3498 - acc: 0.8882 - val_loss: 0.2789 - val_acc: 0.9175\n",
            "Epoch 27/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.3418 - acc: 0.8929 - val_loss: 0.2778 - val_acc: 0.9155\n",
            "Epoch 28/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.3355 - acc: 0.8934 - val_loss: 0.2786 - val_acc: 0.9130\n",
            "Epoch 29/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.3403 - acc: 0.8896 - val_loss: 0.2711 - val_acc: 0.9215\n",
            "Epoch 30/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.3367 - acc: 0.8899 - val_loss: 0.2660 - val_acc: 0.9235\n",
            "Epoch 31/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.3310 - acc: 0.8932 - val_loss: 0.2655 - val_acc: 0.9225\n",
            "Epoch 32/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.3182 - acc: 0.8956 - val_loss: 0.2618 - val_acc: 0.9250\n",
            "Epoch 33/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.3219 - acc: 0.8926 - val_loss: 0.2614 - val_acc: 0.9200\n",
            "Epoch 34/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.3176 - acc: 0.8944 - val_loss: 0.2587 - val_acc: 0.9245\n",
            "Epoch 35/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.3145 - acc: 0.8942 - val_loss: 0.2557 - val_acc: 0.9285\n",
            "Epoch 36/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.3101 - acc: 0.8974 - val_loss: 0.2567 - val_acc: 0.9260\n",
            "Epoch 37/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.3197 - acc: 0.8976 - val_loss: 0.2538 - val_acc: 0.9280\n",
            "Epoch 38/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.3085 - acc: 0.8997 - val_loss: 0.2544 - val_acc: 0.9250\n",
            "Epoch 39/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.3051 - acc: 0.8988 - val_loss: 0.2502 - val_acc: 0.9270\n",
            "Epoch 40/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2988 - acc: 0.9031 - val_loss: 0.2472 - val_acc: 0.9275\n",
            "Epoch 41/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.3059 - acc: 0.9021 - val_loss: 0.2476 - val_acc: 0.9270\n",
            "Epoch 42/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2947 - acc: 0.9034 - val_loss: 0.2456 - val_acc: 0.9290\n",
            "Epoch 43/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2923 - acc: 0.9086 - val_loss: 0.2441 - val_acc: 0.9320\n",
            "Epoch 44/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2998 - acc: 0.9044 - val_loss: 0.2439 - val_acc: 0.9300\n",
            "Epoch 45/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2928 - acc: 0.9069 - val_loss: 0.2451 - val_acc: 0.9260\n",
            "Epoch 46/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2897 - acc: 0.9082 - val_loss: 0.2425 - val_acc: 0.9335\n",
            "Epoch 47/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2936 - acc: 0.9069 - val_loss: 0.2429 - val_acc: 0.9285\n",
            "Epoch 48/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2853 - acc: 0.9085 - val_loss: 0.2410 - val_acc: 0.9325\n",
            "Epoch 49/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2871 - acc: 0.9076 - val_loss: 0.2412 - val_acc: 0.9330\n",
            "Epoch 50/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2941 - acc: 0.9055 - val_loss: 0.2398 - val_acc: 0.9330\n",
            "Epoch 51/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2767 - acc: 0.9151 - val_loss: 0.2383 - val_acc: 0.9350\n",
            "Epoch 52/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2880 - acc: 0.9089 - val_loss: 0.2369 - val_acc: 0.9330\n",
            "Epoch 53/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2792 - acc: 0.9112 - val_loss: 0.2379 - val_acc: 0.9330\n",
            "Epoch 54/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2847 - acc: 0.9097 - val_loss: 0.2366 - val_acc: 0.9360\n",
            "Epoch 55/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2786 - acc: 0.9126 - val_loss: 0.2358 - val_acc: 0.9370\n",
            "Epoch 56/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2710 - acc: 0.9122 - val_loss: 0.2350 - val_acc: 0.9375\n",
            "Epoch 57/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2790 - acc: 0.9112 - val_loss: 0.2335 - val_acc: 0.9355\n",
            "Epoch 58/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2764 - acc: 0.9136 - val_loss: 0.2334 - val_acc: 0.9365\n",
            "Epoch 59/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2730 - acc: 0.9125 - val_loss: 0.2329 - val_acc: 0.9370\n",
            "Epoch 60/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2784 - acc: 0.9134 - val_loss: 0.2317 - val_acc: 0.9360\n",
            "Epoch 61/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2772 - acc: 0.9160 - val_loss: 0.2326 - val_acc: 0.9350\n",
            "Epoch 62/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2666 - acc: 0.9128 - val_loss: 0.2334 - val_acc: 0.9365\n",
            "Epoch 63/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2641 - acc: 0.9149 - val_loss: 0.2321 - val_acc: 0.9370\n",
            "Epoch 64/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2812 - acc: 0.9101 - val_loss: 0.2316 - val_acc: 0.9390\n",
            "Epoch 65/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2706 - acc: 0.9130 - val_loss: 0.2298 - val_acc: 0.9375\n",
            "Epoch 66/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2745 - acc: 0.9112 - val_loss: 0.2293 - val_acc: 0.9380\n",
            "Epoch 67/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2701 - acc: 0.9151 - val_loss: 0.2294 - val_acc: 0.9400\n",
            "Epoch 68/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2702 - acc: 0.9126 - val_loss: 0.2288 - val_acc: 0.9395\n",
            "Epoch 69/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2648 - acc: 0.9176 - val_loss: 0.2317 - val_acc: 0.9360\n",
            "Epoch 70/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2593 - acc: 0.9211 - val_loss: 0.2299 - val_acc: 0.9385\n",
            "Epoch 71/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2601 - acc: 0.9175 - val_loss: 0.2267 - val_acc: 0.9380\n",
            "Epoch 72/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2626 - acc: 0.9170 - val_loss: 0.2275 - val_acc: 0.9380\n",
            "Epoch 73/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2605 - acc: 0.9160 - val_loss: 0.2265 - val_acc: 0.9390\n",
            "Epoch 74/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2658 - acc: 0.9183 - val_loss: 0.2276 - val_acc: 0.9395\n",
            "Epoch 75/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2613 - acc: 0.9160 - val_loss: 0.2293 - val_acc: 0.9415\n",
            "Epoch 76/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2614 - acc: 0.9154 - val_loss: 0.2282 - val_acc: 0.9355\n",
            "Epoch 77/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2616 - acc: 0.9209 - val_loss: 0.2271 - val_acc: 0.9390\n",
            "Epoch 78/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2642 - acc: 0.9186 - val_loss: 0.2278 - val_acc: 0.9395\n",
            "Epoch 79/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2565 - acc: 0.9214 - val_loss: 0.2275 - val_acc: 0.9400\n",
            "Epoch 80/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2572 - acc: 0.9162 - val_loss: 0.2274 - val_acc: 0.9395\n",
            "Epoch 81/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2578 - acc: 0.9183 - val_loss: 0.2266 - val_acc: 0.9380\n",
            "Epoch 82/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2620 - acc: 0.9200 - val_loss: 0.2262 - val_acc: 0.9405\n",
            "Epoch 83/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2581 - acc: 0.9218 - val_loss: 0.2264 - val_acc: 0.9385\n",
            "Epoch 84/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2538 - acc: 0.9206 - val_loss: 0.2230 - val_acc: 0.9405\n",
            "Epoch 85/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2580 - acc: 0.9206 - val_loss: 0.2240 - val_acc: 0.9410\n",
            "Epoch 86/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2550 - acc: 0.9211 - val_loss: 0.2277 - val_acc: 0.9390\n",
            "Epoch 87/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2589 - acc: 0.9194 - val_loss: 0.2258 - val_acc: 0.9390\n",
            "Epoch 88/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2586 - acc: 0.9170 - val_loss: 0.2221 - val_acc: 0.9400\n",
            "Epoch 89/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2556 - acc: 0.9186 - val_loss: 0.2266 - val_acc: 0.9380\n",
            "Epoch 90/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2548 - acc: 0.9224 - val_loss: 0.2224 - val_acc: 0.9400\n",
            "Epoch 91/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2523 - acc: 0.9222 - val_loss: 0.2235 - val_acc: 0.9425\n",
            "Epoch 92/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2580 - acc: 0.9201 - val_loss: 0.2242 - val_acc: 0.9390\n",
            "Epoch 93/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2516 - acc: 0.9234 - val_loss: 0.2274 - val_acc: 0.9395\n",
            "Epoch 94/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2549 - acc: 0.9191 - val_loss: 0.2237 - val_acc: 0.9410\n",
            "Epoch 95/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2497 - acc: 0.9245 - val_loss: 0.2264 - val_acc: 0.9400\n",
            "Epoch 96/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2528 - acc: 0.9193 - val_loss: 0.2234 - val_acc: 0.9410\n",
            "Epoch 97/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2530 - acc: 0.9233 - val_loss: 0.2242 - val_acc: 0.9395\n",
            "Epoch 98/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2508 - acc: 0.9246 - val_loss: 0.2236 - val_acc: 0.9400\n",
            "Epoch 99/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2434 - acc: 0.9251 - val_loss: 0.2214 - val_acc: 0.9425\n",
            "Epoch 100/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2580 - acc: 0.9234 - val_loss: 0.2230 - val_acc: 0.9390\n",
            "Epoch 101/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2511 - acc: 0.9233 - val_loss: 0.2210 - val_acc: 0.9420\n",
            "Epoch 102/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2446 - acc: 0.9260 - val_loss: 0.2217 - val_acc: 0.9410\n",
            "Epoch 103/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2490 - acc: 0.9252 - val_loss: 0.2235 - val_acc: 0.9390\n",
            "Epoch 104/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2437 - acc: 0.9249 - val_loss: 0.2214 - val_acc: 0.9420\n",
            "Epoch 105/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2414 - acc: 0.9264 - val_loss: 0.2218 - val_acc: 0.9385\n",
            "Epoch 106/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2470 - acc: 0.9210 - val_loss: 0.2225 - val_acc: 0.9395\n",
            "Epoch 107/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2462 - acc: 0.9254 - val_loss: 0.2221 - val_acc: 0.9395\n",
            "Epoch 108/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2363 - acc: 0.9269 - val_loss: 0.2207 - val_acc: 0.9395\n",
            "Epoch 109/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2451 - acc: 0.9214 - val_loss: 0.2217 - val_acc: 0.9400\n",
            "Epoch 110/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2443 - acc: 0.9262 - val_loss: 0.2206 - val_acc: 0.9410\n",
            "Epoch 111/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2431 - acc: 0.9240 - val_loss: 0.2218 - val_acc: 0.9415\n",
            "Epoch 112/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2454 - acc: 0.9236 - val_loss: 0.2210 - val_acc: 0.9400\n",
            "Epoch 113/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2396 - acc: 0.9261 - val_loss: 0.2165 - val_acc: 0.9425\n",
            "Epoch 114/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2407 - acc: 0.9247 - val_loss: 0.2210 - val_acc: 0.9415\n",
            "Epoch 115/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2473 - acc: 0.9265 - val_loss: 0.2188 - val_acc: 0.9410\n",
            "Epoch 116/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2372 - acc: 0.9269 - val_loss: 0.2202 - val_acc: 0.9405\n",
            "Epoch 117/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2424 - acc: 0.9247 - val_loss: 0.2164 - val_acc: 0.9435\n",
            "Epoch 118/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2460 - acc: 0.9249 - val_loss: 0.2170 - val_acc: 0.9410\n",
            "Epoch 119/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2399 - acc: 0.9258 - val_loss: 0.2161 - val_acc: 0.9405\n",
            "Epoch 120/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2391 - acc: 0.9273 - val_loss: 0.2154 - val_acc: 0.9425\n",
            "Epoch 121/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2430 - acc: 0.9268 - val_loss: 0.2134 - val_acc: 0.9430\n",
            "Epoch 122/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2394 - acc: 0.9276 - val_loss: 0.2185 - val_acc: 0.9415\n",
            "Epoch 123/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2386 - acc: 0.9275 - val_loss: 0.2171 - val_acc: 0.9410\n",
            "Epoch 124/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2375 - acc: 0.9261 - val_loss: 0.2149 - val_acc: 0.9420\n",
            "Epoch 125/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2380 - acc: 0.9287 - val_loss: 0.2137 - val_acc: 0.9420\n",
            "Epoch 126/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2366 - acc: 0.9241 - val_loss: 0.2138 - val_acc: 0.9425\n",
            "Epoch 127/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2359 - acc: 0.9290 - val_loss: 0.2155 - val_acc: 0.9435\n",
            "Epoch 128/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2394 - acc: 0.9218 - val_loss: 0.2137 - val_acc: 0.9420\n",
            "Epoch 129/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2429 - acc: 0.9241 - val_loss: 0.2142 - val_acc: 0.9410\n",
            "Epoch 130/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2378 - acc: 0.9283 - val_loss: 0.2143 - val_acc: 0.9415\n",
            "Epoch 131/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2384 - acc: 0.9269 - val_loss: 0.2133 - val_acc: 0.9430\n",
            "Epoch 132/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2323 - acc: 0.9296 - val_loss: 0.2164 - val_acc: 0.9425\n",
            "Epoch 133/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2293 - acc: 0.9300 - val_loss: 0.2148 - val_acc: 0.9400\n",
            "Epoch 134/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2368 - acc: 0.9274 - val_loss: 0.2114 - val_acc: 0.9440\n",
            "Epoch 135/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2359 - acc: 0.9294 - val_loss: 0.2112 - val_acc: 0.9435\n",
            "Epoch 136/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2308 - acc: 0.9293 - val_loss: 0.2131 - val_acc: 0.9430\n",
            "Epoch 137/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2350 - acc: 0.9320 - val_loss: 0.2107 - val_acc: 0.9435\n",
            "Epoch 138/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2273 - acc: 0.9321 - val_loss: 0.2117 - val_acc: 0.9425\n",
            "Epoch 139/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2323 - acc: 0.9291 - val_loss: 0.2095 - val_acc: 0.9445\n",
            "Epoch 140/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2330 - acc: 0.9293 - val_loss: 0.2102 - val_acc: 0.9425\n",
            "Epoch 141/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2301 - acc: 0.9274 - val_loss: 0.2121 - val_acc: 0.9435\n",
            "Epoch 142/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2327 - acc: 0.9299 - val_loss: 0.2101 - val_acc: 0.9455\n",
            "Epoch 143/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2333 - acc: 0.9291 - val_loss: 0.2116 - val_acc: 0.9415\n",
            "Epoch 144/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2251 - acc: 0.9333 - val_loss: 0.2108 - val_acc: 0.9420\n",
            "Epoch 145/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2340 - acc: 0.9277 - val_loss: 0.2093 - val_acc: 0.9460\n",
            "Epoch 146/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2308 - acc: 0.9300 - val_loss: 0.2108 - val_acc: 0.9425\n",
            "Epoch 147/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2241 - acc: 0.9342 - val_loss: 0.2123 - val_acc: 0.9425\n",
            "Epoch 148/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2365 - acc: 0.9309 - val_loss: 0.2091 - val_acc: 0.9445\n",
            "Epoch 149/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2291 - acc: 0.9299 - val_loss: 0.2111 - val_acc: 0.9445\n",
            "Epoch 150/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2236 - acc: 0.9311 - val_loss: 0.2101 - val_acc: 0.9430\n",
            "Epoch 151/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2251 - acc: 0.9305 - val_loss: 0.2106 - val_acc: 0.9440\n",
            "Epoch 152/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2308 - acc: 0.9312 - val_loss: 0.2102 - val_acc: 0.9415\n",
            "Epoch 153/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2207 - acc: 0.9334 - val_loss: 0.2102 - val_acc: 0.9425\n",
            "Epoch 154/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2297 - acc: 0.9296 - val_loss: 0.2096 - val_acc: 0.9420\n",
            "Epoch 155/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2324 - acc: 0.9294 - val_loss: 0.2091 - val_acc: 0.9415\n",
            "Epoch 156/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2201 - acc: 0.9337 - val_loss: 0.2099 - val_acc: 0.9425\n",
            "Epoch 157/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2215 - acc: 0.9305 - val_loss: 0.2080 - val_acc: 0.9455\n",
            "Epoch 158/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2265 - acc: 0.9337 - val_loss: 0.2124 - val_acc: 0.9400\n",
            "Epoch 159/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2324 - acc: 0.9301 - val_loss: 0.2081 - val_acc: 0.9430\n",
            "Epoch 160/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2292 - acc: 0.9319 - val_loss: 0.2104 - val_acc: 0.9410\n",
            "Epoch 161/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2262 - acc: 0.9302 - val_loss: 0.2075 - val_acc: 0.9440\n",
            "Epoch 162/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2232 - acc: 0.9329 - val_loss: 0.2060 - val_acc: 0.9440\n",
            "Epoch 163/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2161 - acc: 0.9337 - val_loss: 0.2083 - val_acc: 0.9430\n",
            "Epoch 164/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2212 - acc: 0.9348 - val_loss: 0.2036 - val_acc: 0.9430\n",
            "Epoch 165/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2232 - acc: 0.9312 - val_loss: 0.2068 - val_acc: 0.9435\n",
            "Epoch 166/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2253 - acc: 0.9330 - val_loss: 0.2078 - val_acc: 0.9430\n",
            "Epoch 167/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2232 - acc: 0.9333 - val_loss: 0.2049 - val_acc: 0.9425\n",
            "Epoch 168/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2198 - acc: 0.9358 - val_loss: 0.2086 - val_acc: 0.9430\n",
            "Epoch 169/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2183 - acc: 0.9342 - val_loss: 0.2072 - val_acc: 0.9440\n",
            "Epoch 170/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2258 - acc: 0.9340 - val_loss: 0.2074 - val_acc: 0.9445\n",
            "Epoch 171/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2219 - acc: 0.9349 - val_loss: 0.2043 - val_acc: 0.9435\n",
            "Epoch 172/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2206 - acc: 0.9346 - val_loss: 0.2041 - val_acc: 0.9445\n",
            "Epoch 173/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2197 - acc: 0.9344 - val_loss: 0.2053 - val_acc: 0.9420\n",
            "Epoch 174/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2186 - acc: 0.9330 - val_loss: 0.2057 - val_acc: 0.9445\n",
            "Epoch 175/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2154 - acc: 0.9327 - val_loss: 0.2079 - val_acc: 0.9415\n",
            "Epoch 176/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2209 - acc: 0.9346 - val_loss: 0.2050 - val_acc: 0.9450\n",
            "Epoch 177/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2172 - acc: 0.9366 - val_loss: 0.2082 - val_acc: 0.9420\n",
            "Epoch 178/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2158 - acc: 0.9330 - val_loss: 0.2016 - val_acc: 0.9450\n",
            "Epoch 179/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2148 - acc: 0.9360 - val_loss: 0.2043 - val_acc: 0.9430\n",
            "Epoch 180/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2191 - acc: 0.9337 - val_loss: 0.2057 - val_acc: 0.9440\n",
            "Epoch 181/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2163 - acc: 0.9349 - val_loss: 0.2059 - val_acc: 0.9430\n",
            "Epoch 182/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2140 - acc: 0.9367 - val_loss: 0.2033 - val_acc: 0.9460\n",
            "Epoch 183/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2208 - acc: 0.9336 - val_loss: 0.2049 - val_acc: 0.9430\n",
            "Epoch 184/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2143 - acc: 0.9339 - val_loss: 0.2055 - val_acc: 0.9455\n",
            "Epoch 185/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2194 - acc: 0.9339 - val_loss: 0.2035 - val_acc: 0.9435\n",
            "Epoch 186/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2233 - acc: 0.9315 - val_loss: 0.2045 - val_acc: 0.9425\n",
            "Epoch 187/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2184 - acc: 0.9334 - val_loss: 0.2030 - val_acc: 0.9430\n",
            "Epoch 188/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2213 - acc: 0.9365 - val_loss: 0.2070 - val_acc: 0.9425\n",
            "Epoch 189/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2139 - acc: 0.9342 - val_loss: 0.2036 - val_acc: 0.9435\n",
            "Epoch 190/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2196 - acc: 0.9339 - val_loss: 0.2050 - val_acc: 0.9450\n",
            "Epoch 191/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2152 - acc: 0.9337 - val_loss: 0.2054 - val_acc: 0.9425\n",
            "Epoch 192/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2143 - acc: 0.9348 - val_loss: 0.2035 - val_acc: 0.9445\n",
            "Epoch 193/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2146 - acc: 0.9334 - val_loss: 0.2055 - val_acc: 0.9465\n",
            "Epoch 194/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2153 - acc: 0.9348 - val_loss: 0.2075 - val_acc: 0.9420\n",
            "Epoch 195/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2188 - acc: 0.9327 - val_loss: 0.2078 - val_acc: 0.9420\n",
            "Epoch 196/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2136 - acc: 0.9356 - val_loss: 0.2021 - val_acc: 0.9460\n",
            "Epoch 197/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2171 - acc: 0.9358 - val_loss: 0.2034 - val_acc: 0.9450\n",
            "Epoch 198/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2214 - acc: 0.9358 - val_loss: 0.2054 - val_acc: 0.9435\n",
            "Epoch 199/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2236 - acc: 0.9344 - val_loss: 0.2030 - val_acc: 0.9440\n",
            "Epoch 200/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2149 - acc: 0.9370 - val_loss: 0.2040 - val_acc: 0.9450\n",
            "Epoch 201/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2200 - acc: 0.9323 - val_loss: 0.2059 - val_acc: 0.9440\n",
            "Epoch 202/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2146 - acc: 0.9374 - val_loss: 0.2048 - val_acc: 0.9430\n",
            "Epoch 203/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2120 - acc: 0.9361 - val_loss: 0.2026 - val_acc: 0.9470\n",
            "Epoch 204/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2183 - acc: 0.9339 - val_loss: 0.2043 - val_acc: 0.9430\n",
            "Epoch 205/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2195 - acc: 0.9349 - val_loss: 0.2007 - val_acc: 0.9450\n",
            "Epoch 206/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2132 - acc: 0.9358 - val_loss: 0.2025 - val_acc: 0.9445\n",
            "Epoch 207/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2121 - acc: 0.9349 - val_loss: 0.2055 - val_acc: 0.9425\n",
            "Epoch 208/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2140 - acc: 0.9337 - val_loss: 0.2035 - val_acc: 0.9435\n",
            "Epoch 209/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2140 - acc: 0.9358 - val_loss: 0.2015 - val_acc: 0.9440\n",
            "Epoch 210/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2159 - acc: 0.9375 - val_loss: 0.2026 - val_acc: 0.9460\n",
            "Epoch 211/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2157 - acc: 0.9349 - val_loss: 0.2024 - val_acc: 0.9460\n",
            "Epoch 212/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2123 - acc: 0.9361 - val_loss: 0.2006 - val_acc: 0.9450\n",
            "Epoch 213/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2198 - acc: 0.9326 - val_loss: 0.2087 - val_acc: 0.9430\n",
            "Epoch 214/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2131 - acc: 0.9355 - val_loss: 0.2067 - val_acc: 0.9415\n",
            "Epoch 215/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2124 - acc: 0.9341 - val_loss: 0.2020 - val_acc: 0.9445\n",
            "Epoch 216/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2150 - acc: 0.9362 - val_loss: 0.2002 - val_acc: 0.9465\n",
            "Epoch 217/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2099 - acc: 0.9364 - val_loss: 0.2035 - val_acc: 0.9430\n",
            "Epoch 218/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2143 - acc: 0.9324 - val_loss: 0.1992 - val_acc: 0.9470\n",
            "Epoch 219/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2062 - acc: 0.9385 - val_loss: 0.2004 - val_acc: 0.9460\n",
            "Epoch 220/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2112 - acc: 0.9345 - val_loss: 0.2008 - val_acc: 0.9435\n",
            "Epoch 221/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2083 - acc: 0.9386 - val_loss: 0.2029 - val_acc: 0.9415\n",
            "Epoch 222/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2071 - acc: 0.9365 - val_loss: 0.2029 - val_acc: 0.9425\n",
            "Epoch 223/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2126 - acc: 0.9367 - val_loss: 0.2066 - val_acc: 0.9400\n",
            "Epoch 224/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2088 - acc: 0.9355 - val_loss: 0.2046 - val_acc: 0.9445\n",
            "Epoch 225/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2180 - acc: 0.9325 - val_loss: 0.2015 - val_acc: 0.9450\n",
            "Epoch 226/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2099 - acc: 0.9373 - val_loss: 0.2050 - val_acc: 0.9440\n",
            "Epoch 227/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2131 - acc: 0.9370 - val_loss: 0.2016 - val_acc: 0.9455\n",
            "Epoch 228/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2070 - acc: 0.9370 - val_loss: 0.2037 - val_acc: 0.9425\n",
            "Epoch 229/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2069 - acc: 0.9362 - val_loss: 0.2041 - val_acc: 0.9435\n",
            "Epoch 230/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2087 - acc: 0.9380 - val_loss: 0.2056 - val_acc: 0.9430\n",
            "Epoch 231/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2110 - acc: 0.9366 - val_loss: 0.2005 - val_acc: 0.9445\n",
            "Epoch 232/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2027 - acc: 0.9400 - val_loss: 0.2036 - val_acc: 0.9420\n",
            "Epoch 233/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2126 - acc: 0.9337 - val_loss: 0.1998 - val_acc: 0.9440\n",
            "Epoch 234/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2103 - acc: 0.9359 - val_loss: 0.1984 - val_acc: 0.9450\n",
            "Epoch 235/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2082 - acc: 0.9384 - val_loss: 0.2052 - val_acc: 0.9415\n",
            "Epoch 236/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2039 - acc: 0.9375 - val_loss: 0.2073 - val_acc: 0.9425\n",
            "Epoch 237/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2103 - acc: 0.9376 - val_loss: 0.2025 - val_acc: 0.9440\n",
            "Epoch 238/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2084 - acc: 0.9359 - val_loss: 0.2024 - val_acc: 0.9450\n",
            "Epoch 239/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2155 - acc: 0.9361 - val_loss: 0.2038 - val_acc: 0.9420\n",
            "Epoch 240/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2120 - acc: 0.9370 - val_loss: 0.1992 - val_acc: 0.9460\n",
            "Epoch 241/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2062 - acc: 0.9364 - val_loss: 0.2003 - val_acc: 0.9445\n",
            "Epoch 242/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2126 - acc: 0.9354 - val_loss: 0.2027 - val_acc: 0.9425\n",
            "Epoch 243/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2132 - acc: 0.9371 - val_loss: 0.2039 - val_acc: 0.9440\n",
            "Epoch 244/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2080 - acc: 0.9388 - val_loss: 0.2030 - val_acc: 0.9420\n",
            "Epoch 245/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2101 - acc: 0.9383 - val_loss: 0.2030 - val_acc: 0.9440\n",
            "Epoch 246/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2129 - acc: 0.9388 - val_loss: 0.1998 - val_acc: 0.9460\n",
            "Epoch 247/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2111 - acc: 0.9375 - val_loss: 0.2020 - val_acc: 0.9420\n",
            "Epoch 248/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2077 - acc: 0.9365 - val_loss: 0.2009 - val_acc: 0.9440\n",
            "Epoch 249/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2119 - acc: 0.9370 - val_loss: 0.2006 - val_acc: 0.9460\n",
            "Epoch 250/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2082 - acc: 0.9362 - val_loss: 0.2020 - val_acc: 0.9440\n",
            "Epoch 251/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2016 - acc: 0.9390 - val_loss: 0.2001 - val_acc: 0.9455\n",
            "Epoch 252/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2096 - acc: 0.9373 - val_loss: 0.1993 - val_acc: 0.9440\n",
            "Epoch 253/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2056 - acc: 0.9388 - val_loss: 0.1997 - val_acc: 0.9475\n",
            "Epoch 254/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2068 - acc: 0.9406 - val_loss: 0.2018 - val_acc: 0.9445\n",
            "Epoch 255/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2117 - acc: 0.9380 - val_loss: 0.1982 - val_acc: 0.9460\n",
            "Epoch 256/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2058 - acc: 0.9390 - val_loss: 0.2001 - val_acc: 0.9445\n",
            "Epoch 257/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2050 - acc: 0.9374 - val_loss: 0.1999 - val_acc: 0.9460\n",
            "Epoch 258/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2050 - acc: 0.9402 - val_loss: 0.2020 - val_acc: 0.9445\n",
            "Epoch 259/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2105 - acc: 0.9390 - val_loss: 0.2019 - val_acc: 0.9460\n",
            "Epoch 260/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2060 - acc: 0.9394 - val_loss: 0.2009 - val_acc: 0.9455\n",
            "Epoch 261/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2064 - acc: 0.9391 - val_loss: 0.2024 - val_acc: 0.9445\n",
            "Epoch 262/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2082 - acc: 0.9376 - val_loss: 0.2032 - val_acc: 0.9450\n",
            "Epoch 263/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2036 - acc: 0.9379 - val_loss: 0.2014 - val_acc: 0.9455\n",
            "Epoch 264/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2092 - acc: 0.9374 - val_loss: 0.1994 - val_acc: 0.9455\n",
            "Epoch 265/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2092 - acc: 0.9386 - val_loss: 0.2005 - val_acc: 0.9455\n",
            "Epoch 266/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2028 - acc: 0.9398 - val_loss: 0.2013 - val_acc: 0.9440\n",
            "Epoch 267/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2026 - acc: 0.9389 - val_loss: 0.1996 - val_acc: 0.9455\n",
            "Epoch 268/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2031 - acc: 0.9383 - val_loss: 0.1986 - val_acc: 0.9450\n",
            "Epoch 269/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2096 - acc: 0.9394 - val_loss: 0.1996 - val_acc: 0.9455\n",
            "Epoch 270/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2037 - acc: 0.9374 - val_loss: 0.2006 - val_acc: 0.9430\n",
            "Epoch 271/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2025 - acc: 0.9402 - val_loss: 0.2070 - val_acc: 0.9410\n",
            "Epoch 272/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2065 - acc: 0.9380 - val_loss: 0.1994 - val_acc: 0.9450\n",
            "Epoch 273/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2041 - acc: 0.9389 - val_loss: 0.1985 - val_acc: 0.9440\n",
            "Epoch 274/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2071 - acc: 0.9376 - val_loss: 0.1978 - val_acc: 0.9450\n",
            "Epoch 275/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2023 - acc: 0.9386 - val_loss: 0.2031 - val_acc: 0.9420\n",
            "Epoch 276/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2064 - acc: 0.9423 - val_loss: 0.1994 - val_acc: 0.9465\n",
            "Epoch 277/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2021 - acc: 0.9411 - val_loss: 0.1951 - val_acc: 0.9435\n",
            "Epoch 278/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2027 - acc: 0.9401 - val_loss: 0.1992 - val_acc: 0.9450\n",
            "Epoch 279/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2074 - acc: 0.9381 - val_loss: 0.1969 - val_acc: 0.9455\n",
            "Epoch 280/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2043 - acc: 0.9392 - val_loss: 0.2015 - val_acc: 0.9440\n",
            "Epoch 281/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2041 - acc: 0.9400 - val_loss: 0.1975 - val_acc: 0.9445\n",
            "Epoch 282/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2016 - acc: 0.9392 - val_loss: 0.1995 - val_acc: 0.9450\n",
            "Epoch 283/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2023 - acc: 0.9408 - val_loss: 0.2021 - val_acc: 0.9430\n",
            "Epoch 284/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.1983 - acc: 0.9399 - val_loss: 0.1980 - val_acc: 0.9435\n",
            "Epoch 285/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2007 - acc: 0.9377 - val_loss: 0.2000 - val_acc: 0.9445\n",
            "Epoch 286/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.1964 - acc: 0.9406 - val_loss: 0.2041 - val_acc: 0.9430\n",
            "Epoch 287/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2011 - acc: 0.9395 - val_loss: 0.2007 - val_acc: 0.9435\n",
            "Epoch 288/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2014 - acc: 0.9406 - val_loss: 0.1973 - val_acc: 0.9455\n",
            "Epoch 289/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2034 - acc: 0.9381 - val_loss: 0.1999 - val_acc: 0.9445\n",
            "Epoch 290/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2029 - acc: 0.9400 - val_loss: 0.2029 - val_acc: 0.9405\n",
            "Epoch 291/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2090 - acc: 0.9388 - val_loss: 0.2008 - val_acc: 0.9450\n",
            "Epoch 292/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.1992 - acc: 0.9385 - val_loss: 0.1987 - val_acc: 0.9450\n",
            "Epoch 293/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2034 - acc: 0.9401 - val_loss: 0.1980 - val_acc: 0.9430\n",
            "Epoch 294/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2055 - acc: 0.9370 - val_loss: 0.2003 - val_acc: 0.9435\n",
            "Epoch 295/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2054 - acc: 0.9367 - val_loss: 0.2019 - val_acc: 0.9430\n",
            "Epoch 296/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2027 - acc: 0.9386 - val_loss: 0.2029 - val_acc: 0.9450\n",
            "Epoch 297/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2013 - acc: 0.9380 - val_loss: 0.2027 - val_acc: 0.9440\n",
            "Epoch 298/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.1991 - acc: 0.9396 - val_loss: 0.1979 - val_acc: 0.9440\n",
            "Epoch 299/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2021 - acc: 0.9391 - val_loss: 0.1974 - val_acc: 0.9455\n",
            "Epoch 300/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.1998 - acc: 0.9383 - val_loss: 0.2002 - val_acc: 0.9445\n",
            "Epoch 301/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.1983 - acc: 0.9414 - val_loss: 0.2024 - val_acc: 0.9430\n",
            "Epoch 302/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.1961 - acc: 0.9421 - val_loss: 0.1995 - val_acc: 0.9435\n",
            "Epoch 303/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.1965 - acc: 0.9383 - val_loss: 0.2021 - val_acc: 0.9430\n",
            "Epoch 304/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.1997 - acc: 0.9404 - val_loss: 0.1986 - val_acc: 0.9450\n",
            "Epoch 305/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2021 - acc: 0.9406 - val_loss: 0.1988 - val_acc: 0.9440\n",
            "Epoch 306/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2037 - acc: 0.9380 - val_loss: 0.2013 - val_acc: 0.9425\n",
            "Epoch 307/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.1982 - acc: 0.9415 - val_loss: 0.1978 - val_acc: 0.9450\n",
            "Epoch 308/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2033 - acc: 0.9364 - val_loss: 0.1990 - val_acc: 0.9445\n",
            "Epoch 309/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.1965 - acc: 0.9410 - val_loss: 0.2051 - val_acc: 0.9440\n",
            "Epoch 310/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2001 - acc: 0.9383 - val_loss: 0.2017 - val_acc: 0.9420\n",
            "Epoch 311/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2002 - acc: 0.9374 - val_loss: 0.1980 - val_acc: 0.9440\n",
            "Epoch 312/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.1998 - acc: 0.9358 - val_loss: 0.2023 - val_acc: 0.9440\n",
            "Epoch 313/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2009 - acc: 0.9392 - val_loss: 0.1978 - val_acc: 0.9440\n",
            "Epoch 314/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2004 - acc: 0.9400 - val_loss: 0.2006 - val_acc: 0.9435\n",
            "Epoch 315/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.1997 - acc: 0.9408 - val_loss: 0.1980 - val_acc: 0.9440\n",
            "Epoch 316/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2020 - acc: 0.9370 - val_loss: 0.2032 - val_acc: 0.9435\n",
            "Epoch 317/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2017 - acc: 0.9364 - val_loss: 0.1994 - val_acc: 0.9440\n",
            "Epoch 318/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.1951 - acc: 0.9425 - val_loss: 0.1994 - val_acc: 0.9450\n",
            "Epoch 319/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.1968 - acc: 0.9410 - val_loss: 0.2021 - val_acc: 0.9440\n",
            "Epoch 320/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.1945 - acc: 0.9395 - val_loss: 0.2010 - val_acc: 0.9415\n",
            "Epoch 321/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.1991 - acc: 0.9396 - val_loss: 0.2022 - val_acc: 0.9430\n",
            "Epoch 322/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2015 - acc: 0.9384 - val_loss: 0.1989 - val_acc: 0.9445\n",
            "Epoch 323/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2019 - acc: 0.9399 - val_loss: 0.1981 - val_acc: 0.9460\n",
            "Epoch 324/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.1944 - acc: 0.9398 - val_loss: 0.2038 - val_acc: 0.9425\n",
            "Epoch 325/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.1983 - acc: 0.9396 - val_loss: 0.2003 - val_acc: 0.9435\n",
            "Epoch 326/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2042 - acc: 0.9376 - val_loss: 0.1988 - val_acc: 0.9425\n",
            "Epoch 327/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2017 - acc: 0.9385 - val_loss: 0.2019 - val_acc: 0.9430\n",
            "Epoch 328/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2002 - acc: 0.9375 - val_loss: 0.2017 - val_acc: 0.9435\n",
            "Epoch 329/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2005 - acc: 0.9364 - val_loss: 0.1978 - val_acc: 0.9455\n",
            "Epoch 330/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.1982 - acc: 0.9399 - val_loss: 0.2000 - val_acc: 0.9425\n",
            "Epoch 331/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.1980 - acc: 0.9404 - val_loss: 0.2037 - val_acc: 0.9445\n",
            "Epoch 332/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.1949 - acc: 0.9404 - val_loss: 0.1994 - val_acc: 0.9445\n",
            "Epoch 333/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.1951 - acc: 0.9416 - val_loss: 0.1980 - val_acc: 0.9440\n",
            "Epoch 334/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.1955 - acc: 0.9405 - val_loss: 0.1961 - val_acc: 0.9440\n",
            "Epoch 335/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.1985 - acc: 0.9386 - val_loss: 0.1969 - val_acc: 0.9445\n",
            "Epoch 336/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.1946 - acc: 0.9395 - val_loss: 0.2019 - val_acc: 0.9430\n",
            "Epoch 337/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.1928 - acc: 0.9401 - val_loss: 0.1962 - val_acc: 0.9440\n",
            "Epoch 338/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2003 - acc: 0.9361 - val_loss: 0.2006 - val_acc: 0.9445\n",
            "Epoch 339/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.2005 - acc: 0.9401 - val_loss: 0.2044 - val_acc: 0.9425\n",
            "Epoch 340/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.1945 - acc: 0.9389 - val_loss: 0.1996 - val_acc: 0.9440\n",
            "Epoch 341/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.1947 - acc: 0.9400 - val_loss: 0.1987 - val_acc: 0.9450\n",
            "Epoch 342/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2019 - acc: 0.9384 - val_loss: 0.1983 - val_acc: 0.9445\n",
            "Epoch 343/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.1978 - acc: 0.9400 - val_loss: 0.1972 - val_acc: 0.9445\n",
            "Epoch 344/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.1953 - acc: 0.9400 - val_loss: 0.1961 - val_acc: 0.9475\n",
            "Epoch 345/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.1968 - acc: 0.9401 - val_loss: 0.1988 - val_acc: 0.9435\n",
            "Epoch 346/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2060 - acc: 0.9384 - val_loss: 0.2027 - val_acc: 0.9450\n",
            "Epoch 347/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.1984 - acc: 0.9400 - val_loss: 0.1996 - val_acc: 0.9425\n",
            "Epoch 348/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.1958 - acc: 0.9398 - val_loss: 0.1991 - val_acc: 0.9455\n",
            "Epoch 349/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.1901 - acc: 0.9424 - val_loss: 0.2011 - val_acc: 0.9455\n",
            "Epoch 350/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2004 - acc: 0.9380 - val_loss: 0.2004 - val_acc: 0.9455\n",
            "Epoch 351/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.1983 - acc: 0.9362 - val_loss: 0.2025 - val_acc: 0.9425\n",
            "Epoch 352/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.1932 - acc: 0.9416 - val_loss: 0.1998 - val_acc: 0.9435\n",
            "Epoch 353/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.1964 - acc: 0.9391 - val_loss: 0.1991 - val_acc: 0.9445\n",
            "Epoch 354/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.1993 - acc: 0.9424 - val_loss: 0.2020 - val_acc: 0.9445\n",
            "Epoch 355/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.1981 - acc: 0.9381 - val_loss: 0.1974 - val_acc: 0.9440\n",
            "Epoch 356/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.2013 - acc: 0.9383 - val_loss: 0.2004 - val_acc: 0.9435\n",
            "Epoch 357/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2014 - acc: 0.9383 - val_loss: 0.1989 - val_acc: 0.9465\n",
            "Epoch 358/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.1959 - acc: 0.9395 - val_loss: 0.2013 - val_acc: 0.9440\n",
            "Epoch 359/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2008 - acc: 0.9399 - val_loss: 0.1981 - val_acc: 0.9445\n",
            "Epoch 360/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.1955 - acc: 0.9405 - val_loss: 0.2004 - val_acc: 0.9450\n",
            "Epoch 361/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.1966 - acc: 0.9416 - val_loss: 0.2005 - val_acc: 0.9460\n",
            "Epoch 362/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.1982 - acc: 0.9402 - val_loss: 0.2008 - val_acc: 0.9445\n",
            "Epoch 363/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.1973 - acc: 0.9405 - val_loss: 0.1980 - val_acc: 0.9460\n",
            "Epoch 364/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.2025 - acc: 0.9410 - val_loss: 0.2021 - val_acc: 0.9435\n",
            "Epoch 365/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.2010 - acc: 0.9383 - val_loss: 0.1993 - val_acc: 0.9460\n",
            "Epoch 366/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2008 - acc: 0.9399 - val_loss: 0.1971 - val_acc: 0.9460\n",
            "Epoch 367/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.2006 - acc: 0.9374 - val_loss: 0.1995 - val_acc: 0.9435\n",
            "Epoch 368/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.1960 - acc: 0.9389 - val_loss: 0.2012 - val_acc: 0.9440\n",
            "Epoch 369/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.1993 - acc: 0.9388 - val_loss: 0.2035 - val_acc: 0.9435\n",
            "Epoch 370/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.1923 - acc: 0.9399 - val_loss: 0.1992 - val_acc: 0.9445\n",
            "Epoch 371/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.1973 - acc: 0.9402 - val_loss: 0.1993 - val_acc: 0.9450\n",
            "Epoch 372/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.1916 - acc: 0.9399 - val_loss: 0.1991 - val_acc: 0.9460\n",
            "Epoch 373/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.1976 - acc: 0.9408 - val_loss: 0.1980 - val_acc: 0.9475\n",
            "Epoch 374/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.1925 - acc: 0.9392 - val_loss: 0.1993 - val_acc: 0.9470\n",
            "Epoch 375/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.1959 - acc: 0.9384 - val_loss: 0.2016 - val_acc: 0.9455\n",
            "Epoch 376/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.1965 - acc: 0.9401 - val_loss: 0.1966 - val_acc: 0.9470\n",
            "Epoch 377/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.1967 - acc: 0.9388 - val_loss: 0.1962 - val_acc: 0.9465\n",
            "Epoch 378/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.1951 - acc: 0.9380 - val_loss: 0.1974 - val_acc: 0.9455\n",
            "Epoch 379/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.1904 - acc: 0.9421 - val_loss: 0.2004 - val_acc: 0.9460\n",
            "Epoch 380/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.1977 - acc: 0.9415 - val_loss: 0.2039 - val_acc: 0.9445\n",
            "Epoch 381/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.1994 - acc: 0.9402 - val_loss: 0.2034 - val_acc: 0.9425\n",
            "Epoch 382/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.1941 - acc: 0.9417 - val_loss: 0.1996 - val_acc: 0.9455\n",
            "Epoch 383/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.1953 - acc: 0.9400 - val_loss: 0.1999 - val_acc: 0.9450\n",
            "Epoch 384/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.1949 - acc: 0.9405 - val_loss: 0.1999 - val_acc: 0.9440\n",
            "Epoch 385/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.1953 - acc: 0.9404 - val_loss: 0.2022 - val_acc: 0.9440\n",
            "Epoch 386/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.1976 - acc: 0.9413 - val_loss: 0.2048 - val_acc: 0.9425\n",
            "Epoch 387/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.1906 - acc: 0.9413 - val_loss: 0.2003 - val_acc: 0.9435\n",
            "Epoch 388/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.1965 - acc: 0.9396 - val_loss: 0.2000 - val_acc: 0.9450\n",
            "Epoch 389/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.1940 - acc: 0.9399 - val_loss: 0.1992 - val_acc: 0.9440\n",
            "Epoch 390/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.1940 - acc: 0.9411 - val_loss: 0.2022 - val_acc: 0.9425\n",
            "Epoch 391/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.1900 - acc: 0.9425 - val_loss: 0.2006 - val_acc: 0.9435\n",
            "Epoch 392/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.1978 - acc: 0.9380 - val_loss: 0.1998 - val_acc: 0.9445\n",
            "Epoch 393/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.1889 - acc: 0.9419 - val_loss: 0.2042 - val_acc: 0.9440\n",
            "Epoch 394/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.1956 - acc: 0.9408 - val_loss: 0.2014 - val_acc: 0.9440\n",
            "Epoch 395/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.1915 - acc: 0.9404 - val_loss: 0.1984 - val_acc: 0.9450\n",
            "Epoch 396/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.1962 - acc: 0.9391 - val_loss: 0.2045 - val_acc: 0.9430\n",
            "Epoch 397/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.1882 - acc: 0.9392 - val_loss: 0.2028 - val_acc: 0.9445\n",
            "Epoch 398/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.1872 - acc: 0.9384 - val_loss: 0.2001 - val_acc: 0.9450\n",
            "Epoch 399/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.1957 - acc: 0.9396 - val_loss: 0.1984 - val_acc: 0.9455\n",
            "Epoch 400/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.1946 - acc: 0.9391 - val_loss: 0.1954 - val_acc: 0.9465\n",
            "Epoch 401/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.1912 - acc: 0.9398 - val_loss: 0.1965 - val_acc: 0.9460\n",
            "Epoch 402/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.1882 - acc: 0.9414 - val_loss: 0.2007 - val_acc: 0.9455\n",
            "Epoch 403/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.1889 - acc: 0.9431 - val_loss: 0.2013 - val_acc: 0.9450\n",
            "Epoch 404/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.1904 - acc: 0.9416 - val_loss: 0.1993 - val_acc: 0.9455\n",
            "Epoch 405/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.1932 - acc: 0.9421 - val_loss: 0.2004 - val_acc: 0.9450\n",
            "Epoch 406/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.1847 - acc: 0.9415 - val_loss: 0.1975 - val_acc: 0.9460\n",
            "Epoch 407/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.1903 - acc: 0.9419 - val_loss: 0.1992 - val_acc: 0.9440\n",
            "Epoch 408/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.1941 - acc: 0.9398 - val_loss: 0.1975 - val_acc: 0.9460\n",
            "Epoch 409/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.1890 - acc: 0.9424 - val_loss: 0.2019 - val_acc: 0.9435\n",
            "Epoch 410/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.1931 - acc: 0.9415 - val_loss: 0.2011 - val_acc: 0.9445\n",
            "Epoch 411/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.1879 - acc: 0.9408 - val_loss: 0.2001 - val_acc: 0.9470\n",
            "Epoch 412/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.1929 - acc: 0.9405 - val_loss: 0.2009 - val_acc: 0.9440\n",
            "Epoch 413/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.1917 - acc: 0.9400 - val_loss: 0.2013 - val_acc: 0.9450\n",
            "Epoch 414/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.1953 - acc: 0.9401 - val_loss: 0.2056 - val_acc: 0.9430\n",
            "Epoch 415/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.1918 - acc: 0.9405 - val_loss: 0.2006 - val_acc: 0.9440\n",
            "Epoch 416/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.1973 - acc: 0.9367 - val_loss: 0.2000 - val_acc: 0.9460\n",
            "Epoch 417/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.1864 - acc: 0.9429 - val_loss: 0.2022 - val_acc: 0.9435\n",
            "Epoch 418/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.1936 - acc: 0.9413 - val_loss: 0.2020 - val_acc: 0.9445\n",
            "Epoch 419/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.1916 - acc: 0.9402 - val_loss: 0.1996 - val_acc: 0.9455\n",
            "Epoch 420/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.1920 - acc: 0.9404 - val_loss: 0.1994 - val_acc: 0.9460\n",
            "Epoch 421/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.1911 - acc: 0.9404 - val_loss: 0.2007 - val_acc: 0.9450\n",
            "Epoch 422/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.1863 - acc: 0.9388 - val_loss: 0.2022 - val_acc: 0.9440\n",
            "Epoch 423/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.1908 - acc: 0.9384 - val_loss: 0.1986 - val_acc: 0.9435\n",
            "Epoch 424/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.1936 - acc: 0.9410 - val_loss: 0.2006 - val_acc: 0.9445\n",
            "Epoch 425/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.1834 - acc: 0.9430 - val_loss: 0.1982 - val_acc: 0.9455\n",
            "Epoch 426/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.1914 - acc: 0.9401 - val_loss: 0.2012 - val_acc: 0.9430\n",
            "Epoch 427/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.1954 - acc: 0.9390 - val_loss: 0.2067 - val_acc: 0.9430\n",
            "Epoch 428/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.1908 - acc: 0.9405 - val_loss: 0.2004 - val_acc: 0.9440\n",
            "Epoch 429/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.1869 - acc: 0.9435 - val_loss: 0.1992 - val_acc: 0.9440\n",
            "Epoch 430/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.1885 - acc: 0.9417 - val_loss: 0.2011 - val_acc: 0.9470\n",
            "Epoch 431/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.1941 - acc: 0.9399 - val_loss: 0.1967 - val_acc: 0.9460\n",
            "Epoch 432/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.1913 - acc: 0.9395 - val_loss: 0.2018 - val_acc: 0.9440\n",
            "Epoch 433/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.1872 - acc: 0.9414 - val_loss: 0.2006 - val_acc: 0.9430\n",
            "Epoch 434/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.1850 - acc: 0.9411 - val_loss: 0.2024 - val_acc: 0.9465\n",
            "Epoch 435/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.1939 - acc: 0.9415 - val_loss: 0.2083 - val_acc: 0.9445\n",
            "Epoch 436/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.1920 - acc: 0.9405 - val_loss: 0.1997 - val_acc: 0.9465\n",
            "Epoch 437/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.1865 - acc: 0.9416 - val_loss: 0.1974 - val_acc: 0.9460\n",
            "Epoch 438/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.1946 - acc: 0.9402 - val_loss: 0.1975 - val_acc: 0.9450\n",
            "Epoch 439/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.1911 - acc: 0.9424 - val_loss: 0.1961 - val_acc: 0.9460\n",
            "Epoch 440/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.1894 - acc: 0.9399 - val_loss: 0.2000 - val_acc: 0.9450\n",
            "Epoch 441/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.1854 - acc: 0.9413 - val_loss: 0.1990 - val_acc: 0.9450\n",
            "Epoch 442/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.1865 - acc: 0.9442 - val_loss: 0.2042 - val_acc: 0.9430\n",
            "Epoch 443/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.1884 - acc: 0.9400 - val_loss: 0.2116 - val_acc: 0.9415\n",
            "Epoch 444/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.1870 - acc: 0.9400 - val_loss: 0.1981 - val_acc: 0.9445\n",
            "Epoch 445/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.1881 - acc: 0.9386 - val_loss: 0.2044 - val_acc: 0.9440\n",
            "Epoch 446/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.1881 - acc: 0.9417 - val_loss: 0.2062 - val_acc: 0.9440\n",
            "Epoch 447/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.1917 - acc: 0.9395 - val_loss: 0.2036 - val_acc: 0.9450\n",
            "Epoch 448/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.1907 - acc: 0.9396 - val_loss: 0.1987 - val_acc: 0.9455\n",
            "Epoch 449/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.1896 - acc: 0.9429 - val_loss: 0.2023 - val_acc: 0.9460\n",
            "Epoch 450/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.1938 - acc: 0.9401 - val_loss: 0.2005 - val_acc: 0.9440\n",
            "Epoch 451/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.1897 - acc: 0.9394 - val_loss: 0.2012 - val_acc: 0.9450\n",
            "Epoch 452/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.1865 - acc: 0.9430 - val_loss: 0.2027 - val_acc: 0.9450\n",
            "Epoch 453/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.1870 - acc: 0.9420 - val_loss: 0.2053 - val_acc: 0.9445\n",
            "Epoch 454/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.1921 - acc: 0.9419 - val_loss: 0.2059 - val_acc: 0.9450\n",
            "Epoch 455/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.1915 - acc: 0.9429 - val_loss: 0.2040 - val_acc: 0.9435\n",
            "Epoch 456/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.1916 - acc: 0.9416 - val_loss: 0.2009 - val_acc: 0.9450\n",
            "Epoch 457/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.1873 - acc: 0.9388 - val_loss: 0.2028 - val_acc: 0.9445\n",
            "Epoch 458/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.1934 - acc: 0.9410 - val_loss: 0.2057 - val_acc: 0.9430\n",
            "Epoch 459/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.1810 - acc: 0.9427 - val_loss: 0.2017 - val_acc: 0.9470\n",
            "Epoch 460/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.1914 - acc: 0.9421 - val_loss: 0.2007 - val_acc: 0.9445\n",
            "Epoch 461/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.1907 - acc: 0.9415 - val_loss: 0.2069 - val_acc: 0.9435\n",
            "Epoch 462/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.1904 - acc: 0.9404 - val_loss: 0.2049 - val_acc: 0.9430\n",
            "Epoch 463/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.1865 - acc: 0.9420 - val_loss: 0.2047 - val_acc: 0.9450\n",
            "Epoch 464/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.1899 - acc: 0.9391 - val_loss: 0.2067 - val_acc: 0.9445\n",
            "Epoch 465/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.1960 - acc: 0.9399 - val_loss: 0.2013 - val_acc: 0.9450\n",
            "Epoch 466/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.1919 - acc: 0.9404 - val_loss: 0.1988 - val_acc: 0.9455\n",
            "Epoch 467/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.1941 - acc: 0.9399 - val_loss: 0.1995 - val_acc: 0.9455\n",
            "Epoch 468/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.1885 - acc: 0.9409 - val_loss: 0.2004 - val_acc: 0.9455\n",
            "Epoch 469/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.1894 - acc: 0.9398 - val_loss: 0.2015 - val_acc: 0.9445\n",
            "Epoch 470/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.1911 - acc: 0.9398 - val_loss: 0.2113 - val_acc: 0.9430\n",
            "Epoch 471/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.1857 - acc: 0.9425 - val_loss: 0.2033 - val_acc: 0.9460\n",
            "Epoch 472/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.1881 - acc: 0.9410 - val_loss: 0.2017 - val_acc: 0.9450\n",
            "Epoch 473/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.1882 - acc: 0.9429 - val_loss: 0.2012 - val_acc: 0.9450\n",
            "Epoch 474/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.1833 - acc: 0.9441 - val_loss: 0.2002 - val_acc: 0.9445\n",
            "Epoch 475/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.1901 - acc: 0.9398 - val_loss: 0.1993 - val_acc: 0.9465\n",
            "Epoch 476/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.1882 - acc: 0.9424 - val_loss: 0.2056 - val_acc: 0.9430\n",
            "Epoch 477/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.1862 - acc: 0.9425 - val_loss: 0.2027 - val_acc: 0.9450\n",
            "Epoch 478/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.1937 - acc: 0.9420 - val_loss: 0.2020 - val_acc: 0.9440\n",
            "Epoch 479/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.1839 - acc: 0.9415 - val_loss: 0.2037 - val_acc: 0.9445\n",
            "Epoch 480/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.1854 - acc: 0.9416 - val_loss: 0.2037 - val_acc: 0.9455\n",
            "Epoch 481/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.1864 - acc: 0.9424 - val_loss: 0.2026 - val_acc: 0.9435\n",
            "Epoch 482/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.1857 - acc: 0.9424 - val_loss: 0.2035 - val_acc: 0.9450\n",
            "Epoch 483/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.1862 - acc: 0.9429 - val_loss: 0.2037 - val_acc: 0.9430\n",
            "Epoch 484/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.1948 - acc: 0.9383 - val_loss: 0.2056 - val_acc: 0.9460\n",
            "Epoch 485/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.1849 - acc: 0.9435 - val_loss: 0.2043 - val_acc: 0.9455\n",
            "Epoch 486/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.1884 - acc: 0.9436 - val_loss: 0.2129 - val_acc: 0.9420\n",
            "Epoch 487/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.1862 - acc: 0.9404 - val_loss: 0.2005 - val_acc: 0.9455\n",
            "Epoch 488/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.1846 - acc: 0.9434 - val_loss: 0.2012 - val_acc: 0.9455\n",
            "Epoch 489/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.1876 - acc: 0.9420 - val_loss: 0.2090 - val_acc: 0.9400\n",
            "Epoch 490/500\n",
            "8000/8000 [==============================] - 0s 15us/sample - loss: 0.1847 - acc: 0.9401 - val_loss: 0.2010 - val_acc: 0.9450\n",
            "Epoch 491/500\n",
            "8000/8000 [==============================] - 0s 14us/sample - loss: 0.1875 - acc: 0.9426 - val_loss: 0.2024 - val_acc: 0.9455\n",
            "Epoch 492/500\n",
            "8000/8000 [==============================] - 0s 17us/sample - loss: 0.1876 - acc: 0.9414 - val_loss: 0.2037 - val_acc: 0.9445\n",
            "Epoch 493/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.1809 - acc: 0.9419 - val_loss: 0.2102 - val_acc: 0.9425\n",
            "Epoch 494/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.1886 - acc: 0.9426 - val_loss: 0.2109 - val_acc: 0.9430\n",
            "Epoch 495/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.1850 - acc: 0.9442 - val_loss: 0.2035 - val_acc: 0.9455\n",
            "Epoch 496/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.1905 - acc: 0.9410 - val_loss: 0.2086 - val_acc: 0.9430\n",
            "Epoch 497/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.1912 - acc: 0.9430 - val_loss: 0.2020 - val_acc: 0.9460\n",
            "Epoch 498/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.1889 - acc: 0.9396 - val_loss: 0.2082 - val_acc: 0.9435\n",
            "Epoch 499/500\n",
            "8000/8000 [==============================] - 0s 16us/sample - loss: 0.1821 - acc: 0.9445 - val_loss: 0.2043 - val_acc: 0.9440\n",
            "Epoch 500/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.1889 - acc: 0.9395 - val_loss: 0.2009 - val_acc: 0.9450\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_n0q-1s10eGI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_predictions3 = model3.predict(XT2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obxi1HPOZXnz",
        "colab_type": "code",
        "outputId": "95c13285-5d55-4b70-bb8c-b7c9db115cad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "model4 = tf.keras.models.Sequential()\n",
        "model4.add(tf.keras.layers.Dense(18 , input_shape = (10,)))\n",
        "model4.add(tf.keras.layers.Dense(24 , activation = 'relu'))\n",
        "model4.add(tf.keras.layers.Dropout(0.3))\n",
        "model4.add(tf.keras.layers.Dense(16 , activation = 'relu'))\n",
        "model4.add(tf.keras.layers.Dense(10, activation = 'relu'))\n",
        "model4.add(tf.keras.layers.Dropout(0.3))\n",
        "model4.add(tf.keras.layers.Dense(4 , activation = 'softmax'))\n",
        "model4.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
        "model4.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_16 (Dense)             (None, 18)                198       \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 24)                456       \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 24)                0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 16)                400       \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 10)                170       \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 4)                 44        \n",
            "=================================================================\n",
            "Total params: 1,268\n",
            "Trainable params: 1,268\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sx1rBjLyZ8h_",
        "colab_type": "code",
        "outputId": "d1b5fceb-8e3c-42cd-ccc1-94c275ef2257",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history4 = model4.fit(X_train, y_train, batch_size  = 150, epochs = 500 ,  validation_data = [X_test, y_test] ,shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8000 samples, validate on 2000 samples\n",
            "Epoch 1/500\n",
            "8000/8000 [==============================] - 0s 50us/sample - loss: 1.4070 - acc: 0.2876 - val_loss: 1.3123 - val_acc: 0.3945\n",
            "Epoch 2/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 1.3190 - acc: 0.3498 - val_loss: 1.2431 - val_acc: 0.4265\n",
            "Epoch 3/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 1.2612 - acc: 0.3810 - val_loss: 1.1503 - val_acc: 0.5020\n",
            "Epoch 4/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 1.1693 - acc: 0.4526 - val_loss: 1.0057 - val_acc: 0.5805\n",
            "Epoch 5/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 1.0714 - acc: 0.5023 - val_loss: 0.8933 - val_acc: 0.6605\n",
            "Epoch 6/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.9986 - acc: 0.5322 - val_loss: 0.8058 - val_acc: 0.7215\n",
            "Epoch 7/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.9283 - acc: 0.5819 - val_loss: 0.7086 - val_acc: 0.7955\n",
            "Epoch 8/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.8537 - acc: 0.6495 - val_loss: 0.6222 - val_acc: 0.8435\n",
            "Epoch 9/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.7735 - acc: 0.7195 - val_loss: 0.5372 - val_acc: 0.8670\n",
            "Epoch 10/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.7159 - acc: 0.7408 - val_loss: 0.4766 - val_acc: 0.8825\n",
            "Epoch 11/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.6573 - acc: 0.7635 - val_loss: 0.4205 - val_acc: 0.8890\n",
            "Epoch 12/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.6233 - acc: 0.7744 - val_loss: 0.3942 - val_acc: 0.8905\n",
            "Epoch 13/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.5831 - acc: 0.7958 - val_loss: 0.3647 - val_acc: 0.9005\n",
            "Epoch 14/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5612 - acc: 0.8036 - val_loss: 0.3528 - val_acc: 0.9020\n",
            "Epoch 15/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.5346 - acc: 0.8184 - val_loss: 0.3325 - val_acc: 0.9035\n",
            "Epoch 16/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5189 - acc: 0.8275 - val_loss: 0.3236 - val_acc: 0.9020\n",
            "Epoch 17/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.5088 - acc: 0.8250 - val_loss: 0.3122 - val_acc: 0.9075\n",
            "Epoch 18/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.4987 - acc: 0.8309 - val_loss: 0.3060 - val_acc: 0.9055\n",
            "Epoch 19/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.4918 - acc: 0.8307 - val_loss: 0.3005 - val_acc: 0.9070\n",
            "Epoch 20/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.4798 - acc: 0.8350 - val_loss: 0.2942 - val_acc: 0.9060\n",
            "Epoch 21/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.4732 - acc: 0.8390 - val_loss: 0.2927 - val_acc: 0.9120\n",
            "Epoch 22/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.4652 - acc: 0.8447 - val_loss: 0.2872 - val_acc: 0.9095\n",
            "Epoch 23/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.4657 - acc: 0.8418 - val_loss: 0.2861 - val_acc: 0.9080\n",
            "Epoch 24/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.4517 - acc: 0.8447 - val_loss: 0.2834 - val_acc: 0.9085\n",
            "Epoch 25/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.4556 - acc: 0.8470 - val_loss: 0.2819 - val_acc: 0.9070\n",
            "Epoch 26/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.4537 - acc: 0.8465 - val_loss: 0.2776 - val_acc: 0.9100\n",
            "Epoch 27/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.4404 - acc: 0.8564 - val_loss: 0.2752 - val_acc: 0.9110\n",
            "Epoch 28/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.4280 - acc: 0.8547 - val_loss: 0.2698 - val_acc: 0.9120\n",
            "Epoch 29/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.4215 - acc: 0.8621 - val_loss: 0.2711 - val_acc: 0.9110\n",
            "Epoch 30/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.4153 - acc: 0.8605 - val_loss: 0.2683 - val_acc: 0.9145\n",
            "Epoch 31/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.4313 - acc: 0.8635 - val_loss: 0.2672 - val_acc: 0.9165\n",
            "Epoch 32/500\n",
            "8000/8000 [==============================] - 0s 27us/sample - loss: 0.4142 - acc: 0.8633 - val_loss: 0.2646 - val_acc: 0.9140\n",
            "Epoch 33/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.4170 - acc: 0.8612 - val_loss: 0.2636 - val_acc: 0.9135\n",
            "Epoch 34/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.4082 - acc: 0.8675 - val_loss: 0.2670 - val_acc: 0.9110\n",
            "Epoch 35/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.4030 - acc: 0.8725 - val_loss: 0.2608 - val_acc: 0.9130\n",
            "Epoch 36/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3965 - acc: 0.8712 - val_loss: 0.2609 - val_acc: 0.9115\n",
            "Epoch 37/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.4005 - acc: 0.8691 - val_loss: 0.2592 - val_acc: 0.9150\n",
            "Epoch 38/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.4050 - acc: 0.8709 - val_loss: 0.2543 - val_acc: 0.9145\n",
            "Epoch 39/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.3952 - acc: 0.8691 - val_loss: 0.2563 - val_acc: 0.9150\n",
            "Epoch 40/500\n",
            "8000/8000 [==============================] - 0s 27us/sample - loss: 0.4056 - acc: 0.8648 - val_loss: 0.2608 - val_acc: 0.9110\n",
            "Epoch 41/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3984 - acc: 0.8705 - val_loss: 0.2574 - val_acc: 0.9120\n",
            "Epoch 42/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.4012 - acc: 0.8665 - val_loss: 0.2561 - val_acc: 0.9175\n",
            "Epoch 43/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3955 - acc: 0.8740 - val_loss: 0.2542 - val_acc: 0.9150\n",
            "Epoch 44/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.3937 - acc: 0.8690 - val_loss: 0.2509 - val_acc: 0.9180\n",
            "Epoch 45/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.3869 - acc: 0.8710 - val_loss: 0.2569 - val_acc: 0.9140\n",
            "Epoch 46/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3873 - acc: 0.8731 - val_loss: 0.2541 - val_acc: 0.9135\n",
            "Epoch 47/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3831 - acc: 0.8754 - val_loss: 0.2547 - val_acc: 0.9145\n",
            "Epoch 48/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.3830 - acc: 0.8721 - val_loss: 0.2500 - val_acc: 0.9155\n",
            "Epoch 49/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3888 - acc: 0.8714 - val_loss: 0.2549 - val_acc: 0.9145\n",
            "Epoch 50/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.3775 - acc: 0.8786 - val_loss: 0.2518 - val_acc: 0.9150\n",
            "Epoch 51/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.3854 - acc: 0.8684 - val_loss: 0.2484 - val_acc: 0.9195\n",
            "Epoch 52/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.3794 - acc: 0.8734 - val_loss: 0.2474 - val_acc: 0.9205\n",
            "Epoch 53/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.3750 - acc: 0.8783 - val_loss: 0.2509 - val_acc: 0.9175\n",
            "Epoch 54/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.3746 - acc: 0.8788 - val_loss: 0.2497 - val_acc: 0.9185\n",
            "Epoch 55/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.3790 - acc: 0.8701 - val_loss: 0.2490 - val_acc: 0.9165\n",
            "Epoch 56/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.3837 - acc: 0.8765 - val_loss: 0.2440 - val_acc: 0.9200\n",
            "Epoch 57/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3621 - acc: 0.8804 - val_loss: 0.2521 - val_acc: 0.9200\n",
            "Epoch 58/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3780 - acc: 0.8741 - val_loss: 0.2500 - val_acc: 0.9170\n",
            "Epoch 59/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3767 - acc: 0.8767 - val_loss: 0.2509 - val_acc: 0.9175\n",
            "Epoch 60/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3704 - acc: 0.8791 - val_loss: 0.2469 - val_acc: 0.9195\n",
            "Epoch 61/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.3693 - acc: 0.8785 - val_loss: 0.2436 - val_acc: 0.9230\n",
            "Epoch 62/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.3764 - acc: 0.8770 - val_loss: 0.2446 - val_acc: 0.9220\n",
            "Epoch 63/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.3669 - acc: 0.8800 - val_loss: 0.2483 - val_acc: 0.9185\n",
            "Epoch 64/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.3662 - acc: 0.8765 - val_loss: 0.2439 - val_acc: 0.9220\n",
            "Epoch 65/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.3657 - acc: 0.8789 - val_loss: 0.2468 - val_acc: 0.9230\n",
            "Epoch 66/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.3584 - acc: 0.8825 - val_loss: 0.2464 - val_acc: 0.9195\n",
            "Epoch 67/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3619 - acc: 0.8774 - val_loss: 0.2407 - val_acc: 0.9230\n",
            "Epoch 68/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3641 - acc: 0.8817 - val_loss: 0.2463 - val_acc: 0.9195\n",
            "Epoch 69/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.3607 - acc: 0.8774 - val_loss: 0.2534 - val_acc: 0.9175\n",
            "Epoch 70/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3586 - acc: 0.8809 - val_loss: 0.2405 - val_acc: 0.9215\n",
            "Epoch 71/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3646 - acc: 0.8801 - val_loss: 0.2423 - val_acc: 0.9215\n",
            "Epoch 72/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.3601 - acc: 0.8777 - val_loss: 0.2393 - val_acc: 0.9240\n",
            "Epoch 73/500\n",
            "8000/8000 [==============================] - 0s 27us/sample - loss: 0.3688 - acc: 0.8783 - val_loss: 0.2464 - val_acc: 0.9205\n",
            "Epoch 74/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.3655 - acc: 0.8815 - val_loss: 0.2383 - val_acc: 0.9240\n",
            "Epoch 75/500\n",
            "8000/8000 [==============================] - 0s 28us/sample - loss: 0.3619 - acc: 0.8801 - val_loss: 0.2399 - val_acc: 0.9235\n",
            "Epoch 76/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.3556 - acc: 0.8835 - val_loss: 0.2405 - val_acc: 0.9240\n",
            "Epoch 77/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.3567 - acc: 0.8814 - val_loss: 0.2386 - val_acc: 0.9215\n",
            "Epoch 78/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.3575 - acc: 0.8785 - val_loss: 0.2375 - val_acc: 0.9265\n",
            "Epoch 79/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3527 - acc: 0.8823 - val_loss: 0.2426 - val_acc: 0.9230\n",
            "Epoch 80/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3612 - acc: 0.8770 - val_loss: 0.2435 - val_acc: 0.9225\n",
            "Epoch 81/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3546 - acc: 0.8829 - val_loss: 0.2415 - val_acc: 0.9255\n",
            "Epoch 82/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3517 - acc: 0.8826 - val_loss: 0.2444 - val_acc: 0.9220\n",
            "Epoch 83/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.3599 - acc: 0.8852 - val_loss: 0.2388 - val_acc: 0.9230\n",
            "Epoch 84/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3612 - acc: 0.8821 - val_loss: 0.2397 - val_acc: 0.9220\n",
            "Epoch 85/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3433 - acc: 0.8831 - val_loss: 0.2387 - val_acc: 0.9235\n",
            "Epoch 86/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3535 - acc: 0.8771 - val_loss: 0.2371 - val_acc: 0.9255\n",
            "Epoch 87/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3584 - acc: 0.8819 - val_loss: 0.2343 - val_acc: 0.9240\n",
            "Epoch 88/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.3502 - acc: 0.8863 - val_loss: 0.2353 - val_acc: 0.9245\n",
            "Epoch 89/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.3562 - acc: 0.8836 - val_loss: 0.2371 - val_acc: 0.9250\n",
            "Epoch 90/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.3413 - acc: 0.8849 - val_loss: 0.2379 - val_acc: 0.9250\n",
            "Epoch 91/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3482 - acc: 0.8848 - val_loss: 0.2374 - val_acc: 0.9250\n",
            "Epoch 92/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3498 - acc: 0.8855 - val_loss: 0.2338 - val_acc: 0.9230\n",
            "Epoch 93/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.3438 - acc: 0.8867 - val_loss: 0.2353 - val_acc: 0.9275\n",
            "Epoch 94/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.3474 - acc: 0.8808 - val_loss: 0.2405 - val_acc: 0.9200\n",
            "Epoch 95/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.3461 - acc: 0.8859 - val_loss: 0.2378 - val_acc: 0.9225\n",
            "Epoch 96/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.3464 - acc: 0.8804 - val_loss: 0.2321 - val_acc: 0.9260\n",
            "Epoch 97/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.3483 - acc: 0.8878 - val_loss: 0.2340 - val_acc: 0.9235\n",
            "Epoch 98/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3539 - acc: 0.8810 - val_loss: 0.2306 - val_acc: 0.9260\n",
            "Epoch 99/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.3416 - acc: 0.8849 - val_loss: 0.2347 - val_acc: 0.9270\n",
            "Epoch 100/500\n",
            "8000/8000 [==============================] - 0s 27us/sample - loss: 0.3433 - acc: 0.8849 - val_loss: 0.2324 - val_acc: 0.9255\n",
            "Epoch 101/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3399 - acc: 0.8864 - val_loss: 0.2391 - val_acc: 0.9245\n",
            "Epoch 102/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3355 - acc: 0.8895 - val_loss: 0.2339 - val_acc: 0.9255\n",
            "Epoch 103/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3439 - acc: 0.8826 - val_loss: 0.2319 - val_acc: 0.9280\n",
            "Epoch 104/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3307 - acc: 0.8878 - val_loss: 0.2337 - val_acc: 0.9270\n",
            "Epoch 105/500\n",
            "8000/8000 [==============================] - 0s 27us/sample - loss: 0.3453 - acc: 0.8856 - val_loss: 0.2365 - val_acc: 0.9275\n",
            "Epoch 106/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.3471 - acc: 0.8859 - val_loss: 0.2331 - val_acc: 0.9270\n",
            "Epoch 107/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3520 - acc: 0.8826 - val_loss: 0.2332 - val_acc: 0.9255\n",
            "Epoch 108/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3424 - acc: 0.8866 - val_loss: 0.2311 - val_acc: 0.9280\n",
            "Epoch 109/500\n",
            "8000/8000 [==============================] - 0s 28us/sample - loss: 0.3443 - acc: 0.8861 - val_loss: 0.2317 - val_acc: 0.9265\n",
            "Epoch 110/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.3417 - acc: 0.8866 - val_loss: 0.2329 - val_acc: 0.9245\n",
            "Epoch 111/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3349 - acc: 0.8881 - val_loss: 0.2354 - val_acc: 0.9240\n",
            "Epoch 112/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3413 - acc: 0.8844 - val_loss: 0.2340 - val_acc: 0.9255\n",
            "Epoch 113/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3393 - acc: 0.8855 - val_loss: 0.2324 - val_acc: 0.9295\n",
            "Epoch 114/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3379 - acc: 0.8879 - val_loss: 0.2311 - val_acc: 0.9265\n",
            "Epoch 115/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3414 - acc: 0.8892 - val_loss: 0.2296 - val_acc: 0.9270\n",
            "Epoch 116/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.3430 - acc: 0.8856 - val_loss: 0.2274 - val_acc: 0.9275\n",
            "Epoch 117/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3344 - acc: 0.8879 - val_loss: 0.2286 - val_acc: 0.9275\n",
            "Epoch 118/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3408 - acc: 0.8857 - val_loss: 0.2289 - val_acc: 0.9280\n",
            "Epoch 119/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.3333 - acc: 0.8848 - val_loss: 0.2300 - val_acc: 0.9275\n",
            "Epoch 120/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3304 - acc: 0.8881 - val_loss: 0.2288 - val_acc: 0.9295\n",
            "Epoch 121/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3260 - acc: 0.8878 - val_loss: 0.2291 - val_acc: 0.9285\n",
            "Epoch 122/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3316 - acc: 0.8864 - val_loss: 0.2240 - val_acc: 0.9275\n",
            "Epoch 123/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3338 - acc: 0.8921 - val_loss: 0.2235 - val_acc: 0.9285\n",
            "Epoch 124/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3391 - acc: 0.8848 - val_loss: 0.2287 - val_acc: 0.9265\n",
            "Epoch 125/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3434 - acc: 0.8867 - val_loss: 0.2314 - val_acc: 0.9265\n",
            "Epoch 126/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3364 - acc: 0.8842 - val_loss: 0.2268 - val_acc: 0.9270\n",
            "Epoch 127/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3376 - acc: 0.8881 - val_loss: 0.2257 - val_acc: 0.9285\n",
            "Epoch 128/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.3255 - acc: 0.8920 - val_loss: 0.2276 - val_acc: 0.9265\n",
            "Epoch 129/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3236 - acc: 0.8898 - val_loss: 0.2273 - val_acc: 0.9285\n",
            "Epoch 130/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.3276 - acc: 0.8890 - val_loss: 0.2339 - val_acc: 0.9250\n",
            "Epoch 131/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3236 - acc: 0.8894 - val_loss: 0.2281 - val_acc: 0.9270\n",
            "Epoch 132/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3273 - acc: 0.8913 - val_loss: 0.2254 - val_acc: 0.9295\n",
            "Epoch 133/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3272 - acc: 0.8900 - val_loss: 0.2248 - val_acc: 0.9280\n",
            "Epoch 134/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3375 - acc: 0.8865 - val_loss: 0.2294 - val_acc: 0.9275\n",
            "Epoch 135/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.3388 - acc: 0.8848 - val_loss: 0.2255 - val_acc: 0.9275\n",
            "Epoch 136/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.3270 - acc: 0.8873 - val_loss: 0.2295 - val_acc: 0.9265\n",
            "Epoch 137/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3301 - acc: 0.8870 - val_loss: 0.2257 - val_acc: 0.9280\n",
            "Epoch 138/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.3342 - acc: 0.8889 - val_loss: 0.2262 - val_acc: 0.9295\n",
            "Epoch 139/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.3362 - acc: 0.8871 - val_loss: 0.2210 - val_acc: 0.9290\n",
            "Epoch 140/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3323 - acc: 0.8923 - val_loss: 0.2194 - val_acc: 0.9290\n",
            "Epoch 141/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3245 - acc: 0.8882 - val_loss: 0.2273 - val_acc: 0.9290\n",
            "Epoch 142/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3325 - acc: 0.8900 - val_loss: 0.2199 - val_acc: 0.9295\n",
            "Epoch 143/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3298 - acc: 0.8870 - val_loss: 0.2208 - val_acc: 0.9315\n",
            "Epoch 144/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3280 - acc: 0.8894 - val_loss: 0.2217 - val_acc: 0.9300\n",
            "Epoch 145/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3326 - acc: 0.8884 - val_loss: 0.2222 - val_acc: 0.9305\n",
            "Epoch 146/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3343 - acc: 0.8921 - val_loss: 0.2222 - val_acc: 0.9295\n",
            "Epoch 147/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.3242 - acc: 0.8920 - val_loss: 0.2259 - val_acc: 0.9290\n",
            "Epoch 148/500\n",
            "8000/8000 [==============================] - 0s 27us/sample - loss: 0.3258 - acc: 0.8931 - val_loss: 0.2253 - val_acc: 0.9300\n",
            "Epoch 149/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3351 - acc: 0.8857 - val_loss: 0.2271 - val_acc: 0.9300\n",
            "Epoch 150/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3168 - acc: 0.8974 - val_loss: 0.2235 - val_acc: 0.9285\n",
            "Epoch 151/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3199 - acc: 0.8906 - val_loss: 0.2239 - val_acc: 0.9275\n",
            "Epoch 152/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.3232 - acc: 0.8929 - val_loss: 0.2244 - val_acc: 0.9290\n",
            "Epoch 153/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3183 - acc: 0.8906 - val_loss: 0.2228 - val_acc: 0.9285\n",
            "Epoch 154/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3262 - acc: 0.8889 - val_loss: 0.2224 - val_acc: 0.9285\n",
            "Epoch 155/500\n",
            "8000/8000 [==============================] - 0s 27us/sample - loss: 0.3212 - acc: 0.8928 - val_loss: 0.2261 - val_acc: 0.9275\n",
            "Epoch 156/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3298 - acc: 0.8901 - val_loss: 0.2257 - val_acc: 0.9275\n",
            "Epoch 157/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.3247 - acc: 0.8895 - val_loss: 0.2200 - val_acc: 0.9300\n",
            "Epoch 158/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.3157 - acc: 0.8938 - val_loss: 0.2184 - val_acc: 0.9285\n",
            "Epoch 159/500\n",
            "8000/8000 [==============================] - 0s 27us/sample - loss: 0.3245 - acc: 0.8876 - val_loss: 0.2187 - val_acc: 0.9290\n",
            "Epoch 160/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.3281 - acc: 0.8879 - val_loss: 0.2204 - val_acc: 0.9300\n",
            "Epoch 161/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3124 - acc: 0.8938 - val_loss: 0.2227 - val_acc: 0.9305\n",
            "Epoch 162/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.3244 - acc: 0.8947 - val_loss: 0.2127 - val_acc: 0.9300\n",
            "Epoch 163/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3175 - acc: 0.8936 - val_loss: 0.2172 - val_acc: 0.9290\n",
            "Epoch 164/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3192 - acc: 0.8953 - val_loss: 0.2189 - val_acc: 0.9315\n",
            "Epoch 165/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3142 - acc: 0.8946 - val_loss: 0.2186 - val_acc: 0.9330\n",
            "Epoch 166/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.3277 - acc: 0.8894 - val_loss: 0.2213 - val_acc: 0.9325\n",
            "Epoch 167/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.3270 - acc: 0.8906 - val_loss: 0.2149 - val_acc: 0.9320\n",
            "Epoch 168/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3140 - acc: 0.8954 - val_loss: 0.2166 - val_acc: 0.9325\n",
            "Epoch 169/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3259 - acc: 0.8896 - val_loss: 0.2148 - val_acc: 0.9320\n",
            "Epoch 170/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3171 - acc: 0.8955 - val_loss: 0.2145 - val_acc: 0.9310\n",
            "Epoch 171/500\n",
            "8000/8000 [==============================] - 0s 30us/sample - loss: 0.3168 - acc: 0.8919 - val_loss: 0.2146 - val_acc: 0.9305\n",
            "Epoch 172/500\n",
            "8000/8000 [==============================] - 0s 30us/sample - loss: 0.3198 - acc: 0.8928 - val_loss: 0.2116 - val_acc: 0.9315\n",
            "Epoch 173/500\n",
            "8000/8000 [==============================] - 0s 29us/sample - loss: 0.3223 - acc: 0.8866 - val_loss: 0.2204 - val_acc: 0.9325\n",
            "Epoch 174/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.3179 - acc: 0.8907 - val_loss: 0.2186 - val_acc: 0.9325\n",
            "Epoch 175/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.3061 - acc: 0.8944 - val_loss: 0.2151 - val_acc: 0.9320\n",
            "Epoch 176/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3171 - acc: 0.8972 - val_loss: 0.2116 - val_acc: 0.9340\n",
            "Epoch 177/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3169 - acc: 0.8954 - val_loss: 0.2159 - val_acc: 0.9335\n",
            "Epoch 178/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3167 - acc: 0.8964 - val_loss: 0.2161 - val_acc: 0.9335\n",
            "Epoch 179/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.3100 - acc: 0.8935 - val_loss: 0.2160 - val_acc: 0.9330\n",
            "Epoch 180/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.3122 - acc: 0.8994 - val_loss: 0.2166 - val_acc: 0.9345\n",
            "Epoch 181/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.3217 - acc: 0.8894 - val_loss: 0.2135 - val_acc: 0.9360\n",
            "Epoch 182/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.3114 - acc: 0.8955 - val_loss: 0.2152 - val_acc: 0.9380\n",
            "Epoch 183/500\n",
            "8000/8000 [==============================] - 0s 30us/sample - loss: 0.3200 - acc: 0.8931 - val_loss: 0.2131 - val_acc: 0.9390\n",
            "Epoch 184/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3149 - acc: 0.8974 - val_loss: 0.2137 - val_acc: 0.9330\n",
            "Epoch 185/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.3148 - acc: 0.8946 - val_loss: 0.2122 - val_acc: 0.9350\n",
            "Epoch 186/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.3186 - acc: 0.8911 - val_loss: 0.2107 - val_acc: 0.9350\n",
            "Epoch 187/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.3146 - acc: 0.8930 - val_loss: 0.2100 - val_acc: 0.9340\n",
            "Epoch 188/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.3125 - acc: 0.8981 - val_loss: 0.2124 - val_acc: 0.9340\n",
            "Epoch 189/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.3194 - acc: 0.8940 - val_loss: 0.2172 - val_acc: 0.9315\n",
            "Epoch 190/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.3267 - acc: 0.8950 - val_loss: 0.2113 - val_acc: 0.9370\n",
            "Epoch 191/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3082 - acc: 0.8965 - val_loss: 0.2143 - val_acc: 0.9365\n",
            "Epoch 192/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3205 - acc: 0.8934 - val_loss: 0.2114 - val_acc: 0.9350\n",
            "Epoch 193/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.2991 - acc: 0.9016 - val_loss: 0.2121 - val_acc: 0.9380\n",
            "Epoch 194/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.3258 - acc: 0.8946 - val_loss: 0.2080 - val_acc: 0.9350\n",
            "Epoch 195/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.3081 - acc: 0.8997 - val_loss: 0.2069 - val_acc: 0.9360\n",
            "Epoch 196/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.3152 - acc: 0.8964 - val_loss: 0.2102 - val_acc: 0.9365\n",
            "Epoch 197/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3185 - acc: 0.8939 - val_loss: 0.2150 - val_acc: 0.9365\n",
            "Epoch 198/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3175 - acc: 0.8894 - val_loss: 0.2094 - val_acc: 0.9365\n",
            "Epoch 199/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3143 - acc: 0.8915 - val_loss: 0.2164 - val_acc: 0.9360\n",
            "Epoch 200/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.3132 - acc: 0.8906 - val_loss: 0.2126 - val_acc: 0.9370\n",
            "Epoch 201/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3053 - acc: 0.8986 - val_loss: 0.2121 - val_acc: 0.9360\n",
            "Epoch 202/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.3037 - acc: 0.9016 - val_loss: 0.2093 - val_acc: 0.9380\n",
            "Epoch 203/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3067 - acc: 0.8970 - val_loss: 0.2113 - val_acc: 0.9365\n",
            "Epoch 204/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.3197 - acc: 0.8919 - val_loss: 0.2075 - val_acc: 0.9345\n",
            "Epoch 205/500\n",
            "8000/8000 [==============================] - 0s 30us/sample - loss: 0.3127 - acc: 0.8956 - val_loss: 0.2101 - val_acc: 0.9360\n",
            "Epoch 206/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.3133 - acc: 0.8929 - val_loss: 0.2088 - val_acc: 0.9340\n",
            "Epoch 207/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3196 - acc: 0.8965 - val_loss: 0.2078 - val_acc: 0.9335\n",
            "Epoch 208/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3155 - acc: 0.8970 - val_loss: 0.2087 - val_acc: 0.9365\n",
            "Epoch 209/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3152 - acc: 0.8917 - val_loss: 0.2081 - val_acc: 0.9345\n",
            "Epoch 210/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3081 - acc: 0.8935 - val_loss: 0.2095 - val_acc: 0.9370\n",
            "Epoch 211/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.3108 - acc: 0.8904 - val_loss: 0.2115 - val_acc: 0.9345\n",
            "Epoch 212/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3221 - acc: 0.8914 - val_loss: 0.2064 - val_acc: 0.9405\n",
            "Epoch 213/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3106 - acc: 0.8999 - val_loss: 0.2140 - val_acc: 0.9385\n",
            "Epoch 214/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3060 - acc: 0.8959 - val_loss: 0.2070 - val_acc: 0.9405\n",
            "Epoch 215/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.3202 - acc: 0.8915 - val_loss: 0.2085 - val_acc: 0.9380\n",
            "Epoch 216/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.3150 - acc: 0.8939 - val_loss: 0.2105 - val_acc: 0.9400\n",
            "Epoch 217/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.3128 - acc: 0.8934 - val_loss: 0.2061 - val_acc: 0.9390\n",
            "Epoch 218/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.3115 - acc: 0.8950 - val_loss: 0.2078 - val_acc: 0.9365\n",
            "Epoch 219/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3110 - acc: 0.8951 - val_loss: 0.2111 - val_acc: 0.9365\n",
            "Epoch 220/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.3100 - acc: 0.8988 - val_loss: 0.2174 - val_acc: 0.9360\n",
            "Epoch 221/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3101 - acc: 0.8978 - val_loss: 0.2158 - val_acc: 0.9385\n",
            "Epoch 222/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.3104 - acc: 0.9006 - val_loss: 0.2088 - val_acc: 0.9390\n",
            "Epoch 223/500\n",
            "8000/8000 [==============================] - 0s 27us/sample - loss: 0.3094 - acc: 0.8994 - val_loss: 0.2129 - val_acc: 0.9395\n",
            "Epoch 224/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3064 - acc: 0.8990 - val_loss: 0.2093 - val_acc: 0.9405\n",
            "Epoch 225/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2993 - acc: 0.8994 - val_loss: 0.2068 - val_acc: 0.9400\n",
            "Epoch 226/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.3162 - acc: 0.8940 - val_loss: 0.2088 - val_acc: 0.9400\n",
            "Epoch 227/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2892 - acc: 0.9061 - val_loss: 0.2059 - val_acc: 0.9375\n",
            "Epoch 228/500\n",
            "8000/8000 [==============================] - 0s 27us/sample - loss: 0.3104 - acc: 0.8978 - val_loss: 0.2049 - val_acc: 0.9415\n",
            "Epoch 229/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.3109 - acc: 0.8988 - val_loss: 0.2046 - val_acc: 0.9430\n",
            "Epoch 230/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.3101 - acc: 0.8986 - val_loss: 0.2105 - val_acc: 0.9400\n",
            "Epoch 231/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.3084 - acc: 0.8994 - val_loss: 0.2009 - val_acc: 0.9435\n",
            "Epoch 232/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.3181 - acc: 0.8926 - val_loss: 0.2046 - val_acc: 0.9430\n",
            "Epoch 233/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2877 - acc: 0.9029 - val_loss: 0.2138 - val_acc: 0.9415\n",
            "Epoch 234/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3155 - acc: 0.8984 - val_loss: 0.2100 - val_acc: 0.9390\n",
            "Epoch 235/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3090 - acc: 0.8985 - val_loss: 0.2101 - val_acc: 0.9400\n",
            "Epoch 236/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3036 - acc: 0.8986 - val_loss: 0.2167 - val_acc: 0.9365\n",
            "Epoch 237/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3062 - acc: 0.9000 - val_loss: 0.2089 - val_acc: 0.9420\n",
            "Epoch 238/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.3131 - acc: 0.8997 - val_loss: 0.2105 - val_acc: 0.9410\n",
            "Epoch 239/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.3106 - acc: 0.8941 - val_loss: 0.2050 - val_acc: 0.9415\n",
            "Epoch 240/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3056 - acc: 0.9000 - val_loss: 0.2059 - val_acc: 0.9400\n",
            "Epoch 241/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3084 - acc: 0.8976 - val_loss: 0.2006 - val_acc: 0.9415\n",
            "Epoch 242/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3041 - acc: 0.9010 - val_loss: 0.2039 - val_acc: 0.9420\n",
            "Epoch 243/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3128 - acc: 0.8940 - val_loss: 0.2067 - val_acc: 0.9410\n",
            "Epoch 244/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.3050 - acc: 0.8949 - val_loss: 0.2057 - val_acc: 0.9395\n",
            "Epoch 245/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3065 - acc: 0.8917 - val_loss: 0.2092 - val_acc: 0.9390\n",
            "Epoch 246/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3113 - acc: 0.8963 - val_loss: 0.2037 - val_acc: 0.9420\n",
            "Epoch 247/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.3106 - acc: 0.8940 - val_loss: 0.2052 - val_acc: 0.9405\n",
            "Epoch 248/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.3073 - acc: 0.8965 - val_loss: 0.2031 - val_acc: 0.9410\n",
            "Epoch 249/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.3150 - acc: 0.8955 - val_loss: 0.2062 - val_acc: 0.9420\n",
            "Epoch 250/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.3110 - acc: 0.8957 - val_loss: 0.2019 - val_acc: 0.9400\n",
            "Epoch 251/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3039 - acc: 0.8991 - val_loss: 0.2095 - val_acc: 0.9430\n",
            "Epoch 252/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2972 - acc: 0.8991 - val_loss: 0.2111 - val_acc: 0.9390\n",
            "Epoch 253/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3159 - acc: 0.8995 - val_loss: 0.2036 - val_acc: 0.9425\n",
            "Epoch 254/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2936 - acc: 0.9006 - val_loss: 0.2017 - val_acc: 0.9410\n",
            "Epoch 255/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.3178 - acc: 0.8930 - val_loss: 0.2021 - val_acc: 0.9425\n",
            "Epoch 256/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3092 - acc: 0.8953 - val_loss: 0.2022 - val_acc: 0.9430\n",
            "Epoch 257/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3130 - acc: 0.8969 - val_loss: 0.2030 - val_acc: 0.9410\n",
            "Epoch 258/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.3042 - acc: 0.8991 - val_loss: 0.2057 - val_acc: 0.9405\n",
            "Epoch 259/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2990 - acc: 0.8959 - val_loss: 0.2090 - val_acc: 0.9355\n",
            "Epoch 260/500\n",
            "8000/8000 [==============================] - 0s 27us/sample - loss: 0.3066 - acc: 0.9000 - val_loss: 0.2054 - val_acc: 0.9410\n",
            "Epoch 261/500\n",
            "8000/8000 [==============================] - 0s 31us/sample - loss: 0.3027 - acc: 0.8957 - val_loss: 0.2036 - val_acc: 0.9410\n",
            "Epoch 262/500\n",
            "8000/8000 [==============================] - 0s 31us/sample - loss: 0.3036 - acc: 0.8997 - val_loss: 0.2060 - val_acc: 0.9395\n",
            "Epoch 263/500\n",
            "8000/8000 [==============================] - 0s 29us/sample - loss: 0.3084 - acc: 0.9010 - val_loss: 0.2113 - val_acc: 0.9385\n",
            "Epoch 264/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.3097 - acc: 0.8980 - val_loss: 0.2062 - val_acc: 0.9420\n",
            "Epoch 265/500\n",
            "8000/8000 [==============================] - 0s 27us/sample - loss: 0.2942 - acc: 0.9009 - val_loss: 0.2027 - val_acc: 0.9420\n",
            "Epoch 266/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.3052 - acc: 0.8953 - val_loss: 0.2048 - val_acc: 0.9430\n",
            "Epoch 267/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3039 - acc: 0.8988 - val_loss: 0.2037 - val_acc: 0.9425\n",
            "Epoch 268/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3085 - acc: 0.8942 - val_loss: 0.2024 - val_acc: 0.9395\n",
            "Epoch 269/500\n",
            "8000/8000 [==============================] - 0s 27us/sample - loss: 0.3032 - acc: 0.8989 - val_loss: 0.2037 - val_acc: 0.9405\n",
            "Epoch 270/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.3114 - acc: 0.8965 - val_loss: 0.2046 - val_acc: 0.9385\n",
            "Epoch 271/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.3062 - acc: 0.8950 - val_loss: 0.2055 - val_acc: 0.9420\n",
            "Epoch 272/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3033 - acc: 0.8979 - val_loss: 0.2014 - val_acc: 0.9410\n",
            "Epoch 273/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3021 - acc: 0.8985 - val_loss: 0.2000 - val_acc: 0.9415\n",
            "Epoch 274/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.3007 - acc: 0.9013 - val_loss: 0.2023 - val_acc: 0.9440\n",
            "Epoch 275/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.3075 - acc: 0.8974 - val_loss: 0.2020 - val_acc: 0.9425\n",
            "Epoch 276/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3077 - acc: 0.8991 - val_loss: 0.2008 - val_acc: 0.9425\n",
            "Epoch 277/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3058 - acc: 0.8981 - val_loss: 0.2002 - val_acc: 0.9415\n",
            "Epoch 278/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.3043 - acc: 0.8957 - val_loss: 0.2005 - val_acc: 0.9420\n",
            "Epoch 279/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.3086 - acc: 0.8991 - val_loss: 0.2079 - val_acc: 0.9405\n",
            "Epoch 280/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.3093 - acc: 0.8960 - val_loss: 0.2001 - val_acc: 0.9430\n",
            "Epoch 281/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2994 - acc: 0.8979 - val_loss: 0.2027 - val_acc: 0.9415\n",
            "Epoch 282/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.3006 - acc: 0.8984 - val_loss: 0.2032 - val_acc: 0.9420\n",
            "Epoch 283/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2990 - acc: 0.8982 - val_loss: 0.2025 - val_acc: 0.9425\n",
            "Epoch 284/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.3028 - acc: 0.8976 - val_loss: 0.2016 - val_acc: 0.9440\n",
            "Epoch 285/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.3093 - acc: 0.8939 - val_loss: 0.2005 - val_acc: 0.9415\n",
            "Epoch 286/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.3038 - acc: 0.8996 - val_loss: 0.2027 - val_acc: 0.9415\n",
            "Epoch 287/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.3047 - acc: 0.8978 - val_loss: 0.2039 - val_acc: 0.9405\n",
            "Epoch 288/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.3021 - acc: 0.8936 - val_loss: 0.2027 - val_acc: 0.9420\n",
            "Epoch 289/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.3080 - acc: 0.8984 - val_loss: 0.2004 - val_acc: 0.9450\n",
            "Epoch 290/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3019 - acc: 0.8995 - val_loss: 0.2011 - val_acc: 0.9415\n",
            "Epoch 291/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.3006 - acc: 0.8963 - val_loss: 0.2050 - val_acc: 0.9410\n",
            "Epoch 292/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.3025 - acc: 0.8995 - val_loss: 0.2008 - val_acc: 0.9400\n",
            "Epoch 293/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2995 - acc: 0.8966 - val_loss: 0.1990 - val_acc: 0.9435\n",
            "Epoch 294/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2998 - acc: 0.9013 - val_loss: 0.2013 - val_acc: 0.9415\n",
            "Epoch 295/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3000 - acc: 0.8985 - val_loss: 0.2011 - val_acc: 0.9425\n",
            "Epoch 296/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.2950 - acc: 0.9043 - val_loss: 0.2014 - val_acc: 0.9425\n",
            "Epoch 297/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.3073 - acc: 0.8915 - val_loss: 0.1977 - val_acc: 0.9435\n",
            "Epoch 298/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2969 - acc: 0.9024 - val_loss: 0.1997 - val_acc: 0.9430\n",
            "Epoch 299/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.2951 - acc: 0.9011 - val_loss: 0.2057 - val_acc: 0.9410\n",
            "Epoch 300/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3057 - acc: 0.8971 - val_loss: 0.2028 - val_acc: 0.9405\n",
            "Epoch 301/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3069 - acc: 0.8936 - val_loss: 0.2014 - val_acc: 0.9410\n",
            "Epoch 302/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2999 - acc: 0.8982 - val_loss: 0.1990 - val_acc: 0.9435\n",
            "Epoch 303/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2993 - acc: 0.8975 - val_loss: 0.2021 - val_acc: 0.9410\n",
            "Epoch 304/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3007 - acc: 0.8959 - val_loss: 0.2053 - val_acc: 0.9425\n",
            "Epoch 305/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2960 - acc: 0.8939 - val_loss: 0.2053 - val_acc: 0.9405\n",
            "Epoch 306/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2908 - acc: 0.9011 - val_loss: 0.2071 - val_acc: 0.9390\n",
            "Epoch 307/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2970 - acc: 0.8996 - val_loss: 0.2036 - val_acc: 0.9420\n",
            "Epoch 308/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.3063 - acc: 0.8992 - val_loss: 0.2008 - val_acc: 0.9410\n",
            "Epoch 309/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2993 - acc: 0.9009 - val_loss: 0.2008 - val_acc: 0.9435\n",
            "Epoch 310/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.3051 - acc: 0.8999 - val_loss: 0.2010 - val_acc: 0.9415\n",
            "Epoch 311/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2934 - acc: 0.8995 - val_loss: 0.2004 - val_acc: 0.9420\n",
            "Epoch 312/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2991 - acc: 0.8996 - val_loss: 0.2038 - val_acc: 0.9410\n",
            "Epoch 313/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2963 - acc: 0.9022 - val_loss: 0.2018 - val_acc: 0.9425\n",
            "Epoch 314/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3017 - acc: 0.9003 - val_loss: 0.2025 - val_acc: 0.9415\n",
            "Epoch 315/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2978 - acc: 0.8965 - val_loss: 0.2013 - val_acc: 0.9430\n",
            "Epoch 316/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3013 - acc: 0.8979 - val_loss: 0.1973 - val_acc: 0.9415\n",
            "Epoch 317/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2998 - acc: 0.8990 - val_loss: 0.1985 - val_acc: 0.9415\n",
            "Epoch 318/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2972 - acc: 0.8979 - val_loss: 0.1942 - val_acc: 0.9425\n",
            "Epoch 319/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.3015 - acc: 0.9000 - val_loss: 0.1993 - val_acc: 0.9430\n",
            "Epoch 320/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2934 - acc: 0.8982 - val_loss: 0.1928 - val_acc: 0.9435\n",
            "Epoch 321/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3009 - acc: 0.9007 - val_loss: 0.1969 - val_acc: 0.9440\n",
            "Epoch 322/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3053 - acc: 0.8970 - val_loss: 0.1953 - val_acc: 0.9435\n",
            "Epoch 323/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2978 - acc: 0.9035 - val_loss: 0.1928 - val_acc: 0.9440\n",
            "Epoch 324/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2983 - acc: 0.9041 - val_loss: 0.1960 - val_acc: 0.9455\n",
            "Epoch 325/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2952 - acc: 0.9013 - val_loss: 0.2019 - val_acc: 0.9405\n",
            "Epoch 326/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3029 - acc: 0.8982 - val_loss: 0.1981 - val_acc: 0.9435\n",
            "Epoch 327/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2974 - acc: 0.9054 - val_loss: 0.1971 - val_acc: 0.9420\n",
            "Epoch 328/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2952 - acc: 0.9007 - val_loss: 0.1986 - val_acc: 0.9435\n",
            "Epoch 329/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3050 - acc: 0.8961 - val_loss: 0.1982 - val_acc: 0.9420\n",
            "Epoch 330/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.3013 - acc: 0.9010 - val_loss: 0.1992 - val_acc: 0.9420\n",
            "Epoch 331/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3043 - acc: 0.9000 - val_loss: 0.1962 - val_acc: 0.9440\n",
            "Epoch 332/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3001 - acc: 0.8991 - val_loss: 0.1975 - val_acc: 0.9455\n",
            "Epoch 333/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2928 - acc: 0.9030 - val_loss: 0.1948 - val_acc: 0.9465\n",
            "Epoch 334/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.3046 - acc: 0.8990 - val_loss: 0.1942 - val_acc: 0.9455\n",
            "Epoch 335/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2990 - acc: 0.9006 - val_loss: 0.1962 - val_acc: 0.9435\n",
            "Epoch 336/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.2868 - acc: 0.9022 - val_loss: 0.1927 - val_acc: 0.9430\n",
            "Epoch 337/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2965 - acc: 0.9030 - val_loss: 0.1945 - val_acc: 0.9435\n",
            "Epoch 338/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2945 - acc: 0.9047 - val_loss: 0.2008 - val_acc: 0.9415\n",
            "Epoch 339/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2921 - acc: 0.9001 - val_loss: 0.2004 - val_acc: 0.9405\n",
            "Epoch 340/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2978 - acc: 0.8996 - val_loss: 0.1973 - val_acc: 0.9450\n",
            "Epoch 341/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.2969 - acc: 0.9022 - val_loss: 0.1972 - val_acc: 0.9420\n",
            "Epoch 342/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.3047 - acc: 0.8972 - val_loss: 0.1967 - val_acc: 0.9440\n",
            "Epoch 343/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.3033 - acc: 0.9009 - val_loss: 0.1977 - val_acc: 0.9450\n",
            "Epoch 344/500\n",
            "8000/8000 [==============================] - 0s 27us/sample - loss: 0.2864 - acc: 0.9064 - val_loss: 0.1962 - val_acc: 0.9440\n",
            "Epoch 345/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.3007 - acc: 0.9000 - val_loss: 0.1966 - val_acc: 0.9450\n",
            "Epoch 346/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.3010 - acc: 0.8995 - val_loss: 0.1965 - val_acc: 0.9440\n",
            "Epoch 347/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2899 - acc: 0.9005 - val_loss: 0.1919 - val_acc: 0.9455\n",
            "Epoch 348/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2965 - acc: 0.9060 - val_loss: 0.1981 - val_acc: 0.9435\n",
            "Epoch 349/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3031 - acc: 0.9030 - val_loss: 0.1970 - val_acc: 0.9455\n",
            "Epoch 350/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2914 - acc: 0.9053 - val_loss: 0.1971 - val_acc: 0.9450\n",
            "Epoch 351/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2951 - acc: 0.9021 - val_loss: 0.1924 - val_acc: 0.9445\n",
            "Epoch 352/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2911 - acc: 0.9064 - val_loss: 0.1906 - val_acc: 0.9460\n",
            "Epoch 353/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2918 - acc: 0.9070 - val_loss: 0.1920 - val_acc: 0.9445\n",
            "Epoch 354/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2905 - acc: 0.9078 - val_loss: 0.1917 - val_acc: 0.9445\n",
            "Epoch 355/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2990 - acc: 0.9054 - val_loss: 0.1923 - val_acc: 0.9450\n",
            "Epoch 356/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3021 - acc: 0.9016 - val_loss: 0.1902 - val_acc: 0.9450\n",
            "Epoch 357/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2977 - acc: 0.9046 - val_loss: 0.1967 - val_acc: 0.9445\n",
            "Epoch 358/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2945 - acc: 0.9074 - val_loss: 0.1947 - val_acc: 0.9445\n",
            "Epoch 359/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.3025 - acc: 0.9005 - val_loss: 0.1994 - val_acc: 0.9455\n",
            "Epoch 360/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2999 - acc: 0.9034 - val_loss: 0.1986 - val_acc: 0.9425\n",
            "Epoch 361/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2979 - acc: 0.9005 - val_loss: 0.1934 - val_acc: 0.9445\n",
            "Epoch 362/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2920 - acc: 0.9071 - val_loss: 0.1952 - val_acc: 0.9445\n",
            "Epoch 363/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2889 - acc: 0.9075 - val_loss: 0.1955 - val_acc: 0.9455\n",
            "Epoch 364/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2924 - acc: 0.9045 - val_loss: 0.1959 - val_acc: 0.9445\n",
            "Epoch 365/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2832 - acc: 0.9115 - val_loss: 0.1913 - val_acc: 0.9465\n",
            "Epoch 366/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2883 - acc: 0.9045 - val_loss: 0.1950 - val_acc: 0.9465\n",
            "Epoch 367/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2933 - acc: 0.9040 - val_loss: 0.1936 - val_acc: 0.9455\n",
            "Epoch 368/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2887 - acc: 0.9059 - val_loss: 0.1937 - val_acc: 0.9455\n",
            "Epoch 369/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2951 - acc: 0.9090 - val_loss: 0.1976 - val_acc: 0.9435\n",
            "Epoch 370/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2833 - acc: 0.9044 - val_loss: 0.1923 - val_acc: 0.9470\n",
            "Epoch 371/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2971 - acc: 0.9057 - val_loss: 0.1965 - val_acc: 0.9460\n",
            "Epoch 372/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2907 - acc: 0.9018 - val_loss: 0.1908 - val_acc: 0.9460\n",
            "Epoch 373/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2893 - acc: 0.9055 - val_loss: 0.1902 - val_acc: 0.9470\n",
            "Epoch 374/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2911 - acc: 0.9070 - val_loss: 0.1937 - val_acc: 0.9465\n",
            "Epoch 375/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2826 - acc: 0.9082 - val_loss: 0.2001 - val_acc: 0.9445\n",
            "Epoch 376/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2932 - acc: 0.9055 - val_loss: 0.1949 - val_acc: 0.9455\n",
            "Epoch 377/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2931 - acc: 0.9046 - val_loss: 0.2034 - val_acc: 0.9435\n",
            "Epoch 378/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2904 - acc: 0.9075 - val_loss: 0.1978 - val_acc: 0.9440\n",
            "Epoch 379/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2964 - acc: 0.8992 - val_loss: 0.1976 - val_acc: 0.9455\n",
            "Epoch 380/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2915 - acc: 0.9047 - val_loss: 0.1918 - val_acc: 0.9450\n",
            "Epoch 381/500\n",
            "8000/8000 [==============================] - 0s 28us/sample - loss: 0.3013 - acc: 0.9010 - val_loss: 0.1962 - val_acc: 0.9425\n",
            "Epoch 382/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2946 - acc: 0.9025 - val_loss: 0.2046 - val_acc: 0.9435\n",
            "Epoch 383/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2897 - acc: 0.9025 - val_loss: 0.1971 - val_acc: 0.9455\n",
            "Epoch 384/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2971 - acc: 0.8999 - val_loss: 0.1956 - val_acc: 0.9435\n",
            "Epoch 385/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2883 - acc: 0.9049 - val_loss: 0.1915 - val_acc: 0.9460\n",
            "Epoch 386/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.2890 - acc: 0.8997 - val_loss: 0.2022 - val_acc: 0.9425\n",
            "Epoch 387/500\n",
            "8000/8000 [==============================] - 0s 27us/sample - loss: 0.3053 - acc: 0.9006 - val_loss: 0.1973 - val_acc: 0.9465\n",
            "Epoch 388/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2858 - acc: 0.9068 - val_loss: 0.1938 - val_acc: 0.9475\n",
            "Epoch 389/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2981 - acc: 0.9000 - val_loss: 0.1940 - val_acc: 0.9440\n",
            "Epoch 390/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2780 - acc: 0.9084 - val_loss: 0.1934 - val_acc: 0.9465\n",
            "Epoch 391/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2957 - acc: 0.9019 - val_loss: 0.1956 - val_acc: 0.9460\n",
            "Epoch 392/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2885 - acc: 0.9085 - val_loss: 0.1907 - val_acc: 0.9460\n",
            "Epoch 393/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2874 - acc: 0.9049 - val_loss: 0.1893 - val_acc: 0.9465\n",
            "Epoch 394/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2910 - acc: 0.9056 - val_loss: 0.1949 - val_acc: 0.9440\n",
            "Epoch 395/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2905 - acc: 0.9018 - val_loss: 0.1986 - val_acc: 0.9455\n",
            "Epoch 396/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2910 - acc: 0.9024 - val_loss: 0.2023 - val_acc: 0.9415\n",
            "Epoch 397/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2898 - acc: 0.9050 - val_loss: 0.1948 - val_acc: 0.9440\n",
            "Epoch 398/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2857 - acc: 0.9081 - val_loss: 0.2024 - val_acc: 0.9445\n",
            "Epoch 399/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2954 - acc: 0.9050 - val_loss: 0.1926 - val_acc: 0.9465\n",
            "Epoch 400/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2877 - acc: 0.9064 - val_loss: 0.1895 - val_acc: 0.9470\n",
            "Epoch 401/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2818 - acc: 0.9062 - val_loss: 0.2023 - val_acc: 0.9435\n",
            "Epoch 402/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2894 - acc: 0.9019 - val_loss: 0.1948 - val_acc: 0.9460\n",
            "Epoch 403/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2813 - acc: 0.9064 - val_loss: 0.1930 - val_acc: 0.9460\n",
            "Epoch 404/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2874 - acc: 0.9057 - val_loss: 0.1946 - val_acc: 0.9460\n",
            "Epoch 405/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2839 - acc: 0.9078 - val_loss: 0.1870 - val_acc: 0.9470\n",
            "Epoch 406/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2856 - acc: 0.9053 - val_loss: 0.1926 - val_acc: 0.9445\n",
            "Epoch 407/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2819 - acc: 0.9028 - val_loss: 0.1930 - val_acc: 0.9470\n",
            "Epoch 408/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2900 - acc: 0.9010 - val_loss: 0.1979 - val_acc: 0.9420\n",
            "Epoch 409/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2975 - acc: 0.8988 - val_loss: 0.1973 - val_acc: 0.9460\n",
            "Epoch 410/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2897 - acc: 0.9045 - val_loss: 0.1968 - val_acc: 0.9430\n",
            "Epoch 411/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2868 - acc: 0.9045 - val_loss: 0.1985 - val_acc: 0.9445\n",
            "Epoch 412/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2815 - acc: 0.9044 - val_loss: 0.1922 - val_acc: 0.9455\n",
            "Epoch 413/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2891 - acc: 0.9032 - val_loss: 0.1950 - val_acc: 0.9425\n",
            "Epoch 414/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2791 - acc: 0.9055 - val_loss: 0.1951 - val_acc: 0.9450\n",
            "Epoch 415/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2836 - acc: 0.9039 - val_loss: 0.1881 - val_acc: 0.9465\n",
            "Epoch 416/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2929 - acc: 0.9034 - val_loss: 0.1936 - val_acc: 0.9445\n",
            "Epoch 417/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2915 - acc: 0.9043 - val_loss: 0.1933 - val_acc: 0.9445\n",
            "Epoch 418/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2886 - acc: 0.9034 - val_loss: 0.1968 - val_acc: 0.9440\n",
            "Epoch 419/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2796 - acc: 0.9057 - val_loss: 0.1938 - val_acc: 0.9445\n",
            "Epoch 420/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2955 - acc: 0.8997 - val_loss: 0.1892 - val_acc: 0.9465\n",
            "Epoch 421/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2933 - acc: 0.9029 - val_loss: 0.1928 - val_acc: 0.9465\n",
            "Epoch 422/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2870 - acc: 0.9005 - val_loss: 0.2005 - val_acc: 0.9445\n",
            "Epoch 423/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.2907 - acc: 0.9065 - val_loss: 0.1928 - val_acc: 0.9470\n",
            "Epoch 424/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2896 - acc: 0.9046 - val_loss: 0.1904 - val_acc: 0.9460\n",
            "Epoch 425/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2792 - acc: 0.9049 - val_loss: 0.1901 - val_acc: 0.9465\n",
            "Epoch 426/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2885 - acc: 0.9028 - val_loss: 0.1981 - val_acc: 0.9450\n",
            "Epoch 427/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2899 - acc: 0.9026 - val_loss: 0.1916 - val_acc: 0.9455\n",
            "Epoch 428/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2860 - acc: 0.9035 - val_loss: 0.1956 - val_acc: 0.9435\n",
            "Epoch 429/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2832 - acc: 0.9047 - val_loss: 0.2074 - val_acc: 0.9410\n",
            "Epoch 430/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2989 - acc: 0.9020 - val_loss: 0.1919 - val_acc: 0.9450\n",
            "Epoch 431/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2980 - acc: 0.9024 - val_loss: 0.1967 - val_acc: 0.9445\n",
            "Epoch 432/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2886 - acc: 0.8985 - val_loss: 0.1917 - val_acc: 0.9465\n",
            "Epoch 433/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.2995 - acc: 0.9018 - val_loss: 0.1889 - val_acc: 0.9475\n",
            "Epoch 434/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2837 - acc: 0.9064 - val_loss: 0.1907 - val_acc: 0.9460\n",
            "Epoch 435/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2844 - acc: 0.9095 - val_loss: 0.1911 - val_acc: 0.9465\n",
            "Epoch 436/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.2851 - acc: 0.9059 - val_loss: 0.1893 - val_acc: 0.9465\n",
            "Epoch 437/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2896 - acc: 0.9038 - val_loss: 0.1871 - val_acc: 0.9470\n",
            "Epoch 438/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2809 - acc: 0.9062 - val_loss: 0.1913 - val_acc: 0.9455\n",
            "Epoch 439/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2897 - acc: 0.9101 - val_loss: 0.1979 - val_acc: 0.9450\n",
            "Epoch 440/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2960 - acc: 0.9020 - val_loss: 0.1906 - val_acc: 0.9465\n",
            "Epoch 441/500\n",
            "8000/8000 [==============================] - 0s 27us/sample - loss: 0.2899 - acc: 0.9045 - val_loss: 0.1921 - val_acc: 0.9455\n",
            "Epoch 442/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2805 - acc: 0.9026 - val_loss: 0.1903 - val_acc: 0.9485\n",
            "Epoch 443/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2872 - acc: 0.9057 - val_loss: 0.1930 - val_acc: 0.9430\n",
            "Epoch 444/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2809 - acc: 0.9075 - val_loss: 0.1935 - val_acc: 0.9465\n",
            "Epoch 445/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2876 - acc: 0.9056 - val_loss: 0.2026 - val_acc: 0.9435\n",
            "Epoch 446/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.2845 - acc: 0.9055 - val_loss: 0.1893 - val_acc: 0.9470\n",
            "Epoch 447/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2785 - acc: 0.9064 - val_loss: 0.1874 - val_acc: 0.9475\n",
            "Epoch 448/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2745 - acc: 0.9068 - val_loss: 0.1905 - val_acc: 0.9470\n",
            "Epoch 449/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2862 - acc: 0.9057 - val_loss: 0.1936 - val_acc: 0.9475\n",
            "Epoch 450/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.2877 - acc: 0.9054 - val_loss: 0.1932 - val_acc: 0.9455\n",
            "Epoch 451/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2865 - acc: 0.9075 - val_loss: 0.1928 - val_acc: 0.9455\n",
            "Epoch 452/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2792 - acc: 0.9060 - val_loss: 0.1966 - val_acc: 0.9435\n",
            "Epoch 453/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2878 - acc: 0.9045 - val_loss: 0.1938 - val_acc: 0.9445\n",
            "Epoch 454/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2841 - acc: 0.9096 - val_loss: 0.1941 - val_acc: 0.9440\n",
            "Epoch 455/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2910 - acc: 0.9070 - val_loss: 0.1945 - val_acc: 0.9435\n",
            "Epoch 456/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2825 - acc: 0.9079 - val_loss: 0.1977 - val_acc: 0.9450\n",
            "Epoch 457/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.2912 - acc: 0.9005 - val_loss: 0.1943 - val_acc: 0.9455\n",
            "Epoch 458/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2910 - acc: 0.9054 - val_loss: 0.1965 - val_acc: 0.9450\n",
            "Epoch 459/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.2928 - acc: 0.9091 - val_loss: 0.1925 - val_acc: 0.9465\n",
            "Epoch 460/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2894 - acc: 0.9046 - val_loss: 0.1895 - val_acc: 0.9470\n",
            "Epoch 461/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3015 - acc: 0.9032 - val_loss: 0.1922 - val_acc: 0.9435\n",
            "Epoch 462/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2861 - acc: 0.9053 - val_loss: 0.1967 - val_acc: 0.9440\n",
            "Epoch 463/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2843 - acc: 0.9084 - val_loss: 0.1914 - val_acc: 0.9465\n",
            "Epoch 464/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2908 - acc: 0.9061 - val_loss: 0.1966 - val_acc: 0.9445\n",
            "Epoch 465/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.2864 - acc: 0.9057 - val_loss: 0.1940 - val_acc: 0.9435\n",
            "Epoch 466/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2842 - acc: 0.9075 - val_loss: 0.1928 - val_acc: 0.9465\n",
            "Epoch 467/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2899 - acc: 0.9076 - val_loss: 0.1917 - val_acc: 0.9465\n",
            "Epoch 468/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2868 - acc: 0.9115 - val_loss: 0.1896 - val_acc: 0.9460\n",
            "Epoch 469/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2769 - acc: 0.9076 - val_loss: 0.1892 - val_acc: 0.9460\n",
            "Epoch 470/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2755 - acc: 0.9099 - val_loss: 0.1915 - val_acc: 0.9465\n",
            "Epoch 471/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2861 - acc: 0.9036 - val_loss: 0.1901 - val_acc: 0.9470\n",
            "Epoch 472/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2929 - acc: 0.9021 - val_loss: 0.1934 - val_acc: 0.9450\n",
            "Epoch 473/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2919 - acc: 0.9055 - val_loss: 0.1905 - val_acc: 0.9470\n",
            "Epoch 474/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2866 - acc: 0.9099 - val_loss: 0.1890 - val_acc: 0.9475\n",
            "Epoch 475/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2807 - acc: 0.9062 - val_loss: 0.1864 - val_acc: 0.9475\n",
            "Epoch 476/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2807 - acc: 0.9093 - val_loss: 0.1891 - val_acc: 0.9450\n",
            "Epoch 477/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2870 - acc: 0.9034 - val_loss: 0.1905 - val_acc: 0.9445\n",
            "Epoch 478/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2847 - acc: 0.9060 - val_loss: 0.1907 - val_acc: 0.9460\n",
            "Epoch 479/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2946 - acc: 0.9057 - val_loss: 0.1930 - val_acc: 0.9440\n",
            "Epoch 480/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2771 - acc: 0.9071 - val_loss: 0.1883 - val_acc: 0.9465\n",
            "Epoch 481/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2733 - acc: 0.9124 - val_loss: 0.1897 - val_acc: 0.9460\n",
            "Epoch 482/500\n",
            "8000/8000 [==============================] - 0s 29us/sample - loss: 0.2798 - acc: 0.9097 - val_loss: 0.1911 - val_acc: 0.9455\n",
            "Epoch 483/500\n",
            "8000/8000 [==============================] - 0s 31us/sample - loss: 0.2883 - acc: 0.9066 - val_loss: 0.1901 - val_acc: 0.9455\n",
            "Epoch 484/500\n",
            "8000/8000 [==============================] - 0s 30us/sample - loss: 0.2923 - acc: 0.9043 - val_loss: 0.1940 - val_acc: 0.9445\n",
            "Epoch 485/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.2845 - acc: 0.9059 - val_loss: 0.1904 - val_acc: 0.9455\n",
            "Epoch 486/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2861 - acc: 0.9059 - val_loss: 0.1969 - val_acc: 0.9460\n",
            "Epoch 487/500\n",
            "8000/8000 [==============================] - 0s 27us/sample - loss: 0.2797 - acc: 0.9068 - val_loss: 0.1914 - val_acc: 0.9470\n",
            "Epoch 488/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2803 - acc: 0.9156 - val_loss: 0.1858 - val_acc: 0.9470\n",
            "Epoch 489/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2847 - acc: 0.9104 - val_loss: 0.1920 - val_acc: 0.9460\n",
            "Epoch 490/500\n",
            "8000/8000 [==============================] - 0s 27us/sample - loss: 0.2802 - acc: 0.9086 - val_loss: 0.1866 - val_acc: 0.9505\n",
            "Epoch 491/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2836 - acc: 0.9047 - val_loss: 0.1901 - val_acc: 0.9460\n",
            "Epoch 492/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2891 - acc: 0.9043 - val_loss: 0.1933 - val_acc: 0.9475\n",
            "Epoch 493/500\n",
            "8000/8000 [==============================] - 0s 28us/sample - loss: 0.2856 - acc: 0.9089 - val_loss: 0.1914 - val_acc: 0.9460\n",
            "Epoch 494/500\n",
            "8000/8000 [==============================] - 0s 28us/sample - loss: 0.2852 - acc: 0.9038 - val_loss: 0.1946 - val_acc: 0.9470\n",
            "Epoch 495/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2822 - acc: 0.9096 - val_loss: 0.1891 - val_acc: 0.9485\n",
            "Epoch 496/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2846 - acc: 0.9079 - val_loss: 0.1915 - val_acc: 0.9455\n",
            "Epoch 497/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.2859 - acc: 0.9036 - val_loss: 0.1955 - val_acc: 0.9455\n",
            "Epoch 498/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2889 - acc: 0.9060 - val_loss: 0.1877 - val_acc: 0.9475\n",
            "Epoch 499/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2818 - acc: 0.9068 - val_loss: 0.1940 - val_acc: 0.9455\n",
            "Epoch 500/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2774 - acc: 0.9082 - val_loss: 0.1950 - val_acc: 0.9430\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7_xVCs0aApK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_predictions4 = model4.predict(XT2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0Hg8wXe0uGc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ensemble_preds = [np.argmax((test_predictions2[i] + test_predictions3[i] + test_predictions4[i])/3) for i in range(XT2.shape[0])]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VG1Xxf-X1H8U",
        "colab_type": "code",
        "outputId": "31031f9c-98dc-4acf-b919-84625533ebd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ensemble_preds[:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 2, 3, 0, 2]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50IoT6c61PsS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "answer_column = [index_dict[i] for i in ensemble_preds]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbxgNkKR1hll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d = {'Accident_ID' : acc_ids , 'Severity' : answer_column}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueZnOio91pZQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission_df = pd.DataFrame(d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFSGSaXM1sGA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission_df = submission_df.set_index(['Accident_ID'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cgxC_xn1yl1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission_df.to_csv('ensemble_predictions.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iq_c2zBH17oh",
        "colab_type": "code",
        "outputId": "997c876e-8139-4818-b721-c65461bea8ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "model5 = tf.keras.models.Sequential()\n",
        "model5.add(tf.keras.layers.Dense(12 , input_shape = (10,)))\n",
        "model5.add(tf.keras.layers.Dense(18 , activation = 'relu'))\n",
        "model5.add(tf.keras.layers.Dropout(0.4))\n",
        "model5.add(tf.keras.layers.Dense(10, activation = 'relu'))\n",
        "model5.add(tf.keras.layers.Dense(4 , activation = 'softmax'))\n",
        "model5.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
        "model5.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_25 (Dense)             (None, 12)                132       \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 18)                234       \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 18)                0         \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 10)                190       \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 4)                 44        \n",
            "=================================================================\n",
            "Total params: 600\n",
            "Trainable params: 600\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzSR6FJZ2vuZ",
        "colab_type": "code",
        "outputId": "1f8820bb-8120-4f18-a1d8-0880eb9bc255",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history5 = model5.fit(X_train, y_train, batch_size  = 150, epochs = 500 ,  validation_data = [X_test, y_test] ,shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8000 samples, validate on 2000 samples\n",
            "Epoch 1/500\n",
            "8000/8000 [==============================] - 0s 51us/sample - loss: 1.4353 - acc: 0.2920 - val_loss: 1.3191 - val_acc: 0.3585\n",
            "Epoch 2/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 1.3353 - acc: 0.3429 - val_loss: 1.2600 - val_acc: 0.4215\n",
            "Epoch 3/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 1.2740 - acc: 0.3837 - val_loss: 1.1860 - val_acc: 0.4755\n",
            "Epoch 4/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 1.2106 - acc: 0.4435 - val_loss: 1.1041 - val_acc: 0.5410\n",
            "Epoch 5/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 1.1354 - acc: 0.5054 - val_loss: 1.0145 - val_acc: 0.6300\n",
            "Epoch 6/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 1.0481 - acc: 0.5767 - val_loss: 0.9144 - val_acc: 0.6870\n",
            "Epoch 7/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.9753 - acc: 0.6173 - val_loss: 0.8264 - val_acc: 0.7245\n",
            "Epoch 8/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.8938 - acc: 0.6615 - val_loss: 0.7391 - val_acc: 0.7670\n",
            "Epoch 9/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.8247 - acc: 0.7005 - val_loss: 0.6545 - val_acc: 0.7880\n",
            "Epoch 10/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.7717 - acc: 0.7191 - val_loss: 0.5932 - val_acc: 0.8090\n",
            "Epoch 11/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.7105 - acc: 0.7467 - val_loss: 0.5397 - val_acc: 0.8235\n",
            "Epoch 12/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.6755 - acc: 0.7580 - val_loss: 0.5010 - val_acc: 0.8415\n",
            "Epoch 13/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.6403 - acc: 0.7716 - val_loss: 0.4692 - val_acc: 0.8550\n",
            "Epoch 14/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.5986 - acc: 0.7886 - val_loss: 0.4423 - val_acc: 0.8690\n",
            "Epoch 15/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.5779 - acc: 0.7996 - val_loss: 0.4183 - val_acc: 0.8720\n",
            "Epoch 16/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5516 - acc: 0.8129 - val_loss: 0.4006 - val_acc: 0.8750\n",
            "Epoch 17/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5417 - acc: 0.8100 - val_loss: 0.3838 - val_acc: 0.8790\n",
            "Epoch 18/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.5210 - acc: 0.8219 - val_loss: 0.3713 - val_acc: 0.8850\n",
            "Epoch 19/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.5139 - acc: 0.8219 - val_loss: 0.3623 - val_acc: 0.8865\n",
            "Epoch 20/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.4908 - acc: 0.8322 - val_loss: 0.3543 - val_acc: 0.8960\n",
            "Epoch 21/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.4836 - acc: 0.8346 - val_loss: 0.3458 - val_acc: 0.8950\n",
            "Epoch 22/500\n",
            "8000/8000 [==============================] - 0s 27us/sample - loss: 0.4684 - acc: 0.8447 - val_loss: 0.3369 - val_acc: 0.9005\n",
            "Epoch 23/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.4637 - acc: 0.8457 - val_loss: 0.3317 - val_acc: 0.9035\n",
            "Epoch 24/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.4506 - acc: 0.8461 - val_loss: 0.3252 - val_acc: 0.9085\n",
            "Epoch 25/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.4526 - acc: 0.8493 - val_loss: 0.3222 - val_acc: 0.9055\n",
            "Epoch 26/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.4391 - acc: 0.8549 - val_loss: 0.3151 - val_acc: 0.9075\n",
            "Epoch 27/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.4366 - acc: 0.8571 - val_loss: 0.3123 - val_acc: 0.9140\n",
            "Epoch 28/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.4244 - acc: 0.8545 - val_loss: 0.3097 - val_acc: 0.9115\n",
            "Epoch 29/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.4344 - acc: 0.8533 - val_loss: 0.3032 - val_acc: 0.9185\n",
            "Epoch 30/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.4210 - acc: 0.8571 - val_loss: 0.3020 - val_acc: 0.9190\n",
            "Epoch 31/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.4268 - acc: 0.8590 - val_loss: 0.3013 - val_acc: 0.9215\n",
            "Epoch 32/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.4176 - acc: 0.8619 - val_loss: 0.2969 - val_acc: 0.9230\n",
            "Epoch 33/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.4055 - acc: 0.8643 - val_loss: 0.2920 - val_acc: 0.9220\n",
            "Epoch 34/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.4123 - acc: 0.8670 - val_loss: 0.2979 - val_acc: 0.9240\n",
            "Epoch 35/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.4093 - acc: 0.8637 - val_loss: 0.2880 - val_acc: 0.9250\n",
            "Epoch 36/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3957 - acc: 0.8727 - val_loss: 0.2866 - val_acc: 0.9265\n",
            "Epoch 37/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.4040 - acc: 0.8685 - val_loss: 0.2872 - val_acc: 0.9265\n",
            "Epoch 38/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3898 - acc: 0.8724 - val_loss: 0.2866 - val_acc: 0.9275\n",
            "Epoch 39/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3838 - acc: 0.8740 - val_loss: 0.2824 - val_acc: 0.9285\n",
            "Epoch 40/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.3893 - acc: 0.8712 - val_loss: 0.2822 - val_acc: 0.9290\n",
            "Epoch 41/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3896 - acc: 0.8750 - val_loss: 0.2776 - val_acc: 0.9285\n",
            "Epoch 42/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3846 - acc: 0.8755 - val_loss: 0.2757 - val_acc: 0.9320\n",
            "Epoch 43/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3922 - acc: 0.8744 - val_loss: 0.2792 - val_acc: 0.9295\n",
            "Epoch 44/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.3870 - acc: 0.8727 - val_loss: 0.2793 - val_acc: 0.9295\n",
            "Epoch 45/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.3818 - acc: 0.8737 - val_loss: 0.2775 - val_acc: 0.9330\n",
            "Epoch 46/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.3746 - acc: 0.8801 - val_loss: 0.2742 - val_acc: 0.9315\n",
            "Epoch 47/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.3798 - acc: 0.8799 - val_loss: 0.2726 - val_acc: 0.9320\n",
            "Epoch 48/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.3706 - acc: 0.8790 - val_loss: 0.2791 - val_acc: 0.9340\n",
            "Epoch 49/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.3667 - acc: 0.8852 - val_loss: 0.2703 - val_acc: 0.9335\n",
            "Epoch 50/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.3643 - acc: 0.8855 - val_loss: 0.2661 - val_acc: 0.9345\n",
            "Epoch 51/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.3558 - acc: 0.8890 - val_loss: 0.2669 - val_acc: 0.9330\n",
            "Epoch 52/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.3646 - acc: 0.8788 - val_loss: 0.2672 - val_acc: 0.9355\n",
            "Epoch 53/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.3593 - acc: 0.8831 - val_loss: 0.2682 - val_acc: 0.9320\n",
            "Epoch 54/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3618 - acc: 0.8851 - val_loss: 0.2697 - val_acc: 0.9360\n",
            "Epoch 55/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3601 - acc: 0.8839 - val_loss: 0.2731 - val_acc: 0.9340\n",
            "Epoch 56/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3486 - acc: 0.8884 - val_loss: 0.2671 - val_acc: 0.9325\n",
            "Epoch 57/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.3625 - acc: 0.8850 - val_loss: 0.2703 - val_acc: 0.9330\n",
            "Epoch 58/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3606 - acc: 0.8831 - val_loss: 0.2726 - val_acc: 0.9345\n",
            "Epoch 59/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.3605 - acc: 0.8834 - val_loss: 0.2721 - val_acc: 0.9325\n",
            "Epoch 60/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.3542 - acc: 0.8840 - val_loss: 0.2596 - val_acc: 0.9370\n",
            "Epoch 61/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3533 - acc: 0.8832 - val_loss: 0.2666 - val_acc: 0.9370\n",
            "Epoch 62/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3489 - acc: 0.8882 - val_loss: 0.2643 - val_acc: 0.9370\n",
            "Epoch 63/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3564 - acc: 0.8848 - val_loss: 0.2680 - val_acc: 0.9365\n",
            "Epoch 64/500\n",
            "8000/8000 [==============================] - 0s 27us/sample - loss: 0.3518 - acc: 0.8900 - val_loss: 0.2619 - val_acc: 0.9360\n",
            "Epoch 65/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3524 - acc: 0.8880 - val_loss: 0.2678 - val_acc: 0.9355\n",
            "Epoch 66/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.3493 - acc: 0.8852 - val_loss: 0.2634 - val_acc: 0.9375\n",
            "Epoch 67/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3502 - acc: 0.8859 - val_loss: 0.2591 - val_acc: 0.9365\n",
            "Epoch 68/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3362 - acc: 0.8903 - val_loss: 0.2576 - val_acc: 0.9380\n",
            "Epoch 69/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3397 - acc: 0.8881 - val_loss: 0.2593 - val_acc: 0.9355\n",
            "Epoch 70/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.3434 - acc: 0.8890 - val_loss: 0.2588 - val_acc: 0.9370\n",
            "Epoch 71/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.3476 - acc: 0.8882 - val_loss: 0.2582 - val_acc: 0.9355\n",
            "Epoch 72/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.3480 - acc: 0.8849 - val_loss: 0.2580 - val_acc: 0.9360\n",
            "Epoch 73/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.3500 - acc: 0.8867 - val_loss: 0.2636 - val_acc: 0.9340\n",
            "Epoch 74/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3433 - acc: 0.8894 - val_loss: 0.2654 - val_acc: 0.9340\n",
            "Epoch 75/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.3326 - acc: 0.8904 - val_loss: 0.2615 - val_acc: 0.9350\n",
            "Epoch 76/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3498 - acc: 0.8874 - val_loss: 0.2624 - val_acc: 0.9330\n",
            "Epoch 77/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3425 - acc: 0.8923 - val_loss: 0.2591 - val_acc: 0.9370\n",
            "Epoch 78/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.3381 - acc: 0.8888 - val_loss: 0.2560 - val_acc: 0.9355\n",
            "Epoch 79/500\n",
            "8000/8000 [==============================] - 0s 28us/sample - loss: 0.3460 - acc: 0.8914 - val_loss: 0.2621 - val_acc: 0.9345\n",
            "Epoch 80/500\n",
            "8000/8000 [==============================] - 0s 31us/sample - loss: 0.3382 - acc: 0.8901 - val_loss: 0.2575 - val_acc: 0.9325\n",
            "Epoch 81/500\n",
            "8000/8000 [==============================] - 0s 28us/sample - loss: 0.3526 - acc: 0.8834 - val_loss: 0.2625 - val_acc: 0.9310\n",
            "Epoch 82/500\n",
            "8000/8000 [==============================] - 0s 29us/sample - loss: 0.3436 - acc: 0.8923 - val_loss: 0.2527 - val_acc: 0.9375\n",
            "Epoch 83/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.3281 - acc: 0.8944 - val_loss: 0.2520 - val_acc: 0.9355\n",
            "Epoch 84/500\n",
            "8000/8000 [==============================] - 0s 27us/sample - loss: 0.3402 - acc: 0.8904 - val_loss: 0.2567 - val_acc: 0.9355\n",
            "Epoch 85/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.3349 - acc: 0.8926 - val_loss: 0.2545 - val_acc: 0.9345\n",
            "Epoch 86/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3284 - acc: 0.8940 - val_loss: 0.2513 - val_acc: 0.9350\n",
            "Epoch 87/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.3363 - acc: 0.8911 - val_loss: 0.2529 - val_acc: 0.9355\n",
            "Epoch 88/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3416 - acc: 0.8889 - val_loss: 0.2638 - val_acc: 0.9290\n",
            "Epoch 89/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3361 - acc: 0.8924 - val_loss: 0.2600 - val_acc: 0.9350\n",
            "Epoch 90/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3311 - acc: 0.8921 - val_loss: 0.2524 - val_acc: 0.9375\n",
            "Epoch 91/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3326 - acc: 0.8928 - val_loss: 0.2507 - val_acc: 0.9350\n",
            "Epoch 92/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3254 - acc: 0.8954 - val_loss: 0.2484 - val_acc: 0.9350\n",
            "Epoch 93/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3357 - acc: 0.8909 - val_loss: 0.2486 - val_acc: 0.9370\n",
            "Epoch 94/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.3311 - acc: 0.8926 - val_loss: 0.2468 - val_acc: 0.9325\n",
            "Epoch 95/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3425 - acc: 0.8915 - val_loss: 0.2481 - val_acc: 0.9355\n",
            "Epoch 96/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3347 - acc: 0.8928 - val_loss: 0.2513 - val_acc: 0.9345\n",
            "Epoch 97/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.3232 - acc: 0.8939 - val_loss: 0.2500 - val_acc: 0.9345\n",
            "Epoch 98/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3261 - acc: 0.9000 - val_loss: 0.2541 - val_acc: 0.9315\n",
            "Epoch 99/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.3300 - acc: 0.8964 - val_loss: 0.2504 - val_acc: 0.9325\n",
            "Epoch 100/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.3128 - acc: 0.8981 - val_loss: 0.2480 - val_acc: 0.9345\n",
            "Epoch 101/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.3254 - acc: 0.8965 - val_loss: 0.2453 - val_acc: 0.9360\n",
            "Epoch 102/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3359 - acc: 0.8961 - val_loss: 0.2481 - val_acc: 0.9365\n",
            "Epoch 103/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3235 - acc: 0.8969 - val_loss: 0.2459 - val_acc: 0.9355\n",
            "Epoch 104/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.3244 - acc: 0.8961 - val_loss: 0.2617 - val_acc: 0.9280\n",
            "Epoch 105/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3265 - acc: 0.8934 - val_loss: 0.2449 - val_acc: 0.9365\n",
            "Epoch 106/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.3230 - acc: 0.8981 - val_loss: 0.2483 - val_acc: 0.9370\n",
            "Epoch 107/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3276 - acc: 0.8971 - val_loss: 0.2504 - val_acc: 0.9375\n",
            "Epoch 108/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3213 - acc: 0.8989 - val_loss: 0.2503 - val_acc: 0.9325\n",
            "Epoch 109/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3175 - acc: 0.8936 - val_loss: 0.2472 - val_acc: 0.9375\n",
            "Epoch 110/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3213 - acc: 0.8980 - val_loss: 0.2552 - val_acc: 0.9335\n",
            "Epoch 111/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3199 - acc: 0.8980 - val_loss: 0.2451 - val_acc: 0.9360\n",
            "Epoch 112/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3248 - acc: 0.8971 - val_loss: 0.2490 - val_acc: 0.9365\n",
            "Epoch 113/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.3219 - acc: 0.8955 - val_loss: 0.2437 - val_acc: 0.9355\n",
            "Epoch 114/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3228 - acc: 0.8984 - val_loss: 0.2460 - val_acc: 0.9335\n",
            "Epoch 115/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3296 - acc: 0.8953 - val_loss: 0.2475 - val_acc: 0.9345\n",
            "Epoch 116/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3262 - acc: 0.8939 - val_loss: 0.2459 - val_acc: 0.9355\n",
            "Epoch 117/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3173 - acc: 0.9007 - val_loss: 0.2451 - val_acc: 0.9325\n",
            "Epoch 118/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3185 - acc: 0.8947 - val_loss: 0.2505 - val_acc: 0.9315\n",
            "Epoch 119/500\n",
            "8000/8000 [==============================] - 0s 27us/sample - loss: 0.3211 - acc: 0.8969 - val_loss: 0.2425 - val_acc: 0.9385\n",
            "Epoch 120/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.3163 - acc: 0.8967 - val_loss: 0.2458 - val_acc: 0.9345\n",
            "Epoch 121/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.3164 - acc: 0.8989 - val_loss: 0.2434 - val_acc: 0.9365\n",
            "Epoch 122/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3231 - acc: 0.8955 - val_loss: 0.2462 - val_acc: 0.9365\n",
            "Epoch 123/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3098 - acc: 0.9015 - val_loss: 0.2474 - val_acc: 0.9335\n",
            "Epoch 124/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3169 - acc: 0.8982 - val_loss: 0.2428 - val_acc: 0.9340\n",
            "Epoch 125/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3113 - acc: 0.9019 - val_loss: 0.2405 - val_acc: 0.9365\n",
            "Epoch 126/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.3217 - acc: 0.8995 - val_loss: 0.2536 - val_acc: 0.9280\n",
            "Epoch 127/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.3160 - acc: 0.8976 - val_loss: 0.2541 - val_acc: 0.9300\n",
            "Epoch 128/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.3202 - acc: 0.8995 - val_loss: 0.2515 - val_acc: 0.9315\n",
            "Epoch 129/500\n",
            "8000/8000 [==============================] - 0s 18us/sample - loss: 0.3163 - acc: 0.8966 - val_loss: 0.2420 - val_acc: 0.9355\n",
            "Epoch 130/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3087 - acc: 0.9026 - val_loss: 0.2596 - val_acc: 0.9305\n",
            "Epoch 131/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3132 - acc: 0.9006 - val_loss: 0.2455 - val_acc: 0.9390\n",
            "Epoch 132/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.3146 - acc: 0.9001 - val_loss: 0.2429 - val_acc: 0.9350\n",
            "Epoch 133/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3110 - acc: 0.9025 - val_loss: 0.2347 - val_acc: 0.9395\n",
            "Epoch 134/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3106 - acc: 0.9018 - val_loss: 0.2416 - val_acc: 0.9355\n",
            "Epoch 135/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3059 - acc: 0.9010 - val_loss: 0.2424 - val_acc: 0.9350\n",
            "Epoch 136/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3148 - acc: 0.8995 - val_loss: 0.2410 - val_acc: 0.9405\n",
            "Epoch 137/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3182 - acc: 0.9004 - val_loss: 0.2526 - val_acc: 0.9310\n",
            "Epoch 138/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3107 - acc: 0.9024 - val_loss: 0.2440 - val_acc: 0.9365\n",
            "Epoch 139/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.3084 - acc: 0.9000 - val_loss: 0.2345 - val_acc: 0.9380\n",
            "Epoch 140/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.3064 - acc: 0.9034 - val_loss: 0.2456 - val_acc: 0.9340\n",
            "Epoch 141/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.3162 - acc: 0.9004 - val_loss: 0.2454 - val_acc: 0.9335\n",
            "Epoch 142/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3131 - acc: 0.9000 - val_loss: 0.2419 - val_acc: 0.9295\n",
            "Epoch 143/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.3133 - acc: 0.9009 - val_loss: 0.2435 - val_acc: 0.9380\n",
            "Epoch 144/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3067 - acc: 0.9010 - val_loss: 0.2495 - val_acc: 0.9290\n",
            "Epoch 145/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.3059 - acc: 0.9014 - val_loss: 0.2385 - val_acc: 0.9395\n",
            "Epoch 146/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3063 - acc: 0.9039 - val_loss: 0.2433 - val_acc: 0.9345\n",
            "Epoch 147/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3061 - acc: 0.9026 - val_loss: 0.2478 - val_acc: 0.9325\n",
            "Epoch 148/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.3128 - acc: 0.8960 - val_loss: 0.2406 - val_acc: 0.9380\n",
            "Epoch 149/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.3116 - acc: 0.9030 - val_loss: 0.2481 - val_acc: 0.9305\n",
            "Epoch 150/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3087 - acc: 0.9035 - val_loss: 0.2444 - val_acc: 0.9345\n",
            "Epoch 151/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.3088 - acc: 0.8981 - val_loss: 0.2413 - val_acc: 0.9360\n",
            "Epoch 152/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.3080 - acc: 0.8997 - val_loss: 0.2431 - val_acc: 0.9365\n",
            "Epoch 153/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.3053 - acc: 0.9050 - val_loss: 0.2417 - val_acc: 0.9380\n",
            "Epoch 154/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3063 - acc: 0.9019 - val_loss: 0.2383 - val_acc: 0.9370\n",
            "Epoch 155/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.3073 - acc: 0.9035 - val_loss: 0.2419 - val_acc: 0.9355\n",
            "Epoch 156/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3056 - acc: 0.9026 - val_loss: 0.2468 - val_acc: 0.9315\n",
            "Epoch 157/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3074 - acc: 0.9005 - val_loss: 0.2432 - val_acc: 0.9335\n",
            "Epoch 158/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3029 - acc: 0.9004 - val_loss: 0.2428 - val_acc: 0.9380\n",
            "Epoch 159/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.3020 - acc: 0.9070 - val_loss: 0.2421 - val_acc: 0.9355\n",
            "Epoch 160/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3060 - acc: 0.9001 - val_loss: 0.2334 - val_acc: 0.9405\n",
            "Epoch 161/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.3108 - acc: 0.9029 - val_loss: 0.2446 - val_acc: 0.9340\n",
            "Epoch 162/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3015 - acc: 0.9059 - val_loss: 0.2416 - val_acc: 0.9385\n",
            "Epoch 163/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3101 - acc: 0.9051 - val_loss: 0.2434 - val_acc: 0.9345\n",
            "Epoch 164/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3117 - acc: 0.9018 - val_loss: 0.2419 - val_acc: 0.9365\n",
            "Epoch 165/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3066 - acc: 0.9015 - val_loss: 0.2372 - val_acc: 0.9395\n",
            "Epoch 166/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3018 - acc: 0.9039 - val_loss: 0.2416 - val_acc: 0.9320\n",
            "Epoch 167/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2914 - acc: 0.9051 - val_loss: 0.2403 - val_acc: 0.9350\n",
            "Epoch 168/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.3078 - acc: 0.9016 - val_loss: 0.2344 - val_acc: 0.9385\n",
            "Epoch 169/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3061 - acc: 0.9026 - val_loss: 0.2340 - val_acc: 0.9410\n",
            "Epoch 170/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3112 - acc: 0.9029 - val_loss: 0.2451 - val_acc: 0.9350\n",
            "Epoch 171/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3013 - acc: 0.9051 - val_loss: 0.2392 - val_acc: 0.9385\n",
            "Epoch 172/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3013 - acc: 0.9057 - val_loss: 0.2502 - val_acc: 0.9255\n",
            "Epoch 173/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2961 - acc: 0.9045 - val_loss: 0.2351 - val_acc: 0.9390\n",
            "Epoch 174/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3005 - acc: 0.9066 - val_loss: 0.2345 - val_acc: 0.9390\n",
            "Epoch 175/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2995 - acc: 0.9094 - val_loss: 0.2446 - val_acc: 0.9315\n",
            "Epoch 176/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2912 - acc: 0.9091 - val_loss: 0.2427 - val_acc: 0.9330\n",
            "Epoch 177/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3015 - acc: 0.9006 - val_loss: 0.2397 - val_acc: 0.9365\n",
            "Epoch 178/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3085 - acc: 0.9036 - val_loss: 0.2349 - val_acc: 0.9395\n",
            "Epoch 179/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3044 - acc: 0.9016 - val_loss: 0.2446 - val_acc: 0.9290\n",
            "Epoch 180/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3010 - acc: 0.9018 - val_loss: 0.2453 - val_acc: 0.9310\n",
            "Epoch 181/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.3090 - acc: 0.9028 - val_loss: 0.2352 - val_acc: 0.9350\n",
            "Epoch 182/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2993 - acc: 0.9096 - val_loss: 0.2341 - val_acc: 0.9380\n",
            "Epoch 183/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3049 - acc: 0.9001 - val_loss: 0.2395 - val_acc: 0.9350\n",
            "Epoch 184/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2939 - acc: 0.9060 - val_loss: 0.2448 - val_acc: 0.9295\n",
            "Epoch 185/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.3014 - acc: 0.9061 - val_loss: 0.2359 - val_acc: 0.9365\n",
            "Epoch 186/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2904 - acc: 0.9089 - val_loss: 0.2363 - val_acc: 0.9380\n",
            "Epoch 187/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2965 - acc: 0.9053 - val_loss: 0.2443 - val_acc: 0.9310\n",
            "Epoch 188/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2964 - acc: 0.9080 - val_loss: 0.2375 - val_acc: 0.9370\n",
            "Epoch 189/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2935 - acc: 0.9057 - val_loss: 0.2544 - val_acc: 0.9245\n",
            "Epoch 190/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3054 - acc: 0.9056 - val_loss: 0.2480 - val_acc: 0.9280\n",
            "Epoch 191/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3038 - acc: 0.9053 - val_loss: 0.2411 - val_acc: 0.9315\n",
            "Epoch 192/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.3003 - acc: 0.9059 - val_loss: 0.2439 - val_acc: 0.9300\n",
            "Epoch 193/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2963 - acc: 0.9034 - val_loss: 0.2440 - val_acc: 0.9290\n",
            "Epoch 194/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2962 - acc: 0.9064 - val_loss: 0.2407 - val_acc: 0.9330\n",
            "Epoch 195/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2950 - acc: 0.9066 - val_loss: 0.2400 - val_acc: 0.9335\n",
            "Epoch 196/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2896 - acc: 0.9078 - val_loss: 0.2390 - val_acc: 0.9345\n",
            "Epoch 197/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2890 - acc: 0.9069 - val_loss: 0.2476 - val_acc: 0.9285\n",
            "Epoch 198/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2890 - acc: 0.9062 - val_loss: 0.2396 - val_acc: 0.9315\n",
            "Epoch 199/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3067 - acc: 0.9028 - val_loss: 0.2371 - val_acc: 0.9325\n",
            "Epoch 200/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2944 - acc: 0.9096 - val_loss: 0.2478 - val_acc: 0.9250\n",
            "Epoch 201/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2966 - acc: 0.9044 - val_loss: 0.2400 - val_acc: 0.9355\n",
            "Epoch 202/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2891 - acc: 0.9116 - val_loss: 0.2440 - val_acc: 0.9280\n",
            "Epoch 203/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.3062 - acc: 0.9006 - val_loss: 0.2410 - val_acc: 0.9310\n",
            "Epoch 204/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2927 - acc: 0.9084 - val_loss: 0.2373 - val_acc: 0.9335\n",
            "Epoch 205/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3002 - acc: 0.9071 - val_loss: 0.2389 - val_acc: 0.9340\n",
            "Epoch 206/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.3060 - acc: 0.9034 - val_loss: 0.2405 - val_acc: 0.9325\n",
            "Epoch 207/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2945 - acc: 0.9065 - val_loss: 0.2419 - val_acc: 0.9280\n",
            "Epoch 208/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3020 - acc: 0.9036 - val_loss: 0.2386 - val_acc: 0.9335\n",
            "Epoch 209/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2943 - acc: 0.9084 - val_loss: 0.2380 - val_acc: 0.9345\n",
            "Epoch 210/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2977 - acc: 0.9034 - val_loss: 0.2370 - val_acc: 0.9315\n",
            "Epoch 211/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.3004 - acc: 0.9054 - val_loss: 0.2406 - val_acc: 0.9330\n",
            "Epoch 212/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2970 - acc: 0.9086 - val_loss: 0.2355 - val_acc: 0.9340\n",
            "Epoch 213/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.2865 - acc: 0.9064 - val_loss: 0.2427 - val_acc: 0.9295\n",
            "Epoch 214/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2969 - acc: 0.9061 - val_loss: 0.2453 - val_acc: 0.9280\n",
            "Epoch 215/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2991 - acc: 0.9054 - val_loss: 0.2556 - val_acc: 0.9230\n",
            "Epoch 216/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2983 - acc: 0.9061 - val_loss: 0.2490 - val_acc: 0.9245\n",
            "Epoch 217/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2915 - acc: 0.9079 - val_loss: 0.2471 - val_acc: 0.9260\n",
            "Epoch 218/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.3002 - acc: 0.9032 - val_loss: 0.2390 - val_acc: 0.9330\n",
            "Epoch 219/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2883 - acc: 0.9075 - val_loss: 0.2373 - val_acc: 0.9325\n",
            "Epoch 220/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2963 - acc: 0.9030 - val_loss: 0.2459 - val_acc: 0.9280\n",
            "Epoch 221/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2936 - acc: 0.9020 - val_loss: 0.2299 - val_acc: 0.9390\n",
            "Epoch 222/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2905 - acc: 0.9071 - val_loss: 0.2517 - val_acc: 0.9250\n",
            "Epoch 223/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2949 - acc: 0.9036 - val_loss: 0.2485 - val_acc: 0.9255\n",
            "Epoch 224/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2923 - acc: 0.9085 - val_loss: 0.2393 - val_acc: 0.9305\n",
            "Epoch 225/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2964 - acc: 0.9046 - val_loss: 0.2536 - val_acc: 0.9255\n",
            "Epoch 226/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2896 - acc: 0.9090 - val_loss: 0.2401 - val_acc: 0.9335\n",
            "Epoch 227/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2929 - acc: 0.9040 - val_loss: 0.2310 - val_acc: 0.9350\n",
            "Epoch 228/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2821 - acc: 0.9109 - val_loss: 0.2639 - val_acc: 0.9250\n",
            "Epoch 229/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2894 - acc: 0.9072 - val_loss: 0.2322 - val_acc: 0.9345\n",
            "Epoch 230/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2970 - acc: 0.9031 - val_loss: 0.2371 - val_acc: 0.9320\n",
            "Epoch 231/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2887 - acc: 0.9081 - val_loss: 0.2524 - val_acc: 0.9255\n",
            "Epoch 232/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2928 - acc: 0.9047 - val_loss: 0.2406 - val_acc: 0.9295\n",
            "Epoch 233/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2920 - acc: 0.9071 - val_loss: 0.2429 - val_acc: 0.9315\n",
            "Epoch 234/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2843 - acc: 0.9075 - val_loss: 0.2542 - val_acc: 0.9250\n",
            "Epoch 235/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2986 - acc: 0.9029 - val_loss: 0.2457 - val_acc: 0.9290\n",
            "Epoch 236/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2869 - acc: 0.9101 - val_loss: 0.2491 - val_acc: 0.9270\n",
            "Epoch 237/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2850 - acc: 0.9099 - val_loss: 0.2419 - val_acc: 0.9265\n",
            "Epoch 238/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2885 - acc: 0.9079 - val_loss: 0.2404 - val_acc: 0.9310\n",
            "Epoch 239/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2945 - acc: 0.9065 - val_loss: 0.2364 - val_acc: 0.9350\n",
            "Epoch 240/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2951 - acc: 0.9080 - val_loss: 0.2401 - val_acc: 0.9310\n",
            "Epoch 241/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2934 - acc: 0.9072 - val_loss: 0.2457 - val_acc: 0.9285\n",
            "Epoch 242/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2937 - acc: 0.9087 - val_loss: 0.2452 - val_acc: 0.9255\n",
            "Epoch 243/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2866 - acc: 0.9074 - val_loss: 0.2505 - val_acc: 0.9255\n",
            "Epoch 244/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2871 - acc: 0.9110 - val_loss: 0.2400 - val_acc: 0.9320\n",
            "Epoch 245/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2933 - acc: 0.9071 - val_loss: 0.2357 - val_acc: 0.9335\n",
            "Epoch 246/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2929 - acc: 0.9069 - val_loss: 0.2381 - val_acc: 0.9340\n",
            "Epoch 247/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2928 - acc: 0.9044 - val_loss: 0.2385 - val_acc: 0.9305\n",
            "Epoch 248/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2857 - acc: 0.9081 - val_loss: 0.2338 - val_acc: 0.9315\n",
            "Epoch 249/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2920 - acc: 0.9071 - val_loss: 0.2359 - val_acc: 0.9355\n",
            "Epoch 250/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2901 - acc: 0.9076 - val_loss: 0.2374 - val_acc: 0.9335\n",
            "Epoch 251/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2875 - acc: 0.9100 - val_loss: 0.2426 - val_acc: 0.9270\n",
            "Epoch 252/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2898 - acc: 0.9054 - val_loss: 0.2382 - val_acc: 0.9295\n",
            "Epoch 253/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2930 - acc: 0.9085 - val_loss: 0.2390 - val_acc: 0.9310\n",
            "Epoch 254/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2873 - acc: 0.9056 - val_loss: 0.2321 - val_acc: 0.9365\n",
            "Epoch 255/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2925 - acc: 0.9038 - val_loss: 0.2488 - val_acc: 0.9270\n",
            "Epoch 256/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2939 - acc: 0.9051 - val_loss: 0.2342 - val_acc: 0.9365\n",
            "Epoch 257/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2831 - acc: 0.9099 - val_loss: 0.2471 - val_acc: 0.9275\n",
            "Epoch 258/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2850 - acc: 0.9071 - val_loss: 0.2507 - val_acc: 0.9245\n",
            "Epoch 259/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2902 - acc: 0.9064 - val_loss: 0.2550 - val_acc: 0.9235\n",
            "Epoch 260/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2876 - acc: 0.9038 - val_loss: 0.2449 - val_acc: 0.9265\n",
            "Epoch 261/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2876 - acc: 0.9075 - val_loss: 0.2415 - val_acc: 0.9325\n",
            "Epoch 262/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2830 - acc: 0.9076 - val_loss: 0.2581 - val_acc: 0.9250\n",
            "Epoch 263/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2807 - acc: 0.9074 - val_loss: 0.2472 - val_acc: 0.9275\n",
            "Epoch 264/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2832 - acc: 0.9075 - val_loss: 0.2427 - val_acc: 0.9285\n",
            "Epoch 265/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2930 - acc: 0.9050 - val_loss: 0.2622 - val_acc: 0.9210\n",
            "Epoch 266/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2855 - acc: 0.9099 - val_loss: 0.2391 - val_acc: 0.9300\n",
            "Epoch 267/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2924 - acc: 0.9090 - val_loss: 0.2516 - val_acc: 0.9235\n",
            "Epoch 268/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2883 - acc: 0.9044 - val_loss: 0.2434 - val_acc: 0.9310\n",
            "Epoch 269/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2939 - acc: 0.9028 - val_loss: 0.2468 - val_acc: 0.9295\n",
            "Epoch 270/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2882 - acc: 0.9076 - val_loss: 0.2337 - val_acc: 0.9350\n",
            "Epoch 271/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2821 - acc: 0.9115 - val_loss: 0.2457 - val_acc: 0.9290\n",
            "Epoch 272/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2952 - acc: 0.9074 - val_loss: 0.2452 - val_acc: 0.9295\n",
            "Epoch 273/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2835 - acc: 0.9118 - val_loss: 0.2425 - val_acc: 0.9320\n",
            "Epoch 274/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2862 - acc: 0.9082 - val_loss: 0.2492 - val_acc: 0.9265\n",
            "Epoch 275/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2847 - acc: 0.9096 - val_loss: 0.2556 - val_acc: 0.9255\n",
            "Epoch 276/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2896 - acc: 0.9081 - val_loss: 0.2559 - val_acc: 0.9235\n",
            "Epoch 277/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2803 - acc: 0.9089 - val_loss: 0.2484 - val_acc: 0.9265\n",
            "Epoch 278/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2854 - acc: 0.9103 - val_loss: 0.2579 - val_acc: 0.9225\n",
            "Epoch 279/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2880 - acc: 0.9118 - val_loss: 0.2530 - val_acc: 0.9250\n",
            "Epoch 280/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2805 - acc: 0.9114 - val_loss: 0.2543 - val_acc: 0.9250\n",
            "Epoch 281/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2865 - acc: 0.9089 - val_loss: 0.2600 - val_acc: 0.9255\n",
            "Epoch 282/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2883 - acc: 0.9104 - val_loss: 0.2426 - val_acc: 0.9325\n",
            "Epoch 283/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2771 - acc: 0.9086 - val_loss: 0.2549 - val_acc: 0.9235\n",
            "Epoch 284/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2881 - acc: 0.9104 - val_loss: 0.2456 - val_acc: 0.9290\n",
            "Epoch 285/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2971 - acc: 0.9074 - val_loss: 0.2512 - val_acc: 0.9255\n",
            "Epoch 286/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2812 - acc: 0.9140 - val_loss: 0.2568 - val_acc: 0.9235\n",
            "Epoch 287/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2847 - acc: 0.9089 - val_loss: 0.2657 - val_acc: 0.9210\n",
            "Epoch 288/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2954 - acc: 0.9053 - val_loss: 0.2375 - val_acc: 0.9360\n",
            "Epoch 289/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2764 - acc: 0.9151 - val_loss: 0.2418 - val_acc: 0.9310\n",
            "Epoch 290/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2783 - acc: 0.9114 - val_loss: 0.2403 - val_acc: 0.9320\n",
            "Epoch 291/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2723 - acc: 0.9166 - val_loss: 0.2444 - val_acc: 0.9285\n",
            "Epoch 292/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2814 - acc: 0.9096 - val_loss: 0.2407 - val_acc: 0.9340\n",
            "Epoch 293/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2841 - acc: 0.9082 - val_loss: 0.2367 - val_acc: 0.9365\n",
            "Epoch 294/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2879 - acc: 0.9103 - val_loss: 0.2452 - val_acc: 0.9295\n",
            "Epoch 295/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2858 - acc: 0.9104 - val_loss: 0.2412 - val_acc: 0.9320\n",
            "Epoch 296/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2862 - acc: 0.9090 - val_loss: 0.2416 - val_acc: 0.9285\n",
            "Epoch 297/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2940 - acc: 0.9055 - val_loss: 0.2554 - val_acc: 0.9250\n",
            "Epoch 298/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2866 - acc: 0.9082 - val_loss: 0.2477 - val_acc: 0.9285\n",
            "Epoch 299/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2792 - acc: 0.9095 - val_loss: 0.2390 - val_acc: 0.9310\n",
            "Epoch 300/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2864 - acc: 0.9072 - val_loss: 0.2440 - val_acc: 0.9295\n",
            "Epoch 301/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2785 - acc: 0.9106 - val_loss: 0.2433 - val_acc: 0.9290\n",
            "Epoch 302/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2892 - acc: 0.9085 - val_loss: 0.2444 - val_acc: 0.9295\n",
            "Epoch 303/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2826 - acc: 0.9062 - val_loss: 0.2361 - val_acc: 0.9345\n",
            "Epoch 304/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2865 - acc: 0.9072 - val_loss: 0.2411 - val_acc: 0.9305\n",
            "Epoch 305/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2790 - acc: 0.9097 - val_loss: 0.2536 - val_acc: 0.9260\n",
            "Epoch 306/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2721 - acc: 0.9119 - val_loss: 0.2581 - val_acc: 0.9250\n",
            "Epoch 307/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2837 - acc: 0.9056 - val_loss: 0.2462 - val_acc: 0.9270\n",
            "Epoch 308/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2851 - acc: 0.9074 - val_loss: 0.2468 - val_acc: 0.9255\n",
            "Epoch 309/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2785 - acc: 0.9068 - val_loss: 0.2492 - val_acc: 0.9260\n",
            "Epoch 310/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2803 - acc: 0.9130 - val_loss: 0.2503 - val_acc: 0.9285\n",
            "Epoch 311/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2759 - acc: 0.9137 - val_loss: 0.2522 - val_acc: 0.9250\n",
            "Epoch 312/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2819 - acc: 0.9099 - val_loss: 0.2465 - val_acc: 0.9285\n",
            "Epoch 313/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2768 - acc: 0.9121 - val_loss: 0.2449 - val_acc: 0.9305\n",
            "Epoch 314/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2810 - acc: 0.9120 - val_loss: 0.2392 - val_acc: 0.9320\n",
            "Epoch 315/500\n",
            "8000/8000 [==============================] - 0s 28us/sample - loss: 0.2852 - acc: 0.9096 - val_loss: 0.2400 - val_acc: 0.9315\n",
            "Epoch 316/500\n",
            "8000/8000 [==============================] - 0s 29us/sample - loss: 0.2902 - acc: 0.9062 - val_loss: 0.2393 - val_acc: 0.9320\n",
            "Epoch 317/500\n",
            "8000/8000 [==============================] - 0s 27us/sample - loss: 0.2809 - acc: 0.9106 - val_loss: 0.2516 - val_acc: 0.9290\n",
            "Epoch 318/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2855 - acc: 0.9080 - val_loss: 0.2463 - val_acc: 0.9285\n",
            "Epoch 319/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2915 - acc: 0.9060 - val_loss: 0.2356 - val_acc: 0.9320\n",
            "Epoch 320/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2880 - acc: 0.9062 - val_loss: 0.2397 - val_acc: 0.9285\n",
            "Epoch 321/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2866 - acc: 0.9091 - val_loss: 0.2491 - val_acc: 0.9270\n",
            "Epoch 322/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2747 - acc: 0.9110 - val_loss: 0.2453 - val_acc: 0.9260\n",
            "Epoch 323/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2858 - acc: 0.9060 - val_loss: 0.2530 - val_acc: 0.9250\n",
            "Epoch 324/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2811 - acc: 0.9055 - val_loss: 0.2434 - val_acc: 0.9315\n",
            "Epoch 325/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2815 - acc: 0.9079 - val_loss: 0.2412 - val_acc: 0.9320\n",
            "Epoch 326/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2893 - acc: 0.9107 - val_loss: 0.2568 - val_acc: 0.9230\n",
            "Epoch 327/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.2764 - acc: 0.9093 - val_loss: 0.2394 - val_acc: 0.9285\n",
            "Epoch 328/500\n",
            "8000/8000 [==============================] - 0s 27us/sample - loss: 0.2860 - acc: 0.9080 - val_loss: 0.2458 - val_acc: 0.9290\n",
            "Epoch 329/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2937 - acc: 0.9034 - val_loss: 0.2386 - val_acc: 0.9345\n",
            "Epoch 330/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2767 - acc: 0.9101 - val_loss: 0.2542 - val_acc: 0.9230\n",
            "Epoch 331/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2770 - acc: 0.9154 - val_loss: 0.2421 - val_acc: 0.9325\n",
            "Epoch 332/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2794 - acc: 0.9085 - val_loss: 0.2522 - val_acc: 0.9270\n",
            "Epoch 333/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2754 - acc: 0.9085 - val_loss: 0.2729 - val_acc: 0.9180\n",
            "Epoch 334/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2783 - acc: 0.9090 - val_loss: 0.2566 - val_acc: 0.9225\n",
            "Epoch 335/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2838 - acc: 0.9099 - val_loss: 0.2561 - val_acc: 0.9235\n",
            "Epoch 336/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2806 - acc: 0.9095 - val_loss: 0.2545 - val_acc: 0.9235\n",
            "Epoch 337/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2901 - acc: 0.9064 - val_loss: 0.2605 - val_acc: 0.9265\n",
            "Epoch 338/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2889 - acc: 0.9049 - val_loss: 0.2565 - val_acc: 0.9245\n",
            "Epoch 339/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2728 - acc: 0.9128 - val_loss: 0.2515 - val_acc: 0.9280\n",
            "Epoch 340/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2806 - acc: 0.9110 - val_loss: 0.2650 - val_acc: 0.9200\n",
            "Epoch 341/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2891 - acc: 0.9064 - val_loss: 0.2533 - val_acc: 0.9255\n",
            "Epoch 342/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2849 - acc: 0.9105 - val_loss: 0.2681 - val_acc: 0.9225\n",
            "Epoch 343/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2852 - acc: 0.9065 - val_loss: 0.2385 - val_acc: 0.9305\n",
            "Epoch 344/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2764 - acc: 0.9091 - val_loss: 0.2706 - val_acc: 0.9210\n",
            "Epoch 345/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2808 - acc: 0.9128 - val_loss: 0.2651 - val_acc: 0.9210\n",
            "Epoch 346/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2912 - acc: 0.9074 - val_loss: 0.2867 - val_acc: 0.9095\n",
            "Epoch 347/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2817 - acc: 0.9116 - val_loss: 0.2527 - val_acc: 0.9280\n",
            "Epoch 348/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2787 - acc: 0.9096 - val_loss: 0.2527 - val_acc: 0.9275\n",
            "Epoch 349/500\n",
            "8000/8000 [==============================] - 0s 27us/sample - loss: 0.2844 - acc: 0.9104 - val_loss: 0.2643 - val_acc: 0.9210\n",
            "Epoch 350/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.2839 - acc: 0.9074 - val_loss: 0.2461 - val_acc: 0.9290\n",
            "Epoch 351/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2796 - acc: 0.9114 - val_loss: 0.2495 - val_acc: 0.9260\n",
            "Epoch 352/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2796 - acc: 0.9079 - val_loss: 0.2513 - val_acc: 0.9225\n",
            "Epoch 353/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2787 - acc: 0.9130 - val_loss: 0.2569 - val_acc: 0.9235\n",
            "Epoch 354/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2707 - acc: 0.9136 - val_loss: 0.2563 - val_acc: 0.9280\n",
            "Epoch 355/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2747 - acc: 0.9118 - val_loss: 0.2465 - val_acc: 0.9295\n",
            "Epoch 356/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2776 - acc: 0.9090 - val_loss: 0.2607 - val_acc: 0.9210\n",
            "Epoch 357/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2807 - acc: 0.9105 - val_loss: 0.2622 - val_acc: 0.9225\n",
            "Epoch 358/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2852 - acc: 0.9118 - val_loss: 0.2516 - val_acc: 0.9270\n",
            "Epoch 359/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2783 - acc: 0.9119 - val_loss: 0.2630 - val_acc: 0.9230\n",
            "Epoch 360/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2847 - acc: 0.9085 - val_loss: 0.2639 - val_acc: 0.9245\n",
            "Epoch 361/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2815 - acc: 0.9071 - val_loss: 0.2480 - val_acc: 0.9290\n",
            "Epoch 362/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2855 - acc: 0.9090 - val_loss: 0.2558 - val_acc: 0.9265\n",
            "Epoch 363/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2792 - acc: 0.9082 - val_loss: 0.2570 - val_acc: 0.9230\n",
            "Epoch 364/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2712 - acc: 0.9112 - val_loss: 0.2556 - val_acc: 0.9260\n",
            "Epoch 365/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2835 - acc: 0.9114 - val_loss: 0.2433 - val_acc: 0.9300\n",
            "Epoch 366/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2788 - acc: 0.9104 - val_loss: 0.2450 - val_acc: 0.9290\n",
            "Epoch 367/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.2702 - acc: 0.9131 - val_loss: 0.2575 - val_acc: 0.9250\n",
            "Epoch 368/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2794 - acc: 0.9094 - val_loss: 0.2398 - val_acc: 0.9310\n",
            "Epoch 369/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2899 - acc: 0.9071 - val_loss: 0.2483 - val_acc: 0.9305\n",
            "Epoch 370/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2721 - acc: 0.9128 - val_loss: 0.2431 - val_acc: 0.9305\n",
            "Epoch 371/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2796 - acc: 0.9080 - val_loss: 0.2637 - val_acc: 0.9240\n",
            "Epoch 372/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2768 - acc: 0.9116 - val_loss: 0.2787 - val_acc: 0.9155\n",
            "Epoch 373/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2821 - acc: 0.9068 - val_loss: 0.2713 - val_acc: 0.9170\n",
            "Epoch 374/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2861 - acc: 0.9062 - val_loss: 0.2451 - val_acc: 0.9275\n",
            "Epoch 375/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2766 - acc: 0.9095 - val_loss: 0.2613 - val_acc: 0.9230\n",
            "Epoch 376/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2810 - acc: 0.9116 - val_loss: 0.2626 - val_acc: 0.9265\n",
            "Epoch 377/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2696 - acc: 0.9144 - val_loss: 0.2573 - val_acc: 0.9265\n",
            "Epoch 378/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2801 - acc: 0.9081 - val_loss: 0.2445 - val_acc: 0.9310\n",
            "Epoch 379/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2804 - acc: 0.9114 - val_loss: 0.2500 - val_acc: 0.9265\n",
            "Epoch 380/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2773 - acc: 0.9125 - val_loss: 0.2434 - val_acc: 0.9315\n",
            "Epoch 381/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2746 - acc: 0.9118 - val_loss: 0.2625 - val_acc: 0.9225\n",
            "Epoch 382/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2790 - acc: 0.9086 - val_loss: 0.2577 - val_acc: 0.9260\n",
            "Epoch 383/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2856 - acc: 0.9087 - val_loss: 0.2735 - val_acc: 0.9175\n",
            "Epoch 384/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2699 - acc: 0.9143 - val_loss: 0.2592 - val_acc: 0.9245\n",
            "Epoch 385/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2881 - acc: 0.9078 - val_loss: 0.2534 - val_acc: 0.9270\n",
            "Epoch 386/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2808 - acc: 0.9104 - val_loss: 0.2548 - val_acc: 0.9250\n",
            "Epoch 387/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2781 - acc: 0.9078 - val_loss: 0.2342 - val_acc: 0.9360\n",
            "Epoch 388/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2759 - acc: 0.9134 - val_loss: 0.2699 - val_acc: 0.9240\n",
            "Epoch 389/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2818 - acc: 0.9099 - val_loss: 0.2554 - val_acc: 0.9230\n",
            "Epoch 390/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2848 - acc: 0.9095 - val_loss: 0.2728 - val_acc: 0.9210\n",
            "Epoch 391/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2843 - acc: 0.9091 - val_loss: 0.2761 - val_acc: 0.9155\n",
            "Epoch 392/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2804 - acc: 0.9134 - val_loss: 0.2564 - val_acc: 0.9250\n",
            "Epoch 393/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2797 - acc: 0.9122 - val_loss: 0.2493 - val_acc: 0.9240\n",
            "Epoch 394/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2839 - acc: 0.9097 - val_loss: 0.2639 - val_acc: 0.9190\n",
            "Epoch 395/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.2766 - acc: 0.9096 - val_loss: 0.2723 - val_acc: 0.9205\n",
            "Epoch 396/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2832 - acc: 0.9111 - val_loss: 0.2593 - val_acc: 0.9245\n",
            "Epoch 397/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2860 - acc: 0.9101 - val_loss: 0.2564 - val_acc: 0.9240\n",
            "Epoch 398/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2881 - acc: 0.9072 - val_loss: 0.2565 - val_acc: 0.9265\n",
            "Epoch 399/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2793 - acc: 0.9105 - val_loss: 0.2521 - val_acc: 0.9270\n",
            "Epoch 400/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2790 - acc: 0.9120 - val_loss: 0.2503 - val_acc: 0.9285\n",
            "Epoch 401/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2808 - acc: 0.9050 - val_loss: 0.2580 - val_acc: 0.9275\n",
            "Epoch 402/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2819 - acc: 0.9082 - val_loss: 0.2604 - val_acc: 0.9235\n",
            "Epoch 403/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2876 - acc: 0.9112 - val_loss: 0.2470 - val_acc: 0.9305\n",
            "Epoch 404/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2728 - acc: 0.9120 - val_loss: 0.2537 - val_acc: 0.9280\n",
            "Epoch 405/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2753 - acc: 0.9086 - val_loss: 0.2495 - val_acc: 0.9290\n",
            "Epoch 406/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2714 - acc: 0.9103 - val_loss: 0.2442 - val_acc: 0.9300\n",
            "Epoch 407/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2763 - acc: 0.9087 - val_loss: 0.2545 - val_acc: 0.9275\n",
            "Epoch 408/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2711 - acc: 0.9135 - val_loss: 0.2624 - val_acc: 0.9245\n",
            "Epoch 409/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2801 - acc: 0.9082 - val_loss: 0.2606 - val_acc: 0.9255\n",
            "Epoch 410/500\n",
            "8000/8000 [==============================] - 0s 30us/sample - loss: 0.2803 - acc: 0.9131 - val_loss: 0.2654 - val_acc: 0.9210\n",
            "Epoch 411/500\n",
            "8000/8000 [==============================] - 0s 28us/sample - loss: 0.2780 - acc: 0.9129 - val_loss: 0.2541 - val_acc: 0.9260\n",
            "Epoch 412/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2830 - acc: 0.9110 - val_loss: 0.2600 - val_acc: 0.9230\n",
            "Epoch 413/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2833 - acc: 0.9101 - val_loss: 0.2611 - val_acc: 0.9265\n",
            "Epoch 414/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2779 - acc: 0.9106 - val_loss: 0.2596 - val_acc: 0.9230\n",
            "Epoch 415/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2774 - acc: 0.9087 - val_loss: 0.2556 - val_acc: 0.9255\n",
            "Epoch 416/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2834 - acc: 0.9080 - val_loss: 0.2644 - val_acc: 0.9235\n",
            "Epoch 417/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2771 - acc: 0.9109 - val_loss: 0.2463 - val_acc: 0.9280\n",
            "Epoch 418/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2818 - acc: 0.9081 - val_loss: 0.2727 - val_acc: 0.9190\n",
            "Epoch 419/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2823 - acc: 0.9076 - val_loss: 0.2509 - val_acc: 0.9295\n",
            "Epoch 420/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2738 - acc: 0.9133 - val_loss: 0.2474 - val_acc: 0.9290\n",
            "Epoch 421/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2823 - acc: 0.9106 - val_loss: 0.2549 - val_acc: 0.9260\n",
            "Epoch 422/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2836 - acc: 0.9111 - val_loss: 0.2457 - val_acc: 0.9280\n",
            "Epoch 423/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2774 - acc: 0.9107 - val_loss: 0.2368 - val_acc: 0.9310\n",
            "Epoch 424/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2778 - acc: 0.9161 - val_loss: 0.2718 - val_acc: 0.9210\n",
            "Epoch 425/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2786 - acc: 0.9122 - val_loss: 0.2607 - val_acc: 0.9235\n",
            "Epoch 426/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2781 - acc: 0.9097 - val_loss: 0.2621 - val_acc: 0.9230\n",
            "Epoch 427/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2733 - acc: 0.9107 - val_loss: 0.2651 - val_acc: 0.9240\n",
            "Epoch 428/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2732 - acc: 0.9129 - val_loss: 0.2477 - val_acc: 0.9285\n",
            "Epoch 429/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2771 - acc: 0.9120 - val_loss: 0.2461 - val_acc: 0.9285\n",
            "Epoch 430/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2754 - acc: 0.9128 - val_loss: 0.2417 - val_acc: 0.9330\n",
            "Epoch 431/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2766 - acc: 0.9112 - val_loss: 0.2597 - val_acc: 0.9255\n",
            "Epoch 432/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2850 - acc: 0.9094 - val_loss: 0.2578 - val_acc: 0.9235\n",
            "Epoch 433/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2803 - acc: 0.9090 - val_loss: 0.2803 - val_acc: 0.9185\n",
            "Epoch 434/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2749 - acc: 0.9099 - val_loss: 0.2611 - val_acc: 0.9250\n",
            "Epoch 435/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2803 - acc: 0.9114 - val_loss: 0.2642 - val_acc: 0.9235\n",
            "Epoch 436/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2706 - acc: 0.9145 - val_loss: 0.2539 - val_acc: 0.9280\n",
            "Epoch 437/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2747 - acc: 0.9121 - val_loss: 0.2558 - val_acc: 0.9270\n",
            "Epoch 438/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2759 - acc: 0.9128 - val_loss: 0.2568 - val_acc: 0.9240\n",
            "Epoch 439/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2741 - acc: 0.9129 - val_loss: 0.2630 - val_acc: 0.9210\n",
            "Epoch 440/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2780 - acc: 0.9140 - val_loss: 0.2631 - val_acc: 0.9220\n",
            "Epoch 441/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2782 - acc: 0.9121 - val_loss: 0.2617 - val_acc: 0.9215\n",
            "Epoch 442/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2823 - acc: 0.9106 - val_loss: 0.2678 - val_acc: 0.9180\n",
            "Epoch 443/500\n",
            "8000/8000 [==============================] - 0s 25us/sample - loss: 0.2821 - acc: 0.9079 - val_loss: 0.2828 - val_acc: 0.9135\n",
            "Epoch 444/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2758 - acc: 0.9089 - val_loss: 0.2759 - val_acc: 0.9160\n",
            "Epoch 445/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2758 - acc: 0.9099 - val_loss: 0.2750 - val_acc: 0.9195\n",
            "Epoch 446/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2740 - acc: 0.9107 - val_loss: 0.2425 - val_acc: 0.9320\n",
            "Epoch 447/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2782 - acc: 0.9099 - val_loss: 0.2750 - val_acc: 0.9200\n",
            "Epoch 448/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2831 - acc: 0.9115 - val_loss: 0.2713 - val_acc: 0.9215\n",
            "Epoch 449/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2767 - acc: 0.9143 - val_loss: 0.2672 - val_acc: 0.9235\n",
            "Epoch 450/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2704 - acc: 0.9159 - val_loss: 0.2832 - val_acc: 0.9125\n",
            "Epoch 451/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2798 - acc: 0.9114 - val_loss: 0.2494 - val_acc: 0.9280\n",
            "Epoch 452/500\n",
            "8000/8000 [==============================] - 0s 26us/sample - loss: 0.2773 - acc: 0.9111 - val_loss: 0.2612 - val_acc: 0.9240\n",
            "Epoch 453/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2710 - acc: 0.9126 - val_loss: 0.2797 - val_acc: 0.9170\n",
            "Epoch 454/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2736 - acc: 0.9178 - val_loss: 0.2683 - val_acc: 0.9225\n",
            "Epoch 455/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2739 - acc: 0.9125 - val_loss: 0.2448 - val_acc: 0.9325\n",
            "Epoch 456/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2775 - acc: 0.9141 - val_loss: 0.2600 - val_acc: 0.9260\n",
            "Epoch 457/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2794 - acc: 0.9093 - val_loss: 0.2586 - val_acc: 0.9240\n",
            "Epoch 458/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2717 - acc: 0.9126 - val_loss: 0.2592 - val_acc: 0.9255\n",
            "Epoch 459/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2758 - acc: 0.9106 - val_loss: 0.2571 - val_acc: 0.9250\n",
            "Epoch 460/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2738 - acc: 0.9135 - val_loss: 0.2791 - val_acc: 0.9195\n",
            "Epoch 461/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2744 - acc: 0.9126 - val_loss: 0.2667 - val_acc: 0.9230\n",
            "Epoch 462/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2690 - acc: 0.9144 - val_loss: 0.2807 - val_acc: 0.9160\n",
            "Epoch 463/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2823 - acc: 0.9072 - val_loss: 0.2629 - val_acc: 0.9225\n",
            "Epoch 464/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2848 - acc: 0.9065 - val_loss: 0.2669 - val_acc: 0.9190\n",
            "Epoch 465/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2771 - acc: 0.9114 - val_loss: 0.2371 - val_acc: 0.9325\n",
            "Epoch 466/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2776 - acc: 0.9111 - val_loss: 0.2608 - val_acc: 0.9235\n",
            "Epoch 467/500\n",
            "8000/8000 [==============================] - 0s 19us/sample - loss: 0.2774 - acc: 0.9103 - val_loss: 0.2602 - val_acc: 0.9245\n",
            "Epoch 468/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2805 - acc: 0.9126 - val_loss: 0.2641 - val_acc: 0.9250\n",
            "Epoch 469/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2752 - acc: 0.9134 - val_loss: 0.2683 - val_acc: 0.9230\n",
            "Epoch 470/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2718 - acc: 0.9166 - val_loss: 0.2527 - val_acc: 0.9265\n",
            "Epoch 471/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2832 - acc: 0.9075 - val_loss: 0.2398 - val_acc: 0.9330\n",
            "Epoch 472/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2810 - acc: 0.9135 - val_loss: 0.2659 - val_acc: 0.9220\n",
            "Epoch 473/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2847 - acc: 0.9090 - val_loss: 0.2582 - val_acc: 0.9235\n",
            "Epoch 474/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2808 - acc: 0.9119 - val_loss: 0.2491 - val_acc: 0.9305\n",
            "Epoch 475/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2840 - acc: 0.9095 - val_loss: 0.2625 - val_acc: 0.9215\n",
            "Epoch 476/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2742 - acc: 0.9116 - val_loss: 0.2672 - val_acc: 0.9205\n",
            "Epoch 477/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2754 - acc: 0.9129 - val_loss: 0.2556 - val_acc: 0.9270\n",
            "Epoch 478/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2792 - acc: 0.9107 - val_loss: 0.2499 - val_acc: 0.9285\n",
            "Epoch 479/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2849 - acc: 0.9120 - val_loss: 0.2876 - val_acc: 0.9140\n",
            "Epoch 480/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2733 - acc: 0.9139 - val_loss: 0.2551 - val_acc: 0.9270\n",
            "Epoch 481/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2833 - acc: 0.9110 - val_loss: 0.2484 - val_acc: 0.9300\n",
            "Epoch 482/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2876 - acc: 0.9112 - val_loss: 0.2425 - val_acc: 0.9330\n",
            "Epoch 483/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2708 - acc: 0.9129 - val_loss: 0.2574 - val_acc: 0.9260\n",
            "Epoch 484/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2777 - acc: 0.9118 - val_loss: 0.2875 - val_acc: 0.9110\n",
            "Epoch 485/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2767 - acc: 0.9105 - val_loss: 0.2609 - val_acc: 0.9255\n",
            "Epoch 486/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2857 - acc: 0.9106 - val_loss: 0.2498 - val_acc: 0.9285\n",
            "Epoch 487/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2805 - acc: 0.9095 - val_loss: 0.2587 - val_acc: 0.9250\n",
            "Epoch 488/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2730 - acc: 0.9135 - val_loss: 0.2499 - val_acc: 0.9280\n",
            "Epoch 489/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2676 - acc: 0.9130 - val_loss: 0.2478 - val_acc: 0.9300\n",
            "Epoch 490/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2667 - acc: 0.9158 - val_loss: 0.2671 - val_acc: 0.9230\n",
            "Epoch 491/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2746 - acc: 0.9090 - val_loss: 0.2540 - val_acc: 0.9265\n",
            "Epoch 492/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2778 - acc: 0.9104 - val_loss: 0.2454 - val_acc: 0.9300\n",
            "Epoch 493/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2849 - acc: 0.9056 - val_loss: 0.2418 - val_acc: 0.9325\n",
            "Epoch 494/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2693 - acc: 0.9143 - val_loss: 0.2413 - val_acc: 0.9335\n",
            "Epoch 495/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2755 - acc: 0.9110 - val_loss: 0.2343 - val_acc: 0.9350\n",
            "Epoch 496/500\n",
            "8000/8000 [==============================] - 0s 23us/sample - loss: 0.2784 - acc: 0.9129 - val_loss: 0.2576 - val_acc: 0.9275\n",
            "Epoch 497/500\n",
            "8000/8000 [==============================] - 0s 24us/sample - loss: 0.2771 - acc: 0.9103 - val_loss: 0.2606 - val_acc: 0.9245\n",
            "Epoch 498/500\n",
            "8000/8000 [==============================] - 0s 21us/sample - loss: 0.2728 - acc: 0.9147 - val_loss: 0.2559 - val_acc: 0.9290\n",
            "Epoch 499/500\n",
            "8000/8000 [==============================] - 0s 20us/sample - loss: 0.2804 - acc: 0.9082 - val_loss: 0.2548 - val_acc: 0.9265\n",
            "Epoch 500/500\n",
            "8000/8000 [==============================] - 0s 22us/sample - loss: 0.2882 - acc: 0.9080 - val_loss: 0.2649 - val_acc: 0.9240\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCDNuEdu273E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_predictions5 = model5.predict(XT2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n80xzXLD3rEy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model6 = tf.keras.models.Sequential()\n",
        "model6.add(tf.keras.layers.Dense(64 , input_shape = (10,)))\n",
        "model6.add(tf.keras.layers.Dense(32 , activation = 'relu'))\n",
        "model6.add(tf.keras.layers.Dropout(0.4))\n",
        "model6.add(tf.keras.layers.Dense(16 , activation = 'relu'))\n",
        "model6.add(tf.keras.layers.Dense(24 ,activation = 'relu'))\n",
        "model6.add(tf.keras.layers.Dropout(0.4))\n",
        "model6.add(tf.keras.layers.Dense(12 , activation = 'relu'))\n",
        "model6.add(tf.keras.layers.Dense(4 , activation  ='softmax'))\n",
        "model6.compile(optimizer = 'adagrad',  loss='categorical_crossentropy' , metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYiRlYT45vgW",
        "colab_type": "code",
        "outputId": "a23a6d1f-09bd-4716-81ae-b4638aab6800",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        }
      },
      "source": [
        "history6 = model6.fit(X_train , y_train , batch_size = 100 , epochs = 5000 , validation_data = [X_test, y_test], shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8000 samples, validate on 2000 samples\n",
            "Epoch 1/5000\n",
            "8000/8000 [==============================] - 0s 33us/sample - loss: 0.4288 - acc: 0.8606 - val_loss: 0.2797 - val_acc: 0.9205\n",
            "Epoch 2/5000\n",
            "8000/8000 [==============================] - 0s 37us/sample - loss: 0.4340 - acc: 0.8547 - val_loss: 0.2797 - val_acc: 0.9205\n",
            "Epoch 3/5000\n",
            "8000/8000 [==============================] - 0s 38us/sample - loss: 0.4291 - acc: 0.8593 - val_loss: 0.2796 - val_acc: 0.9205\n",
            "Epoch 4/5000\n",
            "8000/8000 [==============================] - 0s 40us/sample - loss: 0.4331 - acc: 0.8553 - val_loss: 0.2796 - val_acc: 0.9205\n",
            "Epoch 5/5000\n",
            "8000/8000 [==============================] - 0s 37us/sample - loss: 0.4251 - acc: 0.8584 - val_loss: 0.2796 - val_acc: 0.9205\n",
            "Epoch 6/5000\n",
            "8000/8000 [==============================] - 0s 39us/sample - loss: 0.4292 - acc: 0.8551 - val_loss: 0.2796 - val_acc: 0.9210\n",
            "Epoch 7/5000\n",
            "8000/8000 [==============================] - 0s 40us/sample - loss: 0.4298 - acc: 0.8556 - val_loss: 0.2795 - val_acc: 0.9210\n",
            "Epoch 8/5000\n",
            "8000/8000 [==============================] - 0s 34us/sample - loss: 0.4256 - acc: 0.8604 - val_loss: 0.2794 - val_acc: 0.9205\n",
            "Epoch 9/5000\n",
            "8000/8000 [==============================] - 0s 38us/sample - loss: 0.4231 - acc: 0.8636 - val_loss: 0.2792 - val_acc: 0.9205\n",
            "Epoch 10/5000\n",
            "8000/8000 [==============================] - 0s 35us/sample - loss: 0.4282 - acc: 0.8581 - val_loss: 0.2792 - val_acc: 0.9205\n",
            "Epoch 11/5000\n",
            "8000/8000 [==============================] - 0s 38us/sample - loss: 0.4227 - acc: 0.8597 - val_loss: 0.2792 - val_acc: 0.9205\n",
            "Epoch 12/5000\n",
            "8000/8000 [==============================] - 0s 37us/sample - loss: 0.4269 - acc: 0.8610 - val_loss: 0.2792 - val_acc: 0.9205\n",
            "Epoch 13/5000\n",
            "8000/8000 [==============================] - 0s 36us/sample - loss: 0.4348 - acc: 0.8551 - val_loss: 0.2791 - val_acc: 0.9205\n",
            "Epoch 14/5000\n",
            "8000/8000 [==============================] - 0s 35us/sample - loss: 0.4417 - acc: 0.8499 - val_loss: 0.2792 - val_acc: 0.9205\n",
            "Epoch 15/5000\n",
            "8000/8000 [==============================] - 0s 35us/sample - loss: 0.4246 - acc: 0.8610 - val_loss: 0.2791 - val_acc: 0.9205\n",
            "Epoch 16/5000\n",
            "8000/8000 [==============================] - 0s 37us/sample - loss: 0.4284 - acc: 0.8583 - val_loss: 0.2790 - val_acc: 0.9205\n",
            "Epoch 17/5000\n",
            "8000/8000 [==============================] - 0s 35us/sample - loss: 0.4411 - acc: 0.8551 - val_loss: 0.2790 - val_acc: 0.9205\n",
            "Epoch 18/5000\n",
            "8000/8000 [==============================] - 0s 36us/sample - loss: 0.4339 - acc: 0.8550 - val_loss: 0.2789 - val_acc: 0.9210\n",
            "Epoch 19/5000\n",
            "8000/8000 [==============================] - 0s 37us/sample - loss: 0.4220 - acc: 0.8593 - val_loss: 0.2787 - val_acc: 0.9210\n",
            "Epoch 20/5000\n",
            "8000/8000 [==============================] - 0s 35us/sample - loss: 0.4305 - acc: 0.8541 - val_loss: 0.2787 - val_acc: 0.9210\n",
            "Epoch 21/5000\n",
            "8000/8000 [==============================] - 0s 33us/sample - loss: 0.4209 - acc: 0.8593 - val_loss: 0.2786 - val_acc: 0.9205\n",
            "Epoch 22/5000\n",
            "8000/8000 [==============================] - 0s 32us/sample - loss: 0.4261 - acc: 0.8599 - val_loss: 0.2785 - val_acc: 0.9205\n",
            "Epoch 23/5000\n",
            "8000/8000 [==============================] - 0s 33us/sample - loss: 0.4379 - acc: 0.8521 - val_loss: 0.2784 - val_acc: 0.9200\n",
            "Epoch 24/5000\n",
            "8000/8000 [==============================] - 0s 41us/sample - loss: 0.4239 - acc: 0.8571 - val_loss: 0.2784 - val_acc: 0.9210\n",
            "Epoch 25/5000\n",
            "8000/8000 [==============================] - 0s 37us/sample - loss: 0.4282 - acc: 0.8611 - val_loss: 0.2782 - val_acc: 0.9210\n",
            "Epoch 26/5000\n",
            "8000/8000 [==============================] - 0s 33us/sample - loss: 0.4268 - acc: 0.8594 - val_loss: 0.2781 - val_acc: 0.9210\n",
            "Epoch 27/5000\n",
            "8000/8000 [==============================] - 0s 34us/sample - loss: 0.4152 - acc: 0.8655 - val_loss: 0.2780 - val_acc: 0.9205\n",
            "Epoch 28/5000\n",
            "7900/8000 [============================>.] - ETA: 0s - loss: 0.4275 - acc: 0.8619"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bkia1pks5-gr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_predictions6 = model6.predict(XT2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VryZA4_6EOY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ensemble_preds = [np.argmax((test_predictions2[i] + test_predictions3[i] + test_predictions4[i]+test_predictions5[i] + test_predictions6[i])/5) for i in range(XT2.shape[0])]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYWw9hZP6fC8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "answer_column = [index_dict[i] for i in ensemble_preds]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWpa8JXe6lNn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d = {'Accident_ID' : acc_ids , 'Severity' : answer_column}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMMAiGxA6rlW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission_df = pd.DataFrame(d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ws0XwEtC6wB1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission_df =submission_df.set_index(['Accident_ID'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Js0Mu0QT7D_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission_df.to_csv('ensemble_predictions2.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIy0vbnI7KCy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}